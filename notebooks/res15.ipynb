{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import hashlib\n",
    "\n",
    "from enum import Enum\n",
    "from collections import ChainMap\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import librosa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Utils #\n",
    "#########\n",
    "\n",
    "class SimpleCache(dict):\n",
    "    def __init__(self, limit):\n",
    "        super().__init__()\n",
    "        self.limit = limit\n",
    "        self.n_keys = 0\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        if key in self.keys():\n",
    "            super().__setitem__(key, value)\n",
    "        elif self.n_keys < self.limit:\n",
    "            self.n_keys += 1\n",
    "            super().__setitem__(key, value)\n",
    "        return value\n",
    "\n",
    "class SerializableModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def save(self, filename):\n",
    "        torch.save(self.state_dict(), filename)\n",
    "\n",
    "    def load(self, filename):\n",
    "        self.load_state_dict(torch.load(filename, map_location=lambda storage, loc: storage))\n",
    "\n",
    "def play_wav(wav_path):\n",
    "    sample_rate, samples = wavfile.read(wav_path)\n",
    "    return ipd.Audio(samples, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetType(Enum):\n",
    "    TRAIN = 0\n",
    "    DEV = 1\n",
    "    TEST = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful PyTorch abstraction\n",
    "class SpeechDataset(data.Dataset):\n",
    "    def __init__(self, data, set_type, config):\n",
    "        ####\n",
    "        # data – {wave_file_path : label}\n",
    "        # set_type – DatasetType (dev, train or test)\n",
    "        # config.bg_noise_files – will be used to noise wavs during training (see preprocess func)\n",
    "        ####\n",
    "        super().__init__()\n",
    "        self.audio_files = list(data.keys())\n",
    "        self.audio_labels = list(data.values())\n",
    "        self.set_type = set_type\n",
    "        config[\"bg_noise_files\"] = list(filter(lambda x: x.endswith(\"wav\"), config.get(\"bg_noise_files\", [])))\n",
    "        self.bg_noise_audio = [librosa.core.load(file, sr=16000)[0] for file in config[\"bg_noise_files\"]]\n",
    "        self.unknown_prob = config[\"unknown_prob\"]\n",
    "        self.silence_prob = config[\"silence_prob\"]\n",
    "        self.noise_prob = config[\"noise_prob\"]\n",
    "        self.n_dct = config[\"n_dct_filters\"]\n",
    "        self.n_mels = config[\"n_mels\"]\n",
    "        self.input_length = config[\"input_length\"]\n",
    "        self.timeshift_ms = config[\"timeshift_ms\"]\n",
    "        self.filters = librosa.filters.dct(config[\"n_dct_filters\"], config[\"n_mels\"])\n",
    "        self._audio_cache = SimpleCache(config[\"cache_size\"])\n",
    "        self._file_cache = SimpleCache(config[\"cache_size\"])\n",
    "        n_unk = len(list(filter(lambda x: x == 1, self.audio_labels)))\n",
    "        self.n_silence = int(self.silence_prob * (len(self.audio_labels) - n_unk))\n",
    "    \n",
    "    # PyTorch needs this function\n",
    "    def __getitem__(self, index):\n",
    "        if index >= len(self.audio_labels):\n",
    "            return self.preprocess(None, silence=True), 0\n",
    "        return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
    "\n",
    "    # PyTorch needs this function\n",
    "    def __len__(self):\n",
    "        return len(self.audio_labels) + self.n_silence\n",
    "\n",
    "    # Our extra functions go below:\n",
    "    def _timeshift_audio(self, data):\n",
    "        shift = (16000 * self.timeshift_ms) // 1000\n",
    "        shift = random.randint(-shift, shift)\n",
    "        a = -min(0, shift)\n",
    "        b = max(0, shift)\n",
    "        data = np.pad(data, (a, b), \"constant\")\n",
    "        return data[:len(data) - a] if a else data[b:]\n",
    "    \n",
    "    def _preprocess_audio(self, data, n_mels, dct_filters):\n",
    "        data = librosa.feature.melspectrogram(\n",
    "            data, \n",
    "            sr=16000, \n",
    "            n_mels=n_mels, \n",
    "            hop_length=160, \n",
    "            n_fft=480, \n",
    "            fmin=20, \n",
    "            fmax=4000\n",
    "        )\n",
    "        data[data > 0] = np.log(data[data > 0])\n",
    "        data = [np.matmul(dct_filters, x) for x in np.split(data, data.shape[1], axis=1)]\n",
    "        data = np.array(data, order=\"F\").squeeze(2).astype(np.float32)\n",
    "        return data\n",
    "\n",
    "    def preprocess(self, example, silence=False):\n",
    "        if silence:\n",
    "            example = \"__silence__\"\n",
    "        if random.random() < 0.7:\n",
    "            try:\n",
    "                return self._audio_cache[example]\n",
    "            except KeyError:\n",
    "                pass\n",
    "        \n",
    "        in_len = self.input_length\n",
    "        if self.bg_noise_audio:\n",
    "            # take a random samples chunk of a random noise audio\n",
    "            bg_noise = random.choice(self.bg_noise_audio)\n",
    "            a = random.randint(0, len(bg_noise) - in_len - 1)\n",
    "            bg_noise = bg_noise[a:a + in_len]\n",
    "        else:\n",
    "            bg_noise = np.zeros(in_len)\n",
    "        \n",
    "        use_clean = (self.set_type != DatasetType.TRAIN)\n",
    "        if use_clean:\n",
    "            bg_noise = np.zeros(in_len)\n",
    "        if silence:\n",
    "            data = np.zeros(in_len, dtype=np.float32)\n",
    "        else:\n",
    "            file_data = self._file_cache.get(example)\n",
    "            data = librosa.core.load(example, sr=16000)[0] if file_data is None else file_data\n",
    "            self._file_cache[example] = data\n",
    "        data = np.pad(data, (0, max(0, in_len - len(data))), \"constant\")\n",
    "        if not use_clean:\n",
    "            data = self._timeshift_audio(data)\n",
    "\n",
    "        if random.random() < self.noise_prob or silence:\n",
    "            a = random.random() * 0.1\n",
    "            data = np.clip(a * bg_noise + data, -1, 1)\n",
    "        data = torch.from_numpy(self._preprocess_audio(data, self.n_mels, self.filters))\n",
    "        self._audio_cache[example] = data\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    data_folder=\"./../raw_data/train/audio\",\n",
    "    wanted_words=\"yes no up down left right on off stop go\".split(),\n",
    "    \n",
    "    seed=0,\n",
    "    \n",
    "    output_file=\"./../models/model.pt\", \n",
    "    gpu_no=0,\n",
    "    cache_size=32768,\n",
    "    \n",
    "    n_epochs=26,\n",
    "    momentum=0.9, \n",
    "    weight_decay=0.00001,\n",
    "    lr=[0.1, 0.01, 0.001], \n",
    "    schedule=[3000, 6000], \n",
    "    batch_size=64, \n",
    "    dev_every=1,\n",
    "    use_nesterov=False,\n",
    "    \n",
    "    group_speakers_by_id=True,\n",
    "    \n",
    "    silence_prob=0.1,\n",
    "    noise_prob=0.8,\n",
    "    unknown_prob=0.1, # percentage of unknown waves in the train/dev/test dataset\n",
    "    \n",
    "    input_length=16000,\n",
    "    timeshift_ms=100,\n",
    "    # Below are two parameters of Discrete Cosine Transform (http://en.wikipedia.org/wiki/Discrete_cosine_transform)\n",
    "    n_dct_filters=40, \n",
    "    n_mels=40,\n",
    "    \n",
    "    train_pct=80,\n",
    "    dev_pct=10,\n",
    "    test_pct=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = config[\"seed\"]\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = config[\"data_folder\"]\n",
    "wanted_words = config[\"wanted_words\"]\n",
    "unknown_prob = config[\"unknown_prob\"]\n",
    "train_pct = config[\"train_pct\"]\n",
    "dev_pct = config[\"dev_pct\"]\n",
    "test_pct = config[\"test_pct\"]\n",
    "\n",
    "LABEL_UNKNOWN = \"__unknown__\"\n",
    "LABEL_SILENCE = \"__silence__\"\n",
    "\n",
    "words = {word: i + 2 for i, word in enumerate(wanted_words)}\n",
    "words.update({LABEL_SILENCE:0, LABEL_UNKNOWN:1})\n",
    "sets = [{}, {}, {}]  # [train, dev, test] => {wav_name: label}\n",
    "unknowns = [0] * 3 # number of wavs for each dataset to take from collected unknown waves according to unknown_prob\n",
    "bg_noise_files = []\n",
    "unknown_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__silence__': 0,\n",
       " '__unknown__': 1,\n",
       " 'down': 5,\n",
       " 'go': 11,\n",
       " 'left': 6,\n",
       " 'no': 3,\n",
       " 'off': 9,\n",
       " 'on': 8,\n",
       " 'right': 7,\n",
       " 'stop': 10,\n",
       " 'up': 4,\n",
       " 'yes': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prep datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process marvin\n",
      "Process wow\n",
      "Process down\n",
      "Process dog\n",
      "Process cat\n",
      "Process on\n",
      "Process yes\n",
      "Process left\n",
      "Process no\n",
      "Process five\n",
      "Process house\n",
      "Process eight\n",
      "Process _background_noise_\n",
      "Process nine\n",
      "Process stop\n",
      "Process two\n",
      "Process happy\n",
      "Process seven\n",
      "Process zero\n",
      "Process .DS_Store\n",
      "Process bird\n",
      "Process sheila\n",
      "Process go\n",
      "Process six\n",
      "Process off\n",
      "Process bed\n",
      "Process three\n",
      "Process tree\n",
      "Process up\n",
      "Process four\n",
      "Process one\n",
      "Process right\n",
      "Speech dataset created\n"
     ]
    }
   ],
   "source": [
    "max_no_wavs = 2**27 - 1\n",
    "\n",
    "for folder_name in os.listdir(folder):\n",
    "    print(\"Process \" + folder_name)\n",
    "    path_name = os.path.join(folder, folder_name)\n",
    "    is_bg_noise = False\n",
    "    \n",
    "    # Skip files\n",
    "    if os.path.isfile(path_name):\n",
    "        continue\n",
    "    \n",
    "    # Assign the label based on the current folder name\n",
    "    if folder_name in words:\n",
    "        label = words[folder_name]\n",
    "    elif folder_name == \"_background_noise_\":\n",
    "        is_bg_noise = True\n",
    "    else:\n",
    "        label = words[LABEL_UNKNOWN]\n",
    "\n",
    "    for filename in os.listdir(path_name):\n",
    "        wav_name = os.path.join(path_name, filename)\n",
    "        \n",
    "        # Just record background noises files and continue\n",
    "        if is_bg_noise and os.path.isfile(wav_name):\n",
    "            bg_noise_files.append(wav_name)\n",
    "            continue\n",
    "        # collect wav names when label is unknown\n",
    "        elif label == words[LABEL_UNKNOWN]:\n",
    "            unknown_files.append(wav_name)\n",
    "            continue\n",
    "        \n",
    "        # Fill sets with {wave_name : label}\n",
    "        if config[\"group_speakers_by_id\"]:\n",
    "            hashname = re.sub(r\"_nohash_.*$\", \"\", filename)\n",
    "            bucket = int(hashlib.sha1(hashname.encode()).hexdigest(), 16)\n",
    "            bucket = (bucket % (max_no_wavs + 1)) * (100. / max_no_wavs)\n",
    "            if bucket < dev_pct:\n",
    "                tag = DatasetType.DEV\n",
    "            elif bucket < test_pct + dev_pct:\n",
    "                tag = DatasetType.TEST\n",
    "            else:\n",
    "                tag = DatasetType.TRAIN\n",
    "            sets[tag.value][wav_name] = label\n",
    "        else:\n",
    "            raise NotImplementedError(\"Speakers should be grouped for now :/\")\n",
    "            \n",
    "# Mix in unknown wavs in datasets\n",
    "# 1: compute how many files should be mixed in each dataset according to unknown_prob\n",
    "for tag in range(len(sets)):\n",
    "    unknowns[tag] = int(unknown_prob * len(sets[tag]))\n",
    "\n",
    "# 2: shuffle unknown files\n",
    "random.shuffle(unknown_files)\n",
    "\n",
    "# 3: update datasets with unknown_files[a:b], where a:b is the interval\n",
    "a = 0\n",
    "for tag, dataset in enumerate(sets):\n",
    "    b = a + unknowns[tag]\n",
    "    unk_dict = {u: words[LABEL_UNKNOWN] for u in unknown_files[a:b]}\n",
    "    dataset.update(unk_dict)\n",
    "    a = b\n",
    "\n",
    "train_cfg = ChainMap(dict(bg_noise_files=bg_noise_files), config)\n",
    "test_cfg = ChainMap(dict(noise_prob=0), config)\n",
    "datasets = (\n",
    "    SpeechDataset(sets[0], DatasetType.TRAIN, train_cfg), \n",
    "    SpeechDataset(sets[1], DatasetType.DEV, test_cfg),\n",
    "    SpeechDataset(sets[2], DatasetType.TEST, test_cfg)\n",
    ")\n",
    "\n",
    "print(\"Speech dataset created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, dev_set, test_set = datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/1710.10361.pdf\n",
    "class SpeechResModel(SerializableModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        n_labels = config[\"n_labels\"]\n",
    "        n_maps = config[\"n_feature_maps\"]\n",
    "        self.conv0 = nn.Conv2d(1, n_maps, (3, 3), padding=(1, 1), bias=False)\n",
    "        if \"res_pool\" in config:\n",
    "            self.pool = nn.AvgPool2d(config[\"res_pool\"])\n",
    "\n",
    "        self.n_layers = n_layers = config[\"n_layers\"]\n",
    "        dilation = config[\"use_dilation\"]\n",
    "        if dilation:\n",
    "            self.convs = [nn.Conv2d(n_maps, n_maps, (3, 3), padding=int(2**(i // 3)), dilation=int(2**(i // 3)), \n",
    "                bias=False) for i in range(n_layers)]\n",
    "        else:\n",
    "            self.convs = [nn.Conv2d(n_maps, n_maps, (3, 3), padding=1, dilation=1, \n",
    "                bias=False) for _ in range(n_layers)]\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            self.add_module(\"bn{}\".format(i + 1), nn.BatchNorm2d(n_maps, affine=False))\n",
    "            self.add_module(\"conv{}\".format(i + 1), conv)\n",
    "        self.output = nn.Linear(n_maps, n_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        for i in range(self.n_layers + 1):\n",
    "            y = F.relu(getattr(self, \"conv{}\".format(i))(x))\n",
    "            if i == 0:\n",
    "                if hasattr(self, \"pool\"):\n",
    "                    y = self.pool(y)\n",
    "                old_x = y\n",
    "            if i > 0 and i % 2 == 0:\n",
    "                x = y + old_x\n",
    "                old_x = x\n",
    "            else:\n",
    "                x = y\n",
    "            if i > 0:\n",
    "                x = getattr(self, \"bn{}\".format(i))(x)\n",
    "        x = x.view(x.size(0), x.size(1), -1) # shape: (batch, feats, o3)\n",
    "        x = torch.mean(x, 2)\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpeechResModel(\n",
       "  (conv0): Conv2d (1, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
       "  (conv1): Conv2d (45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
       "  (conv2): Conv2d (45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
       "  (conv3): Conv2d (45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn4): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
       "  (conv4): Conv2d (45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  (bn5): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
       "  (conv5): Conv2d (45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  (bn6): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
       "  (conv6): Conv2d (45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  (bn7): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
       "  (conv7): Conv2d (45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "  (bn8): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
       "  (conv8): Conv2d (45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "  (bn9): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
       "  (conv9): Conv2d (45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "  (bn10): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
       "  (conv10): Conv2d (45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
       "  (bn11): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
       "  (conv11): Conv2d (45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
       "  (bn12): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
       "  (conv12): Conv2d (45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
       "  (bn13): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
       "  (conv13): Conv2d (45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
       "  (output): Linear(in_features=45, out_features=12)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res15 = dict(n_labels=12, use_dilation=True, n_layers=13, n_feature_maps=45)\n",
    "model = SpeechResModel(res15)\n",
    "\n",
    "torch.cuda.set_device(config[\"gpu_no\"])\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval(name, scores, labels, loss, end=\"\\n\"):\n",
    "    batch_size = labels.size(0)\n",
    "    accuracy = (torch.max(scores, 1)[1].view(batch_size).data == labels.data).sum() / batch_size\n",
    "    loss = loss.cpu().data.numpy()[0]\n",
    "    print(\"{} accuracy: {:>5}, loss: {:<25}\".format(name, accuracy, loss), end=end)\n",
    "    return accuracy\n",
    "\n",
    "def evaluate(config, model, test_loader):\n",
    "    torch.cuda.set_device(config[\"gpu_no\"])\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    results = []\n",
    "    total = 0\n",
    "    for model_in, labels in test_loader:\n",
    "        model_in = Variable(model_in, requires_grad=False)\n",
    "        \n",
    "        model_in = model_in.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        scores = model(model_in)\n",
    "        labels = Variable(labels, requires_grad=False)\n",
    "        loss = criterion(scores, labels)\n",
    "        results.append(print_eval(\"test\", scores, labels, loss) * model_in.size(0))\n",
    "        total += model_in.size(0)\n",
    "    print(\"final test accuracy: {}\".format(sum(results) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #1 accuracy: 0.078125, loss: 2.478188991546631        \n",
      "train step #2 accuracy: 0.09375, loss: 2.5016794204711914       \n",
      "train step #3 accuracy: 0.03125, loss: 2.4945156574249268       \n",
      "train step #4 accuracy: 0.03125, loss: 2.4963042736053467       \n",
      "train step #5 accuracy: 0.15625, loss: 2.475476026535034        \n",
      "train step #6 accuracy: 0.09375, loss: 2.4538135528564453       \n",
      "train step #7 accuracy: 0.078125, loss: 2.4516944885253906       \n",
      "train step #8 accuracy: 0.125, loss: 2.4377880096435547       \n",
      "train step #9 accuracy: 0.125, loss: 2.455156087875366        \n",
      "train step #10 accuracy: 0.234375, loss: 2.4315528869628906       \n",
      "train step #11 accuracy: 0.203125, loss: 2.424142599105835        \n",
      "train step #12 accuracy: 0.078125, loss: 2.423679828643799        \n",
      "train step #13 accuracy: 0.125, loss: 2.3908770084381104       \n",
      "train step #14 accuracy: 0.109375, loss: 2.348961114883423        \n",
      "train step #15 accuracy: 0.171875, loss: 2.3722429275512695       \n",
      "train step #16 accuracy: 0.203125, loss: 2.3087496757507324       \n",
      "train step #17 accuracy: 0.21875, loss: 2.3360390663146973       \n",
      "train step #18 accuracy: 0.234375, loss: 2.2258434295654297       \n",
      "train step #19 accuracy: 0.1875, loss: 2.3411548137664795       \n",
      "train step #20 accuracy: 0.125, loss: 2.363234281539917        \n",
      "train step #21 accuracy: 0.125, loss: 2.3470041751861572       \n",
      "train step #22 accuracy: 0.125, loss: 2.395526170730591        \n",
      "train step #23 accuracy: 0.140625, loss: 2.3860321044921875       \n",
      "train step #24 accuracy: 0.203125, loss: 2.1846835613250732       \n",
      "train step #25 accuracy: 0.171875, loss: 2.2501211166381836       \n",
      "train step #26 accuracy: 0.171875, loss: 2.273139476776123        \n",
      "train step #27 accuracy: 0.234375, loss: 2.186779737472534        \n",
      "train step #28 accuracy: 0.171875, loss: 2.315762996673584        \n",
      "train step #29 accuracy: 0.15625, loss: 2.3139753341674805       \n",
      "train step #30 accuracy: 0.15625, loss: 2.281665086746216        \n",
      "train step #31 accuracy: 0.15625, loss: 2.4223403930664062       \n",
      "train step #32 accuracy:  0.25, loss: 2.030283212661743        \n",
      "train step #33 accuracy: 0.21875, loss: 2.226991653442383        \n",
      "train step #34 accuracy: 0.1875, loss: 2.206393003463745        \n",
      "train step #35 accuracy: 0.265625, loss: 2.124324321746826        \n",
      "train step #36 accuracy: 0.15625, loss: 2.191753387451172        \n",
      "train step #37 accuracy: 0.140625, loss: 2.497081995010376        \n",
      "train step #38 accuracy: 0.140625, loss: 2.236710548400879        \n",
      "train step #39 accuracy: 0.234375, loss: 2.1463992595672607       \n",
      "train step #40 accuracy:  0.25, loss: 2.208815336227417        \n",
      "train step #41 accuracy: 0.296875, loss: 2.1679635047912598       \n",
      "train step #42 accuracy: 0.203125, loss: 2.3171677589416504       \n",
      "train step #43 accuracy: 0.28125, loss: 2.1082160472869873       \n",
      "train step #44 accuracy: 0.296875, loss: 2.0596649646759033       \n",
      "train step #45 accuracy: 0.234375, loss: 2.0743889808654785       \n",
      "train step #46 accuracy: 0.1875, loss: 2.302645206451416        \n",
      "train step #47 accuracy: 0.265625, loss: 2.084995985031128        \n",
      "train step #48 accuracy: 0.203125, loss: 2.2408132553100586       \n",
      "train step #49 accuracy: 0.21875, loss: 2.0552620887756348       \n",
      "train step #50 accuracy: 0.203125, loss: 2.216862201690674        \n",
      "train step #51 accuracy: 0.328125, loss: 1.9727869033813477       \n",
      "train step #52 accuracy: 0.21875, loss: 2.1432673931121826       \n",
      "train step #53 accuracy: 0.359375, loss: 2.0194592475891113       \n",
      "train step #54 accuracy: 0.234375, loss: 2.184948444366455        \n",
      "train step #55 accuracy: 0.375, loss: 1.8538422584533691       \n",
      "train step #56 accuracy: 0.234375, loss: 2.0747034549713135       \n",
      "train step #57 accuracy: 0.34375, loss: 1.8635492324829102       \n",
      "train step #58 accuracy: 0.375, loss: 1.994676113128662        \n",
      "train step #59 accuracy: 0.34375, loss: 1.9232094287872314       \n",
      "train step #60 accuracy: 0.34375, loss: 1.9417885541915894       \n",
      "train step #61 accuracy: 0.375, loss: 1.875687837600708        \n",
      "train step #62 accuracy: 0.171875, loss: 2.087254285812378        \n",
      "train step #63 accuracy: 0.1875, loss: 2.0452229976654053       \n",
      "train step #64 accuracy: 0.328125, loss: 1.9033578634262085       \n",
      "train step #65 accuracy: 0.328125, loss: 1.874908685684204        \n",
      "train step #66 accuracy: 0.390625, loss: 1.7340432405471802       \n",
      "train step #67 accuracy: 0.375, loss: 1.8954601287841797       \n",
      "train step #68 accuracy: 0.328125, loss: 1.8733420372009277       \n",
      "train step #69 accuracy: 0.328125, loss: 1.7688459157943726       \n",
      "train step #70 accuracy: 0.328125, loss: 1.8487802743911743       \n",
      "train step #71 accuracy: 0.359375, loss: 1.8957831859588623       \n",
      "train step #72 accuracy: 0.3125, loss: 1.869362711906433        \n",
      "train step #73 accuracy:  0.25, loss: 2.0723929405212402       \n",
      "train step #74 accuracy: 0.421875, loss: 1.7546844482421875       \n",
      "train step #75 accuracy: 0.34375, loss: 1.830125093460083        \n",
      "train step #76 accuracy: 0.375, loss: 2.002261161804199        \n",
      "train step #77 accuracy: 0.375, loss: 1.7821533679962158       \n",
      "train step #78 accuracy: 0.328125, loss: 1.9057106971740723       \n",
      "train step #79 accuracy: 0.328125, loss: 1.8135658502578735       \n",
      "train step #80 accuracy: 0.28125, loss: 2.0953216552734375       \n",
      "train step #81 accuracy: 0.390625, loss: 1.9406801462173462       \n",
      "train step #82 accuracy: 0.4375, loss: 1.8646676540374756       \n",
      "train step #83 accuracy: 0.3125, loss: 1.8307193517684937       \n",
      "train step #84 accuracy: 0.390625, loss: 1.723122477531433        \n",
      "train step #85 accuracy:  0.25, loss: 1.9434412717819214       \n",
      "train step #86 accuracy: 0.3125, loss: 1.785434603691101        \n",
      "train step #87 accuracy: 0.390625, loss: 1.6882448196411133       \n",
      "train step #88 accuracy: 0.484375, loss: 1.5372151136398315       \n",
      "train step #89 accuracy: 0.484375, loss: 1.6907451152801514       \n",
      "train step #90 accuracy: 0.40625, loss: 1.8246735334396362       \n",
      "train step #91 accuracy: 0.46875, loss: 1.808854103088379        \n",
      "train step #92 accuracy: 0.453125, loss: 1.7239323854446411       \n",
      "train step #93 accuracy: 0.34375, loss: 1.7302114963531494       \n",
      "train step #94 accuracy: 0.484375, loss: 1.595967173576355        \n",
      "train step #95 accuracy: 0.328125, loss: 1.7792506217956543       \n",
      "train step #96 accuracy: 0.46875, loss: 1.4705991744995117       \n",
      "train step #97 accuracy: 0.515625, loss: 1.5408878326416016       \n",
      "train step #98 accuracy: 0.4375, loss: 1.5107364654541016       \n",
      "train step #99 accuracy: 0.421875, loss: 1.795651912689209        \n",
      "train step #100 accuracy: 0.40625, loss: 1.6123783588409424       \n",
      "train step #101 accuracy: 0.390625, loss: 1.830383062362671        \n",
      "train step #102 accuracy: 0.4375, loss: 1.5791904926300049       \n",
      "train step #103 accuracy: 0.46875, loss: 1.577592372894287        \n",
      "train step #104 accuracy: 0.328125, loss: 1.5736745595932007       \n",
      "train step #105 accuracy: 0.59375, loss: 1.3902336359024048       \n",
      "train step #106 accuracy: 0.421875, loss: 1.745699167251587        \n",
      "train step #107 accuracy: 0.421875, loss: 1.5908904075622559       \n",
      "train step #108 accuracy: 0.4375, loss: 1.5566160678863525       \n",
      "train step #109 accuracy: 0.390625, loss: 1.7054853439331055       \n",
      "train step #110 accuracy: 0.359375, loss: 1.9569464921951294       \n",
      "train step #111 accuracy: 0.34375, loss: 1.7101309299468994       \n",
      "train step #112 accuracy: 0.453125, loss: 1.5839130878448486       \n",
      "train step #113 accuracy: 0.40625, loss: 1.505236029624939        \n",
      "train step #114 accuracy: 0.421875, loss: 1.5824031829833984       \n",
      "train step #115 accuracy: 0.390625, loss: 1.676972508430481        \n",
      "train step #116 accuracy: 0.328125, loss: 1.7605066299438477       \n",
      "train step #117 accuracy: 0.3125, loss: 1.7071282863616943       \n",
      "train step #118 accuracy: 0.40625, loss: 1.65390145778656         \n",
      "train step #119 accuracy: 0.296875, loss: 1.668534755706787        \n",
      "train step #120 accuracy: 0.375, loss: 1.5222327709197998       \n",
      "train step #121 accuracy: 0.484375, loss: 1.4552791118621826       \n",
      "train step #122 accuracy: 0.484375, loss: 1.5589827299118042       \n",
      "train step #123 accuracy: 0.421875, loss: 1.657850742340088        \n",
      "train step #124 accuracy: 0.359375, loss: 1.5758981704711914       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #125 accuracy: 0.546875, loss: 1.5074219703674316       \n",
      "train step #126 accuracy: 0.53125, loss: 1.3601495027542114       \n",
      "train step #127 accuracy: 0.40625, loss: 1.4737846851348877       \n",
      "train step #128 accuracy: 0.515625, loss: 1.2262933254241943       \n",
      "train step #129 accuracy: 0.46875, loss: 1.4745912551879883       \n",
      "train step #130 accuracy: 0.4375, loss: 1.5535123348236084       \n",
      "train step #131 accuracy: 0.515625, loss: 1.4332613945007324       \n",
      "train step #132 accuracy: 0.609375, loss: 1.1841676235198975       \n",
      "train step #133 accuracy: 0.59375, loss: 1.2551127672195435       \n",
      "train step #134 accuracy:   0.5, loss: 1.3790018558502197       \n",
      "train step #135 accuracy: 0.515625, loss: 1.314753770828247        \n",
      "train step #136 accuracy: 0.609375, loss: 1.3310905694961548       \n",
      "train step #137 accuracy: 0.546875, loss: 1.3479448556900024       \n",
      "train step #138 accuracy: 0.515625, loss: 1.3389321565628052       \n",
      "train step #139 accuracy: 0.671875, loss: 1.1904875040054321       \n",
      "train step #140 accuracy: 0.59375, loss: 1.2063668966293335       \n",
      "train step #141 accuracy: 0.390625, loss: 1.4533215761184692       \n",
      "train step #142 accuracy: 0.546875, loss: 1.3732401132583618       \n",
      "train step #143 accuracy: 0.4375, loss: 1.4922266006469727       \n",
      "train step #144 accuracy: 0.53125, loss: 1.4089325666427612       \n",
      "train step #145 accuracy:   0.5, loss: 1.2313271760940552       \n",
      "train step #146 accuracy: 0.609375, loss: 1.1640160083770752       \n",
      "train step #147 accuracy:   0.5, loss: 1.3595216274261475       \n",
      "train step #148 accuracy: 0.46875, loss: 1.302442193031311        \n",
      "train step #149 accuracy: 0.484375, loss: 1.3747327327728271       \n",
      "train step #150 accuracy: 0.46875, loss: 1.3179603815078735       \n",
      "train step #151 accuracy: 0.5625, loss: 1.255612850189209        \n",
      "train step #152 accuracy: 0.53125, loss: 1.4782816171646118       \n",
      "train step #153 accuracy: 0.46875, loss: 1.4751358032226562       \n",
      "train step #154 accuracy: 0.578125, loss: 1.2202426195144653       \n",
      "train step #155 accuracy: 0.546875, loss: 1.3806910514831543       \n",
      "train step #156 accuracy: 0.40625, loss: 1.401235580444336        \n",
      "train step #157 accuracy: 0.5625, loss: 1.257651448249817        \n",
      "train step #158 accuracy:   0.5, loss: 1.4035699367523193       \n",
      "train step #159 accuracy: 0.375, loss: 1.5615655183792114       \n",
      "train step #160 accuracy: 0.609375, loss: 1.3426135778427124       \n",
      "train step #161 accuracy:   0.5, loss: 1.455463171005249        \n",
      "train step #162 accuracy: 0.609375, loss: 1.146783709526062        \n",
      "train step #163 accuracy: 0.59375, loss: 1.1828030347824097       \n",
      "train step #164 accuracy:   0.5, loss: 1.365984320640564        \n",
      "train step #165 accuracy: 0.59375, loss: 1.2755215167999268       \n",
      "train step #166 accuracy: 0.609375, loss: 1.143912434577942        \n",
      "train step #167 accuracy: 0.625, loss: 1.1199127435684204       \n",
      "train step #168 accuracy: 0.578125, loss: 1.246829867362976        \n",
      "train step #169 accuracy: 0.453125, loss: 1.312972903251648        \n",
      "train step #170 accuracy: 0.625, loss: 1.2651654481887817       \n",
      "train step #171 accuracy: 0.6875, loss: 1.1081840991973877       \n",
      "train step #172 accuracy: 0.5625, loss: 1.2030794620513916       \n",
      "train step #173 accuracy: 0.46875, loss: 1.4018946886062622       \n",
      "train step #174 accuracy: 0.609375, loss: 1.1286169290542603       \n",
      "train step #175 accuracy: 0.625, loss: 1.158302903175354        \n",
      "train step #176 accuracy: 0.546875, loss: 1.1840511560440063       \n",
      "train step #177 accuracy: 0.578125, loss: 1.2815589904785156       \n",
      "train step #178 accuracy: 0.609375, loss: 1.0440306663513184       \n",
      "train step #179 accuracy:   0.5, loss: 1.3071695566177368       \n",
      "train step #180 accuracy: 0.609375, loss: 1.199698567390442        \n",
      "train step #181 accuracy: 0.578125, loss: 1.1491739749908447       \n",
      "train step #182 accuracy: 0.59375, loss: 1.1318279504776          \n",
      "train step #183 accuracy: 0.703125, loss: 1.056506872177124        \n",
      "train step #184 accuracy: 0.5625, loss: 1.0281672477722168       \n",
      "train step #185 accuracy: 0.734375, loss: 1.0586823225021362       \n",
      "train step #186 accuracy: 0.515625, loss: 1.4577778577804565       \n",
      "train step #187 accuracy: 0.53125, loss: 1.4460418224334717       \n",
      "train step #188 accuracy: 0.515625, loss: 1.393315315246582        \n",
      "train step #189 accuracy: 0.640625, loss: 0.9709637761116028       \n",
      "train step #190 accuracy: 0.703125, loss: 0.9951242804527283       \n",
      "train step #191 accuracy: 0.671875, loss: 1.1402747631072998       \n",
      "train step #192 accuracy: 0.65625, loss: 0.980171263217926        \n",
      "train step #193 accuracy: 0.703125, loss: 1.0270951986312866       \n",
      "train step #194 accuracy: 0.578125, loss: 1.1082814931869507       \n",
      "train step #195 accuracy: 0.65625, loss: 1.1195120811462402       \n",
      "train step #196 accuracy: 0.671875, loss: 0.9356462359428406       \n",
      "train step #197 accuracy: 0.609375, loss: 1.2266956567764282       \n",
      "train step #198 accuracy: 0.65625, loss: 1.0227301120758057       \n",
      "train step #199 accuracy: 0.625, loss: 1.0996116399765015       \n",
      "train step #200 accuracy: 0.671875, loss: 1.1344190835952759       \n",
      "train step #201 accuracy: 0.640625, loss: 0.9805917739868164       \n",
      "train step #202 accuracy: 0.6875, loss: 1.1341055631637573       \n",
      "train step #203 accuracy: 0.625, loss: 1.0274523496627808       \n",
      "train step #204 accuracy: 0.609375, loss: 1.084650993347168        \n",
      "train step #205 accuracy: 0.609375, loss: 1.0267322063446045       \n",
      "train step #206 accuracy: 0.5625, loss: 1.1143056154251099       \n",
      "train step #207 accuracy: 0.59375, loss: 1.0154740810394287       \n",
      "train step #208 accuracy: 0.703125, loss: 0.9554885625839233       \n",
      "train step #209 accuracy: 0.65625, loss: 0.9404797554016113       \n",
      "train step #210 accuracy: 0.640625, loss: 1.0720634460449219       \n",
      "train step #211 accuracy: 0.671875, loss: 0.9618229269981384       \n",
      "train step #212 accuracy: 0.578125, loss: 1.0400561094284058       \n",
      "train step #213 accuracy: 0.734375, loss: 0.9723681211471558       \n",
      "train step #214 accuracy: 0.578125, loss: 1.220994472503662        \n",
      "train step #215 accuracy: 0.640625, loss: 1.0676947832107544       \n",
      "train step #216 accuracy: 0.609375, loss: 1.1367825269699097       \n",
      "train step #217 accuracy: 0.625, loss: 1.117509126663208        \n",
      "train step #218 accuracy: 0.609375, loss: 1.1190475225448608       \n",
      "train step #219 accuracy: 0.609375, loss: 1.1228744983673096       \n",
      "train step #220 accuracy: 0.609375, loss: 1.0720899105072021       \n",
      "train step #221 accuracy: 0.5625, loss: 1.220677375793457        \n",
      "train step #222 accuracy: 0.703125, loss: 0.8473842144012451       \n",
      "train step #223 accuracy: 0.578125, loss: 1.1060398817062378       \n",
      "train step #224 accuracy: 0.734375, loss: 1.0366990566253662       \n",
      "train step #225 accuracy: 0.53125, loss: 1.0742415189743042       \n",
      "train step #226 accuracy: 0.734375, loss: 0.7987960577011108       \n",
      "train step #227 accuracy: 0.734375, loss: 0.8600311875343323       \n",
      "train step #228 accuracy: 0.703125, loss: 0.8068779110908508       \n",
      "train step #229 accuracy: 0.671875, loss: 0.9569931030273438       \n",
      "train step #230 accuracy: 0.671875, loss: 0.869429349899292        \n",
      "train step #231 accuracy: 0.6875, loss: 0.8677557706832886       \n",
      "train step #232 accuracy: 0.6875, loss: 1.032074213027954        \n",
      "train step #233 accuracy: 0.71875, loss: 0.9563930630683899       \n",
      "train step #234 accuracy: 0.6875, loss: 0.8880496025085449       \n",
      "train step #235 accuracy: 0.640625, loss: 1.0072352886199951       \n",
      "train step #236 accuracy: 0.703125, loss: 0.8768020272254944       \n",
      "train step #237 accuracy: 0.703125, loss: 0.9014018774032593       \n",
      "train step #238 accuracy: 0.5625, loss: 1.1322752237319946       \n",
      "train step #239 accuracy: 0.609375, loss: 0.9470528364181519       \n",
      "train step #240 accuracy: 0.734375, loss: 0.8846431970596313       \n",
      "train step #241 accuracy: 0.703125, loss: 0.9839097857475281       \n",
      "train step #242 accuracy: 0.765625, loss: 0.7787138223648071       \n",
      "train step #243 accuracy: 0.640625, loss: 0.9393901824951172       \n",
      "train step #244 accuracy: 0.640625, loss: 1.0374410152435303       \n",
      "train step #245 accuracy: 0.5625, loss: 1.0818324089050293       \n",
      "train step #246 accuracy: 0.734375, loss: 0.8099492788314819       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #247 accuracy: 0.71875, loss: 0.9378808736801147       \n",
      "train step #248 accuracy: 0.6875, loss: 1.0291564464569092       \n",
      "train step #249 accuracy: 0.71875, loss: 0.812649130821228        \n",
      "train step #250 accuracy: 0.6875, loss: 1.0779352188110352       \n",
      "train step #251 accuracy: 0.703125, loss: 0.8310824632644653       \n",
      "train step #252 accuracy: 0.609375, loss: 1.1507413387298584       \n",
      "train step #253 accuracy: 0.578125, loss: 1.1010152101516724       \n",
      "train step #254 accuracy: 0.703125, loss: 0.8615227341651917       \n",
      "train step #255 accuracy: 0.765625, loss: 0.796261727809906        \n",
      "train step #256 accuracy: 0.65625, loss: 1.0495136976242065       \n",
      "train step #257 accuracy: 0.734375, loss: 0.8052343726158142       \n",
      "train step #258 accuracy: 0.828125, loss: 0.6626462936401367       \n",
      "train step #259 accuracy: 0.671875, loss: 1.0098766088485718       \n",
      "train step #260 accuracy: 0.71875, loss: 1.0065826177597046       \n",
      "train step #261 accuracy: 0.6875, loss: 0.9711439609527588       \n",
      "train step #262 accuracy: 0.65625, loss: 1.045886754989624        \n",
      "train step #263 accuracy: 0.625, loss: 1.0328941345214844       \n",
      "train step #264 accuracy: 0.65625, loss: 0.7694464325904846       \n",
      "train step #265 accuracy: 0.71875, loss: 0.8989949226379395       \n",
      "train step #266 accuracy: 0.671875, loss: 0.9567323327064514       \n",
      "train step #267 accuracy: 0.78125, loss: 0.9372333288192749       \n",
      "train step #268 accuracy: 0.703125, loss: 0.8781723380088806       \n",
      "train step #269 accuracy: 0.734375, loss: 0.7218253016471863       \n",
      "train step #270 accuracy: 0.703125, loss: 0.8265690803527832       \n",
      "train step #271 accuracy: 0.671875, loss: 0.9848480224609375       \n",
      "train step #272 accuracy: 0.71875, loss: 0.8746079206466675       \n",
      "train step #273 accuracy: 0.71875, loss: 0.7596081495285034       \n",
      "train step #274 accuracy: 0.765625, loss: 0.7061873078346252       \n",
      "train step #275 accuracy: 0.6875, loss: 0.8635749816894531       \n",
      "train step #276 accuracy: 0.765625, loss: 0.7930390238761902       \n",
      "train step #277 accuracy:  0.75, loss: 0.7335646748542786       \n",
      "train step #278 accuracy: 0.765625, loss: 0.7243745923042297       \n",
      "train step #279 accuracy: 0.6875, loss: 0.788421094417572        \n",
      "train step #280 accuracy: 0.703125, loss: 0.8674873113632202       \n",
      "train step #281 accuracy: 0.765625, loss: 0.8434328436851501       \n",
      "train step #282 accuracy: 0.796875, loss: 0.8120012283325195       \n",
      "train step #283 accuracy: 0.65625, loss: 0.9877917766571045       \n",
      "train step #284 accuracy: 0.703125, loss: 1.0367728471755981       \n",
      "train step #285 accuracy: 0.78125, loss: 0.849351704120636        \n",
      "train step #286 accuracy: 0.65625, loss: 0.9821635484695435       \n",
      "train step #287 accuracy: 0.734375, loss: 0.7999632358551025       \n",
      "train step #288 accuracy: 0.703125, loss: 0.7794527411460876       \n",
      "train step #289 accuracy:  0.75, loss: 0.624056339263916        \n",
      "train step #290 accuracy: 0.640625, loss: 1.068202018737793        \n",
      "train step #291 accuracy: 0.8125, loss: 0.690312385559082        \n",
      "train step #292 accuracy: 0.828125, loss: 0.555849015712738        \n",
      "train step #293 accuracy: 0.6875, loss: 0.9036421775817871       \n",
      "train step #294 accuracy: 0.65625, loss: 0.8308020234107971       \n",
      "train step #295 accuracy: 0.6875, loss: 0.9794113636016846       \n",
      "train step #296 accuracy: 0.6875, loss: 1.0828956365585327       \n",
      "train step #297 accuracy: 0.6875, loss: 0.834866464138031        \n",
      "train step #298 accuracy: 0.671875, loss: 1.0508478879928589       \n",
      "train step #299 accuracy: 0.765625, loss: 0.7427621483802795       \n",
      "train step #300 accuracy:  0.75, loss: 0.7082686424255371       \n",
      "train step #301 accuracy: 0.765625, loss: 0.7879608273506165       \n",
      "train step #302 accuracy: 0.78125, loss: 0.8310885429382324       \n",
      "train step #303 accuracy: 0.78125, loss: 0.6419163942337036       \n",
      "train step #304 accuracy: 0.78125, loss: 0.878453254699707        \n",
      "train step #305 accuracy: 0.8125, loss: 0.5376298427581787       \n",
      "train step #306 accuracy: 0.703125, loss: 0.8197342157363892       \n",
      "train step #307 accuracy: 0.703125, loss: 0.791555643081665        \n",
      "train step #308 accuracy: 0.703125, loss: 0.9134706258773804       \n",
      "train step #309 accuracy: 0.6875, loss: 0.8561397194862366       \n",
      "train step #310 accuracy: 0.71875, loss: 0.8349494934082031       \n",
      "train step #311 accuracy: 0.84375, loss: 0.5938666462898254       \n",
      "train step #312 accuracy:  0.75, loss: 0.7219794988632202       \n",
      "train step #313 accuracy: 0.734375, loss: 0.8593305349349976       \n",
      "train step #314 accuracy:  0.75, loss: 0.7664076089859009       \n",
      "train step #315 accuracy: 0.796875, loss: 0.668646514415741        \n",
      "train step #316 accuracy:  0.75, loss: 0.7993296384811401       \n",
      "train step #317 accuracy: 0.828125, loss: 0.7362352013587952       \n",
      "train step #318 accuracy: 0.65625, loss: 0.9510977268218994       \n",
      "train step #319 accuracy: 0.84375, loss: 0.5504798889160156       \n",
      "train step #320 accuracy: 0.703125, loss: 1.0002979040145874       \n",
      "train step #321 accuracy: 0.734375, loss: 0.8141698837280273       \n",
      "train step #322 accuracy: 0.6875, loss: 0.895629346370697        \n",
      "train step #323 accuracy: 0.796875, loss: 0.7324885129928589       \n",
      "train step #324 accuracy: 0.765625, loss: 0.7282296419143677       \n",
      "train step #325 accuracy: 0.734375, loss: 0.8317168354988098       \n",
      "train step #326 accuracy: 0.703125, loss: 0.7692854404449463       \n",
      "train step #327 accuracy: 0.734375, loss: 0.7126135230064392       \n",
      "train step #328 accuracy:  0.75, loss: 0.7215823531150818       \n",
      "train step #329 accuracy: 0.78125, loss: 0.61150062084198         \n",
      "train step #330 accuracy: 0.734375, loss: 0.7595526576042175       \n",
      "train step #331 accuracy: 0.734375, loss: 0.7559150457382202       \n",
      "train step #332 accuracy: 0.859375, loss: 0.6386154890060425       \n",
      "train step #333 accuracy: 0.734375, loss: 0.867672860622406        \n",
      "train step #334 accuracy:  0.75, loss: 0.6861438751220703       \n",
      "train step #335 accuracy: 0.65625, loss: 1.094985008239746        \n",
      "train step #336 accuracy: 0.796875, loss: 0.6042357087135315       \n",
      "train step #337 accuracy: 0.734375, loss: 0.872177243232727        \n",
      "train step #338 accuracy: 0.78125, loss: 0.7195736169815063       \n",
      "train step #339 accuracy: 0.828125, loss: 0.44885697960853577      \n",
      "train step #340 accuracy: 0.796875, loss: 0.8329372406005859       \n",
      "train step #341 accuracy: 0.765625, loss: 0.7927113175392151       \n",
      "train step #342 accuracy:  0.75, loss: 0.7570458054542542       \n",
      "train step #343 accuracy:  0.75, loss: 0.7972667217254639       \n",
      "train step #344 accuracy: 0.78125, loss: 0.6098083257675171       \n",
      "train step #345 accuracy: 0.765625, loss: 0.8055073022842407       \n",
      "train step #346 accuracy: 0.6875, loss: 1.037543535232544        \n",
      "train step #347 accuracy: 0.78125, loss: 0.6647123098373413       \n",
      "dev accuracy:  0.75, loss: 0.7014338970184326       \n",
      "dev accuracy: 0.8125, loss: 0.6356775164604187       \n",
      "dev accuracy: 0.6875, loss: 0.7921729683876038       \n",
      "dev accuracy: 0.875, loss: 0.47962120175361633      \n",
      "dev accuracy: 0.6875, loss: 0.734776496887207        \n",
      "dev accuracy:  0.75, loss: 0.7793731093406677       \n",
      "dev accuracy:  0.75, loss: 0.769063413143158        \n",
      "dev accuracy: 0.8125, loss: 0.722253143787384        \n",
      "dev accuracy: 0.6875, loss: 1.2873034477233887       \n",
      "dev accuracy: 0.6875, loss: 1.2156872749328613       \n",
      "dev accuracy: 0.625, loss: 1.2820957899093628       \n",
      "dev accuracy: 0.8125, loss: 1.1139038801193237       \n",
      "dev accuracy: 0.6875, loss: 1.2146424055099487       \n",
      "dev accuracy: 0.6875, loss: 1.1594725847244263       \n",
      "dev accuracy: 0.875, loss: 0.6262383460998535       \n",
      "dev accuracy: 0.875, loss: 0.5853773951530457       \n",
      "dev accuracy: 0.5625, loss: 1.1913361549377441       \n",
      "dev accuracy: 0.625, loss: 1.2353944778442383       \n",
      "dev accuracy: 0.6875, loss: 1.1306841373443604       \n",
      "dev accuracy: 0.875, loss: 0.4915968179702759       \n",
      "dev accuracy: 0.6875, loss: 0.9050686955451965       \n",
      "dev accuracy:  0.75, loss: 1.0001695156097412       \n",
      "dev accuracy: 0.625, loss: 0.9512431621551514       \n",
      "dev accuracy: 0.625, loss: 1.0905377864837646       \n",
      "dev accuracy: 0.8125, loss: 0.7918797731399536       \n",
      "dev accuracy: 0.5625, loss: 1.1954401731491089       \n",
      "dev accuracy: 0.875, loss: 0.5347810983657837       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy: 0.9375, loss: 0.5912676453590393       \n",
      "dev accuracy:  0.75, loss: 0.9014200568199158       \n",
      "dev accuracy: 0.8125, loss: 0.6786653995513916       \n",
      "dev accuracy: 0.6875, loss: 0.992845892906189        \n",
      "dev accuracy: 0.9375, loss: 0.5874707698822021       \n",
      "dev accuracy: 0.875, loss: 0.8343795537948608       \n",
      "dev accuracy: 0.625, loss: 1.5827196836471558       \n",
      "dev accuracy: 0.6875, loss: 1.1307759284973145       \n",
      "dev accuracy:  0.75, loss: 0.7607854604721069       \n",
      "dev accuracy:   0.5, loss: 1.5315074920654297       \n",
      "dev accuracy: 0.8125, loss: 0.7784029245376587       \n",
      "dev accuracy: 0.9375, loss: 0.4699128270149231       \n",
      "dev accuracy: 0.875, loss: 0.5683741569519043       \n",
      "dev accuracy: 0.8125, loss: 0.8013444542884827       \n",
      "dev accuracy: 0.625, loss: 1.3412015438079834       \n",
      "dev accuracy:  0.75, loss: 0.9572815299034119       \n",
      "dev accuracy: 0.875, loss: 0.6469597816467285       \n",
      "dev accuracy: 0.875, loss: 0.6679229736328125       \n",
      "dev accuracy: 0.625, loss: 0.9771777391433716       \n",
      "dev accuracy: 0.625, loss: 0.8523485660552979       \n",
      "dev accuracy: 0.625, loss: 1.242821455001831        \n",
      "dev accuracy:  0.75, loss: 1.1152437925338745       \n",
      "dev accuracy: 0.8125, loss: 0.8007204532623291       \n",
      "dev accuracy: 0.8125, loss: 0.559088945388794        \n",
      "dev accuracy: 0.6875, loss: 1.0610101222991943       \n",
      "dev accuracy: 0.625, loss: 1.238224744796753        \n",
      "dev accuracy:  0.75, loss: 0.880399763584137        \n",
      "dev accuracy: 0.8125, loss: 0.5992417931556702       \n",
      "dev accuracy: 0.6875, loss: 0.8419619798660278       \n",
      "dev accuracy: 0.8125, loss: 0.48240604996681213      \n",
      "dev accuracy: 0.625, loss: 0.9310392141342163       \n",
      "dev accuracy: 0.6875, loss: 0.8448331356048584       \n",
      "dev accuracy: 0.875, loss: 0.9041544198989868       \n",
      "dev accuracy: 0.6875, loss: 0.6727515459060669       \n",
      "dev accuracy: 0.9375, loss: 0.4614531099796295       \n",
      "dev accuracy:  0.75, loss: 0.8745547533035278       \n",
      "dev accuracy: 0.875, loss: 0.39813587069511414      \n",
      "dev accuracy: 0.8125, loss: 0.7390456199645996       \n",
      "dev accuracy: 0.6875, loss: 0.7856141328811646       \n",
      "dev accuracy:  0.75, loss: 1.1705756187438965       \n",
      "dev accuracy: 0.8125, loss: 1.0634608268737793       \n",
      "dev accuracy: 0.625, loss: 0.9210896492004395       \n",
      "dev accuracy: 0.8125, loss: 1.0509743690490723       \n",
      "dev accuracy: 0.875, loss: 0.847791314125061        \n",
      "dev accuracy:  0.75, loss: 0.6441065669059753       \n",
      "dev accuracy: 0.625, loss: 1.3855869770050049       \n",
      "dev accuracy: 0.6875, loss: 0.9424337148666382       \n",
      "dev accuracy: 0.5625, loss: 1.0607514381408691       \n",
      "dev accuracy: 0.8125, loss: 0.8124120831489563       \n",
      "dev accuracy: 0.875, loss: 0.8910488486289978       \n",
      "dev accuracy: 0.8125, loss: 0.7505384683609009       \n",
      "dev accuracy:   1.0, loss: 0.22277796268463135      \n",
      "dev accuracy: 0.875, loss: 0.5958137512207031       \n",
      "dev accuracy:  0.75, loss: 0.9397309422492981       \n",
      "dev accuracy: 0.8125, loss: 0.511747419834137        \n",
      "dev accuracy: 0.6875, loss: 0.754414439201355        \n",
      "dev accuracy: 0.875, loss: 0.5760990381240845       \n",
      "dev accuracy: 0.5625, loss: 1.1718337535858154       \n",
      "dev accuracy: 0.9375, loss: 0.4207450747489929       \n",
      "dev accuracy:  0.75, loss: 0.72120201587677         \n",
      "dev accuracy:  0.75, loss: 1.1084299087524414       \n",
      "dev accuracy: 0.8125, loss: 0.563048243522644        \n",
      "dev accuracy:  0.75, loss: 0.8656024932861328       \n",
      "dev accuracy: 0.625, loss: 1.242936134338379        \n",
      "dev accuracy: 0.6875, loss: 0.9031835794448853       \n",
      "dev accuracy: 0.8125, loss: 0.41105055809020996      \n",
      "dev accuracy:  0.75, loss: 0.9707499146461487       \n",
      "dev accuracy: 0.8125, loss: 0.7291070222854614       \n",
      "dev accuracy: 0.6875, loss: 0.919230043888092        \n",
      "dev accuracy: 0.625, loss: 0.9251130223274231       \n",
      "dev accuracy:  0.75, loss: 0.8040851354598999       \n",
      "dev accuracy: 0.875, loss: 0.4016377031803131       \n",
      "dev accuracy: 0.625, loss: 0.7254445552825928       \n",
      "dev accuracy: 0.6875, loss: 0.9739407896995544       \n",
      "dev accuracy: 0.875, loss: 0.5938029289245605       \n",
      "dev accuracy:  0.75, loss: 0.9747267961502075       \n",
      "dev accuracy: 0.625, loss: 0.8369375467300415       \n",
      "dev accuracy: 0.875, loss: 0.8594877123832703       \n",
      "dev accuracy: 0.9375, loss: 0.44657623767852783      \n",
      "dev accuracy: 0.8125, loss: 0.48453232645988464      \n",
      "dev accuracy: 0.875, loss: 0.6587554812431335       \n",
      "dev accuracy: 0.625, loss: 1.0503990650177002       \n",
      "dev accuracy:  0.75, loss: 0.8897472620010376       \n",
      "dev accuracy: 0.8125, loss: 0.8962035775184631       \n",
      "dev accuracy: 0.8125, loss: 0.6280745267868042       \n",
      "dev accuracy:  0.75, loss: 1.3072556257247925       \n",
      "dev accuracy:  0.75, loss: 0.8938806653022766       \n",
      "dev accuracy: 0.6875, loss: 0.7246401309967041       \n",
      "dev accuracy:  0.75, loss: 0.9505936503410339       \n",
      "dev accuracy: 0.8125, loss: 0.8903806805610657       \n",
      "dev accuracy:  0.75, loss: 0.8679376840591431       \n",
      "dev accuracy:  0.75, loss: 0.6050816774368286       \n",
      "dev accuracy: 0.5625, loss: 1.035506248474121        \n",
      "dev accuracy: 0.625, loss: 1.0032752752304077       \n",
      "dev accuracy: 0.6875, loss: 1.008528232574463        \n",
      "dev accuracy: 0.6875, loss: 0.8921093344688416       \n",
      "dev accuracy: 0.875, loss: 0.5485929250717163       \n",
      "dev accuracy: 0.875, loss: 0.6414957046508789       \n",
      "dev accuracy: 0.625, loss: 0.7482339143753052       \n",
      "dev accuracy: 0.625, loss: 1.0033748149871826       \n",
      "dev accuracy: 0.8125, loss: 0.5825585722923279       \n",
      "dev accuracy:  0.75, loss: 0.7272826433181763       \n",
      "dev accuracy: 0.6875, loss: 1.051847219467163        \n",
      "dev accuracy:  0.75, loss: 1.0105715990066528       \n",
      "dev accuracy: 0.375, loss: 1.5604534149169922       \n",
      "dev accuracy:  0.75, loss: 0.7068748474121094       \n",
      "dev accuracy:  0.75, loss: 0.7023495435714722       \n",
      "dev accuracy:  0.75, loss: 0.6254110932350159       \n",
      "dev accuracy: 0.6875, loss: 1.0379773378372192       \n",
      "dev accuracy: 0.5625, loss: 1.0907269716262817       \n",
      "dev accuracy: 0.8125, loss: 0.7260599136352539       \n",
      "dev accuracy: 0.6875, loss: 1.1173032522201538       \n",
      "dev accuracy: 0.625, loss: 0.9470337629318237       \n",
      "dev accuracy: 0.8125, loss: 0.5198121666908264       \n",
      "dev accuracy: 0.875, loss: 0.5566736459732056       \n",
      "dev accuracy:  0.75, loss: 0.9047541618347168       \n",
      "dev accuracy: 0.875, loss: 0.7879152894020081       \n",
      "dev accuracy: 0.6875, loss: 0.7555891871452332       \n",
      "dev accuracy: 0.5625, loss: 1.0113023519515991       \n",
      "dev accuracy: 0.8125, loss: 0.7201471328735352       \n",
      "dev accuracy:  0.75, loss: 0.7388100028038025       \n",
      "dev accuracy:  0.75, loss: 1.2860302925109863       \n",
      "dev accuracy: 0.6875, loss: 1.1517674922943115       \n",
      "dev accuracy: 0.9375, loss: 0.4089567959308624       \n",
      "dev accuracy: 0.8125, loss: 0.5910410284996033       \n",
      "dev accuracy: 0.5625, loss: 1.463600516319275        \n",
      "dev accuracy: 0.6875, loss: 0.9616137742996216       \n",
      "dev accuracy: 0.875, loss: 0.4313752353191376       \n",
      "dev accuracy: 0.625, loss: 1.1640467643737793       \n",
      "dev accuracy:  0.75, loss: 0.9212620854377747       \n",
      "dev accuracy: 0.625, loss: 1.554526448249817        \n",
      "dev accuracy:  0.75, loss: 1.1680854558944702       \n",
      "dev accuracy: 0.8125, loss: 0.71486496925354         \n",
      "dev accuracy:  0.75, loss: 0.5791187286376953       \n",
      "dev accuracy: 0.8125, loss: 0.6010088920593262       \n",
      "dev accuracy: 0.625, loss: 1.0663989782333374       \n",
      "dev accuracy: 0.8125, loss: 0.6835083961486816       \n",
      "dev accuracy:   0.5, loss: 0.9809057712554932       \n",
      "dev accuracy:  0.75, loss: 0.7523818016052246       \n",
      "dev accuracy: 0.875, loss: 0.5423787236213684       \n",
      "dev accuracy: 0.6875, loss: 0.9223151206970215       \n",
      "dev accuracy: 0.5625, loss: 1.4523696899414062       \n",
      "dev accuracy:  0.75, loss: 1.0735085010528564       \n",
      "dev accuracy: 0.8125, loss: 1.102225661277771        \n",
      "dev accuracy: 0.8125, loss: 0.8515837788581848       \n",
      "dev accuracy: 0.8125, loss: 0.48504123091697693      \n",
      "dev accuracy: 0.8125, loss: 0.9266101717948914       \n",
      "dev accuracy:  0.75, loss: 0.5821346044540405       \n",
      "dev accuracy:  0.75, loss: 0.8537631034851074       \n",
      "dev accuracy: 0.625, loss: 1.216212511062622        \n",
      "dev accuracy:  0.75, loss: 0.8727015256881714       \n",
      "dev accuracy: 0.8125, loss: 0.5666100978851318       \n",
      "dev accuracy: 0.875, loss: 0.5031232833862305       \n",
      "dev accuracy:  0.75, loss: 1.0778391361236572       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy: 0.875, loss: 0.8064447641372681       \n",
      "dev accuracy:  0.75, loss: 1.0199278593063354       \n",
      "dev accuracy:  0.75, loss: 0.7074865102767944       \n",
      "dev accuracy: 0.8125, loss: 0.5280083417892456       \n",
      "dev accuracy:  0.75, loss: 0.9609752297401428       \n",
      "dev accuracy: 0.6875, loss: 1.2425576448440552       \n",
      "dev accuracy: 0.6875, loss: 1.175414800643921        \n",
      "dev accuracy: 0.8125, loss: 0.7339799404144287       \n",
      "dev accuracy: 0.625, loss: 1.2195992469787598       \n",
      "dev accuracy:  0.75, loss: 0.915190577507019        \n",
      "dev accuracy:  0.75, loss: 0.576938271522522        \n",
      "dev accuracy: 0.6875, loss: 1.3360960483551025       \n",
      "dev accuracy: 0.6666666666666666, loss: 0.45454859733581543      \n",
      "final dev accuracy: 0.7463487972508592\n",
      "saving best model...\n",
      "train step #348 accuracy: 0.671875, loss: 0.8103102445602417       \n",
      "train step #349 accuracy: 0.796875, loss: 0.6990839838981628       \n",
      "train step #350 accuracy: 0.796875, loss: 0.6088122129440308       \n",
      "train step #351 accuracy: 0.765625, loss: 0.5816211700439453       \n",
      "train step #352 accuracy: 0.84375, loss: 0.4821312427520752       \n",
      "train step #353 accuracy: 0.828125, loss: 0.5893204808235168       \n",
      "train step #354 accuracy: 0.765625, loss: 0.6475582122802734       \n",
      "train step #355 accuracy: 0.703125, loss: 0.8677033185958862       \n",
      "train step #356 accuracy: 0.734375, loss: 0.962529718875885        \n",
      "train step #357 accuracy: 0.78125, loss: 0.6195129752159119       \n",
      "train step #358 accuracy:  0.75, loss: 0.7819353938102722       \n",
      "train step #359 accuracy: 0.8125, loss: 0.5030978322029114       \n",
      "train step #360 accuracy: 0.78125, loss: 0.5677782297134399       \n",
      "train step #361 accuracy: 0.84375, loss: 0.5315918326377869       \n",
      "train step #362 accuracy: 0.796875, loss: 0.6620151400566101       \n",
      "train step #363 accuracy: 0.828125, loss: 0.5143622159957886       \n",
      "train step #364 accuracy: 0.71875, loss: 0.7659677267074585       \n",
      "train step #365 accuracy: 0.8125, loss: 0.6400192975997925       \n",
      "train step #366 accuracy: 0.703125, loss: 0.8919109106063843       \n",
      "train step #367 accuracy:  0.75, loss: 0.6926640272140503       \n",
      "train step #368 accuracy: 0.78125, loss: 0.5777498483657837       \n",
      "train step #369 accuracy: 0.71875, loss: 0.8244562745094299       \n",
      "train step #370 accuracy: 0.84375, loss: 0.5007208585739136       \n",
      "train step #371 accuracy: 0.765625, loss: 0.6395471096038818       \n",
      "train step #372 accuracy: 0.8125, loss: 0.5629042983055115       \n",
      "train step #373 accuracy: 0.796875, loss: 0.5327262282371521       \n",
      "train step #374 accuracy: 0.703125, loss: 0.7378600239753723       \n",
      "train step #375 accuracy: 0.828125, loss: 0.5021368861198425       \n",
      "train step #376 accuracy: 0.78125, loss: 0.6000260710716248       \n",
      "train step #377 accuracy: 0.84375, loss: 0.5141658782958984       \n",
      "train step #378 accuracy: 0.8125, loss: 0.6801023483276367       \n",
      "train step #379 accuracy: 0.703125, loss: 0.9499399662017822       \n",
      "train step #380 accuracy: 0.78125, loss: 0.6083264350891113       \n",
      "train step #381 accuracy: 0.859375, loss: 0.6746766567230225       \n",
      "train step #382 accuracy: 0.71875, loss: 0.7843672037124634       \n",
      "train step #383 accuracy: 0.828125, loss: 0.6143964529037476       \n",
      "train step #384 accuracy: 0.71875, loss: 0.7571114301681519       \n",
      "train step #385 accuracy:  0.75, loss: 0.648256242275238        \n",
      "train step #386 accuracy: 0.796875, loss: 0.5885483622550964       \n",
      "train step #387 accuracy: 0.765625, loss: 0.5842298269271851       \n",
      "train step #388 accuracy: 0.765625, loss: 0.5585427284240723       \n",
      "train step #389 accuracy: 0.6875, loss: 0.9423496127128601       \n",
      "train step #390 accuracy: 0.734375, loss: 0.6464722156524658       \n",
      "train step #391 accuracy: 0.734375, loss: 0.6963374018669128       \n",
      "train step #392 accuracy: 0.8125, loss: 0.5609920024871826       \n",
      "train step #393 accuracy: 0.78125, loss: 0.6763042211532593       \n",
      "train step #394 accuracy: 0.734375, loss: 0.7760715484619141       \n",
      "train step #395 accuracy: 0.796875, loss: 0.5397061109542847       \n",
      "train step #396 accuracy: 0.703125, loss: 0.8296723365783691       \n",
      "train step #397 accuracy: 0.828125, loss: 0.6374321579933167       \n",
      "train step #398 accuracy: 0.78125, loss: 0.6750923991203308       \n",
      "train step #399 accuracy: 0.6875, loss: 0.8184973001480103       \n",
      "train step #400 accuracy: 0.84375, loss: 0.5892531871795654       \n",
      "train step #401 accuracy: 0.6875, loss: 0.9547758102416992       \n",
      "train step #402 accuracy: 0.78125, loss: 0.6684446930885315       \n",
      "train step #403 accuracy: 0.828125, loss: 0.548726499080658        \n",
      "train step #404 accuracy: 0.78125, loss: 0.6073822379112244       \n",
      "train step #405 accuracy: 0.796875, loss: 0.5761469602584839       \n",
      "train step #406 accuracy: 0.765625, loss: 0.6879872679710388       \n",
      "train step #407 accuracy: 0.84375, loss: 0.4803529977798462       \n",
      "train step #408 accuracy: 0.859375, loss: 0.6522523760795593       \n",
      "train step #409 accuracy: 0.78125, loss: 0.5780920386314392       \n",
      "train step #410 accuracy: 0.734375, loss: 0.8095225095748901       \n",
      "train step #411 accuracy: 0.765625, loss: 0.7068765163421631       \n",
      "train step #412 accuracy: 0.859375, loss: 0.5044615268707275       \n",
      "train step #413 accuracy: 0.734375, loss: 0.9088897109031677       \n",
      "train step #414 accuracy: 0.78125, loss: 0.6943147778511047       \n",
      "train step #415 accuracy: 0.734375, loss: 0.7078043222427368       \n",
      "train step #416 accuracy: 0.8125, loss: 0.5701858997344971       \n",
      "train step #417 accuracy: 0.84375, loss: 0.46719080209732056      \n",
      "train step #418 accuracy: 0.796875, loss: 0.5801493525505066       \n",
      "train step #419 accuracy: 0.796875, loss: 0.5930452346801758       \n",
      "train step #420 accuracy: 0.796875, loss: 0.647917628288269        \n",
      "train step #421 accuracy: 0.78125, loss: 0.6348774433135986       \n",
      "train step #422 accuracy: 0.703125, loss: 0.9892544150352478       \n",
      "train step #423 accuracy: 0.796875, loss: 0.5690845251083374       \n",
      "train step #424 accuracy: 0.78125, loss: 0.6978511810302734       \n",
      "train step #425 accuracy: 0.796875, loss: 0.4994882345199585       \n",
      "train step #426 accuracy: 0.859375, loss: 0.4808514416217804       \n",
      "train step #427 accuracy: 0.796875, loss: 0.614345133304596        \n",
      "train step #428 accuracy: 0.8125, loss: 0.6503888368606567       \n",
      "train step #429 accuracy: 0.828125, loss: 0.5095632672309875       \n",
      "train step #430 accuracy: 0.765625, loss: 0.8763675689697266       \n",
      "train step #431 accuracy: 0.796875, loss: 0.7281424403190613       \n",
      "train step #432 accuracy: 0.859375, loss: 0.4759407937526703       \n",
      "train step #433 accuracy: 0.765625, loss: 0.7436817288398743       \n",
      "train step #434 accuracy: 0.84375, loss: 0.43877142667770386      \n",
      "train step #435 accuracy: 0.8125, loss: 0.6604050993919373       \n",
      "train step #436 accuracy: 0.765625, loss: 0.711523175239563        \n",
      "train step #437 accuracy: 0.796875, loss: 0.6418265104293823       \n",
      "train step #438 accuracy: 0.859375, loss: 0.5419981479644775       \n",
      "train step #439 accuracy: 0.734375, loss: 0.8932535648345947       \n",
      "train step #440 accuracy: 0.828125, loss: 0.6116077303886414       \n",
      "train step #441 accuracy: 0.796875, loss: 0.6110842823982239       \n",
      "train step #442 accuracy: 0.84375, loss: 0.5115277767181396       \n",
      "train step #443 accuracy: 0.84375, loss: 0.5439045429229736       \n",
      "train step #444 accuracy: 0.8125, loss: 0.6403791308403015       \n",
      "train step #445 accuracy: 0.796875, loss: 0.6867027282714844       \n",
      "train step #446 accuracy: 0.671875, loss: 1.0248247385025024       \n",
      "train step #447 accuracy: 0.859375, loss: 0.567855715751648        \n",
      "train step #448 accuracy: 0.734375, loss: 0.9702922701835632       \n",
      "train step #449 accuracy:  0.75, loss: 0.7545266151428223       \n",
      "train step #450 accuracy: 0.828125, loss: 0.5023188591003418       \n",
      "train step #451 accuracy: 0.828125, loss: 0.564583420753479        \n",
      "train step #452 accuracy: 0.6875, loss: 0.8719176054000854       \n",
      "train step #453 accuracy: 0.8125, loss: 0.677700400352478        \n",
      "train step #454 accuracy: 0.8125, loss: 0.6320127248764038       \n",
      "train step #455 accuracy: 0.859375, loss: 0.5426015257835388       \n",
      "train step #456 accuracy: 0.71875, loss: 0.798230767250061        \n",
      "train step #457 accuracy: 0.828125, loss: 0.46493998169898987      \n",
      "train step #458 accuracy: 0.78125, loss: 0.6767061352729797       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #459 accuracy: 0.875, loss: 0.5210042595863342       \n",
      "train step #460 accuracy:  0.75, loss: 0.7224792838096619       \n",
      "train step #461 accuracy: 0.84375, loss: 0.47671282291412354      \n",
      "train step #462 accuracy: 0.875, loss: 0.38984692096710205      \n",
      "train step #463 accuracy: 0.8125, loss: 0.6320125460624695       \n",
      "train step #464 accuracy: 0.6875, loss: 0.8698963522911072       \n",
      "train step #465 accuracy: 0.8125, loss: 0.6444043517112732       \n",
      "train step #466 accuracy: 0.890625, loss: 0.5241720676422119       \n",
      "train step #467 accuracy: 0.765625, loss: 0.7012597322463989       \n",
      "train step #468 accuracy: 0.796875, loss: 0.5877965092658997       \n",
      "train step #469 accuracy: 0.8125, loss: 0.6945542097091675       \n",
      "train step #470 accuracy: 0.78125, loss: 0.5800239443778992       \n",
      "train step #471 accuracy: 0.796875, loss: 0.6350106000900269       \n",
      "train step #472 accuracy: 0.796875, loss: 0.5584632158279419       \n",
      "train step #473 accuracy: 0.8125, loss: 0.4628323018550873       \n",
      "train step #474 accuracy: 0.84375, loss: 0.4664144515991211       \n",
      "train step #475 accuracy: 0.828125, loss: 0.497336208820343        \n",
      "train step #476 accuracy: 0.875, loss: 0.5731399059295654       \n",
      "train step #477 accuracy: 0.765625, loss: 0.696832001209259        \n",
      "train step #478 accuracy: 0.796875, loss: 0.5898396372795105       \n",
      "train step #479 accuracy: 0.890625, loss: 0.4852994382381439       \n",
      "train step #480 accuracy: 0.859375, loss: 0.4266256093978882       \n",
      "train step #481 accuracy: 0.90625, loss: 0.4253046214580536       \n",
      "train step #482 accuracy: 0.78125, loss: 0.6994863748550415       \n",
      "train step #483 accuracy: 0.796875, loss: 0.4763568341732025       \n",
      "train step #484 accuracy: 0.84375, loss: 0.4149649143218994       \n",
      "train step #485 accuracy:  0.75, loss: 0.661072313785553        \n",
      "train step #486 accuracy:  0.75, loss: 0.7370980978012085       \n",
      "train step #487 accuracy: 0.796875, loss: 0.6370576024055481       \n",
      "train step #488 accuracy: 0.765625, loss: 0.6731491684913635       \n",
      "train step #489 accuracy: 0.796875, loss: 0.6192651391029358       \n",
      "train step #490 accuracy: 0.78125, loss: 0.6133756637573242       \n",
      "train step #491 accuracy: 0.828125, loss: 0.5761281251907349       \n",
      "train step #492 accuracy: 0.828125, loss: 0.5486730933189392       \n",
      "train step #493 accuracy: 0.796875, loss: 0.6105692386627197       \n",
      "train step #494 accuracy: 0.796875, loss: 0.561955451965332        \n",
      "train step #495 accuracy: 0.796875, loss: 0.49260616302490234      \n",
      "train step #496 accuracy: 0.859375, loss: 0.48066771030426025      \n",
      "train step #497 accuracy: 0.8125, loss: 0.5969094038009644       \n",
      "train step #498 accuracy: 0.765625, loss: 0.8449171781539917       \n",
      "train step #499 accuracy: 0.828125, loss: 0.5873490571975708       \n",
      "train step #500 accuracy: 0.84375, loss: 0.4392825961112976       \n",
      "train step #501 accuracy: 0.828125, loss: 0.5531949400901794       \n",
      "train step #502 accuracy: 0.8125, loss: 0.5928928256034851       \n",
      "train step #503 accuracy: 0.6875, loss: 0.7825936079025269       \n",
      "train step #504 accuracy: 0.8125, loss: 0.5230810642242432       \n",
      "train step #505 accuracy:  0.75, loss: 0.748059093952179        \n",
      "train step #506 accuracy: 0.78125, loss: 0.6341501474380493       \n",
      "train step #507 accuracy: 0.875, loss: 0.3479834794998169       \n",
      "train step #508 accuracy: 0.8125, loss: 0.6772362589836121       \n",
      "train step #509 accuracy: 0.84375, loss: 0.6755124926567078       \n",
      "train step #510 accuracy:  0.75, loss: 0.802983820438385        \n",
      "train step #511 accuracy: 0.78125, loss: 0.6742002964019775       \n",
      "train step #512 accuracy: 0.796875, loss: 0.5601821541786194       \n",
      "train step #513 accuracy: 0.765625, loss: 0.6585277318954468       \n",
      "train step #514 accuracy: 0.796875, loss: 0.6709333062171936       \n",
      "train step #515 accuracy: 0.796875, loss: 0.6381191611289978       \n",
      "train step #516 accuracy: 0.796875, loss: 0.5651810765266418       \n",
      "train step #517 accuracy: 0.859375, loss: 0.5019748210906982       \n",
      "train step #518 accuracy: 0.84375, loss: 0.658518373966217        \n",
      "train step #519 accuracy: 0.78125, loss: 0.7747153043746948       \n",
      "train step #520 accuracy: 0.8125, loss: 0.627637505531311        \n",
      "train step #521 accuracy: 0.9375, loss: 0.3141535222530365       \n",
      "train step #522 accuracy: 0.875, loss: 0.4649503827095032       \n",
      "train step #523 accuracy: 0.828125, loss: 0.4734751582145691       \n",
      "train step #524 accuracy: 0.8125, loss: 0.547774076461792        \n",
      "train step #525 accuracy:  0.75, loss: 0.6226589679718018       \n",
      "train step #526 accuracy: 0.921875, loss: 0.3298953175544739       \n",
      "train step #527 accuracy: 0.84375, loss: 0.5714452862739563       \n",
      "train step #528 accuracy: 0.796875, loss: 0.6549258232116699       \n",
      "train step #529 accuracy: 0.859375, loss: 0.46939197182655334      \n",
      "train step #530 accuracy: 0.828125, loss: 0.6022157073020935       \n",
      "train step #531 accuracy: 0.734375, loss: 0.8206090927124023       \n",
      "train step #532 accuracy: 0.796875, loss: 0.6028413772583008       \n",
      "train step #533 accuracy: 0.859375, loss: 0.37612903118133545      \n",
      "train step #534 accuracy: 0.890625, loss: 0.4045460820198059       \n",
      "train step #535 accuracy: 0.875, loss: 0.5041988492012024       \n",
      "train step #536 accuracy: 0.84375, loss: 0.6312609314918518       \n",
      "train step #537 accuracy: 0.84375, loss: 0.609571635723114        \n",
      "train step #538 accuracy: 0.84375, loss: 0.400885671377182        \n",
      "train step #539 accuracy: 0.921875, loss: 0.4194945693016052       \n",
      "train step #540 accuracy: 0.734375, loss: 0.7773715853691101       \n",
      "train step #541 accuracy: 0.796875, loss: 0.7218270897865295       \n",
      "train step #542 accuracy: 0.875, loss: 0.3478451371192932       \n",
      "train step #543 accuracy: 0.828125, loss: 0.655739963054657        \n",
      "train step #544 accuracy: 0.765625, loss: 0.625688374042511        \n",
      "train step #545 accuracy: 0.8125, loss: 0.5759263038635254       \n",
      "train step #546 accuracy: 0.90625, loss: 0.3097836375236511       \n",
      "train step #547 accuracy: 0.78125, loss: 0.7456874251365662       \n",
      "train step #548 accuracy: 0.9375, loss: 0.43053504824638367      \n",
      "train step #549 accuracy: 0.890625, loss: 0.32337701320648193      \n",
      "train step #550 accuracy: 0.796875, loss: 0.687865138053894        \n",
      "train step #551 accuracy: 0.8125, loss: 0.5719634294509888       \n",
      "train step #552 accuracy: 0.796875, loss: 0.6335460543632507       \n",
      "train step #553 accuracy: 0.953125, loss: 0.31451505422592163      \n",
      "train step #554 accuracy: 0.921875, loss: 0.3342333436012268       \n",
      "train step #555 accuracy: 0.890625, loss: 0.3366824984550476       \n",
      "train step #556 accuracy: 0.78125, loss: 0.5837917327880859       \n",
      "train step #557 accuracy: 0.8125, loss: 0.6691559553146362       \n",
      "train step #558 accuracy: 0.765625, loss: 0.5487553477287292       \n",
      "train step #559 accuracy: 0.859375, loss: 0.6937812566757202       \n",
      "train step #560 accuracy: 0.8125, loss: 0.4661567509174347       \n",
      "train step #561 accuracy: 0.84375, loss: 0.45679476857185364      \n",
      "train step #562 accuracy: 0.828125, loss: 0.6265470385551453       \n",
      "train step #563 accuracy: 0.875, loss: 0.47161513566970825      \n",
      "train step #564 accuracy: 0.890625, loss: 0.3950403332710266       \n",
      "train step #565 accuracy: 0.828125, loss: 0.5643495321273804       \n",
      "train step #566 accuracy: 0.828125, loss: 0.4905594289302826       \n",
      "train step #567 accuracy: 0.765625, loss: 0.6747509241104126       \n",
      "train step #568 accuracy: 0.90625, loss: 0.3079899251461029       \n",
      "train step #569 accuracy: 0.875, loss: 0.5114357471466064       \n",
      "train step #570 accuracy: 0.828125, loss: 0.5060105919837952       \n",
      "train step #571 accuracy: 0.859375, loss: 0.5962474346160889       \n",
      "train step #572 accuracy: 0.8125, loss: 0.5923226475715637       \n",
      "train step #573 accuracy: 0.859375, loss: 0.4313340485095978       \n",
      "train step #574 accuracy: 0.859375, loss: 0.4829410910606384       \n",
      "train step #575 accuracy: 0.828125, loss: 0.5314319133758545       \n",
      "train step #576 accuracy: 0.78125, loss: 0.6102986335754395       \n",
      "train step #577 accuracy: 0.8125, loss: 0.4965990483760834       \n",
      "train step #578 accuracy: 0.890625, loss: 0.3832635283470154       \n",
      "train step #579 accuracy: 0.859375, loss: 0.5452281832695007       \n",
      "train step #580 accuracy: 0.8125, loss: 0.6869325041770935       \n",
      "train step #581 accuracy:  0.75, loss: 0.6934291124343872       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #582 accuracy:  0.75, loss: 0.7426272630691528       \n",
      "train step #583 accuracy: 0.8125, loss: 0.6042454242706299       \n",
      "train step #584 accuracy: 0.90625, loss: 0.30631110072135925      \n",
      "train step #585 accuracy: 0.859375, loss: 0.39225053787231445      \n",
      "train step #586 accuracy: 0.796875, loss: 0.6309025287628174       \n",
      "train step #587 accuracy: 0.84375, loss: 0.49928557872772217      \n",
      "train step #588 accuracy: 0.765625, loss: 0.7556442618370056       \n",
      "train step #589 accuracy: 0.875, loss: 0.49124133586883545      \n",
      "train step #590 accuracy: 0.796875, loss: 0.528489887714386        \n",
      "train step #591 accuracy: 0.8125, loss: 0.5292081832885742       \n",
      "train step #592 accuracy: 0.84375, loss: 0.6959702968597412       \n",
      "train step #593 accuracy: 0.828125, loss: 0.5038726925849915       \n",
      "train step #594 accuracy: 0.859375, loss: 0.5226267576217651       \n",
      "train step #595 accuracy: 0.828125, loss: 0.7122702598571777       \n",
      "train step #596 accuracy: 0.90625, loss: 0.3491179645061493       \n",
      "train step #597 accuracy: 0.8125, loss: 0.4826991856098175       \n",
      "train step #598 accuracy: 0.8125, loss: 0.570740818977356        \n",
      "train step #599 accuracy: 0.890625, loss: 0.38989758491516113      \n",
      "train step #600 accuracy: 0.828125, loss: 0.5093517899513245       \n",
      "train step #601 accuracy: 0.84375, loss: 0.4674984812736511       \n",
      "train step #602 accuracy: 0.859375, loss: 0.5181454420089722       \n",
      "train step #603 accuracy: 0.859375, loss: 0.4283026456832886       \n",
      "train step #604 accuracy: 0.78125, loss: 0.6617414951324463       \n",
      "train step #605 accuracy: 0.671875, loss: 0.9175143241882324       \n",
      "train step #606 accuracy: 0.84375, loss: 0.6218555569648743       \n",
      "train step #607 accuracy: 0.84375, loss: 0.5474795699119568       \n",
      "train step #608 accuracy: 0.796875, loss: 0.6290979385375977       \n",
      "train step #609 accuracy: 0.734375, loss: 0.6730301380157471       \n",
      "train step #610 accuracy: 0.84375, loss: 0.5017023086547852       \n",
      "train step #611 accuracy: 0.828125, loss: 0.38143670558929443      \n",
      "train step #612 accuracy: 0.890625, loss: 0.42603060603141785      \n",
      "train step #613 accuracy: 0.84375, loss: 0.37042227387428284      \n",
      "train step #614 accuracy: 0.828125, loss: 0.6362196803092957       \n",
      "train step #615 accuracy: 0.921875, loss: 0.3004962205886841       \n",
      "train step #616 accuracy: 0.859375, loss: 0.35473620891571045      \n",
      "train step #617 accuracy: 0.890625, loss: 0.4027717113494873       \n",
      "train step #618 accuracy: 0.859375, loss: 0.5340606570243835       \n",
      "train step #619 accuracy: 0.890625, loss: 0.37305718660354614      \n",
      "train step #620 accuracy: 0.84375, loss: 0.4452105760574341       \n",
      "train step #621 accuracy: 0.828125, loss: 0.5581364035606384       \n",
      "train step #622 accuracy: 0.765625, loss: 0.7323375940322876       \n",
      "train step #623 accuracy: 0.84375, loss: 0.5896306037902832       \n",
      "train step #624 accuracy: 0.8125, loss: 0.4874182939529419       \n",
      "train step #625 accuracy: 0.859375, loss: 0.60371994972229         \n",
      "train step #626 accuracy: 0.875, loss: 0.6296024322509766       \n",
      "train step #627 accuracy: 0.859375, loss: 0.35637837648391724      \n",
      "train step #628 accuracy: 0.859375, loss: 0.529806911945343        \n",
      "train step #629 accuracy: 0.84375, loss: 0.48599064350128174      \n",
      "train step #630 accuracy: 0.890625, loss: 0.42049920558929443      \n",
      "train step #631 accuracy: 0.890625, loss: 0.317290723323822        \n",
      "train step #632 accuracy: 0.828125, loss: 0.48425137996673584      \n",
      "train step #633 accuracy: 0.859375, loss: 0.47342002391815186      \n",
      "train step #634 accuracy: 0.875, loss: 0.48817387223243713      \n",
      "train step #635 accuracy: 0.859375, loss: 0.424099326133728        \n",
      "train step #636 accuracy: 0.90625, loss: 0.33337584137916565      \n",
      "train step #637 accuracy: 0.84375, loss: 0.471145361661911        \n",
      "train step #638 accuracy: 0.8125, loss: 0.5306996703147888       \n",
      "train step #639 accuracy: 0.859375, loss: 0.4132910668849945       \n",
      "train step #640 accuracy: 0.8125, loss: 0.4273608922958374       \n",
      "train step #641 accuracy: 0.84375, loss: 0.5538119673728943       \n",
      "train step #642 accuracy: 0.859375, loss: 0.49156659841537476      \n",
      "train step #643 accuracy: 0.890625, loss: 0.3863905072212219       \n",
      "train step #644 accuracy: 0.90625, loss: 0.36820292472839355      \n",
      "train step #645 accuracy: 0.84375, loss: 0.45185381174087524      \n",
      "train step #646 accuracy: 0.875, loss: 0.46258142590522766      \n",
      "train step #647 accuracy: 0.796875, loss: 0.5901387929916382       \n",
      "train step #648 accuracy: 0.875, loss: 0.45305100083351135      \n",
      "train step #649 accuracy: 0.8125, loss: 0.4946590065956116       \n",
      "train step #650 accuracy: 0.828125, loss: 0.4823751151561737       \n",
      "train step #651 accuracy: 0.796875, loss: 0.603513777256012        \n",
      "train step #652 accuracy: 0.8125, loss: 0.5750155448913574       \n",
      "train step #653 accuracy: 0.859375, loss: 0.39240407943725586      \n",
      "train step #654 accuracy: 0.9375, loss: 0.33259546756744385      \n",
      "train step #655 accuracy: 0.859375, loss: 0.38281482458114624      \n",
      "train step #656 accuracy: 0.875, loss: 0.5233542919158936       \n",
      "train step #657 accuracy: 0.90625, loss: 0.33601459860801697      \n",
      "train step #658 accuracy: 0.828125, loss: 0.4907374680042267       \n",
      "train step #659 accuracy: 0.8125, loss: 0.55256587266922         \n",
      "train step #660 accuracy: 0.890625, loss: 0.35833147168159485      \n",
      "train step #661 accuracy: 0.84375, loss: 0.49553731083869934      \n",
      "train step #662 accuracy: 0.8125, loss: 0.5588703155517578       \n",
      "train step #663 accuracy: 0.875, loss: 0.386809766292572        \n",
      "train step #664 accuracy: 0.875, loss: 0.3429602086544037       \n",
      "train step #665 accuracy: 0.84375, loss: 0.5332620739936829       \n",
      "train step #666 accuracy: 0.890625, loss: 0.4049208164215088       \n",
      "train step #667 accuracy: 0.90625, loss: 0.40677523612976074      \n",
      "train step #668 accuracy: 0.796875, loss: 0.7007884383201599       \n",
      "train step #669 accuracy: 0.859375, loss: 0.3987511396408081       \n",
      "train step #670 accuracy: 0.796875, loss: 0.690808892250061        \n",
      "train step #671 accuracy: 0.84375, loss: 0.438006728887558        \n",
      "train step #672 accuracy: 0.875, loss: 0.3497926592826843       \n",
      "train step #673 accuracy: 0.875, loss: 0.4735851287841797       \n",
      "train step #674 accuracy: 0.890625, loss: 0.3843153417110443       \n",
      "train step #675 accuracy: 0.84375, loss: 0.41980597376823425      \n",
      "train step #676 accuracy: 0.828125, loss: 0.5220354795455933       \n",
      "train step #677 accuracy: 0.859375, loss: 0.5430284738540649       \n",
      "train step #678 accuracy: 0.859375, loss: 0.4677976071834564       \n",
      "train step #679 accuracy: 0.90625, loss: 0.3573586940765381       \n",
      "train step #680 accuracy: 0.875, loss: 0.36445096135139465      \n",
      "train step #681 accuracy: 0.90625, loss: 0.33933886885643005      \n",
      "train step #682 accuracy: 0.796875, loss: 0.5676628351211548       \n",
      "train step #683 accuracy: 0.953125, loss: 0.20429250597953796      \n",
      "train step #684 accuracy: 0.796875, loss: 0.5615139007568359       \n",
      "train step #685 accuracy: 0.9375, loss: 0.28383058309555054      \n",
      "train step #686 accuracy: 0.875, loss: 0.419761061668396        \n",
      "train step #687 accuracy: 0.90625, loss: 0.4350478947162628       \n",
      "train step #688 accuracy: 0.859375, loss: 0.47277843952178955      \n",
      "train step #689 accuracy: 0.859375, loss: 0.540416955947876        \n",
      "train step #690 accuracy: 0.859375, loss: 0.4379897713661194       \n",
      "train step #691 accuracy: 0.953125, loss: 0.19625945389270782      \n",
      "train step #692 accuracy: 0.78125, loss: 0.5729044079780579       \n",
      "train step #693 accuracy: 0.765625, loss: 0.6580618619918823       \n",
      "train step #694 accuracy: 0.9375, loss: 0.1899891197681427       \n",
      "dev accuracy: 0.8125, loss: 0.6084704399108887       \n",
      "dev accuracy: 0.8125, loss: 0.8369736671447754       \n",
      "dev accuracy: 0.9375, loss: 0.4623561501502991       \n",
      "dev accuracy: 0.875, loss: 0.43123751878738403      \n",
      "dev accuracy: 0.9375, loss: 0.19434577226638794      \n",
      "dev accuracy: 0.8125, loss: 0.3532089293003082       \n",
      "dev accuracy: 0.6875, loss: 1.1387746334075928       \n",
      "dev accuracy: 0.8125, loss: 0.2771267294883728       \n",
      "dev accuracy: 0.875, loss: 0.7359896898269653       \n",
      "dev accuracy:  0.75, loss: 0.7055332064628601       \n",
      "dev accuracy: 0.9375, loss: 0.17340487241744995      \n",
      "dev accuracy: 0.8125, loss: 0.5725976228713989       \n",
      "dev accuracy:   1.0, loss: 0.09954068064689636      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy: 0.875, loss: 0.3237675726413727       \n",
      "dev accuracy: 0.875, loss: 0.3418372571468353       \n",
      "dev accuracy: 0.9375, loss: 0.3483610451221466       \n",
      "dev accuracy: 0.875, loss: 0.49154767394065857      \n",
      "dev accuracy: 0.875, loss: 0.4506339132785797       \n",
      "dev accuracy:  0.75, loss: 0.5983823537826538       \n",
      "dev accuracy: 0.9375, loss: 0.36624225974082947      \n",
      "dev accuracy: 0.875, loss: 0.4401472210884094       \n",
      "dev accuracy: 0.875, loss: 0.31067901849746704      \n",
      "dev accuracy:   1.0, loss: 0.21311646699905396      \n",
      "dev accuracy: 0.8125, loss: 0.6689149141311646       \n",
      "dev accuracy: 0.9375, loss: 0.15862426161766052      \n",
      "dev accuracy:  0.75, loss: 0.6081251502037048       \n",
      "dev accuracy:  0.75, loss: 0.48125046491622925      \n",
      "dev accuracy: 0.8125, loss: 0.37910744547843933      \n",
      "dev accuracy: 0.8125, loss: 0.41911160945892334      \n",
      "dev accuracy: 0.625, loss: 1.1301543712615967       \n",
      "dev accuracy: 0.8125, loss: 0.5299848914146423       \n",
      "dev accuracy: 0.8125, loss: 0.4206528663635254       \n",
      "dev accuracy: 0.6875, loss: 0.9295375943183899       \n",
      "dev accuracy: 0.8125, loss: 0.4503074288368225       \n",
      "dev accuracy: 0.875, loss: 0.5547876358032227       \n",
      "dev accuracy:   1.0, loss: 0.03333723545074463      \n",
      "dev accuracy: 0.9375, loss: 0.22320698201656342      \n",
      "dev accuracy: 0.875, loss: 0.20177105069160461      \n",
      "dev accuracy: 0.9375, loss: 0.34338662028312683      \n",
      "dev accuracy: 0.6875, loss: 0.5155322551727295       \n",
      "dev accuracy: 0.9375, loss: 0.26614129543304443      \n",
      "dev accuracy: 0.875, loss: 0.36095279455184937      \n",
      "dev accuracy: 0.8125, loss: 0.8448194265365601       \n",
      "dev accuracy: 0.875, loss: 0.43498894572257996      \n",
      "dev accuracy: 0.8125, loss: 0.5034987926483154       \n",
      "dev accuracy: 0.6875, loss: 0.6747646331787109       \n",
      "dev accuracy: 0.875, loss: 0.6205413937568665       \n",
      "dev accuracy: 0.9375, loss: 0.3508634567260742       \n",
      "dev accuracy: 0.5625, loss: 1.2503618001937866       \n",
      "dev accuracy: 0.6875, loss: 0.8779888153076172       \n",
      "dev accuracy:  0.75, loss: 1.0568149089813232       \n",
      "dev accuracy: 0.6875, loss: 0.7502078413963318       \n",
      "dev accuracy: 0.9375, loss: 0.20028460025787354      \n",
      "dev accuracy:   1.0, loss: 0.1591128706932068       \n",
      "dev accuracy: 0.9375, loss: 0.2902209162712097       \n",
      "dev accuracy: 0.9375, loss: 0.367565780878067        \n",
      "dev accuracy: 0.875, loss: 0.34086212515830994      \n",
      "dev accuracy: 0.875, loss: 0.45419421792030334      \n",
      "dev accuracy:   1.0, loss: 0.15991508960723877      \n",
      "dev accuracy: 0.9375, loss: 0.11321547627449036      \n",
      "dev accuracy: 0.875, loss: 0.32426637411117554      \n",
      "dev accuracy: 0.875, loss: 0.33442604541778564      \n",
      "dev accuracy: 0.8125, loss: 0.43628281354904175      \n",
      "dev accuracy: 0.9375, loss: 0.3234860897064209       \n",
      "dev accuracy: 0.875, loss: 0.39508751034736633      \n",
      "dev accuracy: 0.875, loss: 0.352823942899704        \n",
      "dev accuracy: 0.6875, loss: 0.8467769622802734       \n",
      "dev accuracy: 0.9375, loss: 0.24867549538612366      \n",
      "dev accuracy: 0.875, loss: 0.5145826935768127       \n",
      "dev accuracy: 0.9375, loss: 0.3807966411113739       \n",
      "dev accuracy:   1.0, loss: 0.0755387544631958       \n",
      "dev accuracy:   1.0, loss: 0.18927684426307678      \n",
      "dev accuracy: 0.8125, loss: 0.7034257650375366       \n",
      "dev accuracy: 0.8125, loss: 0.5795326232910156       \n",
      "dev accuracy: 0.875, loss: 0.47476786375045776      \n",
      "dev accuracy: 0.8125, loss: 0.6196600198745728       \n",
      "dev accuracy: 0.875, loss: 0.3089595437049866       \n",
      "dev accuracy: 0.875, loss: 0.2715607285499573       \n",
      "dev accuracy: 0.875, loss: 0.5329244136810303       \n",
      "dev accuracy: 0.9375, loss: 0.31580179929733276      \n",
      "dev accuracy: 0.875, loss: 0.5734236836433411       \n",
      "dev accuracy: 0.9375, loss: 0.34091657400131226      \n",
      "dev accuracy: 0.9375, loss: 0.17421257495880127      \n",
      "dev accuracy:   1.0, loss: 0.16862699389457703      \n",
      "dev accuracy: 0.875, loss: 0.34643101692199707      \n",
      "dev accuracy: 0.8125, loss: 0.37062522768974304      \n",
      "dev accuracy: 0.8125, loss: 0.47796007990837097      \n",
      "dev accuracy: 0.8125, loss: 0.4072406589984894       \n",
      "dev accuracy: 0.875, loss: 0.34454846382141113      \n",
      "dev accuracy: 0.875, loss: 0.434553861618042        \n",
      "dev accuracy: 0.875, loss: 0.4193510115146637       \n",
      "dev accuracy: 0.875, loss: 0.750157356262207        \n",
      "dev accuracy:   1.0, loss: 0.1451110988855362       \n",
      "dev accuracy: 0.9375, loss: 0.24381539225578308      \n",
      "dev accuracy: 0.9375, loss: 0.38484498858451843      \n",
      "dev accuracy:   1.0, loss: 0.10698863863945007      \n",
      "dev accuracy: 0.8125, loss: 0.6237283945083618       \n",
      "dev accuracy: 0.9375, loss: 0.21792519092559814      \n",
      "dev accuracy: 0.9375, loss: 0.12497258186340332      \n",
      "dev accuracy:   1.0, loss: 0.1297987997531891       \n",
      "dev accuracy: 0.625, loss: 0.925957441329956        \n",
      "dev accuracy: 0.875, loss: 0.34753498435020447      \n",
      "dev accuracy: 0.875, loss: 0.4497162401676178       \n",
      "dev accuracy: 0.9375, loss: 0.12836849689483643      \n",
      "dev accuracy: 0.8125, loss: 0.7825037240982056       \n",
      "dev accuracy:  0.75, loss: 0.709502637386322        \n",
      "dev accuracy: 0.875, loss: 0.3145533800125122       \n",
      "dev accuracy: 0.9375, loss: 0.19233624637126923      \n",
      "dev accuracy: 0.8125, loss: 0.3593815267086029       \n",
      "dev accuracy: 0.875, loss: 0.3346599042415619       \n",
      "dev accuracy:  0.75, loss: 0.824233889579773        \n",
      "dev accuracy: 0.875, loss: 0.3065028786659241       \n",
      "dev accuracy: 0.9375, loss: 0.11068642139434814      \n",
      "dev accuracy: 0.9375, loss: 0.16320520639419556      \n",
      "dev accuracy: 0.9375, loss: 0.2235775738954544       \n",
      "dev accuracy: 0.8125, loss: 0.4644390046596527       \n",
      "dev accuracy: 0.8125, loss: 0.916645348072052        \n",
      "dev accuracy:   1.0, loss: 0.2042873203754425       \n",
      "dev accuracy:   1.0, loss: 0.06886264681816101      \n",
      "dev accuracy:  0.75, loss: 0.7272772192955017       \n",
      "dev accuracy: 0.875, loss: 0.4266270697116852       \n",
      "dev accuracy: 0.9375, loss: 0.10762837529182434      \n",
      "dev accuracy:   1.0, loss: 0.08749935030937195      \n",
      "dev accuracy: 0.9375, loss: 0.26668986678123474      \n",
      "dev accuracy: 0.8125, loss: 0.6600591540336609       \n",
      "dev accuracy: 0.9375, loss: 0.22470110654830933      \n",
      "dev accuracy: 0.9375, loss: 0.36859607696533203      \n",
      "dev accuracy: 0.8125, loss: 0.4165404140949249       \n",
      "dev accuracy: 0.8125, loss: 0.5652399063110352       \n",
      "dev accuracy: 0.8125, loss: 0.7381550073623657       \n",
      "dev accuracy: 0.875, loss: 0.39258888363838196      \n",
      "dev accuracy: 0.9375, loss: 0.36485886573791504      \n",
      "dev accuracy:   1.0, loss: 0.09097960591316223      \n",
      "dev accuracy: 0.875, loss: 0.19917252659797668      \n",
      "dev accuracy: 0.8125, loss: 0.6418536901473999       \n",
      "dev accuracy:  0.75, loss: 0.8148341774940491       \n",
      "dev accuracy:   1.0, loss: 0.10191234946250916      \n",
      "dev accuracy: 0.875, loss: 0.3105182945728302       \n",
      "dev accuracy: 0.8125, loss: 0.5280231833457947       \n",
      "dev accuracy:   1.0, loss: 0.1265951693058014       \n",
      "dev accuracy: 0.9375, loss: 0.3007999360561371       \n",
      "dev accuracy: 0.8125, loss: 0.48826077580451965      \n",
      "dev accuracy: 0.9375, loss: 0.15691092610359192      \n",
      "dev accuracy: 0.875, loss: 0.43479669094085693      \n",
      "dev accuracy:   1.0, loss: 0.033503323793411255     \n",
      "dev accuracy: 0.8125, loss: 0.3370485305786133       \n",
      "dev accuracy: 0.9375, loss: 0.15371555089950562      \n",
      "dev accuracy: 0.8125, loss: 0.5732425451278687       \n",
      "dev accuracy: 0.875, loss: 0.38189423084259033      \n",
      "dev accuracy: 0.9375, loss: 0.12078085541725159      \n",
      "dev accuracy:  0.75, loss: 0.433115154504776        \n",
      "dev accuracy: 0.8125, loss: 0.7161375880241394       \n",
      "dev accuracy: 0.875, loss: 0.4564511477947235       \n",
      "dev accuracy: 0.8125, loss: 0.349760502576828        \n",
      "dev accuracy: 0.6875, loss: 0.8312340974807739       \n",
      "dev accuracy: 0.8125, loss: 0.28337734937667847      \n",
      "dev accuracy: 0.6875, loss: 1.0936474800109863       \n",
      "dev accuracy: 0.9375, loss: 0.23371897637844086      \n",
      "dev accuracy: 0.8125, loss: 0.4904581308364868       \n",
      "dev accuracy: 0.875, loss: 0.5955651998519897       \n",
      "dev accuracy: 0.875, loss: 0.3182898163795471       \n",
      "dev accuracy: 0.8125, loss: 0.41846126317977905      \n",
      "dev accuracy:  0.75, loss: 0.7964637875556946       \n",
      "dev accuracy: 0.875, loss: 0.27438217401504517      \n",
      "dev accuracy:  0.75, loss: 0.5561029314994812       \n",
      "dev accuracy:  0.75, loss: 0.6966564059257507       \n",
      "dev accuracy: 0.8125, loss: 0.5325809717178345       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy:  0.75, loss: 0.7855867147445679       \n",
      "dev accuracy: 0.9375, loss: 0.47214406728744507      \n",
      "dev accuracy: 0.9375, loss: 0.14810220897197723      \n",
      "dev accuracy: 0.9375, loss: 0.2138228416442871       \n",
      "dev accuracy: 0.875, loss: 0.43536248803138733      \n",
      "dev accuracy: 0.8125, loss: 0.4386327266693115       \n",
      "dev accuracy: 0.8125, loss: 0.5777715444564819       \n",
      "dev accuracy: 0.875, loss: 0.5499103665351868       \n",
      "dev accuracy: 0.9375, loss: 0.3005184233188629       \n",
      "dev accuracy:   1.0, loss: 0.08977630734443665      \n",
      "dev accuracy: 0.8125, loss: 0.4867893159389496       \n",
      "dev accuracy: 0.9375, loss: 0.25651901960372925      \n",
      "dev accuracy: 0.8125, loss: 0.4921709895133972       \n",
      "dev accuracy: 0.8125, loss: 0.5077401399612427       \n",
      "dev accuracy:  0.75, loss: 0.9920893311500549       \n",
      "dev accuracy: 0.875, loss: 0.4165487587451935       \n",
      "dev accuracy: 0.8125, loss: 0.7027818560600281       \n",
      "dev accuracy:   1.0, loss: 0.12817656993865967      \n",
      "dev accuracy:   1.0, loss: 0.11649350821971893      \n",
      "dev accuracy: 0.8125, loss: 0.352167546749115        \n",
      "dev accuracy: 0.875, loss: 0.3658411502838135       \n",
      "dev accuracy: 0.875, loss: 0.41409921646118164      \n",
      "dev accuracy: 0.875, loss: 0.30162984132766724      \n",
      "dev accuracy: 0.8125, loss: 0.5418363809585571       \n",
      "dev accuracy: 0.875, loss: 0.345698744058609        \n",
      "dev accuracy: 0.9375, loss: 0.2220693826675415       \n",
      "dev accuracy: 0.6666666666666666, loss: 0.36764922738075256      \n",
      "final dev accuracy: 0.8639390034364263\n",
      "saving best model...\n",
      "train step #695 accuracy: 0.890625, loss: 0.3592003285884857       \n",
      "train step #696 accuracy: 0.796875, loss: 0.6195557713508606       \n",
      "train step #697 accuracy: 0.84375, loss: 0.524465799331665        \n",
      "train step #698 accuracy: 0.875, loss: 0.40531980991363525      \n",
      "train step #699 accuracy: 0.84375, loss: 0.47390249371528625      \n",
      "train step #700 accuracy: 0.875, loss: 0.5987256765365601       \n",
      "train step #701 accuracy: 0.8125, loss: 0.5922820568084717       \n",
      "train step #702 accuracy: 0.859375, loss: 0.37663960456848145      \n",
      "train step #703 accuracy: 0.796875, loss: 0.6394594311714172       \n",
      "train step #704 accuracy: 0.921875, loss: 0.3703324794769287       \n",
      "train step #705 accuracy: 0.953125, loss: 0.22147825360298157      \n",
      "train step #706 accuracy: 0.875, loss: 0.5013365745544434       \n",
      "train step #707 accuracy: 0.890625, loss: 0.4410392940044403       \n",
      "train step #708 accuracy: 0.84375, loss: 0.5664241313934326       \n",
      "train step #709 accuracy: 0.890625, loss: 0.3063269853591919       \n",
      "train step #710 accuracy: 0.90625, loss: 0.3533002734184265       \n",
      "train step #711 accuracy: 0.859375, loss: 0.3901074230670929       \n",
      "train step #712 accuracy: 0.84375, loss: 0.6881227493286133       \n",
      "train step #713 accuracy: 0.859375, loss: 0.4309988021850586       \n",
      "train step #714 accuracy: 0.890625, loss: 0.37103307247161865      \n",
      "train step #715 accuracy: 0.828125, loss: 0.5584303736686707       \n",
      "train step #716 accuracy: 0.828125, loss: 0.48043665289878845      \n",
      "train step #717 accuracy: 0.875, loss: 0.26980099081993103      \n",
      "train step #718 accuracy: 0.921875, loss: 0.30702877044677734      \n",
      "train step #719 accuracy: 0.875, loss: 0.3252373933792114       \n",
      "train step #720 accuracy: 0.859375, loss: 0.4236264228820801       \n",
      "train step #721 accuracy: 0.875, loss: 0.4009789824485779       \n",
      "train step #722 accuracy: 0.90625, loss: 0.4957078993320465       \n",
      "train step #723 accuracy: 0.859375, loss: 0.3930184841156006       \n",
      "train step #724 accuracy: 0.859375, loss: 0.42806434631347656      \n",
      "train step #725 accuracy: 0.828125, loss: 0.5161607265472412       \n",
      "train step #726 accuracy: 0.953125, loss: 0.29911181330680847      \n",
      "train step #727 accuracy: 0.875, loss: 0.4554562568664551       \n",
      "train step #728 accuracy: 0.84375, loss: 0.5159589648246765       \n",
      "train step #729 accuracy: 0.90625, loss: 0.34647369384765625      \n",
      "train step #730 accuracy: 0.8125, loss: 0.47294384241104126      \n",
      "train step #731 accuracy: 0.734375, loss: 0.6929528713226318       \n",
      "train step #732 accuracy: 0.921875, loss: 0.33288025856018066      \n",
      "train step #733 accuracy: 0.828125, loss: 0.6224713325500488       \n",
      "train step #734 accuracy: 0.90625, loss: 0.32621675729751587      \n",
      "train step #735 accuracy: 0.796875, loss: 0.6463152766227722       \n",
      "train step #736 accuracy: 0.84375, loss: 0.500770092010498        \n",
      "train step #737 accuracy: 0.859375, loss: 0.4317163825035095       \n",
      "train step #738 accuracy: 0.90625, loss: 0.3798521161079407       \n",
      "train step #739 accuracy: 0.90625, loss: 0.36352235078811646      \n",
      "train step #740 accuracy: 0.890625, loss: 0.3313137888908386       \n",
      "train step #741 accuracy: 0.890625, loss: 0.4281964898109436       \n",
      "train step #742 accuracy: 0.71875, loss: 0.8196871876716614       \n",
      "train step #743 accuracy: 0.859375, loss: 0.4594860076904297       \n",
      "train step #744 accuracy: 0.90625, loss: 0.3800007402896881       \n",
      "train step #745 accuracy: 0.8125, loss: 0.6161434054374695       \n",
      "train step #746 accuracy: 0.859375, loss: 0.543811559677124        \n",
      "train step #747 accuracy: 0.90625, loss: 0.2715086042881012       \n",
      "train step #748 accuracy: 0.890625, loss: 0.4545992612838745       \n",
      "train step #749 accuracy: 0.8125, loss: 0.4708148241043091       \n",
      "train step #750 accuracy: 0.9375, loss: 0.23525792360305786      \n",
      "train step #751 accuracy: 0.875, loss: 0.4513879716396332       \n",
      "train step #752 accuracy: 0.890625, loss: 0.33309704065322876      \n",
      "train step #753 accuracy: 0.9375, loss: 0.31559115648269653      \n",
      "train step #754 accuracy: 0.875, loss: 0.41411668062210083      \n",
      "train step #755 accuracy: 0.8125, loss: 0.4550882875919342       \n",
      "train step #756 accuracy: 0.875, loss: 0.5058974027633667       \n",
      "train step #757 accuracy: 0.921875, loss: 0.3520227074623108       \n",
      "train step #758 accuracy: 0.890625, loss: 0.31438684463500977      \n",
      "train step #759 accuracy: 0.921875, loss: 0.22992850840091705      \n",
      "train step #760 accuracy: 0.90625, loss: 0.3784220218658447       \n",
      "train step #761 accuracy: 0.90625, loss: 0.20414116978645325      \n",
      "train step #762 accuracy: 0.90625, loss: 0.25024184584617615      \n",
      "train step #763 accuracy: 0.921875, loss: 0.2700456380844116       \n",
      "train step #764 accuracy: 0.828125, loss: 0.5895475149154663       \n",
      "train step #765 accuracy: 0.78125, loss: 0.5595833659172058       \n",
      "train step #766 accuracy: 0.84375, loss: 0.5428851246833801       \n",
      "train step #767 accuracy: 0.875, loss: 0.3739672601222992       \n",
      "train step #768 accuracy: 0.890625, loss: 0.3459671437740326       \n",
      "train step #769 accuracy: 0.84375, loss: 0.6687874794006348       \n",
      "train step #770 accuracy: 0.921875, loss: 0.2925458252429962       \n",
      "train step #771 accuracy: 0.90625, loss: 0.3267453908920288       \n",
      "train step #772 accuracy:  0.75, loss: 0.7754701972007751       \n",
      "train step #773 accuracy: 0.859375, loss: 0.49656665325164795      \n",
      "train step #774 accuracy: 0.875, loss: 0.4951036274433136       \n",
      "train step #775 accuracy: 0.875, loss: 0.4028290808200836       \n",
      "train step #776 accuracy: 0.890625, loss: 0.3793095052242279       \n",
      "train step #777 accuracy: 0.84375, loss: 0.49466362595558167      \n",
      "train step #778 accuracy: 0.890625, loss: 0.4079267978668213       \n",
      "train step #779 accuracy: 0.9375, loss: 0.29079124331474304      \n",
      "train step #780 accuracy: 0.90625, loss: 0.2788454294204712       \n",
      "train step #781 accuracy: 0.890625, loss: 0.3725205063819885       \n",
      "train step #782 accuracy: 0.84375, loss: 0.6212820410728455       \n",
      "train step #783 accuracy: 0.90625, loss: 0.3542124629020691       \n",
      "train step #784 accuracy: 0.796875, loss: 0.5954927802085876       \n",
      "train step #785 accuracy: 0.796875, loss: 0.45076650381088257      \n",
      "train step #786 accuracy: 0.875, loss: 0.3517734706401825       \n",
      "train step #787 accuracy: 0.84375, loss: 0.3697759509086609       \n",
      "train step #788 accuracy: 0.875, loss: 0.3906223475933075       \n",
      "train step #789 accuracy: 0.828125, loss: 0.4784930348396301       \n",
      "train step #790 accuracy: 0.90625, loss: 0.35303065180778503      \n",
      "train step #791 accuracy: 0.890625, loss: 0.32867953181266785      \n",
      "train step #792 accuracy: 0.890625, loss: 0.43694978952407837      \n",
      "train step #793 accuracy: 0.875, loss: 0.5196486115455627       \n",
      "train step #794 accuracy: 0.90625, loss: 0.38812780380249023      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #795 accuracy: 0.875, loss: 0.4300798773765564       \n",
      "train step #796 accuracy: 0.828125, loss: 0.47023075819015503      \n",
      "train step #797 accuracy: 0.859375, loss: 0.44225990772247314      \n",
      "train step #798 accuracy: 0.828125, loss: 0.5496166944503784       \n",
      "train step #799 accuracy: 0.828125, loss: 0.41226160526275635      \n",
      "train step #800 accuracy: 0.828125, loss: 0.45089051127433777      \n",
      "train step #801 accuracy: 0.8125, loss: 0.5296439528465271       \n",
      "train step #802 accuracy: 0.890625, loss: 0.31095290184020996      \n",
      "train step #803 accuracy: 0.796875, loss: 0.6017547845840454       \n",
      "train step #804 accuracy: 0.890625, loss: 0.3610886037349701       \n",
      "train step #805 accuracy: 0.921875, loss: 0.26930898427963257      \n",
      "train step #806 accuracy: 0.921875, loss: 0.2654650807380676       \n",
      "train step #807 accuracy: 0.875, loss: 0.3787534236907959       \n",
      "train step #808 accuracy: 0.90625, loss: 0.2744883596897125       \n",
      "train step #809 accuracy: 0.828125, loss: 0.6665169596672058       \n",
      "train step #810 accuracy: 0.9375, loss: 0.18547594547271729      \n",
      "train step #811 accuracy: 0.875, loss: 0.2927152216434479       \n",
      "train step #812 accuracy: 0.96875, loss: 0.12299850583076477      \n",
      "train step #813 accuracy: 0.859375, loss: 0.47316211462020874      \n",
      "train step #814 accuracy: 0.859375, loss: 0.3514399528503418       \n",
      "train step #815 accuracy: 0.90625, loss: 0.3023647964000702       \n",
      "train step #816 accuracy: 0.90625, loss: 0.3236859440803528       \n",
      "train step #817 accuracy: 0.828125, loss: 0.5275942087173462       \n",
      "train step #818 accuracy: 0.796875, loss: 0.6156160831451416       \n",
      "train step #819 accuracy: 0.875, loss: 0.46512335538864136      \n",
      "train step #820 accuracy: 0.9375, loss: 0.29104143381118774      \n",
      "train step #821 accuracy: 0.890625, loss: 0.3330990672111511       \n",
      "train step #822 accuracy: 0.953125, loss: 0.33899250626564026      \n",
      "train step #823 accuracy: 0.890625, loss: 0.3258599638938904       \n",
      "train step #824 accuracy: 0.90625, loss: 0.42686203122138977      \n",
      "train step #825 accuracy: 0.96875, loss: 0.1516038179397583       \n",
      "train step #826 accuracy: 0.875, loss: 0.3724077045917511       \n",
      "train step #827 accuracy: 0.8125, loss: 0.5968738794326782       \n",
      "train step #828 accuracy: 0.890625, loss: 0.2833459675312042       \n",
      "train step #829 accuracy: 0.90625, loss: 0.3191085159778595       \n",
      "train step #830 accuracy: 0.84375, loss: 0.3770548403263092       \n",
      "train step #831 accuracy: 0.921875, loss: 0.2548668682575226       \n",
      "train step #832 accuracy: 0.921875, loss: 0.20029085874557495      \n",
      "train step #833 accuracy: 0.84375, loss: 0.44563058018684387      \n",
      "train step #834 accuracy: 0.828125, loss: 0.42649775743484497      \n",
      "train step #835 accuracy: 0.890625, loss: 0.3216415047645569       \n",
      "train step #836 accuracy: 0.84375, loss: 0.6539112329483032       \n",
      "train step #837 accuracy: 0.890625, loss: 0.3188527226448059       \n",
      "train step #838 accuracy: 0.78125, loss: 0.5893073678016663       \n",
      "train step #839 accuracy: 0.84375, loss: 0.6310408711433411       \n",
      "train step #840 accuracy: 0.9375, loss: 0.2010849565267563       \n",
      "train step #841 accuracy: 0.859375, loss: 0.44594526290893555      \n",
      "train step #842 accuracy: 0.828125, loss: 0.4633944630622864       \n",
      "train step #843 accuracy: 0.78125, loss: 0.78005051612854         \n",
      "train step #844 accuracy: 0.953125, loss: 0.23609302937984467      \n",
      "train step #845 accuracy: 0.890625, loss: 0.4006149172782898       \n",
      "train step #846 accuracy: 0.84375, loss: 0.4104998707771301       \n",
      "train step #847 accuracy: 0.828125, loss: 0.4535885155200958       \n",
      "train step #848 accuracy: 0.8125, loss: 0.6148746013641357       \n",
      "train step #849 accuracy: 0.875, loss: 0.3497437536716461       \n",
      "train step #850 accuracy: 0.890625, loss: 0.32362326979637146      \n",
      "train step #851 accuracy: 0.96875, loss: 0.17536687850952148      \n",
      "train step #852 accuracy: 0.8125, loss: 0.5054148435592651       \n",
      "train step #853 accuracy: 0.84375, loss: 0.4570944011211395       \n",
      "train step #854 accuracy: 0.84375, loss: 0.37321344017982483      \n",
      "train step #855 accuracy: 0.828125, loss: 0.4420822262763977       \n",
      "train step #856 accuracy: 0.921875, loss: 0.2757152318954468       \n",
      "train step #857 accuracy: 0.890625, loss: 0.3941298723220825       \n",
      "train step #858 accuracy: 0.875, loss: 0.4186752438545227       \n",
      "train step #859 accuracy: 0.875, loss: 0.5292998552322388       \n",
      "train step #860 accuracy: 0.890625, loss: 0.3258976936340332       \n",
      "train step #861 accuracy: 0.84375, loss: 0.46594706177711487      \n",
      "train step #862 accuracy: 0.84375, loss: 0.4237837791442871       \n",
      "train step #863 accuracy: 0.890625, loss: 0.3506224751472473       \n",
      "train step #864 accuracy: 0.921875, loss: 0.27357709407806396      \n",
      "train step #865 accuracy: 0.921875, loss: 0.27374473214149475      \n",
      "train step #866 accuracy: 0.828125, loss: 0.536805272102356        \n",
      "train step #867 accuracy: 0.84375, loss: 0.35704174637794495      \n",
      "train step #868 accuracy: 0.890625, loss: 0.5218549370765686       \n",
      "train step #869 accuracy: 0.84375, loss: 0.5043447613716125       \n",
      "train step #870 accuracy: 0.84375, loss: 0.4455244839191437       \n",
      "train step #871 accuracy: 0.90625, loss: 0.32209527492523193      \n",
      "train step #872 accuracy: 0.921875, loss: 0.28572291135787964      \n",
      "train step #873 accuracy: 0.84375, loss: 0.4684768319129944       \n",
      "train step #874 accuracy: 0.828125, loss: 0.5145137310028076       \n",
      "train step #875 accuracy: 0.84375, loss: 0.56378173828125         \n",
      "train step #876 accuracy: 0.78125, loss: 0.5865681171417236       \n",
      "train step #877 accuracy: 0.90625, loss: 0.4310115575790405       \n",
      "train step #878 accuracy: 0.859375, loss: 0.44188788533210754      \n",
      "train step #879 accuracy: 0.90625, loss: 0.33700859546661377      \n",
      "train step #880 accuracy: 0.796875, loss: 0.5498005151748657       \n",
      "train step #881 accuracy: 0.921875, loss: 0.36441195011138916      \n",
      "train step #882 accuracy: 0.875, loss: 0.4730493426322937       \n",
      "train step #883 accuracy: 0.921875, loss: 0.35124364495277405      \n",
      "train step #884 accuracy: 0.84375, loss: 0.4908020794391632       \n",
      "train step #885 accuracy: 0.875, loss: 0.4439549148082733       \n",
      "train step #886 accuracy: 0.875, loss: 0.47413909435272217      \n",
      "train step #887 accuracy: 0.84375, loss: 0.45462489128112793      \n",
      "train step #888 accuracy: 0.890625, loss: 0.3561173677444458       \n",
      "train step #889 accuracy: 0.90625, loss: 0.3860950469970703       \n",
      "train step #890 accuracy: 0.828125, loss: 0.4787093698978424       \n",
      "train step #891 accuracy: 0.890625, loss: 0.2877567708492279       \n",
      "train step #892 accuracy: 0.890625, loss: 0.5581724643707275       \n",
      "train step #893 accuracy: 0.875, loss: 0.38440588116645813      \n",
      "train step #894 accuracy: 0.875, loss: 0.3239566385746002       \n",
      "train step #895 accuracy: 0.828125, loss: 0.403110533952713        \n",
      "train step #896 accuracy: 0.9375, loss: 0.2720412015914917       \n",
      "train step #897 accuracy: 0.890625, loss: 0.2726101279258728       \n",
      "train step #898 accuracy: 0.8125, loss: 0.4323350787162781       \n",
      "train step #899 accuracy: 0.859375, loss: 0.4738003611564636       \n",
      "train step #900 accuracy: 0.78125, loss: 0.7435066103935242       \n",
      "train step #901 accuracy: 0.84375, loss: 0.4374687671661377       \n",
      "train step #902 accuracy: 0.84375, loss: 0.42959609627723694      \n",
      "train step #903 accuracy: 0.953125, loss: 0.2885291576385498       \n",
      "train step #904 accuracy: 0.828125, loss: 0.5954110026359558       \n",
      "train step #905 accuracy: 0.90625, loss: 0.3442552089691162       \n",
      "train step #906 accuracy: 0.9375, loss: 0.2625868618488312       \n",
      "train step #907 accuracy: 0.84375, loss: 0.37053361535072327      \n",
      "train step #908 accuracy: 0.921875, loss: 0.3015519976615906       \n",
      "train step #909 accuracy: 0.921875, loss: 0.3464512228965759       \n",
      "train step #910 accuracy: 0.875, loss: 0.4070962071418762       \n",
      "train step #911 accuracy: 0.921875, loss: 0.2844732105731964       \n",
      "train step #912 accuracy: 0.890625, loss: 0.30705106258392334      \n",
      "train step #913 accuracy: 0.796875, loss: 0.49333059787750244      \n",
      "train step #914 accuracy: 0.875, loss: 0.44632667303085327      \n",
      "train step #915 accuracy: 0.890625, loss: 0.44408944249153137      \n",
      "train step #916 accuracy: 0.9375, loss: 0.22834113240242004      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #917 accuracy: 0.875, loss: 0.45573586225509644      \n",
      "train step #918 accuracy: 0.84375, loss: 0.49747925996780396      \n",
      "train step #919 accuracy: 0.84375, loss: 0.5419078469276428       \n",
      "train step #920 accuracy: 0.90625, loss: 0.3713459074497223       \n",
      "train step #921 accuracy: 0.890625, loss: 0.3206481337547302       \n",
      "train step #922 accuracy: 0.828125, loss: 0.4395195245742798       \n",
      "train step #923 accuracy: 0.84375, loss: 0.3987141251564026       \n",
      "train step #924 accuracy: 0.9375, loss: 0.17606176435947418      \n",
      "train step #925 accuracy: 0.921875, loss: 0.27387237548828125      \n",
      "train step #926 accuracy: 0.859375, loss: 0.4233781397342682       \n",
      "train step #927 accuracy: 0.90625, loss: 0.35055840015411377      \n",
      "train step #928 accuracy: 0.890625, loss: 0.34047025442123413      \n",
      "train step #929 accuracy: 0.90625, loss: 0.35087624192237854      \n",
      "train step #930 accuracy: 0.875, loss: 0.5025882124900818       \n",
      "train step #931 accuracy: 0.796875, loss: 0.45883050560951233      \n",
      "train step #932 accuracy: 0.84375, loss: 0.509980320930481        \n",
      "train step #933 accuracy: 0.9375, loss: 0.22378361225128174      \n",
      "train step #934 accuracy: 0.890625, loss: 0.45799005031585693      \n",
      "train step #935 accuracy: 0.9375, loss: 0.20545446872711182      \n",
      "train step #936 accuracy: 0.84375, loss: 0.45233336091041565      \n",
      "train step #937 accuracy: 0.859375, loss: 0.46474581956863403      \n",
      "train step #938 accuracy: 0.90625, loss: 0.3754754662513733       \n",
      "train step #939 accuracy: 0.921875, loss: 0.32246655225753784      \n",
      "train step #940 accuracy: 0.890625, loss: 0.3217719793319702       \n",
      "train step #941 accuracy: 0.84375, loss: 0.3801896274089813       \n",
      "train step #942 accuracy: 0.875, loss: 0.4505506753921509       \n",
      "train step #943 accuracy: 0.953125, loss: 0.28089088201522827      \n",
      "train step #944 accuracy: 0.921875, loss: 0.3317987322807312       \n",
      "train step #945 accuracy: 0.890625, loss: 0.3720117211341858       \n",
      "train step #946 accuracy: 0.890625, loss: 0.3441579341888428       \n",
      "train step #947 accuracy: 0.96875, loss: 0.21324509382247925      \n",
      "train step #948 accuracy: 0.84375, loss: 0.6935052871704102       \n",
      "train step #949 accuracy: 0.9375, loss: 0.3066595792770386       \n",
      "train step #950 accuracy: 0.921875, loss: 0.2551206350326538       \n",
      "train step #951 accuracy: 0.90625, loss: 0.30743008852005005      \n",
      "train step #952 accuracy: 0.828125, loss: 0.453707218170166        \n",
      "train step #953 accuracy: 0.875, loss: 0.40138739347457886      \n",
      "train step #954 accuracy: 0.90625, loss: 0.2783241868019104       \n",
      "train step #955 accuracy: 0.84375, loss: 0.6186570525169373       \n",
      "train step #956 accuracy: 0.890625, loss: 0.33324873447418213      \n",
      "train step #957 accuracy: 0.9375, loss: 0.23692947626113892      \n",
      "train step #958 accuracy: 0.90625, loss: 0.34559446573257446      \n",
      "train step #959 accuracy: 0.875, loss: 0.3118610382080078       \n",
      "train step #960 accuracy: 0.921875, loss: 0.29792338609695435      \n",
      "train step #961 accuracy: 0.828125, loss: 0.5421068072319031       \n",
      "train step #962 accuracy: 0.875, loss: 0.3840453624725342       \n",
      "train step #963 accuracy: 0.921875, loss: 0.26945972442626953      \n",
      "train step #964 accuracy: 0.921875, loss: 0.26003381609916687      \n",
      "train step #965 accuracy: 0.953125, loss: 0.1720656454563141       \n",
      "train step #966 accuracy: 0.875, loss: 0.4124721586704254       \n",
      "train step #967 accuracy: 0.890625, loss: 0.426542729139328        \n",
      "train step #968 accuracy: 0.890625, loss: 0.33842524886131287      \n",
      "train step #969 accuracy: 0.890625, loss: 0.38280320167541504      \n",
      "train step #970 accuracy: 0.828125, loss: 0.6034674644470215       \n",
      "train step #971 accuracy: 0.90625, loss: 0.46732163429260254      \n",
      "train step #972 accuracy: 0.953125, loss: 0.24493667483329773      \n",
      "train step #973 accuracy: 0.859375, loss: 0.46111005544662476      \n",
      "train step #974 accuracy: 0.875, loss: 0.4646114706993103       \n",
      "train step #975 accuracy: 0.8125, loss: 0.6311872005462646       \n",
      "train step #976 accuracy: 0.859375, loss: 0.31287682056427         \n",
      "train step #977 accuracy: 0.875, loss: 0.3190535306930542       \n",
      "train step #978 accuracy: 0.828125, loss: 0.517106831073761        \n",
      "train step #979 accuracy: 0.921875, loss: 0.29043257236480713      \n",
      "train step #980 accuracy: 0.875, loss: 0.4270402789115906       \n",
      "train step #981 accuracy: 0.921875, loss: 0.39314979314804077      \n",
      "train step #982 accuracy: 0.890625, loss: 0.47052738070487976      \n",
      "train step #983 accuracy: 0.859375, loss: 0.453470915555954        \n",
      "train step #984 accuracy: 0.890625, loss: 0.3855434060096741       \n",
      "train step #985 accuracy: 0.90625, loss: 0.3034883439540863       \n",
      "train step #986 accuracy: 0.953125, loss: 0.15825219452381134      \n",
      "train step #987 accuracy: 0.828125, loss: 0.47289562225341797      \n",
      "train step #988 accuracy: 0.90625, loss: 0.30700036883354187      \n",
      "train step #989 accuracy: 0.890625, loss: 0.3998609781265259       \n",
      "train step #990 accuracy: 0.890625, loss: 0.31483209133148193      \n",
      "train step #991 accuracy: 0.890625, loss: 0.299321711063385        \n",
      "train step #992 accuracy: 0.890625, loss: 0.3491574823856354       \n",
      "train step #993 accuracy: 0.828125, loss: 0.4043172597885132       \n",
      "train step #994 accuracy: 0.796875, loss: 0.5173494219779968       \n",
      "train step #995 accuracy: 0.875, loss: 0.4501795768737793       \n",
      "train step #996 accuracy: 0.9375, loss: 0.2509250044822693       \n",
      "train step #997 accuracy: 0.921875, loss: 0.24509814381599426      \n",
      "train step #998 accuracy: 0.953125, loss: 0.2815275192260742       \n",
      "train step #999 accuracy: 0.875, loss: 0.5107023119926453       \n",
      "train step #1000 accuracy: 0.890625, loss: 0.28703975677490234      \n",
      "train step #1001 accuracy: 0.90625, loss: 0.26796549558639526      \n",
      "train step #1002 accuracy: 0.875, loss: 0.44716522097587585      \n",
      "train step #1003 accuracy: 0.9375, loss: 0.24888890981674194      \n",
      "train step #1004 accuracy: 0.890625, loss: 0.4514728784561157       \n",
      "train step #1005 accuracy: 0.84375, loss: 0.30131080746650696      \n",
      "train step #1006 accuracy: 0.890625, loss: 0.2597757875919342       \n",
      "train step #1007 accuracy: 0.859375, loss: 0.4093829393386841       \n",
      "train step #1008 accuracy: 0.875, loss: 0.3137860894203186       \n",
      "train step #1009 accuracy:  0.75, loss: 0.5919778347015381       \n",
      "train step #1010 accuracy: 0.90625, loss: 0.2701961100101471       \n",
      "train step #1011 accuracy: 0.90625, loss: 0.24027986824512482      \n",
      "train step #1012 accuracy: 0.875, loss: 0.40694746375083923      \n",
      "train step #1013 accuracy: 0.90625, loss: 0.23986183106899261      \n",
      "train step #1014 accuracy: 0.90625, loss: 0.34512680768966675      \n",
      "train step #1015 accuracy: 0.921875, loss: 0.33059579133987427      \n",
      "train step #1016 accuracy: 0.875, loss: 0.37363380193710327      \n",
      "train step #1017 accuracy: 0.8125, loss: 0.5746179819107056       \n",
      "train step #1018 accuracy: 0.90625, loss: 0.31653064489364624      \n",
      "train step #1019 accuracy: 0.921875, loss: 0.2200629562139511       \n",
      "train step #1020 accuracy: 0.796875, loss: 0.5937216877937317       \n",
      "train step #1021 accuracy: 0.90625, loss: 0.2733994722366333       \n",
      "train step #1022 accuracy: 0.8125, loss: 0.44960230588912964      \n",
      "train step #1023 accuracy: 0.953125, loss: 0.23587951064109802      \n",
      "train step #1024 accuracy: 0.9375, loss: 0.3174518942832947       \n",
      "train step #1025 accuracy: 0.921875, loss: 0.21987394988536835      \n",
      "train step #1026 accuracy: 0.890625, loss: 0.47930580377578735      \n",
      "train step #1027 accuracy: 0.90625, loss: 0.3950527608394623       \n",
      "train step #1028 accuracy: 0.78125, loss: 0.7017500400543213       \n",
      "train step #1029 accuracy: 0.90625, loss: 0.4364354908466339       \n",
      "train step #1030 accuracy: 0.90625, loss: 0.4320795238018036       \n",
      "train step #1031 accuracy: 0.828125, loss: 0.45754268765449524      \n",
      "train step #1032 accuracy: 0.90625, loss: 0.29837965965270996      \n",
      "train step #1033 accuracy: 0.921875, loss: 0.20561447739601135      \n",
      "train step #1034 accuracy: 0.8125, loss: 0.540773868560791        \n",
      "train step #1035 accuracy: 0.921875, loss: 0.20401543378829956      \n",
      "train step #1036 accuracy: 0.921875, loss: 0.2691984474658966       \n",
      "train step #1037 accuracy: 0.890625, loss: 0.33351975679397583      \n",
      "train step #1038 accuracy: 0.890625, loss: 0.29090166091918945      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #1039 accuracy: 0.875, loss: 0.34834015369415283      \n",
      "train step #1040 accuracy: 0.96875, loss: 0.14337563514709473      \n",
      "train step #1041 accuracy: 0.890625, loss: 0.5409772396087646       \n",
      "dev accuracy: 0.9375, loss: 0.13661377131938934      \n",
      "dev accuracy: 0.875, loss: 0.41968411207199097      \n",
      "dev accuracy:  0.75, loss: 0.4515356421470642       \n",
      "dev accuracy: 0.8125, loss: 0.42663857340812683      \n",
      "dev accuracy: 0.9375, loss: 0.23460820317268372      \n",
      "dev accuracy: 0.9375, loss: 0.476374089717865        \n",
      "dev accuracy:  0.75, loss: 0.6494755744934082       \n",
      "dev accuracy: 0.9375, loss: 0.23526640236377716      \n",
      "dev accuracy: 0.8125, loss: 0.6152892112731934       \n",
      "dev accuracy: 0.8125, loss: 0.4512729048728943       \n",
      "dev accuracy: 0.9375, loss: 0.19095994532108307      \n",
      "dev accuracy: 0.8125, loss: 0.6441839337348938       \n",
      "dev accuracy:  0.75, loss: 0.6308186650276184       \n",
      "dev accuracy: 0.9375, loss: 0.176998570561409        \n",
      "dev accuracy: 0.8125, loss: 0.48254573345184326      \n",
      "dev accuracy: 0.875, loss: 0.5462808609008789       \n",
      "dev accuracy: 0.9375, loss: 0.17884215712547302      \n",
      "dev accuracy: 0.9375, loss: 0.3111010193824768       \n",
      "dev accuracy: 0.875, loss: 0.3100779056549072       \n",
      "dev accuracy: 0.9375, loss: 0.17387184500694275      \n",
      "dev accuracy: 0.9375, loss: 0.24389412999153137      \n",
      "dev accuracy: 0.9375, loss: 0.22883276641368866      \n",
      "dev accuracy: 0.9375, loss: 0.2874182164669037       \n",
      "dev accuracy: 0.875, loss: 0.6674339175224304       \n",
      "dev accuracy:   1.0, loss: 0.13016462326049805      \n",
      "dev accuracy: 0.875, loss: 0.5350046157836914       \n",
      "dev accuracy: 0.875, loss: 0.3899829089641571       \n",
      "dev accuracy:   1.0, loss: 0.06316325068473816      \n",
      "dev accuracy:   1.0, loss: 0.07841449975967407      \n",
      "dev accuracy:   1.0, loss: 0.21913877129554749      \n",
      "dev accuracy: 0.6875, loss: 0.8695726990699768       \n",
      "dev accuracy:  0.75, loss: 0.8748491406440735       \n",
      "dev accuracy: 0.875, loss: 0.3640215992927551       \n",
      "dev accuracy: 0.8125, loss: 0.457887202501297        \n",
      "dev accuracy:   1.0, loss: 0.08458563685417175      \n",
      "dev accuracy: 0.8125, loss: 0.5722198486328125       \n",
      "dev accuracy: 0.8125, loss: 0.6923896074295044       \n",
      "dev accuracy: 0.875, loss: 0.2447301149368286       \n",
      "dev accuracy:   1.0, loss: 0.16065436601638794      \n",
      "dev accuracy:  0.75, loss: 0.9662632346153259       \n",
      "dev accuracy:   1.0, loss: 0.11256876587867737      \n",
      "dev accuracy:  0.75, loss: 0.6084021329879761       \n",
      "dev accuracy: 0.9375, loss: 0.22443531453609467      \n",
      "dev accuracy: 0.8125, loss: 0.4705880880355835       \n",
      "dev accuracy: 0.9375, loss: 0.20042744278907776      \n",
      "dev accuracy: 0.8125, loss: 0.40310007333755493      \n",
      "dev accuracy: 0.875, loss: 0.308735191822052        \n",
      "dev accuracy: 0.6875, loss: 0.9077290892601013       \n",
      "dev accuracy: 0.875, loss: 0.5190768241882324       \n",
      "dev accuracy: 0.875, loss: 0.48240020871162415      \n",
      "dev accuracy: 0.875, loss: 0.4619951844215393       \n",
      "dev accuracy:   1.0, loss: 0.09136086702346802      \n",
      "dev accuracy:  0.75, loss: 0.5145005583763123       \n",
      "dev accuracy: 0.8125, loss: 0.3870236873626709       \n",
      "dev accuracy: 0.8125, loss: 0.4567575454711914       \n",
      "dev accuracy: 0.875, loss: 0.3517288565635681       \n",
      "dev accuracy: 0.875, loss: 0.34131622314453125      \n",
      "dev accuracy:  0.75, loss: 1.164957046508789        \n",
      "dev accuracy: 0.9375, loss: 0.1614769548177719       \n",
      "dev accuracy: 0.875, loss: 0.3892412781715393       \n",
      "dev accuracy: 0.9375, loss: 0.4442426860332489       \n",
      "dev accuracy: 0.8125, loss: 0.47477102279663086      \n",
      "dev accuracy: 0.9375, loss: 0.22122350335121155      \n",
      "dev accuracy: 0.875, loss: 0.4749293625354767       \n",
      "dev accuracy: 0.9375, loss: 0.2251998484134674       \n",
      "dev accuracy: 0.9375, loss: 0.24975396692752838      \n",
      "dev accuracy: 0.9375, loss: 0.1961376816034317       \n",
      "dev accuracy: 0.9375, loss: 0.2545177936553955       \n",
      "dev accuracy:  0.75, loss: 0.6956777572631836       \n",
      "dev accuracy: 0.8125, loss: 0.3452005386352539       \n",
      "dev accuracy:   1.0, loss: 0.09438781440258026      \n",
      "dev accuracy: 0.875, loss: 0.2863462567329407       \n",
      "dev accuracy: 0.8125, loss: 0.47209686040878296      \n",
      "dev accuracy: 0.9375, loss: 0.319107323884964        \n",
      "dev accuracy: 0.875, loss: 0.31258463859558105      \n",
      "dev accuracy: 0.9375, loss: 0.2916591763496399       \n",
      "dev accuracy: 0.8125, loss: 0.4231472909450531       \n",
      "dev accuracy: 0.875, loss: 0.35354989767074585      \n",
      "dev accuracy: 0.9375, loss: 0.19679422676563263      \n",
      "dev accuracy: 0.875, loss: 0.24857760965824127      \n",
      "dev accuracy: 0.875, loss: 0.45526647567749023      \n",
      "dev accuracy:   1.0, loss: 0.0891769528388977       \n",
      "dev accuracy: 0.8125, loss: 0.31067192554473877      \n",
      "dev accuracy: 0.9375, loss: 0.24142968654632568      \n",
      "dev accuracy: 0.875, loss: 0.4892107844352722       \n",
      "dev accuracy: 0.9375, loss: 0.3594307005405426       \n",
      "dev accuracy: 0.875, loss: 0.21562455594539642      \n",
      "dev accuracy: 0.8125, loss: 0.5499101877212524       \n",
      "dev accuracy: 0.9375, loss: 0.3022232949733734       \n",
      "dev accuracy:   1.0, loss: 0.08641161024570465      \n",
      "dev accuracy: 0.875, loss: 0.21012498438358307      \n",
      "dev accuracy:  0.75, loss: 0.6812788248062134       \n",
      "dev accuracy: 0.9375, loss: 0.15759985148906708      \n",
      "dev accuracy: 0.875, loss: 0.7013986706733704       \n",
      "dev accuracy: 0.9375, loss: 0.27474698424339294      \n",
      "dev accuracy: 0.9375, loss: 0.3424477279186249       \n",
      "dev accuracy:   1.0, loss: 0.07632759213447571      \n",
      "dev accuracy: 0.875, loss: 0.14204764366149902      \n",
      "dev accuracy: 0.9375, loss: 0.28041326999664307      \n",
      "dev accuracy:  0.75, loss: 0.5273456573486328       \n",
      "dev accuracy: 0.875, loss: 0.18966072797775269      \n",
      "dev accuracy: 0.8125, loss: 0.4975484609603882       \n",
      "dev accuracy: 0.9375, loss: 0.3222469091415405       \n",
      "dev accuracy: 0.875, loss: 0.36061564087867737      \n",
      "dev accuracy: 0.875, loss: 0.27669066190719604      \n",
      "dev accuracy: 0.875, loss: 0.5108532309532166       \n",
      "dev accuracy: 0.9375, loss: 0.23406314849853516      \n",
      "dev accuracy:   1.0, loss: 0.06800106167793274      \n",
      "dev accuracy: 0.8125, loss: 0.48809459805488586      \n",
      "dev accuracy: 0.8125, loss: 0.33565351366996765      \n",
      "dev accuracy:  0.75, loss: 0.40698811411857605      \n",
      "dev accuracy:  0.75, loss: 0.7557933330535889       \n",
      "dev accuracy: 0.9375, loss: 0.5307519435882568       \n",
      "dev accuracy: 0.9375, loss: 0.25737810134887695      \n",
      "dev accuracy: 0.8125, loss: 0.5702306032180786       \n",
      "dev accuracy: 0.6875, loss: 0.7059127688407898       \n",
      "dev accuracy: 0.9375, loss: 0.4673026502132416       \n",
      "dev accuracy: 0.6875, loss: 0.6046270728111267       \n",
      "dev accuracy:   1.0, loss: 0.1841306835412979       \n",
      "dev accuracy: 0.9375, loss: 0.141525000333786        \n",
      "dev accuracy: 0.9375, loss: 0.19358527660369873      \n",
      "dev accuracy: 0.9375, loss: 0.27105244994163513      \n",
      "dev accuracy: 0.9375, loss: 0.32422176003456116      \n",
      "dev accuracy: 0.8125, loss: 0.41938501596450806      \n",
      "dev accuracy:   1.0, loss: 0.12689130008220673      \n",
      "dev accuracy:  0.75, loss: 0.4495067000389099       \n",
      "dev accuracy: 0.875, loss: 0.427765816450119        \n",
      "dev accuracy:   1.0, loss: 0.09717586636543274      \n",
      "dev accuracy:   1.0, loss: 0.07447861135005951      \n",
      "dev accuracy: 0.875, loss: 0.2951817512512207       \n",
      "dev accuracy: 0.9375, loss: 0.2598908245563507       \n",
      "dev accuracy: 0.9375, loss: 0.26864898204803467      \n",
      "dev accuracy: 0.9375, loss: 0.2761264741420746       \n",
      "dev accuracy: 0.9375, loss: 0.21784810721874237      \n",
      "dev accuracy:  0.75, loss: 0.720429539680481        \n",
      "dev accuracy: 0.9375, loss: 0.32404449582099915      \n",
      "dev accuracy: 0.875, loss: 0.36704888939857483      \n",
      "dev accuracy: 0.9375, loss: 0.2599382698535919       \n",
      "dev accuracy: 0.875, loss: 0.49065184593200684      \n",
      "dev accuracy: 0.9375, loss: 0.3035973012447357       \n",
      "dev accuracy: 0.8125, loss: 0.5286121368408203       \n",
      "dev accuracy:   1.0, loss: 0.12537600100040436      \n",
      "dev accuracy: 0.8125, loss: 0.43969205021858215      \n",
      "dev accuracy: 0.8125, loss: 0.4413357377052307       \n",
      "dev accuracy: 0.9375, loss: 0.22621403634548187      \n",
      "dev accuracy: 0.9375, loss: 0.22104567289352417      \n",
      "dev accuracy: 0.9375, loss: 0.19911451637744904      \n",
      "dev accuracy:   1.0, loss: 0.03229570388793945      \n",
      "dev accuracy: 0.9375, loss: 0.24418304860591888      \n",
      "dev accuracy: 0.8125, loss: 0.31199774146080017      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy:   1.0, loss: 0.09273332357406616      \n",
      "dev accuracy: 0.875, loss: 0.2900233864784241       \n",
      "dev accuracy:  0.75, loss: 0.9368761777877808       \n",
      "dev accuracy:   1.0, loss: 0.029333919286727905     \n",
      "dev accuracy: 0.875, loss: 0.2312087118625641       \n",
      "dev accuracy: 0.8125, loss: 0.8382302522659302       \n",
      "dev accuracy: 0.875, loss: 0.8819791078567505       \n",
      "dev accuracy:   1.0, loss: 0.040294647216796875     \n",
      "dev accuracy: 0.8125, loss: 0.5750263333320618       \n",
      "dev accuracy: 0.8125, loss: 0.6414759755134583       \n",
      "dev accuracy:   1.0, loss: 0.08809548616409302      \n",
      "dev accuracy: 0.9375, loss: 0.24410560727119446      \n",
      "dev accuracy: 0.9375, loss: 0.22655707597732544      \n",
      "dev accuracy:   1.0, loss: 0.061563730239868164     \n",
      "dev accuracy: 0.875, loss: 0.620944619178772        \n",
      "dev accuracy: 0.9375, loss: 0.26764407753944397      \n",
      "dev accuracy: 0.9375, loss: 0.2170284539461136       \n",
      "dev accuracy:   1.0, loss: 0.045192569494247437     \n",
      "dev accuracy: 0.875, loss: 0.6354770660400391       \n",
      "dev accuracy: 0.9375, loss: 0.23497545719146729      \n",
      "dev accuracy: 0.875, loss: 0.6862455606460571       \n",
      "dev accuracy: 0.875, loss: 0.2100895196199417       \n",
      "dev accuracy: 0.875, loss: 0.4669896960258484       \n",
      "dev accuracy: 0.9375, loss: 0.2135189175605774       \n",
      "dev accuracy: 0.875, loss: 0.44986724853515625      \n",
      "dev accuracy: 0.875, loss: 0.5390664935112          \n",
      "dev accuracy: 0.9375, loss: 0.27100419998168945      \n",
      "dev accuracy:   1.0, loss: 0.046249836683273315     \n",
      "dev accuracy: 0.875, loss: 0.509246826171875        \n",
      "dev accuracy: 0.875, loss: 0.20864561200141907      \n",
      "dev accuracy: 0.8125, loss: 0.37655648589134216      \n",
      "dev accuracy: 0.9375, loss: 0.2842627763748169       \n",
      "dev accuracy: 0.9375, loss: 0.1769842803478241       \n",
      "dev accuracy:   1.0, loss: 0.10791552066802979      \n",
      "dev accuracy: 0.9375, loss: 0.5429229140281677       \n",
      "dev accuracy: 0.875, loss: 0.3132629096508026       \n",
      "dev accuracy: 0.9375, loss: 0.2057974487543106       \n",
      "dev accuracy: 0.875, loss: 0.47376957535743713      \n",
      "dev accuracy: 0.875, loss: 0.47908008098602295      \n",
      "dev accuracy: 0.9375, loss: 0.21692833304405212      \n",
      "dev accuracy: 0.875, loss: 0.22956956923007965      \n",
      "dev accuracy:   1.0, loss: 0.007589906454086304     \n",
      "dev accuracy: 0.9375, loss: 0.38767534494400024      \n",
      "dev accuracy: 0.6666666666666666, loss: 0.5730001330375671       \n",
      "final dev accuracy: 0.8884235395189004\n",
      "saving best model...\n",
      "train step #1042 accuracy: 0.921875, loss: 0.2970481514930725       \n",
      "train step #1043 accuracy: 0.875, loss: 0.37634772062301636      \n",
      "train step #1044 accuracy: 0.90625, loss: 0.2775803804397583       \n",
      "train step #1045 accuracy: 0.84375, loss: 0.40856990218162537      \n",
      "train step #1046 accuracy: 0.9375, loss: 0.25652015209198         \n",
      "train step #1047 accuracy: 0.84375, loss: 0.44571417570114136      \n",
      "train step #1048 accuracy: 0.859375, loss: 0.3052286207675934       \n",
      "train step #1049 accuracy: 0.8125, loss: 0.4535049498081207       \n",
      "train step #1050 accuracy: 0.921875, loss: 0.28892406821250916      \n",
      "train step #1051 accuracy: 0.9375, loss: 0.25163108110427856      \n",
      "train step #1052 accuracy: 0.859375, loss: 0.4136795699596405       \n",
      "train step #1053 accuracy: 0.921875, loss: 0.4252874553203583       \n",
      "train step #1054 accuracy: 0.859375, loss: 0.49596545100212097      \n",
      "train step #1055 accuracy: 0.921875, loss: 0.2803182005882263       \n",
      "train step #1056 accuracy: 0.890625, loss: 0.30058473348617554      \n",
      "train step #1057 accuracy: 0.890625, loss: 0.3090069890022278       \n",
      "train step #1058 accuracy: 0.90625, loss: 0.38137972354888916      \n",
      "train step #1059 accuracy: 0.875, loss: 0.3662571310997009       \n",
      "train step #1060 accuracy: 0.875, loss: 0.42998871207237244      \n",
      "train step #1061 accuracy: 0.921875, loss: 0.20569302141666412      \n",
      "train step #1062 accuracy: 0.890625, loss: 0.29403677582740784      \n",
      "train step #1063 accuracy: 0.875, loss: 0.40964800119400024      \n",
      "train step #1064 accuracy: 0.890625, loss: 0.30906540155410767      \n",
      "train step #1065 accuracy: 0.921875, loss: 0.2910705506801605       \n",
      "train step #1066 accuracy: 0.890625, loss: 0.3084673583507538       \n",
      "train step #1067 accuracy: 0.890625, loss: 0.2764987647533417       \n",
      "train step #1068 accuracy: 0.890625, loss: 0.4440757632255554       \n",
      "train step #1069 accuracy: 0.90625, loss: 0.384726881980896        \n",
      "train step #1070 accuracy: 0.953125, loss: 0.3417864441871643       \n",
      "train step #1071 accuracy: 0.90625, loss: 0.2519344389438629       \n",
      "train step #1072 accuracy: 0.921875, loss: 0.3857743740081787       \n",
      "train step #1073 accuracy: 0.953125, loss: 0.15994922816753387      \n",
      "train step #1074 accuracy: 0.890625, loss: 0.36437803506851196      \n",
      "train step #1075 accuracy: 0.859375, loss: 0.4398467540740967       \n",
      "train step #1076 accuracy: 0.921875, loss: 0.32213377952575684      \n",
      "train step #1077 accuracy: 0.921875, loss: 0.21321535110473633      \n",
      "train step #1078 accuracy: 0.953125, loss: 0.12885481119155884      \n",
      "train step #1079 accuracy: 0.90625, loss: 0.3921573758125305       \n",
      "train step #1080 accuracy: 0.890625, loss: 0.31610333919525146      \n",
      "train step #1081 accuracy: 0.859375, loss: 0.5194888114929199       \n",
      "train step #1082 accuracy: 0.96875, loss: 0.17000406980514526      \n",
      "train step #1083 accuracy: 0.90625, loss: 0.3246504068374634       \n",
      "train step #1084 accuracy: 0.921875, loss: 0.23685140907764435      \n",
      "train step #1085 accuracy: 0.890625, loss: 0.29522705078125         \n",
      "train step #1086 accuracy: 0.96875, loss: 0.18609978258609772      \n",
      "train step #1087 accuracy: 0.890625, loss: 0.4262698292732239       \n",
      "train step #1088 accuracy: 0.859375, loss: 0.4517386257648468       \n",
      "train step #1089 accuracy: 0.921875, loss: 0.30151066184043884      \n",
      "train step #1090 accuracy: 0.875, loss: 0.384787380695343        \n",
      "train step #1091 accuracy: 0.859375, loss: 0.43233218789100647      \n",
      "train step #1092 accuracy: 0.921875, loss: 0.239267960190773        \n",
      "train step #1093 accuracy: 0.890625, loss: 0.28757166862487793      \n",
      "train step #1094 accuracy: 0.921875, loss: 0.2605193257331848       \n",
      "train step #1095 accuracy: 0.859375, loss: 0.42898374795913696      \n",
      "train step #1096 accuracy: 0.9375, loss: 0.3213697075843811       \n",
      "train step #1097 accuracy: 0.9375, loss: 0.31452077627182007      \n",
      "train step #1098 accuracy: 0.921875, loss: 0.34446442127227783      \n",
      "train step #1099 accuracy: 0.9375, loss: 0.26650092005729675      \n",
      "train step #1100 accuracy: 0.890625, loss: 0.3765546679496765       \n",
      "train step #1101 accuracy: 0.9375, loss: 0.1704433560371399       \n",
      "train step #1102 accuracy: 0.875, loss: 0.3414295017719269       \n",
      "train step #1103 accuracy: 0.953125, loss: 0.20832717418670654      \n",
      "train step #1104 accuracy: 0.9375, loss: 0.2125978320837021       \n",
      "train step #1105 accuracy: 0.921875, loss: 0.20137950778007507      \n",
      "train step #1106 accuracy: 0.8125, loss: 0.6307360529899597       \n",
      "train step #1107 accuracy: 0.921875, loss: 0.20249688625335693      \n",
      "train step #1108 accuracy: 0.875, loss: 0.36683911085128784      \n",
      "train step #1109 accuracy: 0.875, loss: 0.3376944661140442       \n",
      "train step #1110 accuracy: 0.921875, loss: 0.33860400319099426      \n",
      "train step #1111 accuracy: 0.90625, loss: 0.37090903520584106      \n",
      "train step #1112 accuracy: 0.890625, loss: 0.3445557951927185       \n",
      "train step #1113 accuracy: 0.890625, loss: 0.43540653586387634      \n",
      "train step #1114 accuracy: 0.890625, loss: 0.3361862301826477       \n",
      "train step #1115 accuracy: 0.953125, loss: 0.2159673571586609       \n",
      "train step #1116 accuracy: 0.890625, loss: 0.2946087718009949       \n",
      "train step #1117 accuracy: 0.875, loss: 0.4147215187549591       \n",
      "train step #1118 accuracy: 0.84375, loss: 0.5358936786651611       \n",
      "train step #1119 accuracy: 0.90625, loss: 0.4113745093345642       \n",
      "train step #1120 accuracy: 0.890625, loss: 0.29348137974739075      \n",
      "train step #1121 accuracy: 0.8125, loss: 0.6505019068717957       \n",
      "train step #1122 accuracy: 0.90625, loss: 0.3172714114189148       \n",
      "train step #1123 accuracy: 0.953125, loss: 0.13964755833148956      \n",
      "train step #1124 accuracy: 0.859375, loss: 0.4802788197994232       \n",
      "train step #1125 accuracy: 0.90625, loss: 0.2247190773487091       \n",
      "train step #1126 accuracy: 0.859375, loss: 0.44379714131355286      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #1127 accuracy: 0.875, loss: 0.3970598578453064       \n",
      "train step #1128 accuracy: 0.890625, loss: 0.4865233600139618       \n",
      "train step #1129 accuracy: 0.890625, loss: 0.32048845291137695      \n",
      "train step #1130 accuracy: 0.890625, loss: 0.41553977131843567      \n",
      "train step #1131 accuracy: 0.890625, loss: 0.44445502758026123      \n",
      "train step #1132 accuracy: 0.890625, loss: 0.432993620634079        \n",
      "train step #1133 accuracy: 0.90625, loss: 0.3209252953529358       \n",
      "train step #1134 accuracy: 0.875, loss: 0.40526729822158813      \n",
      "train step #1135 accuracy: 0.875, loss: 0.4853951334953308       \n",
      "train step #1136 accuracy: 0.828125, loss: 0.4337661862373352       \n",
      "train step #1137 accuracy: 0.8125, loss: 0.5860119462013245       \n",
      "train step #1138 accuracy: 0.875, loss: 0.3830842971801758       \n",
      "train step #1139 accuracy: 0.9375, loss: 0.3065681457519531       \n",
      "train step #1140 accuracy: 0.921875, loss: 0.337762713432312        \n",
      "train step #1141 accuracy: 0.859375, loss: 0.45475417375564575      \n",
      "train step #1142 accuracy: 0.921875, loss: 0.2666246294975281       \n",
      "train step #1143 accuracy: 0.875, loss: 0.4006883502006531       \n",
      "train step #1144 accuracy: 0.8125, loss: 0.5405095219612122       \n",
      "train step #1145 accuracy: 0.921875, loss: 0.26391685009002686      \n",
      "train step #1146 accuracy: 0.921875, loss: 0.26242321729660034      \n",
      "train step #1147 accuracy: 0.859375, loss: 0.44887086749076843      \n",
      "train step #1148 accuracy: 0.875, loss: 0.32416385412216187      \n",
      "train step #1149 accuracy: 0.90625, loss: 0.3572827875614166       \n",
      "train step #1150 accuracy: 0.90625, loss: 0.29694053530693054      \n",
      "train step #1151 accuracy: 0.875, loss: 0.5141292810440063       \n",
      "train step #1152 accuracy: 0.828125, loss: 0.5111186504364014       \n",
      "train step #1153 accuracy: 0.890625, loss: 0.39775580167770386      \n",
      "train step #1154 accuracy: 0.96875, loss: 0.1532261073589325       \n",
      "train step #1155 accuracy: 0.9375, loss: 0.22666436433792114      \n",
      "train step #1156 accuracy: 0.90625, loss: 0.26517996191978455      \n",
      "train step #1157 accuracy: 0.875, loss: 0.361117422580719        \n",
      "train step #1158 accuracy: 0.890625, loss: 0.3966718018054962       \n",
      "train step #1159 accuracy: 0.953125, loss: 0.22424331307411194      \n",
      "train step #1160 accuracy: 0.875, loss: 0.4238179624080658       \n",
      "train step #1161 accuracy: 0.875, loss: 0.3909687101840973       \n",
      "train step #1162 accuracy: 0.890625, loss: 0.3856944739818573       \n",
      "train step #1163 accuracy: 0.90625, loss: 0.3687077760696411       \n",
      "train step #1164 accuracy: 0.96875, loss: 0.12906557321548462      \n",
      "train step #1165 accuracy: 0.90625, loss: 0.35470566153526306      \n",
      "train step #1166 accuracy: 0.984375, loss: 0.10993875563144684      \n",
      "train step #1167 accuracy: 0.90625, loss: 0.30068641901016235      \n",
      "train step #1168 accuracy: 0.90625, loss: 0.2615249752998352       \n",
      "train step #1169 accuracy: 0.890625, loss: 0.39733362197875977      \n",
      "train step #1170 accuracy: 0.84375, loss: 0.449432373046875        \n",
      "train step #1171 accuracy: 0.953125, loss: 0.2192554920911789       \n",
      "train step #1172 accuracy: 0.890625, loss: 0.4070609211921692       \n",
      "train step #1173 accuracy: 0.90625, loss: 0.32781779766082764      \n",
      "train step #1174 accuracy: 0.90625, loss: 0.2310376763343811       \n",
      "train step #1175 accuracy: 0.890625, loss: 0.44702959060668945      \n",
      "train step #1176 accuracy: 0.9375, loss: 0.2521982789039612       \n",
      "train step #1177 accuracy: 0.921875, loss: 0.30511951446533203      \n",
      "train step #1178 accuracy: 0.859375, loss: 0.41945680975914         \n",
      "train step #1179 accuracy: 0.859375, loss: 0.4182124137878418       \n",
      "train step #1180 accuracy: 0.90625, loss: 0.2753037214279175       \n",
      "train step #1181 accuracy: 0.84375, loss: 0.4745924770832062       \n",
      "train step #1182 accuracy: 0.953125, loss: 0.262079119682312        \n",
      "train step #1183 accuracy: 0.90625, loss: 0.4024076461791992       \n",
      "train step #1184 accuracy: 0.859375, loss: 0.5411345362663269       \n",
      "train step #1185 accuracy: 0.890625, loss: 0.3501443862915039       \n",
      "train step #1186 accuracy: 0.84375, loss: 0.4763360321521759       \n",
      "train step #1187 accuracy: 0.90625, loss: 0.25045621395111084      \n",
      "train step #1188 accuracy: 0.921875, loss: 0.21697993576526642      \n",
      "train step #1189 accuracy: 0.84375, loss: 0.49883589148521423      \n",
      "train step #1190 accuracy: 0.921875, loss: 0.19593314826488495      \n",
      "train step #1191 accuracy: 0.859375, loss: 0.3892061710357666       \n",
      "train step #1192 accuracy: 0.890625, loss: 0.24538391828536987      \n",
      "train step #1193 accuracy: 0.90625, loss: 0.4131416380405426       \n",
      "train step #1194 accuracy: 0.9375, loss: 0.14023500680923462      \n",
      "train step #1195 accuracy: 0.828125, loss: 0.4720003008842468       \n",
      "train step #1196 accuracy: 0.828125, loss: 0.6205195188522339       \n",
      "train step #1197 accuracy: 0.984375, loss: 0.12303532660007477      \n",
      "train step #1198 accuracy: 0.953125, loss: 0.17961427569389343      \n",
      "train step #1199 accuracy: 0.921875, loss: 0.21442082524299622      \n",
      "train step #1200 accuracy: 0.9375, loss: 0.27130651473999023      \n",
      "train step #1201 accuracy: 0.921875, loss: 0.24686002731323242      \n",
      "train step #1202 accuracy: 0.859375, loss: 0.46849316358566284      \n",
      "train step #1203 accuracy: 0.921875, loss: 0.24643602967262268      \n",
      "train step #1204 accuracy: 0.828125, loss: 0.44497764110565186      \n",
      "train step #1205 accuracy: 0.9375, loss: 0.26659539341926575      \n",
      "train step #1206 accuracy: 0.890625, loss: 0.38707607984542847      \n",
      "train step #1207 accuracy: 0.84375, loss: 0.46157968044281006      \n",
      "train step #1208 accuracy: 0.90625, loss: 0.32021188735961914      \n",
      "train step #1209 accuracy: 0.875, loss: 0.30555009841918945      \n",
      "train step #1210 accuracy: 0.890625, loss: 0.37382274866104126      \n",
      "train step #1211 accuracy: 0.9375, loss: 0.30642277002334595      \n",
      "train step #1212 accuracy: 0.90625, loss: 0.2549760937690735       \n",
      "train step #1213 accuracy: 0.921875, loss: 0.26867401599884033      \n",
      "train step #1214 accuracy: 0.9375, loss: 0.3287692666053772       \n",
      "train step #1215 accuracy: 0.890625, loss: 0.2936250567436218       \n",
      "train step #1216 accuracy: 0.828125, loss: 0.48858436942100525      \n",
      "train step #1217 accuracy: 0.9375, loss: 0.15230348706245422      \n",
      "train step #1218 accuracy: 0.859375, loss: 0.2824588418006897       \n",
      "train step #1219 accuracy: 0.96875, loss: 0.18757283687591553      \n",
      "train step #1220 accuracy: 0.890625, loss: 0.26658880710601807      \n",
      "train step #1221 accuracy: 0.953125, loss: 0.15296918153762817      \n",
      "train step #1222 accuracy: 0.890625, loss: 0.32708051800727844      \n",
      "train step #1223 accuracy: 0.875, loss: 0.4057823419570923       \n",
      "train step #1224 accuracy: 0.9375, loss: 0.19456569850444794      \n",
      "train step #1225 accuracy: 0.890625, loss: 0.36267760396003723      \n",
      "train step #1226 accuracy: 0.859375, loss: 0.4976097345352173       \n",
      "train step #1227 accuracy: 0.921875, loss: 0.23686137795448303      \n",
      "train step #1228 accuracy: 0.90625, loss: 0.3650517463684082       \n",
      "train step #1229 accuracy: 0.875, loss: 0.3691102862358093       \n",
      "train step #1230 accuracy: 0.90625, loss: 0.249503031373024        \n",
      "train step #1231 accuracy: 0.921875, loss: 0.2588406205177307       \n",
      "train step #1232 accuracy: 0.890625, loss: 0.3006175756454468       \n",
      "train step #1233 accuracy: 0.875, loss: 0.4340501129627228       \n",
      "train step #1234 accuracy: 0.921875, loss: 0.30457162857055664      \n",
      "train step #1235 accuracy: 0.90625, loss: 0.32372361421585083      \n",
      "train step #1236 accuracy: 0.90625, loss: 0.2804928123950958       \n",
      "train step #1237 accuracy: 0.890625, loss: 0.41951942443847656      \n",
      "train step #1238 accuracy: 0.921875, loss: 0.2937212884426117       \n",
      "train step #1239 accuracy: 0.84375, loss: 0.520674467086792        \n",
      "train step #1240 accuracy: 0.9375, loss: 0.21841657161712646      \n",
      "train step #1241 accuracy: 0.890625, loss: 0.3126223087310791       \n",
      "train step #1242 accuracy: 0.96875, loss: 0.19451670348644257      \n",
      "train step #1243 accuracy: 0.90625, loss: 0.2295510619878769       \n",
      "train step #1244 accuracy: 0.859375, loss: 0.37324875593185425      \n",
      "train step #1245 accuracy: 0.859375, loss: 0.3149433135986328       \n",
      "train step #1246 accuracy: 0.796875, loss: 0.5845289826393127       \n",
      "train step #1247 accuracy: 0.890625, loss: 0.24900026619434357      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #1248 accuracy: 0.765625, loss: 0.6516322493553162       \n",
      "train step #1249 accuracy: 0.890625, loss: 0.41513553261756897      \n",
      "train step #1250 accuracy: 0.890625, loss: 0.28278297185897827      \n",
      "train step #1251 accuracy: 0.90625, loss: 0.2188689410686493       \n",
      "train step #1252 accuracy: 0.90625, loss: 0.25703465938568115      \n",
      "train step #1253 accuracy: 0.90625, loss: 0.3125869631767273       \n",
      "train step #1254 accuracy: 0.921875, loss: 0.21738377213478088      \n",
      "train step #1255 accuracy: 0.90625, loss: 0.4379793405532837       \n",
      "train step #1256 accuracy: 0.90625, loss: 0.3104671239852905       \n",
      "train step #1257 accuracy: 0.9375, loss: 0.22452637553215027      \n",
      "train step #1258 accuracy: 0.953125, loss: 0.1510835886001587       \n",
      "train step #1259 accuracy: 0.9375, loss: 0.27977895736694336      \n",
      "train step #1260 accuracy: 0.9375, loss: 0.2724549174308777       \n",
      "train step #1261 accuracy: 0.90625, loss: 0.2753872871398926       \n",
      "train step #1262 accuracy: 0.859375, loss: 0.3644271194934845       \n",
      "train step #1263 accuracy: 0.890625, loss: 0.4163854420185089       \n",
      "train step #1264 accuracy: 0.9375, loss: 0.2079697549343109       \n",
      "train step #1265 accuracy: 0.921875, loss: 0.17445744574069977      \n",
      "train step #1266 accuracy: 0.9375, loss: 0.1789739429950714       \n",
      "train step #1267 accuracy: 0.890625, loss: 0.29631349444389343      \n",
      "train step #1268 accuracy: 0.890625, loss: 0.41911056637763977      \n",
      "train step #1269 accuracy: 0.84375, loss: 0.49071216583251953      \n",
      "train step #1270 accuracy: 0.859375, loss: 0.5810911059379578       \n",
      "train step #1271 accuracy: 0.90625, loss: 0.33003777265548706      \n",
      "train step #1272 accuracy: 0.890625, loss: 0.373119980096817        \n",
      "train step #1273 accuracy: 0.890625, loss: 0.32087281346321106      \n",
      "train step #1274 accuracy: 0.953125, loss: 0.15640461444854736      \n",
      "train step #1275 accuracy: 0.90625, loss: 0.25129377841949463      \n",
      "train step #1276 accuracy: 0.859375, loss: 0.47972238063812256      \n",
      "train step #1277 accuracy: 0.921875, loss: 0.2674809694290161       \n",
      "train step #1278 accuracy: 0.84375, loss: 0.386034220457077        \n",
      "train step #1279 accuracy: 0.90625, loss: 0.3340736925601959       \n",
      "train step #1280 accuracy: 0.90625, loss: 0.31375744938850403      \n",
      "train step #1281 accuracy: 0.953125, loss: 0.24505457282066345      \n",
      "train step #1282 accuracy: 0.875, loss: 0.4113924205303192       \n",
      "train step #1283 accuracy: 0.859375, loss: 0.460329532623291        \n",
      "train step #1284 accuracy: 0.890625, loss: 0.33039385080337524      \n",
      "train step #1285 accuracy: 0.828125, loss: 0.4899105727672577       \n",
      "train step #1286 accuracy: 0.875, loss: 0.3863171637058258       \n",
      "train step #1287 accuracy: 0.953125, loss: 0.19552789628505707      \n",
      "train step #1288 accuracy: 0.890625, loss: 0.34302371740341187      \n",
      "train step #1289 accuracy: 0.921875, loss: 0.2921234965324402       \n",
      "train step #1290 accuracy: 0.9375, loss: 0.22264084219932556      \n",
      "train step #1291 accuracy: 0.9375, loss: 0.24647168815135956      \n",
      "train step #1292 accuracy: 0.9375, loss: 0.23086223006248474      \n",
      "train step #1293 accuracy: 0.9375, loss: 0.189238041639328        \n",
      "train step #1294 accuracy: 0.875, loss: 0.3004242777824402       \n",
      "train step #1295 accuracy: 0.84375, loss: 0.5150701403617859       \n",
      "train step #1296 accuracy: 0.875, loss: 0.30611348152160645      \n",
      "train step #1297 accuracy: 0.859375, loss: 0.4167485237121582       \n",
      "train step #1298 accuracy: 0.921875, loss: 0.3386528491973877       \n",
      "train step #1299 accuracy: 0.9375, loss: 0.31621846556663513      \n",
      "train step #1300 accuracy: 0.921875, loss: 0.1813085973262787       \n",
      "train step #1301 accuracy: 0.90625, loss: 0.244066059589386        \n",
      "train step #1302 accuracy: 0.890625, loss: 0.29075998067855835      \n",
      "train step #1303 accuracy: 0.890625, loss: 0.28166815638542175      \n",
      "train step #1304 accuracy: 0.90625, loss: 0.3046034574508667       \n",
      "train step #1305 accuracy: 0.9375, loss: 0.19814088940620422      \n",
      "train step #1306 accuracy: 0.921875, loss: 0.351714551448822        \n",
      "train step #1307 accuracy: 0.9375, loss: 0.19659090042114258      \n",
      "train step #1308 accuracy: 0.90625, loss: 0.2787880599498749       \n",
      "train step #1309 accuracy: 0.90625, loss: 0.3271239399909973       \n",
      "train step #1310 accuracy: 0.890625, loss: 0.4954368472099304       \n",
      "train step #1311 accuracy: 0.921875, loss: 0.2792348861694336       \n",
      "train step #1312 accuracy: 0.890625, loss: 0.4908934235572815       \n",
      "train step #1313 accuracy: 0.921875, loss: 0.30407577753067017      \n",
      "train step #1314 accuracy: 0.875, loss: 0.4985005259513855       \n",
      "train step #1315 accuracy: 0.921875, loss: 0.2603107690811157       \n",
      "train step #1316 accuracy: 0.84375, loss: 0.4808502793312073       \n",
      "train step #1317 accuracy: 0.921875, loss: 0.25996261835098267      \n",
      "train step #1318 accuracy: 0.90625, loss: 0.25132495164871216      \n",
      "train step #1319 accuracy: 0.890625, loss: 0.3491631746292114       \n",
      "train step #1320 accuracy: 0.90625, loss: 0.2747749984264374       \n",
      "train step #1321 accuracy: 0.890625, loss: 0.30327826738357544      \n",
      "train step #1322 accuracy: 0.921875, loss: 0.19459766149520874      \n",
      "train step #1323 accuracy: 0.9375, loss: 0.1766325980424881       \n",
      "train step #1324 accuracy: 0.859375, loss: 0.4376378059387207       \n",
      "train step #1325 accuracy: 0.96875, loss: 0.20250606536865234      \n",
      "train step #1326 accuracy: 0.84375, loss: 0.4913235008716583       \n",
      "train step #1327 accuracy: 0.875, loss: 0.43161505460739136      \n",
      "train step #1328 accuracy: 0.859375, loss: 0.3822029232978821       \n",
      "train step #1329 accuracy: 0.90625, loss: 0.3170372247695923       \n",
      "train step #1330 accuracy: 0.84375, loss: 0.5199494361877441       \n",
      "train step #1331 accuracy: 0.84375, loss: 0.4131532609462738       \n",
      "train step #1332 accuracy: 0.9375, loss: 0.21124182641506195      \n",
      "train step #1333 accuracy: 0.8125, loss: 0.5945605039596558       \n",
      "train step #1334 accuracy: 0.953125, loss: 0.326717734336853        \n",
      "train step #1335 accuracy: 0.90625, loss: 0.28158318996429443      \n",
      "train step #1336 accuracy: 0.921875, loss: 0.2608371376991272       \n",
      "train step #1337 accuracy: 0.9375, loss: 0.23096154630184174      \n",
      "train step #1338 accuracy: 0.890625, loss: 0.36477071046829224      \n",
      "train step #1339 accuracy: 0.921875, loss: 0.3308457136154175       \n",
      "train step #1340 accuracy: 0.859375, loss: 0.4519463777542114       \n",
      "train step #1341 accuracy: 0.84375, loss: 0.4056406617164612       \n",
      "train step #1342 accuracy: 0.90625, loss: 0.2927701771259308       \n",
      "train step #1343 accuracy: 0.890625, loss: 0.2952318489551544       \n",
      "train step #1344 accuracy: 0.90625, loss: 0.33534926176071167      \n",
      "train step #1345 accuracy: 0.921875, loss: 0.35047727823257446      \n",
      "train step #1346 accuracy: 0.890625, loss: 0.3935207724571228       \n",
      "train step #1347 accuracy: 0.875, loss: 0.3594425916671753       \n",
      "train step #1348 accuracy: 0.9375, loss: 0.3249882459640503       \n",
      "train step #1349 accuracy: 0.875, loss: 0.4302836060523987       \n",
      "train step #1350 accuracy: 0.875, loss: 0.3458947241306305       \n",
      "train step #1351 accuracy: 0.9375, loss: 0.3155517280101776       \n",
      "train step #1352 accuracy: 0.953125, loss: 0.15213368833065033      \n",
      "train step #1353 accuracy: 0.875, loss: 0.4313892126083374       \n",
      "train step #1354 accuracy: 0.90625, loss: 0.24448972940444946      \n",
      "train step #1355 accuracy: 0.875, loss: 0.4510517120361328       \n",
      "train step #1356 accuracy: 0.921875, loss: 0.3205011785030365       \n",
      "train step #1357 accuracy: 0.859375, loss: 0.47021523118019104      \n",
      "train step #1358 accuracy: 0.921875, loss: 0.308977872133255        \n",
      "train step #1359 accuracy: 0.96875, loss: 0.1482546329498291       \n",
      "train step #1360 accuracy: 0.921875, loss: 0.28790509700775146      \n",
      "train step #1361 accuracy: 0.9375, loss: 0.29021885991096497      \n",
      "train step #1362 accuracy: 0.921875, loss: 0.29622411727905273      \n",
      "train step #1363 accuracy: 0.828125, loss: 0.49289485812187195      \n",
      "train step #1364 accuracy: 0.875, loss: 0.40124332904815674      \n",
      "train step #1365 accuracy: 0.921875, loss: 0.18682070076465607      \n",
      "train step #1366 accuracy: 0.890625, loss: 0.34493210911750793      \n",
      "train step #1367 accuracy: 0.953125, loss: 0.18017801642417908      \n",
      "train step #1368 accuracy: 0.875, loss: 0.31941258907318115      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #1369 accuracy: 0.90625, loss: 0.25182396173477173      \n",
      "train step #1370 accuracy: 0.90625, loss: 0.2648330628871918       \n",
      "train step #1371 accuracy: 0.9375, loss: 0.25114476680755615      \n",
      "train step #1372 accuracy: 0.890625, loss: 0.338492751121521        \n",
      "train step #1373 accuracy: 0.890625, loss: 0.40878820419311523      \n",
      "train step #1374 accuracy: 0.96875, loss: 0.17527052760124207      \n",
      "train step #1375 accuracy: 0.96875, loss: 0.22559255361557007      \n",
      "train step #1376 accuracy: 0.90625, loss: 0.3173307180404663       \n",
      "train step #1377 accuracy: 0.890625, loss: 0.4127441942691803       \n",
      "train step #1378 accuracy: 0.96875, loss: 0.2464795708656311       \n",
      "train step #1379 accuracy: 0.90625, loss: 0.2173355668783188       \n",
      "train step #1380 accuracy: 0.9375, loss: 0.23760145902633667      \n",
      "train step #1381 accuracy: 0.9375, loss: 0.26496750116348267      \n",
      "train step #1382 accuracy: 0.890625, loss: 0.4454362094402313       \n",
      "train step #1383 accuracy: 0.90625, loss: 0.4361024498939514       \n",
      "train step #1384 accuracy: 0.90625, loss: 0.27706804871559143      \n",
      "train step #1385 accuracy: 0.875, loss: 0.4645393490791321       \n",
      "train step #1386 accuracy: 0.859375, loss: 0.3531469404697418       \n",
      "train step #1387 accuracy: 0.828125, loss: 0.3728253245353699       \n",
      "train step #1388 accuracy: 0.9375, loss: 0.26769885420799255      \n",
      "dev accuracy: 0.9375, loss: 0.32156985998153687      \n",
      "dev accuracy:  0.75, loss: 0.5608155131340027       \n",
      "dev accuracy:  0.75, loss: 0.5451100468635559       \n",
      "dev accuracy: 0.875, loss: 0.24366000294685364      \n",
      "dev accuracy: 0.6875, loss: 1.377378225326538        \n",
      "dev accuracy: 0.9375, loss: 0.26744019985198975      \n",
      "dev accuracy: 0.875, loss: 0.4460015594959259       \n",
      "dev accuracy: 0.6875, loss: 1.0231326818466187       \n",
      "dev accuracy: 0.8125, loss: 0.6556963324546814       \n",
      "dev accuracy: 0.8125, loss: 0.4254182279109955       \n",
      "dev accuracy:   1.0, loss: 0.026663154363632202     \n",
      "dev accuracy: 0.9375, loss: 0.25020432472229004      \n",
      "dev accuracy: 0.8125, loss: 0.47164273262023926      \n",
      "dev accuracy: 0.875, loss: 0.22927317023277283      \n",
      "dev accuracy: 0.875, loss: 0.41316089034080505      \n",
      "dev accuracy:  0.75, loss: 0.6338576078414917       \n",
      "dev accuracy:   1.0, loss: 0.13688158988952637      \n",
      "dev accuracy: 0.875, loss: 0.21966931223869324      \n",
      "dev accuracy: 0.8125, loss: 0.48329415917396545      \n",
      "dev accuracy: 0.6875, loss: 1.1541922092437744       \n",
      "dev accuracy: 0.9375, loss: 0.1629008948802948       \n",
      "dev accuracy: 0.875, loss: 0.4674258530139923       \n",
      "dev accuracy: 0.8125, loss: 0.3744651675224304       \n",
      "dev accuracy:  0.75, loss: 0.8260993957519531       \n",
      "dev accuracy: 0.8125, loss: 0.8282177448272705       \n",
      "dev accuracy: 0.6875, loss: 0.7073314189910889       \n",
      "dev accuracy: 0.8125, loss: 0.46685990691185         \n",
      "dev accuracy: 0.8125, loss: 0.3138222098350525       \n",
      "dev accuracy: 0.9375, loss: 0.18569284677505493      \n",
      "dev accuracy: 0.875, loss: 0.39696553349494934      \n",
      "dev accuracy: 0.875, loss: 0.24494773149490356      \n",
      "dev accuracy: 0.9375, loss: 0.16836676001548767      \n",
      "dev accuracy:  0.75, loss: 0.6229112148284912       \n",
      "dev accuracy: 0.875, loss: 0.17780302464962006      \n",
      "dev accuracy: 0.9375, loss: 0.15924400091171265      \n",
      "dev accuracy: 0.8125, loss: 0.6425879001617432       \n",
      "dev accuracy: 0.6875, loss: 0.6819091439247131       \n",
      "dev accuracy: 0.9375, loss: 0.17905336618423462      \n",
      "dev accuracy:  0.75, loss: 0.8268992304801941       \n",
      "dev accuracy: 0.9375, loss: 0.16096347570419312      \n",
      "dev accuracy: 0.6875, loss: 1.0814087390899658       \n",
      "dev accuracy:   1.0, loss: 0.07142111659049988      \n",
      "dev accuracy: 0.875, loss: 0.38217049837112427      \n",
      "dev accuracy: 0.9375, loss: 0.2140214890241623       \n",
      "dev accuracy: 0.8125, loss: 0.4134480059146881       \n",
      "dev accuracy: 0.625, loss: 0.8490772247314453       \n",
      "dev accuracy: 0.8125, loss: 0.42087456583976746      \n",
      "dev accuracy: 0.8125, loss: 0.6392838954925537       \n",
      "dev accuracy: 0.8125, loss: 0.4040873646736145       \n",
      "dev accuracy: 0.625, loss: 0.6643226146697998       \n",
      "dev accuracy:   1.0, loss: 0.03533199429512024      \n",
      "dev accuracy:  0.75, loss: 0.7028095126152039       \n",
      "dev accuracy:  0.75, loss: 0.7110921740531921       \n",
      "dev accuracy: 0.8125, loss: 0.650000810623169        \n",
      "dev accuracy: 0.875, loss: 0.3847636580467224       \n",
      "dev accuracy: 0.8125, loss: 0.3423870801925659       \n",
      "dev accuracy:  0.75, loss: 0.493294358253479        \n",
      "dev accuracy: 0.875, loss: 0.530582070350647        \n",
      "dev accuracy: 0.875, loss: 0.36288315057754517      \n",
      "dev accuracy: 0.8125, loss: 0.4543144106864929       \n",
      "dev accuracy: 0.875, loss: 0.25951850414276123      \n",
      "dev accuracy:  0.75, loss: 0.6727856397628784       \n",
      "dev accuracy: 0.9375, loss: 0.24342939257621765      \n",
      "dev accuracy: 0.9375, loss: 0.15825220942497253      \n",
      "dev accuracy:  0.75, loss: 0.6045569181442261       \n",
      "dev accuracy: 0.8125, loss: 0.38058117032051086      \n",
      "dev accuracy:   1.0, loss: 0.03532633185386658      \n",
      "dev accuracy: 0.875, loss: 0.263132244348526        \n",
      "dev accuracy: 0.875, loss: 0.20637989044189453      \n",
      "dev accuracy: 0.9375, loss: 0.29970675706863403      \n",
      "dev accuracy: 0.9375, loss: 0.16107302904129028      \n",
      "dev accuracy: 0.9375, loss: 0.16787847876548767      \n",
      "dev accuracy: 0.8125, loss: 0.39314234256744385      \n",
      "dev accuracy: 0.8125, loss: 0.44341591000556946      \n",
      "dev accuracy: 0.6875, loss: 0.6417568922042847       \n",
      "dev accuracy: 0.875, loss: 0.7523715496063232       \n",
      "dev accuracy: 0.625, loss: 0.7758434414863586       \n",
      "dev accuracy: 0.8125, loss: 0.5928913354873657       \n",
      "dev accuracy:  0.75, loss: 0.7408984303474426       \n",
      "dev accuracy: 0.9375, loss: 0.13692544400691986      \n",
      "dev accuracy: 0.6875, loss: 0.747044563293457        \n",
      "dev accuracy: 0.8125, loss: 0.38845667243003845      \n",
      "dev accuracy: 0.875, loss: 0.5806361436843872       \n",
      "dev accuracy:  0.75, loss: 0.6530298590660095       \n",
      "dev accuracy:  0.75, loss: 0.5141417384147644       \n",
      "dev accuracy: 0.9375, loss: 0.20845288038253784      \n",
      "dev accuracy: 0.8125, loss: 0.3900276720523834       \n",
      "dev accuracy: 0.875, loss: 0.36957213282585144      \n",
      "dev accuracy:  0.75, loss: 0.47449079155921936      \n",
      "dev accuracy:   1.0, loss: 0.028603553771972656     \n",
      "dev accuracy:   1.0, loss: 0.06283244490623474      \n",
      "dev accuracy:   1.0, loss: 0.06874313950538635      \n",
      "dev accuracy: 0.8125, loss: 0.46088555455207825      \n",
      "dev accuracy: 0.875, loss: 0.40195998549461365      \n",
      "dev accuracy: 0.9375, loss: 0.2493009865283966       \n",
      "dev accuracy: 0.875, loss: 0.2542417049407959       \n",
      "dev accuracy: 0.625, loss: 1.0285613536834717       \n",
      "dev accuracy: 0.875, loss: 0.3653309643268585       \n",
      "dev accuracy: 0.9375, loss: 0.12895838916301727      \n",
      "dev accuracy: 0.8125, loss: 0.5958547592163086       \n",
      "dev accuracy: 0.9375, loss: 0.1468227207660675       \n",
      "dev accuracy:  0.75, loss: 0.5335514545440674       \n",
      "dev accuracy: 0.8125, loss: 0.5079190135002136       \n",
      "dev accuracy: 0.875, loss: 0.32498207688331604      \n",
      "dev accuracy: 0.875, loss: 0.24826039373874664      \n",
      "dev accuracy: 0.9375, loss: 0.19231583178043365      \n",
      "dev accuracy: 0.875, loss: 0.6193112134933472       \n",
      "dev accuracy:  0.75, loss: 0.8987463712692261       \n",
      "dev accuracy:  0.75, loss: 0.8699542880058289       \n",
      "dev accuracy:  0.75, loss: 0.6042854189872742       \n",
      "dev accuracy:  0.75, loss: 0.6229033470153809       \n",
      "dev accuracy:  0.75, loss: 1.1439025402069092       \n",
      "dev accuracy: 0.9375, loss: 0.3908805549144745       \n",
      "dev accuracy: 0.6875, loss: 0.5553988814353943       \n",
      "dev accuracy: 0.6875, loss: 0.544530987739563        \n",
      "dev accuracy: 0.875, loss: 0.3029502332210541       \n",
      "dev accuracy: 0.8125, loss: 0.33437401056289673      \n",
      "dev accuracy:  0.75, loss: 0.774577796459198        \n",
      "dev accuracy: 0.8125, loss: 0.46987417340278625      \n",
      "dev accuracy: 0.8125, loss: 0.701737105846405        \n",
      "dev accuracy: 0.875, loss: 0.34678906202316284      \n",
      "dev accuracy: 0.875, loss: 0.20669059455394745      \n",
      "dev accuracy: 0.875, loss: 0.2762220799922943       \n",
      "dev accuracy:  0.75, loss: 0.5578136444091797       \n",
      "dev accuracy: 0.8125, loss: 0.4767250120639801       \n",
      "dev accuracy: 0.8125, loss: 0.4817993640899658       \n",
      "dev accuracy: 0.875, loss: 0.42751872539520264      \n",
      "dev accuracy: 0.875, loss: 0.32260337471961975      \n",
      "dev accuracy:  0.75, loss: 1.0202124118804932       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy: 0.6875, loss: 0.5648728609085083       \n",
      "dev accuracy:   1.0, loss: 0.07607138156890869      \n",
      "dev accuracy: 0.9375, loss: 0.23930621147155762      \n",
      "dev accuracy: 0.9375, loss: 0.21174973249435425      \n",
      "dev accuracy:   1.0, loss: 0.05567634105682373      \n",
      "dev accuracy: 0.8125, loss: 0.8612437844276428       \n",
      "dev accuracy: 0.875, loss: 0.29126420617103577      \n",
      "dev accuracy: 0.9375, loss: 0.31933730840682983      \n",
      "dev accuracy:  0.75, loss: 0.7491900324821472       \n",
      "dev accuracy:  0.75, loss: 0.5903586149215698       \n",
      "dev accuracy: 0.9375, loss: 0.2293095588684082       \n",
      "dev accuracy: 0.875, loss: 0.35388994216918945      \n",
      "dev accuracy: 0.9375, loss: 0.30672696232795715      \n",
      "dev accuracy: 0.875, loss: 0.21125122904777527      \n",
      "dev accuracy: 0.8125, loss: 0.37745049595832825      \n",
      "dev accuracy: 0.875, loss: 0.32320940494537354      \n",
      "dev accuracy: 0.875, loss: 0.4782350957393646       \n",
      "dev accuracy: 0.9375, loss: 0.16813799738883972      \n",
      "dev accuracy:  0.75, loss: 0.5212774276733398       \n",
      "dev accuracy:  0.75, loss: 0.5721250772476196       \n",
      "dev accuracy: 0.875, loss: 0.5607764720916748       \n",
      "dev accuracy: 0.8125, loss: 0.5386691689491272       \n",
      "dev accuracy: 0.875, loss: 0.376657634973526        \n",
      "dev accuracy:  0.75, loss: 0.6077252626419067       \n",
      "dev accuracy: 0.8125, loss: 0.6314384937286377       \n",
      "dev accuracy:  0.75, loss: 0.8458313345909119       \n",
      "dev accuracy: 0.625, loss: 1.0215981006622314       \n",
      "dev accuracy: 0.875, loss: 0.38144707679748535      \n",
      "dev accuracy: 0.9375, loss: 0.24799370765686035      \n",
      "dev accuracy: 0.9375, loss: 0.2310163527727127       \n",
      "dev accuracy: 0.8125, loss: 0.6732039451599121       \n",
      "dev accuracy: 0.625, loss: 0.6778913736343384       \n",
      "dev accuracy: 0.8125, loss: 0.5685819387435913       \n",
      "dev accuracy: 0.8125, loss: 0.3324337899684906       \n",
      "dev accuracy: 0.9375, loss: 0.14905913174152374      \n",
      "dev accuracy:  0.75, loss: 0.4876292645931244       \n",
      "dev accuracy:  0.75, loss: 0.5275465250015259       \n",
      "dev accuracy: 0.6875, loss: 0.5291146636009216       \n",
      "dev accuracy:  0.75, loss: 0.6295337080955505       \n",
      "dev accuracy: 0.6875, loss: 0.6374441385269165       \n",
      "dev accuracy: 0.8125, loss: 0.5016684532165527       \n",
      "dev accuracy: 0.9375, loss: 0.15868067741394043      \n",
      "dev accuracy: 0.875, loss: 0.2678537666797638       \n",
      "dev accuracy:   1.0, loss: 0.15622958540916443      \n",
      "dev accuracy: 0.8125, loss: 0.4618530869483948       \n",
      "dev accuracy: 0.6875, loss: 0.6550981998443604       \n",
      "dev accuracy: 0.8125, loss: 0.41710853576660156      \n",
      "dev accuracy: 0.8125, loss: 0.4823209047317505       \n",
      "dev accuracy:  0.75, loss: 0.6647193431854248       \n",
      "dev accuracy: 0.875, loss: 0.5073865652084351       \n",
      "dev accuracy: 0.875, loss: 0.34591519832611084      \n",
      "dev accuracy: 0.9375, loss: 0.1904725432395935       \n",
      "dev accuracy: 0.6875, loss: 0.8232449889183044       \n",
      "dev accuracy:  0.75, loss: 0.41954517364501953      \n",
      "dev accuracy: 0.8125, loss: 0.293159157037735        \n",
      "dev accuracy: 0.8125, loss: 0.577303409576416        \n",
      "dev accuracy: 0.875, loss: 0.3843069076538086       \n",
      "dev accuracy: 0.9375, loss: 0.10714441537857056      \n",
      "dev accuracy:  0.75, loss: 0.5999342203140259       \n",
      "dev accuracy: 0.875, loss: 0.4686948359012604       \n",
      "dev accuracy: 0.6875, loss: 0.6556864380836487       \n",
      "dev accuracy: 0.8125, loss: 0.425277441740036        \n",
      "dev accuracy:   1.0, loss: 0.0522976815700531       \n",
      "dev accuracy: 0.625, loss: 0.7157564759254456       \n",
      "dev accuracy: 0.3333333333333333, loss: 1.0626568794250488       \n",
      "final dev accuracy: 0.8290378006872852\n",
      "train step #1389 accuracy: 0.96875, loss: 0.2142554670572281       \n",
      "train step #1390 accuracy: 0.875, loss: 0.3475149869918823       \n",
      "train step #1391 accuracy: 0.953125, loss: 0.19112814962863922      \n",
      "train step #1392 accuracy: 0.9375, loss: 0.22621330618858337      \n",
      "train step #1393 accuracy: 0.875, loss: 0.5502418279647827       \n",
      "train step #1394 accuracy: 0.9375, loss: 0.23575012385845184      \n",
      "train step #1395 accuracy: 0.953125, loss: 0.25536200404167175      \n",
      "train step #1396 accuracy: 0.875, loss: 0.31955599784851074      \n",
      "train step #1397 accuracy: 0.921875, loss: 0.2654578387737274       \n",
      "train step #1398 accuracy: 0.96875, loss: 0.13780564069747925      \n",
      "train step #1399 accuracy: 0.9375, loss: 0.2431122362613678       \n",
      "train step #1400 accuracy: 0.9375, loss: 0.14357635378837585      \n",
      "train step #1401 accuracy: 0.84375, loss: 0.44581151008605957      \n",
      "train step #1402 accuracy: 0.84375, loss: 0.6792181134223938       \n",
      "train step #1403 accuracy: 0.9375, loss: 0.25061100721359253      \n",
      "train step #1404 accuracy: 0.90625, loss: 0.2650194764137268       \n",
      "train step #1405 accuracy: 0.9375, loss: 0.19890432059764862      \n",
      "train step #1406 accuracy: 0.921875, loss: 0.3100318908691406       \n",
      "train step #1407 accuracy: 0.875, loss: 0.3673221170902252       \n",
      "train step #1408 accuracy: 0.953125, loss: 0.19529582560062408      \n",
      "train step #1409 accuracy: 0.84375, loss: 0.4722864627838135       \n",
      "train step #1410 accuracy: 0.84375, loss: 0.4303646683692932       \n",
      "train step #1411 accuracy: 0.859375, loss: 0.47279974818229675      \n",
      "train step #1412 accuracy: 0.890625, loss: 0.33254075050354004      \n",
      "train step #1413 accuracy: 0.890625, loss: 0.2627559304237366       \n",
      "train step #1414 accuracy: 0.984375, loss: 0.11138531565666199      \n",
      "train step #1415 accuracy: 0.90625, loss: 0.24464745819568634      \n",
      "train step #1416 accuracy: 0.953125, loss: 0.16651897132396698      \n",
      "train step #1417 accuracy: 0.875, loss: 0.4070993959903717       \n",
      "train step #1418 accuracy: 0.921875, loss: 0.25343310832977295      \n",
      "train step #1419 accuracy: 0.890625, loss: 0.48784130811691284      \n",
      "train step #1420 accuracy: 0.921875, loss: 0.23797035217285156      \n",
      "train step #1421 accuracy: 0.921875, loss: 0.26735925674438477      \n",
      "train step #1422 accuracy: 0.828125, loss: 0.5395400524139404       \n",
      "train step #1423 accuracy: 0.890625, loss: 0.28898686170578003      \n",
      "train step #1424 accuracy: 0.984375, loss: 0.15329116582870483      \n",
      "train step #1425 accuracy: 0.9375, loss: 0.2808571457862854       \n",
      "train step #1426 accuracy: 0.875, loss: 0.39908367395401         \n",
      "train step #1427 accuracy: 0.84375, loss: 0.33527815341949463      \n",
      "train step #1428 accuracy: 0.90625, loss: 0.4335779845714569       \n",
      "train step #1429 accuracy: 0.921875, loss: 0.22081880271434784      \n",
      "train step #1430 accuracy: 0.9375, loss: 0.2643665075302124       \n",
      "train step #1431 accuracy: 0.921875, loss: 0.31617099046707153      \n",
      "train step #1432 accuracy: 0.90625, loss: 0.3337177038192749       \n",
      "train step #1433 accuracy: 0.875, loss: 0.37084251642227173      \n",
      "train step #1434 accuracy: 0.859375, loss: 0.414811372756958        \n",
      "train step #1435 accuracy: 0.953125, loss: 0.2132798135280609       \n",
      "train step #1436 accuracy: 0.796875, loss: 0.624555766582489        \n",
      "train step #1437 accuracy: 0.875, loss: 0.31406691670417786      \n",
      "train step #1438 accuracy: 0.875, loss: 0.3991021513938904       \n",
      "train step #1439 accuracy: 0.890625, loss: 0.39532271027565         \n",
      "train step #1440 accuracy: 0.90625, loss: 0.2430349439382553       \n",
      "train step #1441 accuracy: 0.921875, loss: 0.3674047589302063       \n",
      "train step #1442 accuracy: 0.9375, loss: 0.24198296666145325      \n",
      "train step #1443 accuracy: 0.875, loss: 0.4460533857345581       \n",
      "train step #1444 accuracy: 0.96875, loss: 0.22262965142726898      \n",
      "train step #1445 accuracy: 0.96875, loss: 0.17773456871509552      \n",
      "train step #1446 accuracy: 0.921875, loss: 0.3056533634662628       \n",
      "train step #1447 accuracy: 0.921875, loss: 0.19760417938232422      \n",
      "train step #1448 accuracy: 0.90625, loss: 0.300485223531723        \n",
      "train step #1449 accuracy: 0.859375, loss: 0.3203163146972656       \n",
      "train step #1450 accuracy: 0.875, loss: 0.3566476106643677       \n",
      "train step #1451 accuracy: 0.96875, loss: 0.15404868125915527      \n",
      "train step #1452 accuracy: 0.859375, loss: 0.4493531584739685       \n",
      "train step #1453 accuracy: 0.96875, loss: 0.1983899176120758       \n",
      "train step #1454 accuracy: 0.9375, loss: 0.2827359735965729       \n",
      "train step #1455 accuracy: 0.9375, loss: 0.28988128900527954      \n",
      "train step #1456 accuracy: 0.96875, loss: 0.26483818888664246      \n",
      "train step #1457 accuracy: 0.953125, loss: 0.2006179392337799       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #1458 accuracy: 0.875, loss: 0.3753063678741455       \n",
      "train step #1459 accuracy: 0.984375, loss: 0.08528263121843338      \n",
      "train step #1460 accuracy: 0.90625, loss: 0.339921236038208        \n",
      "train step #1461 accuracy: 0.890625, loss: 0.36979514360427856      \n",
      "train step #1462 accuracy: 0.78125, loss: 0.6718323230743408       \n",
      "train step #1463 accuracy: 0.921875, loss: 0.19448886811733246      \n",
      "train step #1464 accuracy: 0.875, loss: 0.3747556805610657       \n",
      "train step #1465 accuracy: 0.953125, loss: 0.23570767045021057      \n",
      "train step #1466 accuracy: 0.9375, loss: 0.2827305793762207       \n",
      "train step #1467 accuracy: 0.890625, loss: 0.38575753569602966      \n",
      "train step #1468 accuracy: 0.9375, loss: 0.25192829966545105      \n",
      "train step #1469 accuracy: 0.953125, loss: 0.23888149857521057      \n",
      "train step #1470 accuracy: 0.921875, loss: 0.25770968198776245      \n",
      "train step #1471 accuracy: 0.9375, loss: 0.17425931990146637      \n",
      "train step #1472 accuracy: 0.9375, loss: 0.3628752529621124       \n",
      "train step #1473 accuracy: 0.859375, loss: 0.4696163237094879       \n",
      "train step #1474 accuracy: 0.90625, loss: 0.24037234485149384      \n",
      "train step #1475 accuracy: 0.890625, loss: 0.2980329394340515       \n",
      "train step #1476 accuracy: 0.9375, loss: 0.25473326444625854      \n",
      "train step #1477 accuracy: 0.953125, loss: 0.16239416599273682      \n",
      "train step #1478 accuracy: 0.921875, loss: 0.20062445104122162      \n",
      "train step #1479 accuracy: 0.9375, loss: 0.16762924194335938      \n",
      "train step #1480 accuracy: 0.921875, loss: 0.3077365756034851       \n",
      "train step #1481 accuracy: 0.859375, loss: 0.27517902851104736      \n",
      "train step #1482 accuracy: 0.90625, loss: 0.28337782621383667      \n",
      "train step #1483 accuracy: 0.921875, loss: 0.2873385548591614       \n",
      "train step #1484 accuracy: 0.953125, loss: 0.2017921656370163       \n",
      "train step #1485 accuracy: 0.96875, loss: 0.16201767325401306      \n",
      "train step #1486 accuracy: 0.875, loss: 0.3056812584400177       \n",
      "train step #1487 accuracy: 0.890625, loss: 0.3695647418498993       \n",
      "train step #1488 accuracy: 0.9375, loss: 0.1842942237854004       \n",
      "train step #1489 accuracy: 0.890625, loss: 0.4105062782764435       \n",
      "train step #1490 accuracy: 0.875, loss: 0.5158785581588745       \n",
      "train step #1491 accuracy: 0.984375, loss: 0.14016708731651306      \n",
      "train step #1492 accuracy: 0.9375, loss: 0.24326355755329132      \n",
      "train step #1493 accuracy: 0.96875, loss: 0.15223796665668488      \n",
      "train step #1494 accuracy: 0.921875, loss: 0.36502838134765625      \n",
      "train step #1495 accuracy: 0.90625, loss: 0.2985560894012451       \n",
      "train step #1496 accuracy: 0.90625, loss: 0.32050782442092896      \n",
      "train step #1497 accuracy: 0.953125, loss: 0.24718661606311798      \n",
      "train step #1498 accuracy: 0.90625, loss: 0.3756292462348938       \n",
      "train step #1499 accuracy: 0.9375, loss: 0.16890957951545715      \n",
      "train step #1500 accuracy: 0.9375, loss: 0.2528727352619171       \n",
      "train step #1501 accuracy: 0.953125, loss: 0.2752987742424011       \n",
      "train step #1502 accuracy: 0.9375, loss: 0.13947373628616333      \n",
      "train step #1503 accuracy: 0.921875, loss: 0.26025140285491943      \n",
      "train step #1504 accuracy: 0.890625, loss: 0.31967008113861084      \n",
      "train step #1505 accuracy: 0.90625, loss: 0.28346699476242065      \n",
      "train step #1506 accuracy: 0.9375, loss: 0.2083432376384735       \n",
      "train step #1507 accuracy: 0.890625, loss: 0.26472029089927673      \n",
      "train step #1508 accuracy: 0.890625, loss: 0.39193618297576904      \n",
      "train step #1509 accuracy: 0.921875, loss: 0.20929650962352753      \n",
      "train step #1510 accuracy: 0.90625, loss: 0.48343098163604736      \n",
      "train step #1511 accuracy: 0.9375, loss: 0.2408549040555954       \n",
      "train step #1512 accuracy: 0.921875, loss: 0.2370704561471939       \n",
      "train step #1513 accuracy: 0.84375, loss: 0.4447052776813507       \n",
      "train step #1514 accuracy: 0.859375, loss: 0.5162928700447083       \n",
      "train step #1515 accuracy: 0.890625, loss: 0.29109814763069153      \n",
      "train step #1516 accuracy: 0.921875, loss: 0.22975315153598785      \n",
      "train step #1517 accuracy: 0.953125, loss: 0.23019461333751678      \n",
      "train step #1518 accuracy: 0.875, loss: 0.4335758686065674       \n",
      "train step #1519 accuracy: 0.859375, loss: 0.3522501587867737       \n",
      "train step #1520 accuracy: 0.84375, loss: 0.4615722894668579       \n",
      "train step #1521 accuracy: 0.875, loss: 0.33908385038375854      \n",
      "train step #1522 accuracy: 0.90625, loss: 0.306280255317688        \n",
      "train step #1523 accuracy: 0.9375, loss: 0.2118685394525528       \n",
      "train step #1524 accuracy: 0.875, loss: 0.43495476245880127      \n",
      "train step #1525 accuracy: 0.90625, loss: 0.22213059663772583      \n",
      "train step #1526 accuracy: 0.875, loss: 0.4081558585166931       \n",
      "train step #1527 accuracy: 0.90625, loss: 0.24579107761383057      \n",
      "train step #1528 accuracy: 0.9375, loss: 0.28437352180480957      \n",
      "train step #1529 accuracy: 0.890625, loss: 0.2610781788825989       \n",
      "train step #1530 accuracy: 0.90625, loss: 0.37837955355644226      \n",
      "train step #1531 accuracy: 0.890625, loss: 0.3971828520298004       \n",
      "train step #1532 accuracy: 0.90625, loss: 0.265268474817276        \n",
      "train step #1533 accuracy: 0.890625, loss: 0.3656734526157379       \n",
      "train step #1534 accuracy: 0.90625, loss: 0.2594301998615265       \n",
      "train step #1535 accuracy: 0.9375, loss: 0.24021777510643005      \n",
      "train step #1536 accuracy: 0.921875, loss: 0.33415916562080383      \n",
      "train step #1537 accuracy: 0.875, loss: 0.35451599955558777      \n",
      "train step #1538 accuracy: 0.90625, loss: 0.3374520242214203       \n",
      "train step #1539 accuracy: 0.953125, loss: 0.3346326947212219       \n",
      "train step #1540 accuracy: 0.890625, loss: 0.3774482011795044       \n",
      "train step #1541 accuracy: 0.890625, loss: 0.37331634759902954      \n",
      "train step #1542 accuracy: 0.859375, loss: 0.38066181540489197      \n",
      "train step #1543 accuracy: 0.96875, loss: 0.11179981380701065      \n",
      "train step #1544 accuracy: 0.953125, loss: 0.1687973141670227       \n",
      "train step #1545 accuracy: 0.90625, loss: 0.3650479018688202       \n",
      "train step #1546 accuracy: 0.859375, loss: 0.4364794194698334       \n",
      "train step #1547 accuracy: 0.984375, loss: 0.13207349181175232      \n",
      "train step #1548 accuracy: 0.859375, loss: 0.45433279871940613      \n",
      "train step #1549 accuracy: 0.90625, loss: 0.26206687092781067      \n",
      "train step #1550 accuracy: 0.96875, loss: 0.1726662963628769       \n",
      "train step #1551 accuracy: 0.890625, loss: 0.29411011934280396      \n",
      "train step #1552 accuracy: 0.90625, loss: 0.3345843553543091       \n",
      "train step #1553 accuracy: 0.984375, loss: 0.10198719799518585      \n",
      "train step #1554 accuracy: 0.921875, loss: 0.2965105175971985       \n",
      "train step #1555 accuracy: 0.953125, loss: 0.1360921412706375       \n",
      "train step #1556 accuracy: 0.96875, loss: 0.09196644276380539      \n",
      "train step #1557 accuracy: 0.875, loss: 0.37017443776130676      \n",
      "train step #1558 accuracy: 0.921875, loss: 0.24422740936279297      \n",
      "train step #1559 accuracy: 0.84375, loss: 0.43384304642677307      \n",
      "train step #1560 accuracy: 0.890625, loss: 0.37257230281829834      \n",
      "train step #1561 accuracy: 0.859375, loss: 0.3879151940345764       \n",
      "train step #1562 accuracy: 0.828125, loss: 0.5883620381355286       \n",
      "train step #1563 accuracy: 0.921875, loss: 0.22468499839305878      \n",
      "train step #1564 accuracy: 0.828125, loss: 0.4120538532733917       \n",
      "train step #1565 accuracy: 0.96875, loss: 0.10797178000211716      \n",
      "train step #1566 accuracy: 0.953125, loss: 0.20616984367370605      \n",
      "train step #1567 accuracy: 0.90625, loss: 0.2924463152885437       \n",
      "train step #1568 accuracy: 0.9375, loss: 0.22748935222625732      \n",
      "train step #1569 accuracy: 0.921875, loss: 0.22332119941711426      \n",
      "train step #1570 accuracy: 0.953125, loss: 0.24226261675357819      \n",
      "train step #1571 accuracy: 0.890625, loss: 0.2526678144931793       \n",
      "train step #1572 accuracy: 0.90625, loss: 0.2832261323928833       \n",
      "train step #1573 accuracy: 0.921875, loss: 0.28373879194259644      \n",
      "train step #1574 accuracy: 0.890625, loss: 0.30358535051345825      \n",
      "train step #1575 accuracy: 0.984375, loss: 0.10851002484560013      \n",
      "train step #1576 accuracy: 0.9375, loss: 0.2545824944972992       \n",
      "train step #1577 accuracy: 0.96875, loss: 0.12208482623100281      \n",
      "train step #1578 accuracy: 0.890625, loss: 0.47132259607315063      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #1579 accuracy: 0.9375, loss: 0.3204094171524048       \n",
      "train step #1580 accuracy: 0.921875, loss: 0.3141712546348572       \n",
      "train step #1581 accuracy: 0.90625, loss: 0.30199041962623596      \n",
      "train step #1582 accuracy: 0.875, loss: 0.44556838274002075      \n",
      "train step #1583 accuracy: 0.921875, loss: 0.2511078715324402       \n",
      "train step #1584 accuracy: 0.9375, loss: 0.23064865171909332      \n",
      "train step #1585 accuracy: 0.9375, loss: 0.206525057554245        \n",
      "train step #1586 accuracy: 0.890625, loss: 0.2997817099094391       \n",
      "train step #1587 accuracy: 0.953125, loss: 0.2078763246536255       \n",
      "train step #1588 accuracy: 0.875, loss: 0.3427209258079529       \n",
      "train step #1589 accuracy: 0.953125, loss: 0.15843838453292847      \n",
      "train step #1590 accuracy: 0.921875, loss: 0.22334659099578857      \n",
      "train step #1591 accuracy: 0.96875, loss: 0.19503656029701233      \n",
      "train step #1592 accuracy: 0.953125, loss: 0.19688525795936584      \n",
      "train step #1593 accuracy: 0.9375, loss: 0.24493245780467987      \n",
      "train step #1594 accuracy: 0.984375, loss: 0.10791926085948944      \n",
      "train step #1595 accuracy: 0.921875, loss: 0.2680913507938385       \n",
      "train step #1596 accuracy: 0.90625, loss: 0.4466773569583893       \n",
      "train step #1597 accuracy: 0.90625, loss: 0.31548526883125305      \n",
      "train step #1598 accuracy: 0.875, loss: 0.4268493056297302       \n",
      "train step #1599 accuracy: 0.890625, loss: 0.283857524394989        \n",
      "train step #1600 accuracy: 0.953125, loss: 0.1693817675113678       \n",
      "train step #1601 accuracy: 0.828125, loss: 0.5221530199050903       \n",
      "train step #1602 accuracy: 0.9375, loss: 0.2886390686035156       \n",
      "train step #1603 accuracy: 0.90625, loss: 0.34471654891967773      \n",
      "train step #1604 accuracy: 0.9375, loss: 0.1772063672542572       \n",
      "train step #1605 accuracy: 0.953125, loss: 0.16934743523597717      \n",
      "train step #1606 accuracy: 0.921875, loss: 0.18863242864608765      \n",
      "train step #1607 accuracy: 0.953125, loss: 0.2133939266204834       \n",
      "train step #1608 accuracy: 0.90625, loss: 0.23871202766895294      \n",
      "train step #1609 accuracy: 0.9375, loss: 0.2067069113254547       \n",
      "train step #1610 accuracy: 0.9375, loss: 0.30023694038391113      \n",
      "train step #1611 accuracy: 0.96875, loss: 0.18722820281982422      \n",
      "train step #1612 accuracy: 0.921875, loss: 0.2169327735900879       \n",
      "train step #1613 accuracy: 0.9375, loss: 0.25613465905189514      \n",
      "train step #1614 accuracy: 0.9375, loss: 0.18633487820625305      \n",
      "train step #1615 accuracy: 0.84375, loss: 0.35876309871673584      \n",
      "train step #1616 accuracy: 0.890625, loss: 0.34078240394592285      \n",
      "train step #1617 accuracy: 0.90625, loss: 0.3301047682762146       \n",
      "train step #1618 accuracy: 0.953125, loss: 0.2524425983428955       \n",
      "train step #1619 accuracy: 0.9375, loss: 0.20180435478687286      \n",
      "train step #1620 accuracy: 0.90625, loss: 0.21692588925361633      \n",
      "train step #1621 accuracy: 0.921875, loss: 0.2049781233072281       \n",
      "train step #1622 accuracy: 0.921875, loss: 0.2892681956291199       \n",
      "train step #1623 accuracy: 0.953125, loss: 0.1365637481212616       \n",
      "train step #1624 accuracy: 0.921875, loss: 0.1979396641254425       \n",
      "train step #1625 accuracy: 0.921875, loss: 0.29545116424560547      \n",
      "train step #1626 accuracy: 0.9375, loss: 0.17768791317939758      \n",
      "train step #1627 accuracy: 0.9375, loss: 0.2538275122642517       \n",
      "train step #1628 accuracy: 0.953125, loss: 0.2208980917930603       \n",
      "train step #1629 accuracy: 0.90625, loss: 0.36338523030281067      \n",
      "train step #1630 accuracy: 0.921875, loss: 0.32933035492897034      \n",
      "train step #1631 accuracy: 0.90625, loss: 0.20654650032520294      \n",
      "train step #1632 accuracy: 0.96875, loss: 0.17294198274612427      \n",
      "train step #1633 accuracy: 0.90625, loss: 0.36111846566200256      \n",
      "train step #1634 accuracy: 0.875, loss: 0.3153492212295532       \n",
      "train step #1635 accuracy: 0.890625, loss: 0.3327372074127197       \n",
      "train step #1636 accuracy: 0.9375, loss: 0.18111760914325714      \n",
      "train step #1637 accuracy: 0.96875, loss: 0.12249838560819626      \n",
      "train step #1638 accuracy: 0.984375, loss: 0.1967860758304596       \n",
      "train step #1639 accuracy: 0.875, loss: 0.27521634101867676      \n",
      "train step #1640 accuracy: 0.890625, loss: 0.34067782759666443      \n",
      "train step #1641 accuracy: 0.921875, loss: 0.32302412390708923      \n",
      "train step #1642 accuracy: 0.921875, loss: 0.20296873152256012      \n",
      "train step #1643 accuracy: 0.890625, loss: 0.5240405797958374       \n",
      "train step #1644 accuracy: 0.9375, loss: 0.2451222538948059       \n",
      "train step #1645 accuracy: 0.859375, loss: 0.5807822942733765       \n",
      "train step #1646 accuracy: 0.953125, loss: 0.15534546971321106      \n",
      "train step #1647 accuracy: 0.921875, loss: 0.234950989484787        \n",
      "train step #1648 accuracy: 0.921875, loss: 0.1917589008808136       \n",
      "train step #1649 accuracy: 0.953125, loss: 0.1618848443031311       \n",
      "train step #1650 accuracy: 0.875, loss: 0.4107897877693176       \n",
      "train step #1651 accuracy: 0.953125, loss: 0.2505485415458679       \n",
      "train step #1652 accuracy: 0.90625, loss: 0.2064700424671173       \n",
      "train step #1653 accuracy: 0.796875, loss: 0.5312730669975281       \n",
      "train step #1654 accuracy: 0.9375, loss: 0.24062073230743408      \n",
      "train step #1655 accuracy: 0.859375, loss: 0.4142175316810608       \n",
      "train step #1656 accuracy: 0.953125, loss: 0.1998034119606018       \n",
      "train step #1657 accuracy: 0.9375, loss: 0.1596401035785675       \n",
      "train step #1658 accuracy: 0.90625, loss: 0.287597119808197        \n",
      "train step #1659 accuracy: 0.90625, loss: 0.3676527440547943       \n",
      "train step #1660 accuracy: 0.9375, loss: 0.22531349956989288      \n",
      "train step #1661 accuracy: 0.859375, loss: 0.40911751985549927      \n",
      "train step #1662 accuracy: 0.96875, loss: 0.15832465887069702      \n",
      "train step #1663 accuracy: 0.859375, loss: 0.4785761535167694       \n",
      "train step #1664 accuracy: 0.890625, loss: 0.39445504546165466      \n",
      "train step #1665 accuracy: 0.875, loss: 0.3791882395744324       \n",
      "train step #1666 accuracy: 0.90625, loss: 0.31837692856788635      \n",
      "train step #1667 accuracy: 0.921875, loss: 0.2942790985107422       \n",
      "train step #1668 accuracy: 0.921875, loss: 0.266740083694458        \n",
      "train step #1669 accuracy: 0.921875, loss: 0.36028262972831726      \n",
      "train step #1670 accuracy: 0.9375, loss: 0.3052675127983093       \n",
      "train step #1671 accuracy: 0.921875, loss: 0.34152328968048096      \n",
      "train step #1672 accuracy: 0.953125, loss: 0.2548570930957794       \n",
      "train step #1673 accuracy: 0.875, loss: 0.37566155195236206      \n",
      "train step #1674 accuracy: 0.9375, loss: 0.28016623854637146      \n",
      "train step #1675 accuracy: 0.9375, loss: 0.20918384194374084      \n",
      "train step #1676 accuracy: 0.875, loss: 0.2940847873687744       \n",
      "train step #1677 accuracy: 0.953125, loss: 0.2600007653236389       \n",
      "train step #1678 accuracy: 0.9375, loss: 0.24439063668251038      \n",
      "train step #1679 accuracy: 0.890625, loss: 0.23940911889076233      \n",
      "train step #1680 accuracy: 0.9375, loss: 0.23126468062400818      \n",
      "train step #1681 accuracy: 0.890625, loss: 0.37376612424850464      \n",
      "train step #1682 accuracy: 0.90625, loss: 0.3061812222003937       \n",
      "train step #1683 accuracy: 0.90625, loss: 0.29728400707244873      \n",
      "train step #1684 accuracy: 0.890625, loss: 0.1971999704837799       \n",
      "train step #1685 accuracy: 0.953125, loss: 0.19700495898723602      \n",
      "train step #1686 accuracy: 0.9375, loss: 0.17368419468402863      \n",
      "train step #1687 accuracy: 0.921875, loss: 0.4261852502822876       \n",
      "train step #1688 accuracy: 0.828125, loss: 0.5328721404075623       \n",
      "train step #1689 accuracy: 0.921875, loss: 0.189762681722641        \n",
      "train step #1690 accuracy: 0.9375, loss: 0.24046841263771057      \n",
      "train step #1691 accuracy: 0.90625, loss: 0.30928611755371094      \n",
      "train step #1692 accuracy: 0.875, loss: 0.36517539620399475      \n",
      "train step #1693 accuracy: 0.921875, loss: 0.1870860755443573       \n",
      "train step #1694 accuracy: 0.9375, loss: 0.1443009078502655       \n",
      "train step #1695 accuracy: 0.953125, loss: 0.22727862000465393      \n",
      "train step #1696 accuracy: 0.953125, loss: 0.13869990408420563      \n",
      "train step #1697 accuracy: 0.90625, loss: 0.22880180180072784      \n",
      "train step #1698 accuracy: 0.90625, loss: 0.23195098340511322      \n",
      "train step #1699 accuracy: 0.890625, loss: 0.3877919614315033       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #1700 accuracy: 0.9375, loss: 0.27277612686157227      \n",
      "train step #1701 accuracy: 0.84375, loss: 0.5153321027755737       \n",
      "train step #1702 accuracy: 0.921875, loss: 0.32609713077545166      \n",
      "train step #1703 accuracy: 0.890625, loss: 0.45879918336868286      \n",
      "train step #1704 accuracy: 0.9375, loss: 0.24987037479877472      \n",
      "train step #1705 accuracy: 0.921875, loss: 0.32031139731407166      \n",
      "train step #1706 accuracy: 0.875, loss: 0.3123457431793213       \n",
      "train step #1707 accuracy: 0.90625, loss: 0.3334541320800781       \n",
      "train step #1708 accuracy: 0.953125, loss: 0.2073705941438675       \n",
      "train step #1709 accuracy: 0.84375, loss: 0.4051705002784729       \n",
      "train step #1710 accuracy: 0.9375, loss: 0.24321818351745605      \n",
      "train step #1711 accuracy: 0.90625, loss: 0.404419481754303        \n",
      "train step #1712 accuracy: 0.90625, loss: 0.29048919677734375      \n",
      "train step #1713 accuracy: 0.984375, loss: 0.07012808322906494      \n",
      "train step #1714 accuracy: 0.8125, loss: 0.5781435966491699       \n",
      "train step #1715 accuracy: 0.9375, loss: 0.43309229612350464      \n",
      "train step #1716 accuracy: 0.90625, loss: 0.27285367250442505      \n",
      "train step #1717 accuracy: 0.921875, loss: 0.28359267115592957      \n",
      "train step #1718 accuracy: 0.921875, loss: 0.3049895167350769       \n",
      "train step #1719 accuracy: 0.90625, loss: 0.3283807337284088       \n",
      "train step #1720 accuracy: 0.921875, loss: 0.33150309324264526      \n",
      "train step #1721 accuracy: 0.921875, loss: 0.3190479874610901       \n",
      "train step #1722 accuracy: 0.921875, loss: 0.2512221038341522       \n",
      "train step #1723 accuracy: 0.953125, loss: 0.16386418044567108      \n",
      "train step #1724 accuracy: 0.96875, loss: 0.16382239758968353      \n",
      "train step #1725 accuracy: 0.953125, loss: 0.12292344123125076      \n",
      "train step #1726 accuracy: 0.921875, loss: 0.30543696880340576      \n",
      "train step #1727 accuracy: 0.953125, loss: 0.18200978636741638      \n",
      "train step #1728 accuracy: 0.921875, loss: 0.2680293023586273       \n",
      "train step #1729 accuracy: 0.9375, loss: 0.3322545289993286       \n",
      "train step #1730 accuracy: 0.921875, loss: 0.16999655961990356      \n",
      "train step #1731 accuracy: 0.9375, loss: 0.27099472284317017      \n",
      "train step #1732 accuracy: 0.921875, loss: 0.39731523394584656      \n",
      "train step #1733 accuracy: 0.84375, loss: 0.3497433066368103       \n",
      "train step #1734 accuracy: 0.9375, loss: 0.23914869129657745      \n",
      "train step #1735 accuracy: 0.9375, loss: 0.2532585561275482       \n",
      "dev accuracy: 0.9375, loss: 0.14908528327941895      \n",
      "dev accuracy: 0.8125, loss: 0.7695468664169312       \n",
      "dev accuracy:   1.0, loss: 0.06015491485595703      \n",
      "dev accuracy:   1.0, loss: 0.11352008581161499      \n",
      "dev accuracy: 0.9375, loss: 0.13386449217796326      \n",
      "dev accuracy: 0.9375, loss: 0.16825278103351593      \n",
      "dev accuracy: 0.9375, loss: 0.12781181931495667      \n",
      "dev accuracy: 0.9375, loss: 0.49491971731185913      \n",
      "dev accuracy:   1.0, loss: 0.0326998233795166       \n",
      "dev accuracy: 0.9375, loss: 0.148727685213089        \n",
      "dev accuracy: 0.8125, loss: 0.37751346826553345      \n",
      "dev accuracy: 0.9375, loss: 0.2880144417285919       \n",
      "dev accuracy: 0.9375, loss: 0.16370421648025513      \n",
      "dev accuracy: 0.9375, loss: 0.3936922252178192       \n",
      "dev accuracy: 0.9375, loss: 0.28214210271835327      \n",
      "dev accuracy: 0.8125, loss: 0.606740415096283        \n",
      "dev accuracy:   1.0, loss: 0.03524097800254822      \n",
      "dev accuracy: 0.9375, loss: 0.21348686516284943      \n",
      "dev accuracy: 0.9375, loss: 0.27305498719215393      \n",
      "dev accuracy: 0.8125, loss: 0.33961936831474304      \n",
      "dev accuracy: 0.875, loss: 0.18250146508216858      \n",
      "dev accuracy: 0.9375, loss: 0.11100548505783081      \n",
      "dev accuracy: 0.875, loss: 0.5490407347679138       \n",
      "dev accuracy: 0.9375, loss: 0.1625363826751709       \n",
      "dev accuracy: 0.9375, loss: 0.09122288227081299      \n",
      "dev accuracy: 0.875, loss: 0.3271353840827942       \n",
      "dev accuracy: 0.875, loss: 0.2715167999267578       \n",
      "dev accuracy: 0.9375, loss: 0.5046160817146301       \n",
      "dev accuracy: 0.9375, loss: 0.20728518068790436      \n",
      "dev accuracy: 0.9375, loss: 0.14543917775154114      \n",
      "dev accuracy: 0.9375, loss: 0.24123609066009521      \n",
      "dev accuracy: 0.9375, loss: 0.11466750502586365      \n",
      "dev accuracy:   1.0, loss: 0.06692314147949219      \n",
      "dev accuracy: 0.8125, loss: 0.539666473865509        \n",
      "dev accuracy: 0.9375, loss: 0.13568466901779175      \n",
      "dev accuracy: 0.9375, loss: 0.17343638837337494      \n",
      "dev accuracy: 0.875, loss: 0.6026582717895508       \n",
      "dev accuracy: 0.875, loss: 0.24112051725387573      \n",
      "dev accuracy:   1.0, loss: 0.13026908040046692      \n",
      "dev accuracy: 0.875, loss: 0.5302160382270813       \n",
      "dev accuracy:   1.0, loss: 0.01111912727355957      \n",
      "dev accuracy:   1.0, loss: 0.007264852523803711     \n",
      "dev accuracy:   1.0, loss: 0.07614487409591675      \n",
      "dev accuracy: 0.8125, loss: 0.5773580074310303       \n",
      "dev accuracy:   1.0, loss: 0.1589033305644989       \n",
      "dev accuracy: 0.875, loss: 0.31719261407852173      \n",
      "dev accuracy: 0.875, loss: 0.22750762104988098      \n",
      "dev accuracy: 0.875, loss: 0.4251617193222046       \n",
      "dev accuracy:   1.0, loss: 0.08353832364082336      \n",
      "dev accuracy: 0.8125, loss: 0.8072385787963867       \n",
      "dev accuracy:   1.0, loss: 0.013337463140487671     \n",
      "dev accuracy: 0.875, loss: 0.16837501525878906      \n",
      "dev accuracy: 0.9375, loss: 0.24989572167396545      \n",
      "dev accuracy: 0.9375, loss: 0.06815369427204132      \n",
      "dev accuracy: 0.9375, loss: 0.11878177523612976      \n",
      "dev accuracy:   1.0, loss: 0.06777742505073547      \n",
      "dev accuracy: 0.875, loss: 0.2783363461494446       \n",
      "dev accuracy:   1.0, loss: 0.0979299545288086       \n",
      "dev accuracy:   1.0, loss: 0.06460496783256531      \n",
      "dev accuracy: 0.9375, loss: 0.19815859198570251      \n",
      "dev accuracy:   1.0, loss: 0.09588733315467834      \n",
      "dev accuracy:   1.0, loss: 0.0716668963432312       \n",
      "dev accuracy: 0.9375, loss: 0.40833020210266113      \n",
      "dev accuracy: 0.875, loss: 0.23259451985359192      \n",
      "dev accuracy:   1.0, loss: 0.030772656202316284     \n",
      "dev accuracy: 0.875, loss: 0.6249068379402161       \n",
      "dev accuracy: 0.875, loss: 0.2603100538253784       \n",
      "dev accuracy:   1.0, loss: 0.08407139778137207      \n",
      "dev accuracy: 0.8125, loss: 0.26411575078964233      \n",
      "dev accuracy: 0.875, loss: 0.2424706369638443       \n",
      "dev accuracy: 0.9375, loss: 0.23550906777381897      \n",
      "dev accuracy:   1.0, loss: 0.04113253951072693      \n",
      "dev accuracy: 0.9375, loss: 0.23517227172851562      \n",
      "dev accuracy: 0.875, loss: 0.24998700618743896      \n",
      "dev accuracy: 0.875, loss: 0.3355025351047516       \n",
      "dev accuracy: 0.875, loss: 0.3383314907550812       \n",
      "dev accuracy: 0.9375, loss: 0.15278801321983337      \n",
      "dev accuracy: 0.9375, loss: 0.23132401704788208      \n",
      "dev accuracy:   1.0, loss: 0.040788859128952026     \n",
      "dev accuracy:   1.0, loss: 0.011121481657028198     \n",
      "dev accuracy: 0.9375, loss: 0.0792725682258606       \n",
      "dev accuracy:   1.0, loss: 0.03231227397918701      \n",
      "dev accuracy:  0.75, loss: 0.40669476985931396      \n",
      "dev accuracy: 0.9375, loss: 0.1585759073495865       \n",
      "dev accuracy: 0.8125, loss: 0.3809816837310791       \n",
      "dev accuracy: 0.8125, loss: 0.3493497967720032       \n",
      "dev accuracy: 0.875, loss: 0.47138428688049316      \n",
      "dev accuracy: 0.8125, loss: 0.7814328670501709       \n",
      "dev accuracy: 0.8125, loss: 0.7383042573928833       \n",
      "dev accuracy:   1.0, loss: 0.013294816017150879     \n",
      "dev accuracy:   1.0, loss: 0.04836946725845337      \n",
      "dev accuracy: 0.9375, loss: 0.3263244330883026       \n",
      "dev accuracy: 0.9375, loss: 0.1261403113603592       \n",
      "dev accuracy: 0.8125, loss: 0.5284407138824463       \n",
      "dev accuracy:   1.0, loss: 0.006662160158157349     \n",
      "dev accuracy: 0.9375, loss: 0.18143555521965027      \n",
      "dev accuracy: 0.9375, loss: 0.07615360617637634      \n",
      "dev accuracy:   1.0, loss: 0.011942058801651001     \n",
      "dev accuracy:   1.0, loss: 0.052684128284454346     \n",
      "dev accuracy: 0.875, loss: 0.28127145767211914      \n",
      "dev accuracy: 0.875, loss: 0.3165684938430786       \n",
      "dev accuracy: 0.9375, loss: 0.10459697246551514      \n",
      "dev accuracy: 0.9375, loss: 0.2490728199481964       \n",
      "dev accuracy: 0.9375, loss: 0.27336516976356506      \n",
      "dev accuracy: 0.875, loss: 0.5460672378540039       \n",
      "dev accuracy: 0.875, loss: 0.4624685049057007       \n",
      "dev accuracy:   1.0, loss: 0.011654555797576904     \n",
      "dev accuracy:   1.0, loss: 0.05551934242248535      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy: 0.9375, loss: 0.17074714601039886      \n",
      "dev accuracy: 0.9375, loss: 0.43493086099624634      \n",
      "dev accuracy: 0.9375, loss: 0.18567496538162231      \n",
      "dev accuracy: 0.8125, loss: 0.49400877952575684      \n",
      "dev accuracy:   1.0, loss: 0.012523949146270752     \n",
      "dev accuracy: 0.875, loss: 0.3263348340988159       \n",
      "dev accuracy: 0.9375, loss: 0.17424261569976807      \n",
      "dev accuracy: 0.9375, loss: 0.20940959453582764      \n",
      "dev accuracy: 0.875, loss: 0.4159559905529022       \n",
      "dev accuracy: 0.8125, loss: 0.8261871337890625       \n",
      "dev accuracy: 0.875, loss: 0.3197575807571411       \n",
      "dev accuracy:  0.75, loss: 0.7152577042579651       \n",
      "dev accuracy:   1.0, loss: 0.006162285804748535     \n",
      "dev accuracy: 0.9375, loss: 0.2043125331401825       \n",
      "dev accuracy:   1.0, loss: 0.012962043285369873     \n",
      "dev accuracy: 0.875, loss: 0.28372722864151         \n",
      "dev accuracy: 0.8125, loss: 0.43673309683799744      \n",
      "dev accuracy: 0.875, loss: 0.2787126302719116       \n",
      "dev accuracy: 0.9375, loss: 0.40616294741630554      \n",
      "dev accuracy: 0.875, loss: 0.6502854228019714       \n",
      "dev accuracy: 0.9375, loss: 0.1839371621608734       \n",
      "dev accuracy: 0.875, loss: 0.1689942479133606       \n",
      "dev accuracy: 0.875, loss: 0.30294305086135864      \n",
      "dev accuracy: 0.9375, loss: 0.15953515470027924      \n",
      "dev accuracy:  0.75, loss: 0.6504728198051453       \n",
      "dev accuracy:   1.0, loss: 0.09135782718658447      \n",
      "dev accuracy:   1.0, loss: 0.0777946412563324       \n",
      "dev accuracy:   1.0, loss: 0.15779009461402893      \n",
      "dev accuracy: 0.8125, loss: 0.8562614917755127       \n",
      "dev accuracy: 0.875, loss: 0.33684420585632324      \n",
      "dev accuracy:   1.0, loss: 0.03922170400619507      \n",
      "dev accuracy: 0.9375, loss: 0.2511342763900757       \n",
      "dev accuracy: 0.9375, loss: 0.4158805012702942       \n",
      "dev accuracy: 0.9375, loss: 0.25106367468833923      \n",
      "dev accuracy: 0.9375, loss: 0.2511366307735443       \n",
      "dev accuracy:   1.0, loss: 0.01438075304031372      \n",
      "dev accuracy:   1.0, loss: 0.04115784168243408      \n",
      "dev accuracy: 0.875, loss: 0.5031296610832214       \n",
      "dev accuracy:   1.0, loss: 0.15716159343719482      \n",
      "dev accuracy: 0.9375, loss: 0.18371707201004028      \n",
      "dev accuracy: 0.9375, loss: 0.15107715129852295      \n",
      "dev accuracy:   1.0, loss: 0.1460847407579422       \n",
      "dev accuracy: 0.875, loss: 0.18221360445022583      \n",
      "dev accuracy: 0.9375, loss: 0.11278200149536133      \n",
      "dev accuracy:   1.0, loss: 0.06835800409317017      \n",
      "dev accuracy:   1.0, loss: 0.03409987688064575      \n",
      "dev accuracy:   1.0, loss: 0.11490797996520996      \n",
      "dev accuracy: 0.9375, loss: 0.14593607187271118      \n",
      "dev accuracy: 0.9375, loss: 0.15844403207302094      \n",
      "dev accuracy: 0.9375, loss: 0.4135851562023163       \n",
      "dev accuracy: 0.9375, loss: 0.10441833734512329      \n",
      "dev accuracy: 0.9375, loss: 0.19501492381095886      \n",
      "dev accuracy: 0.9375, loss: 0.21423402428627014      \n",
      "dev accuracy:   1.0, loss: 0.04317930340766907      \n",
      "dev accuracy: 0.9375, loss: 0.22177961468696594      \n",
      "dev accuracy: 0.9375, loss: 0.29508209228515625      \n",
      "dev accuracy:   1.0, loss: 0.12791715562343597      \n",
      "dev accuracy: 0.875, loss: 0.31671714782714844      \n",
      "dev accuracy: 0.875, loss: 0.3998804986476898       \n",
      "dev accuracy: 0.875, loss: 0.33276277780532837      \n",
      "dev accuracy: 0.9375, loss: 0.1819765865802765       \n",
      "dev accuracy: 0.9375, loss: 0.12291643023490906      \n",
      "dev accuracy:   1.0, loss: 0.028727591037750244     \n",
      "dev accuracy:   1.0, loss: 0.04820743203163147      \n",
      "dev accuracy: 0.9375, loss: 0.28002190589904785      \n",
      "dev accuracy: 0.8125, loss: 0.3102574646472931       \n",
      "dev accuracy:   1.0, loss: 0.0062011778354644775    \n",
      "dev accuracy:   1.0, loss: 0.0661945641040802       \n",
      "dev accuracy: 0.9375, loss: 0.2059556543827057       \n",
      "dev accuracy: 0.875, loss: 0.43485161662101746      \n",
      "dev accuracy: 0.9375, loss: 0.18877603113651276      \n",
      "dev accuracy: 0.8125, loss: 0.43542009592056274      \n",
      "dev accuracy: 0.9375, loss: 0.10785198211669922      \n",
      "dev accuracy:   1.0, loss: 0.0746239721775055       \n",
      "dev accuracy:   1.0, loss: 0.012542814016342163     \n",
      "dev accuracy: 0.9375, loss: 0.15773361921310425      \n",
      "dev accuracy:   1.0, loss: 0.06069737672805786      \n",
      "dev accuracy: 0.8125, loss: 0.3034524619579315       \n",
      "dev accuracy:   1.0, loss: 0.02693384885787964      \n",
      "dev accuracy: 0.625, loss: 0.8846712112426758       \n",
      "dev accuracy: 0.9375, loss: 0.15924426913261414      \n",
      "dev accuracy: 0.9375, loss: 0.08965802192687988      \n",
      "dev accuracy: 0.875, loss: 0.39846980571746826      \n",
      "dev accuracy: 0.9375, loss: 0.12704035639762878      \n",
      "dev accuracy:   1.0, loss: 0.041200488805770874     \n",
      "dev accuracy:   1.0, loss: 0.2579263746738434       \n",
      "final dev accuracy: 0.9252577319587629\n",
      "saving best model...\n",
      "train step #1736 accuracy: 0.96875, loss: 0.18254491686820984      \n",
      "train step #1737 accuracy: 0.96875, loss: 0.13901475071907043      \n",
      "train step #1738 accuracy: 0.953125, loss: 0.13040177524089813      \n",
      "train step #1739 accuracy: 0.9375, loss: 0.22916892170906067      \n",
      "train step #1740 accuracy: 0.9375, loss: 0.21578961610794067      \n",
      "train step #1741 accuracy: 0.9375, loss: 0.1878446787595749       \n",
      "train step #1742 accuracy: 0.921875, loss: 0.2928534746170044       \n",
      "train step #1743 accuracy: 0.9375, loss: 0.13600638508796692      \n",
      "train step #1744 accuracy: 0.921875, loss: 0.2468709945678711       \n",
      "train step #1745 accuracy: 0.96875, loss: 0.18594464659690857      \n",
      "train step #1746 accuracy: 0.9375, loss: 0.16110095381736755      \n",
      "train step #1747 accuracy: 0.921875, loss: 0.16159726679325104      \n",
      "train step #1748 accuracy: 0.96875, loss: 0.10119595378637314      \n",
      "train step #1749 accuracy: 0.96875, loss: 0.1508476883172989       \n",
      "train step #1750 accuracy: 0.921875, loss: 0.3372664451599121       \n",
      "train step #1751 accuracy: 0.96875, loss: 0.22830462455749512      \n",
      "train step #1752 accuracy: 0.96875, loss: 0.24251867830753326      \n",
      "train step #1753 accuracy: 0.9375, loss: 0.14936278760433197      \n",
      "train step #1754 accuracy: 0.9375, loss: 0.2629605829715729       \n",
      "train step #1755 accuracy: 0.9375, loss: 0.1744178682565689       \n",
      "train step #1756 accuracy: 0.96875, loss: 0.21859419345855713      \n",
      "train step #1757 accuracy: 0.90625, loss: 0.43684840202331543      \n",
      "train step #1758 accuracy: 0.921875, loss: 0.22014495730400085      \n",
      "train step #1759 accuracy: 0.984375, loss: 0.11363927274942398      \n",
      "train step #1760 accuracy: 0.9375, loss: 0.2079504132270813       \n",
      "train step #1761 accuracy: 0.921875, loss: 0.37382394075393677      \n",
      "train step #1762 accuracy: 0.953125, loss: 0.2039000391960144       \n",
      "train step #1763 accuracy: 0.9375, loss: 0.2728618085384369       \n",
      "train step #1764 accuracy: 0.9375, loss: 0.18249790370464325      \n",
      "train step #1765 accuracy: 0.953125, loss: 0.1899195909500122       \n",
      "train step #1766 accuracy: 0.96875, loss: 0.10472259670495987      \n",
      "train step #1767 accuracy: 0.859375, loss: 0.41141292452812195      \n",
      "train step #1768 accuracy: 0.890625, loss: 0.4213621914386749       \n",
      "train step #1769 accuracy: 0.90625, loss: 0.25854119658470154      \n",
      "train step #1770 accuracy: 0.890625, loss: 0.27012330293655396      \n",
      "train step #1771 accuracy: 0.921875, loss: 0.40354490280151367      \n",
      "train step #1772 accuracy: 0.9375, loss: 0.2574901580810547       \n",
      "train step #1773 accuracy: 0.890625, loss: 0.34130603075027466      \n",
      "train step #1774 accuracy: 0.953125, loss: 0.15389980375766754      \n",
      "train step #1775 accuracy: 0.953125, loss: 0.22752615809440613      \n",
      "train step #1776 accuracy: 0.9375, loss: 0.2090826779603958       \n",
      "train step #1777 accuracy: 0.921875, loss: 0.21926137804985046      \n",
      "train step #1778 accuracy: 0.890625, loss: 0.3790426552295685       \n",
      "train step #1779 accuracy: 0.859375, loss: 0.45455402135849         \n",
      "train step #1780 accuracy: 0.90625, loss: 0.34102824330329895      \n",
      "train step #1781 accuracy: 0.9375, loss: 0.22380882501602173      \n",
      "train step #1782 accuracy: 0.96875, loss: 0.1579100489616394       \n",
      "train step #1783 accuracy: 0.9375, loss: 0.168256014585495        \n",
      "train step #1784 accuracy: 0.921875, loss: 0.24001005291938782      \n",
      "train step #1785 accuracy: 0.953125, loss: 0.16781245172023773      \n",
      "train step #1786 accuracy: 0.890625, loss: 0.37703514099121094      \n",
      "train step #1787 accuracy: 0.9375, loss: 0.19905278086662292      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #1788 accuracy: 0.921875, loss: 0.28392526507377625      \n",
      "train step #1789 accuracy: 0.9375, loss: 0.1807837039232254       \n",
      "train step #1790 accuracy: 0.9375, loss: 0.15856072306632996      \n",
      "train step #1791 accuracy: 0.9375, loss: 0.219178706407547        \n",
      "train step #1792 accuracy: 0.953125, loss: 0.11065871268510818      \n",
      "train step #1793 accuracy: 0.96875, loss: 0.12946096062660217      \n",
      "train step #1794 accuracy: 0.96875, loss: 0.11576636880636215      \n",
      "train step #1795 accuracy: 0.875, loss: 0.3528927266597748       \n",
      "train step #1796 accuracy: 0.953125, loss: 0.20130720734596252      \n",
      "train step #1797 accuracy: 0.859375, loss: 0.4245645999908447       \n",
      "train step #1798 accuracy: 0.890625, loss: 0.36067649722099304      \n",
      "train step #1799 accuracy: 0.828125, loss: 0.6236488819122314       \n",
      "train step #1800 accuracy: 0.921875, loss: 0.19728030264377594      \n",
      "train step #1801 accuracy: 0.90625, loss: 0.24545693397521973      \n",
      "train step #1802 accuracy: 0.890625, loss: 0.39175719022750854      \n",
      "train step #1803 accuracy: 0.9375, loss: 0.201190784573555        \n",
      "train step #1804 accuracy: 0.9375, loss: 0.1752777397632599       \n",
      "train step #1805 accuracy: 0.875, loss: 0.4375714361667633       \n",
      "train step #1806 accuracy: 0.90625, loss: 0.19708451628684998      \n",
      "train step #1807 accuracy: 0.953125, loss: 0.14385531842708588      \n",
      "train step #1808 accuracy: 0.921875, loss: 0.3808262348175049       \n",
      "train step #1809 accuracy: 0.921875, loss: 0.4117136001586914       \n",
      "train step #1810 accuracy: 0.890625, loss: 0.2398276925086975       \n",
      "train step #1811 accuracy: 0.90625, loss: 0.37350577116012573      \n",
      "train step #1812 accuracy: 0.90625, loss: 0.3217274248600006       \n",
      "train step #1813 accuracy: 0.921875, loss: 0.24148604273796082      \n",
      "train step #1814 accuracy: 0.90625, loss: 0.33341026306152344      \n",
      "train step #1815 accuracy: 0.9375, loss: 0.17252495884895325      \n",
      "train step #1816 accuracy: 0.96875, loss: 0.09538721293210983      \n",
      "train step #1817 accuracy: 0.90625, loss: 0.2946889400482178       \n",
      "train step #1818 accuracy: 0.90625, loss: 0.26807701587677         \n",
      "train step #1819 accuracy: 0.796875, loss: 0.5731850266456604       \n",
      "train step #1820 accuracy: 0.90625, loss: 0.375660240650177        \n",
      "train step #1821 accuracy: 0.859375, loss: 0.35877636075019836      \n",
      "train step #1822 accuracy: 0.859375, loss: 0.4366888999938965       \n",
      "train step #1823 accuracy: 0.921875, loss: 0.3253110647201538       \n",
      "train step #1824 accuracy: 0.875, loss: 0.2598455250263214       \n",
      "train step #1825 accuracy: 0.9375, loss: 0.29044055938720703      \n",
      "train step #1826 accuracy: 0.890625, loss: 0.34693488478660583      \n",
      "train step #1827 accuracy: 0.921875, loss: 0.31458160281181335      \n",
      "train step #1828 accuracy: 0.921875, loss: 0.24247054755687714      \n",
      "train step #1829 accuracy: 0.90625, loss: 0.3264337480068207       \n",
      "train step #1830 accuracy: 0.90625, loss: 0.3050183057785034       \n",
      "train step #1831 accuracy: 0.890625, loss: 0.2403925210237503       \n",
      "train step #1832 accuracy: 0.953125, loss: 0.13871179521083832      \n",
      "train step #1833 accuracy: 0.890625, loss: 0.3305319547653198       \n",
      "train step #1834 accuracy: 0.953125, loss: 0.15125568211078644      \n",
      "train step #1835 accuracy: 0.921875, loss: 0.3484627902507782       \n",
      "train step #1836 accuracy: 0.921875, loss: 0.26623889803886414      \n",
      "train step #1837 accuracy: 0.890625, loss: 0.36797571182250977      \n",
      "train step #1838 accuracy: 0.953125, loss: 0.19981390237808228      \n",
      "train step #1839 accuracy: 0.875, loss: 0.3778464198112488       \n",
      "train step #1840 accuracy: 0.921875, loss: 0.23244938254356384      \n",
      "train step #1841 accuracy: 0.90625, loss: 0.2847028970718384       \n",
      "train step #1842 accuracy: 0.96875, loss: 0.13339532911777496      \n",
      "train step #1843 accuracy: 0.90625, loss: 0.24321401119232178      \n",
      "train step #1844 accuracy: 0.90625, loss: 0.3185161352157593       \n",
      "train step #1845 accuracy: 0.953125, loss: 0.22781574726104736      \n",
      "train step #1846 accuracy: 0.90625, loss: 0.2938355803489685       \n",
      "train step #1847 accuracy: 0.921875, loss: 0.26843374967575073      \n",
      "train step #1848 accuracy: 0.90625, loss: 0.34766340255737305      \n",
      "train step #1849 accuracy: 0.921875, loss: 0.24713066220283508      \n",
      "train step #1850 accuracy: 0.890625, loss: 0.2691524624824524       \n",
      "train step #1851 accuracy: 0.953125, loss: 0.1579180359840393       \n",
      "train step #1852 accuracy: 0.921875, loss: 0.21419745683670044      \n",
      "train step #1853 accuracy: 0.9375, loss: 0.2566944360733032       \n",
      "train step #1854 accuracy: 0.96875, loss: 0.13406255841255188      \n",
      "train step #1855 accuracy: 0.953125, loss: 0.14367002248764038      \n",
      "train step #1856 accuracy: 0.9375, loss: 0.21713122725486755      \n",
      "train step #1857 accuracy: 0.9375, loss: 0.1609603464603424       \n",
      "train step #1858 accuracy: 0.9375, loss: 0.1678970456123352       \n",
      "train step #1859 accuracy: 0.9375, loss: 0.2179034948348999       \n",
      "train step #1860 accuracy: 0.90625, loss: 0.23203812539577484      \n",
      "train step #1861 accuracy: 0.9375, loss: 0.1854354739189148       \n",
      "train step #1862 accuracy: 0.953125, loss: 0.16123586893081665      \n",
      "train step #1863 accuracy: 0.90625, loss: 0.35390400886535645      \n",
      "train step #1864 accuracy: 0.984375, loss: 0.10996484756469727      \n",
      "train step #1865 accuracy: 0.9375, loss: 0.2023603320121765       \n",
      "train step #1866 accuracy: 0.953125, loss: 0.1780272126197815       \n",
      "train step #1867 accuracy: 0.953125, loss: 0.17740297317504883      \n",
      "train step #1868 accuracy: 0.90625, loss: 0.13679520785808563      \n",
      "train step #1869 accuracy: 0.96875, loss: 0.12012121081352234      \n",
      "train step #1870 accuracy: 0.9375, loss: 0.2905068099498749       \n",
      "train step #1871 accuracy: 0.90625, loss: 0.2880963683128357       \n",
      "train step #1872 accuracy: 0.96875, loss: 0.12593090534210205      \n",
      "train step #1873 accuracy: 0.90625, loss: 0.37535279989242554      \n",
      "train step #1874 accuracy: 0.921875, loss: 0.21478255093097687      \n",
      "train step #1875 accuracy: 0.90625, loss: 0.15984711050987244      \n",
      "train step #1876 accuracy: 0.96875, loss: 0.14537164568901062      \n",
      "train step #1877 accuracy: 0.96875, loss: 0.12796653807163239      \n",
      "train step #1878 accuracy: 0.875, loss: 0.2977263331413269       \n",
      "train step #1879 accuracy: 0.9375, loss: 0.35201388597488403      \n",
      "train step #1880 accuracy: 0.875, loss: 0.27273985743522644      \n",
      "train step #1881 accuracy: 0.953125, loss: 0.16316500306129456      \n",
      "train step #1882 accuracy: 0.96875, loss: 0.113042451441288        \n",
      "train step #1883 accuracy: 0.921875, loss: 0.22088807821273804      \n",
      "train step #1884 accuracy: 0.9375, loss: 0.22798828780651093      \n",
      "train step #1885 accuracy: 0.890625, loss: 0.20648185908794403      \n",
      "train step #1886 accuracy: 0.859375, loss: 0.35917529463768005      \n",
      "train step #1887 accuracy: 0.96875, loss: 0.10803212970495224      \n",
      "train step #1888 accuracy: 0.953125, loss: 0.1741035282611847       \n",
      "train step #1889 accuracy: 0.890625, loss: 0.3869795501232147       \n",
      "train step #1890 accuracy: 0.9375, loss: 0.16554489731788635      \n",
      "train step #1891 accuracy: 0.96875, loss: 0.21270525455474854      \n",
      "train step #1892 accuracy: 0.921875, loss: 0.2464098334312439       \n",
      "train step #1893 accuracy: 0.90625, loss: 0.3726233243942261       \n",
      "train step #1894 accuracy: 0.9375, loss: 0.17689526081085205      \n",
      "train step #1895 accuracy: 0.9375, loss: 0.16989381611347198      \n",
      "train step #1896 accuracy: 0.9375, loss: 0.22182877361774445      \n",
      "train step #1897 accuracy: 0.921875, loss: 0.276927649974823        \n",
      "train step #1898 accuracy: 0.953125, loss: 0.20216670632362366      \n",
      "train step #1899 accuracy: 0.875, loss: 0.4215797185897827       \n",
      "train step #1900 accuracy: 0.984375, loss: 0.07785509526729584      \n",
      "train step #1901 accuracy: 0.921875, loss: 0.23639513552188873      \n",
      "train step #1902 accuracy: 0.921875, loss: 0.25478535890579224      \n",
      "train step #1903 accuracy: 0.953125, loss: 0.1253461092710495       \n",
      "train step #1904 accuracy: 0.890625, loss: 0.2920348644256592       \n",
      "train step #1905 accuracy: 0.921875, loss: 0.31652122735977173      \n",
      "train step #1906 accuracy:   1.0, loss: 0.07593628019094467      \n",
      "train step #1907 accuracy: 0.953125, loss: 0.1925864815711975       \n",
      "train step #1908 accuracy: 0.96875, loss: 0.2169686108827591       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #1909 accuracy: 0.9375, loss: 0.25642335414886475      \n",
      "train step #1910 accuracy: 0.9375, loss: 0.20761661231517792      \n",
      "train step #1911 accuracy: 0.96875, loss: 0.2051626741886139       \n",
      "train step #1912 accuracy: 0.9375, loss: 0.2704734802246094       \n",
      "train step #1913 accuracy: 0.90625, loss: 0.24450689554214478      \n",
      "train step #1914 accuracy: 0.921875, loss: 0.19986765086650848      \n",
      "train step #1915 accuracy: 0.984375, loss: 0.08678605407476425      \n",
      "train step #1916 accuracy: 0.953125, loss: 0.2359011173248291       \n",
      "train step #1917 accuracy: 0.953125, loss: 0.18983380496501923      \n",
      "train step #1918 accuracy: 0.828125, loss: 0.5723716020584106       \n",
      "train step #1919 accuracy: 0.90625, loss: 0.26813048124313354      \n",
      "train step #1920 accuracy: 0.96875, loss: 0.13559895753860474      \n",
      "train step #1921 accuracy: 0.875, loss: 0.3674353063106537       \n",
      "train step #1922 accuracy: 0.90625, loss: 0.3711585998535156       \n",
      "train step #1923 accuracy: 0.9375, loss: 0.22088590264320374      \n",
      "train step #1924 accuracy: 0.890625, loss: 0.3370698094367981       \n",
      "train step #1925 accuracy: 0.875, loss: 0.361850768327713        \n",
      "train step #1926 accuracy: 0.921875, loss: 0.28510338068008423      \n",
      "train step #1927 accuracy: 0.8125, loss: 0.5590915679931641       \n",
      "train step #1928 accuracy: 0.890625, loss: 0.45251840353012085      \n",
      "train step #1929 accuracy: 0.9375, loss: 0.1903631091117859       \n",
      "train step #1930 accuracy: 0.953125, loss: 0.28742972016334534      \n",
      "train step #1931 accuracy: 0.875, loss: 0.44974976778030396      \n",
      "train step #1932 accuracy: 0.984375, loss: 0.09393804520368576      \n",
      "train step #1933 accuracy: 0.9375, loss: 0.23776978254318237      \n",
      "train step #1934 accuracy: 0.953125, loss: 0.10606394708156586      \n",
      "train step #1935 accuracy: 0.921875, loss: 0.223969504237175        \n",
      "train step #1936 accuracy: 0.890625, loss: 0.30552732944488525      \n",
      "train step #1937 accuracy: 0.875, loss: 0.4211236536502838       \n",
      "train step #1938 accuracy: 0.921875, loss: 0.24274230003356934      \n",
      "train step #1939 accuracy: 0.921875, loss: 0.19430385529994965      \n",
      "train step #1940 accuracy: 0.921875, loss: 0.2679469585418701       \n",
      "train step #1941 accuracy: 0.859375, loss: 0.47061046957969666      \n",
      "train step #1942 accuracy: 0.9375, loss: 0.19517546892166138      \n",
      "train step #1943 accuracy: 0.953125, loss: 0.13696980476379395      \n",
      "train step #1944 accuracy: 0.953125, loss: 0.2342742532491684       \n",
      "train step #1945 accuracy: 0.875, loss: 0.4274512529373169       \n",
      "train step #1946 accuracy: 0.9375, loss: 0.34907200932502747      \n",
      "train step #1947 accuracy: 0.953125, loss: 0.3400614261627197       \n",
      "train step #1948 accuracy: 0.9375, loss: 0.1846114695072174       \n",
      "train step #1949 accuracy: 0.875, loss: 0.34864169359207153      \n",
      "train step #1950 accuracy: 0.953125, loss: 0.19350473582744598      \n",
      "train step #1951 accuracy: 0.953125, loss: 0.17074137926101685      \n",
      "train step #1952 accuracy: 0.921875, loss: 0.2699606418609619       \n",
      "train step #1953 accuracy: 0.96875, loss: 0.14761346578598022      \n",
      "train step #1954 accuracy: 0.9375, loss: 0.2770842909812927       \n",
      "train step #1955 accuracy: 0.890625, loss: 0.3426527976989746       \n",
      "train step #1956 accuracy: 0.9375, loss: 0.25101757049560547      \n",
      "train step #1957 accuracy: 0.890625, loss: 0.382946252822876        \n",
      "train step #1958 accuracy: 0.953125, loss: 0.13392992317676544      \n",
      "train step #1959 accuracy: 0.890625, loss: 0.37311434745788574      \n",
      "train step #1960 accuracy: 0.9375, loss: 0.16946899890899658      \n",
      "train step #1961 accuracy: 0.84375, loss: 0.5598462224006653       \n",
      "train step #1962 accuracy: 0.90625, loss: 0.2982890009880066       \n",
      "train step #1963 accuracy: 0.921875, loss: 0.29198774695396423      \n",
      "train step #1964 accuracy: 0.890625, loss: 0.2654513120651245       \n",
      "train step #1965 accuracy: 0.90625, loss: 0.2741173207759857       \n",
      "train step #1966 accuracy: 0.828125, loss: 0.5605984330177307       \n",
      "train step #1967 accuracy: 0.90625, loss: 0.2697840929031372       \n",
      "train step #1968 accuracy: 0.921875, loss: 0.29702937602996826      \n",
      "train step #1969 accuracy: 0.96875, loss: 0.15671071410179138      \n",
      "train step #1970 accuracy: 0.984375, loss: 0.1149885430932045       \n",
      "train step #1971 accuracy: 0.90625, loss: 0.324169397354126        \n",
      "train step #1972 accuracy: 0.90625, loss: 0.42328840494155884      \n",
      "train step #1973 accuracy: 0.84375, loss: 0.5168560743331909       \n",
      "train step #1974 accuracy: 0.921875, loss: 0.25578945875167847      \n",
      "train step #1975 accuracy: 0.9375, loss: 0.15686702728271484      \n",
      "train step #1976 accuracy: 0.984375, loss: 0.1404186487197876       \n",
      "train step #1977 accuracy: 0.9375, loss: 0.14807763695716858      \n",
      "train step #1978 accuracy: 0.921875, loss: 0.1972004622220993       \n",
      "train step #1979 accuracy: 0.953125, loss: 0.18695613741874695      \n",
      "train step #1980 accuracy: 0.890625, loss: 0.4382164776325226       \n",
      "train step #1981 accuracy: 0.96875, loss: 0.15097813308238983      \n",
      "train step #1982 accuracy: 0.9375, loss: 0.2986072301864624       \n",
      "train step #1983 accuracy: 0.9375, loss: 0.21641626954078674      \n",
      "train step #1984 accuracy: 0.890625, loss: 0.27989643812179565      \n",
      "train step #1985 accuracy: 0.96875, loss: 0.14399372041225433      \n",
      "train step #1986 accuracy: 0.890625, loss: 0.3077351450920105       \n",
      "train step #1987 accuracy: 0.875, loss: 0.4128917455673218       \n",
      "train step #1988 accuracy: 0.921875, loss: 0.15050199627876282      \n",
      "train step #1989 accuracy: 0.90625, loss: 0.28068798780441284      \n",
      "train step #1990 accuracy: 0.859375, loss: 0.588089108467102        \n",
      "train step #1991 accuracy: 0.890625, loss: 0.18292169272899628      \n",
      "train step #1992 accuracy: 0.953125, loss: 0.23368914425373077      \n",
      "train step #1993 accuracy: 0.953125, loss: 0.1552865356206894       \n",
      "train step #1994 accuracy: 0.921875, loss: 0.2735360860824585       \n",
      "train step #1995 accuracy: 0.90625, loss: 0.2949301302433014       \n",
      "train step #1996 accuracy: 0.875, loss: 0.3924785852432251       \n",
      "train step #1997 accuracy: 0.875, loss: 0.3997802436351776       \n",
      "train step #1998 accuracy:   1.0, loss: 0.0691923201084137       \n",
      "train step #1999 accuracy: 0.953125, loss: 0.18993781507015228      \n",
      "train step #2000 accuracy: 0.9375, loss: 0.29174381494522095      \n",
      "train step #2001 accuracy: 0.9375, loss: 0.2019626498222351       \n",
      "train step #2002 accuracy: 0.890625, loss: 0.35527175664901733      \n",
      "train step #2003 accuracy: 0.859375, loss: 0.4226876497268677       \n",
      "train step #2004 accuracy: 0.953125, loss: 0.21488653123378754      \n",
      "train step #2005 accuracy: 0.953125, loss: 0.1972123384475708       \n",
      "train step #2006 accuracy: 0.9375, loss: 0.2476273626089096       \n",
      "train step #2007 accuracy: 0.890625, loss: 0.26569536328315735      \n",
      "train step #2008 accuracy: 0.9375, loss: 0.3090062439441681       \n",
      "train step #2009 accuracy: 0.875, loss: 0.37075257301330566      \n",
      "train step #2010 accuracy: 0.96875, loss: 0.113825224339962        \n",
      "train step #2011 accuracy: 0.9375, loss: 0.17437735199928284      \n",
      "train step #2012 accuracy: 0.921875, loss: 0.2582028806209564       \n",
      "train step #2013 accuracy: 0.9375, loss: 0.2376539409160614       \n",
      "train step #2014 accuracy: 0.875, loss: 0.26675277948379517      \n",
      "train step #2015 accuracy: 0.921875, loss: 0.23552468419075012      \n",
      "train step #2016 accuracy: 0.9375, loss: 0.18627837300300598      \n",
      "train step #2017 accuracy: 0.984375, loss: 0.0741937905550003       \n",
      "train step #2018 accuracy: 0.953125, loss: 0.19849926233291626      \n",
      "train step #2019 accuracy: 0.90625, loss: 0.2964513599872589       \n",
      "train step #2020 accuracy: 0.9375, loss: 0.2664952874183655       \n",
      "train step #2021 accuracy: 0.859375, loss: 0.3653889298439026       \n",
      "train step #2022 accuracy: 0.90625, loss: 0.33759620785713196      \n",
      "train step #2023 accuracy: 0.984375, loss: 0.11655272543430328      \n",
      "train step #2024 accuracy: 0.90625, loss: 0.26202312111854553      \n",
      "train step #2025 accuracy: 0.921875, loss: 0.24351723492145538      \n",
      "train step #2026 accuracy: 0.921875, loss: 0.33512014150619507      \n",
      "train step #2027 accuracy: 0.9375, loss: 0.13993138074874878      \n",
      "train step #2028 accuracy: 0.96875, loss: 0.07902219146490097      \n",
      "train step #2029 accuracy: 0.921875, loss: 0.32178881764411926      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #2030 accuracy: 0.875, loss: 0.2540806829929352       \n",
      "train step #2031 accuracy: 0.921875, loss: 0.2523178458213806       \n",
      "train step #2032 accuracy: 0.953125, loss: 0.12498536705970764      \n",
      "train step #2033 accuracy: 0.96875, loss: 0.12419728189706802      \n",
      "train step #2034 accuracy: 0.96875, loss: 0.14718449115753174      \n",
      "train step #2035 accuracy: 0.96875, loss: 0.18310217559337616      \n",
      "train step #2036 accuracy: 0.9375, loss: 0.14859436452388763      \n",
      "train step #2037 accuracy: 0.984375, loss: 0.16327224671840668      \n",
      "train step #2038 accuracy: 0.890625, loss: 0.24994942545890808      \n",
      "train step #2039 accuracy: 0.890625, loss: 0.4051487445831299       \n",
      "train step #2040 accuracy: 0.890625, loss: 0.33764779567718506      \n",
      "train step #2041 accuracy: 0.96875, loss: 0.12039888650178909      \n",
      "train step #2042 accuracy: 0.90625, loss: 0.18928110599517822      \n",
      "train step #2043 accuracy: 0.9375, loss: 0.1694669872522354       \n",
      "train step #2044 accuracy: 0.96875, loss: 0.15206725895404816      \n",
      "train step #2045 accuracy: 0.921875, loss: 0.3064913749694824       \n",
      "train step #2046 accuracy: 0.921875, loss: 0.2679134011268616       \n",
      "train step #2047 accuracy: 0.921875, loss: 0.4331192374229431       \n",
      "train step #2048 accuracy: 0.9375, loss: 0.21078655123710632      \n",
      "train step #2049 accuracy: 0.84375, loss: 0.39517664909362793      \n",
      "train step #2050 accuracy: 0.953125, loss: 0.21475574374198914      \n",
      "train step #2051 accuracy: 0.9375, loss: 0.25784337520599365      \n",
      "train step #2052 accuracy: 0.9375, loss: 0.1676923781633377       \n",
      "train step #2053 accuracy: 0.9375, loss: 0.2053895741701126       \n",
      "train step #2054 accuracy: 0.890625, loss: 0.36750102043151855      \n",
      "train step #2055 accuracy: 0.9375, loss: 0.16563484072685242      \n",
      "train step #2056 accuracy: 0.90625, loss: 0.2746681272983551       \n",
      "train step #2057 accuracy: 0.921875, loss: 0.2426379919052124       \n",
      "train step #2058 accuracy: 0.9375, loss: 0.3183354139328003       \n",
      "train step #2059 accuracy: 0.9375, loss: 0.21925096213817596      \n",
      "train step #2060 accuracy: 0.90625, loss: 0.3433232307434082       \n",
      "train step #2061 accuracy: 0.921875, loss: 0.3451738655567169       \n",
      "train step #2062 accuracy: 0.90625, loss: 0.2786071002483368       \n",
      "train step #2063 accuracy: 0.921875, loss: 0.3476704955101013       \n",
      "train step #2064 accuracy: 0.984375, loss: 0.06378433108329773      \n",
      "train step #2065 accuracy: 0.953125, loss: 0.2217406928539276       \n",
      "train step #2066 accuracy: 0.9375, loss: 0.20334504544734955      \n",
      "train step #2067 accuracy: 0.84375, loss: 0.434553861618042        \n",
      "train step #2068 accuracy: 0.9375, loss: 0.2428695261478424       \n",
      "train step #2069 accuracy: 0.9375, loss: 0.14860278367996216      \n",
      "train step #2070 accuracy: 0.953125, loss: 0.25287163257598877      \n",
      "train step #2071 accuracy: 0.9375, loss: 0.2341369390487671       \n",
      "train step #2072 accuracy: 0.78125, loss: 0.6637539863586426       \n",
      "train step #2073 accuracy: 0.890625, loss: 0.3034129738807678       \n",
      "train step #2074 accuracy: 0.921875, loss: 0.1708422154188156       \n",
      "train step #2075 accuracy: 0.9375, loss: 0.18029636144638062      \n",
      "train step #2076 accuracy: 0.953125, loss: 0.17004317045211792      \n",
      "train step #2077 accuracy: 0.9375, loss: 0.23628342151641846      \n",
      "train step #2078 accuracy: 0.9375, loss: 0.2833864688873291       \n",
      "train step #2079 accuracy: 0.9375, loss: 0.2930125892162323       \n",
      "train step #2080 accuracy: 0.9375, loss: 0.21727338433265686      \n",
      "train step #2081 accuracy: 0.953125, loss: 0.1693863719701767       \n",
      "train step #2082 accuracy: 0.890625, loss: 0.3112567365169525       \n",
      "dev accuracy: 0.9375, loss: 0.24780283868312836      \n",
      "dev accuracy: 0.9375, loss: 0.3259811997413635       \n",
      "dev accuracy: 0.9375, loss: 0.18645069003105164      \n",
      "dev accuracy:   1.0, loss: 0.027203410863876343     \n",
      "dev accuracy:  0.75, loss: 0.39694744348526         \n",
      "dev accuracy: 0.9375, loss: 0.108225017786026        \n",
      "dev accuracy: 0.875, loss: 0.8513665795326233       \n",
      "dev accuracy: 0.875, loss: 0.5204554796218872       \n",
      "dev accuracy: 0.9375, loss: 0.4714292287826538       \n",
      "dev accuracy:   1.0, loss: 0.014121055603027344     \n",
      "dev accuracy:   1.0, loss: 0.016791075468063354     \n",
      "dev accuracy: 0.875, loss: 0.2901691794395447       \n",
      "dev accuracy:   1.0, loss: 0.005092620849609375     \n",
      "dev accuracy: 0.8125, loss: 0.43403708934783936      \n",
      "dev accuracy: 0.6875, loss: 0.6632986068725586       \n",
      "dev accuracy: 0.9375, loss: 0.1805344521999359       \n",
      "dev accuracy: 0.6875, loss: 0.7938123345375061       \n",
      "dev accuracy:   1.0, loss: 0.014873355627059937     \n",
      "dev accuracy: 0.875, loss: 0.37407901883125305      \n",
      "dev accuracy: 0.9375, loss: 0.3217601180076599       \n",
      "dev accuracy: 0.9375, loss: 0.44057339429855347      \n",
      "dev accuracy:   1.0, loss: 0.05050215125083923      \n",
      "dev accuracy: 0.9375, loss: 0.294321209192276        \n",
      "dev accuracy:   1.0, loss: 0.094464972615242        \n",
      "dev accuracy: 0.9375, loss: 0.13948974013328552      \n",
      "dev accuracy: 0.9375, loss: 0.2331790030002594       \n",
      "dev accuracy: 0.9375, loss: 0.16094085574150085      \n",
      "dev accuracy: 0.9375, loss: 0.13987740874290466      \n",
      "dev accuracy: 0.9375, loss: 0.38209715485572815      \n",
      "dev accuracy: 0.8125, loss: 0.34958797693252563      \n",
      "dev accuracy: 0.875, loss: 0.5742627382278442       \n",
      "dev accuracy: 0.9375, loss: 0.1894667148590088       \n",
      "dev accuracy:  0.75, loss: 0.6362016201019287       \n",
      "dev accuracy: 0.875, loss: 0.2596280872821808       \n",
      "dev accuracy: 0.875, loss: 0.239344984292984        \n",
      "dev accuracy: 0.9375, loss: 0.23874562978744507      \n",
      "dev accuracy:   1.0, loss: 0.022318512201309204     \n",
      "dev accuracy: 0.875, loss: 0.3383420705795288       \n",
      "dev accuracy: 0.875, loss: 0.2381579577922821       \n",
      "dev accuracy: 0.9375, loss: 0.18371941149234772      \n",
      "dev accuracy: 0.9375, loss: 0.4265594184398651       \n",
      "dev accuracy: 0.875, loss: 0.49368298053741455      \n",
      "dev accuracy: 0.8125, loss: 0.31892478466033936      \n",
      "dev accuracy: 0.8125, loss: 0.32153940200805664      \n",
      "dev accuracy: 0.9375, loss: 0.13694533705711365      \n",
      "dev accuracy: 0.9375, loss: 0.1930217444896698       \n",
      "dev accuracy: 0.875, loss: 0.5663739442825317       \n",
      "dev accuracy: 0.8125, loss: 0.37756314873695374      \n",
      "dev accuracy: 0.8125, loss: 0.333788126707077        \n",
      "dev accuracy: 0.875, loss: 0.2801310122013092       \n",
      "dev accuracy: 0.875, loss: 0.6610793471336365       \n",
      "dev accuracy: 0.8125, loss: 0.942854642868042        \n",
      "dev accuracy:   1.0, loss: 0.04763570427894592      \n",
      "dev accuracy:  0.75, loss: 0.5496616363525391       \n",
      "dev accuracy:   1.0, loss: 0.0526832640171051       \n",
      "dev accuracy: 0.9375, loss: 0.128717303276062        \n",
      "dev accuracy: 0.9375, loss: 0.1332678496837616       \n",
      "dev accuracy:   1.0, loss: 0.022655874490737915     \n",
      "dev accuracy: 0.8125, loss: 0.4813246726989746       \n",
      "dev accuracy:   1.0, loss: 0.03435409069061279      \n",
      "dev accuracy:   1.0, loss: 0.03694036602973938      \n",
      "dev accuracy: 0.9375, loss: 0.1619586944580078       \n",
      "dev accuracy: 0.875, loss: 0.45040827989578247      \n",
      "dev accuracy: 0.9375, loss: 0.12419472634792328      \n",
      "dev accuracy: 0.875, loss: 0.44895535707473755      \n",
      "dev accuracy: 0.875, loss: 0.2769588828086853       \n",
      "dev accuracy: 0.875, loss: 0.1659373641014099       \n",
      "dev accuracy:   1.0, loss: 0.13350078463554382      \n",
      "dev accuracy: 0.9375, loss: 0.23599934577941895      \n",
      "dev accuracy: 0.875, loss: 0.44935938715934753      \n",
      "dev accuracy:   1.0, loss: 0.06786999106407166      \n",
      "dev accuracy: 0.9375, loss: 0.24515673518180847      \n",
      "dev accuracy:  0.75, loss: 0.9078835844993591       \n",
      "dev accuracy: 0.8125, loss: 0.5783981680870056       \n",
      "dev accuracy:   1.0, loss: 0.10463352501392365      \n",
      "dev accuracy: 0.875, loss: 0.24992288649082184      \n",
      "dev accuracy:   1.0, loss: 0.034836262464523315     \n",
      "dev accuracy:   1.0, loss: 0.1802464723587036       \n",
      "dev accuracy:   1.0, loss: 0.07954660058021545      \n",
      "dev accuracy: 0.875, loss: 0.4360526204109192       \n",
      "dev accuracy: 0.875, loss: 0.2479616105556488       \n",
      "dev accuracy:   1.0, loss: 0.14173075556755066      \n",
      "dev accuracy:   1.0, loss: 0.06511765718460083      \n",
      "dev accuracy: 0.8125, loss: 0.8339590430259705       \n",
      "dev accuracy: 0.875, loss: 0.2974260151386261       \n",
      "dev accuracy: 0.6875, loss: 1.186992883682251        \n",
      "dev accuracy: 0.9375, loss: 0.12495235353708267      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy: 0.875, loss: 0.5887781381607056       \n",
      "dev accuracy: 0.875, loss: 0.35662418603897095      \n",
      "dev accuracy: 0.875, loss: 0.20575964450836182      \n",
      "dev accuracy: 0.8125, loss: 0.2781214714050293       \n",
      "dev accuracy:   1.0, loss: 0.08007384836673737      \n",
      "dev accuracy:  0.75, loss: 0.5466129779815674       \n",
      "dev accuracy: 0.9375, loss: 0.29618167877197266      \n",
      "dev accuracy:   1.0, loss: 0.030552655458450317     \n",
      "dev accuracy: 0.9375, loss: 0.22785545885562897      \n",
      "dev accuracy: 0.875, loss: 0.18949614465236664      \n",
      "dev accuracy: 0.9375, loss: 0.48886722326278687      \n",
      "dev accuracy:   1.0, loss: 0.15980808436870575      \n",
      "dev accuracy: 0.875, loss: 0.2495088130235672       \n",
      "dev accuracy:   1.0, loss: 0.09037449955940247      \n",
      "dev accuracy: 0.8125, loss: 0.2908087372779846       \n",
      "dev accuracy:   1.0, loss: 0.028426319360733032     \n",
      "dev accuracy: 0.9375, loss: 0.12236985564231873      \n",
      "dev accuracy: 0.9375, loss: 0.19833175837993622      \n",
      "dev accuracy: 0.9375, loss: 0.12481054663658142      \n",
      "dev accuracy:   1.0, loss: 0.03588584065437317      \n",
      "dev accuracy: 0.9375, loss: 0.13674437999725342      \n",
      "dev accuracy: 0.8125, loss: 1.0131762027740479       \n",
      "dev accuracy:   1.0, loss: 0.00793042778968811      \n",
      "dev accuracy: 0.9375, loss: 0.2430627942085266       \n",
      "dev accuracy: 0.8125, loss: 0.40466615557670593      \n",
      "dev accuracy:   1.0, loss: 0.009301066398620605     \n",
      "dev accuracy:   1.0, loss: 0.11112290620803833      \n",
      "dev accuracy:   1.0, loss: 0.009280920028686523     \n",
      "dev accuracy: 0.875, loss: 0.47559958696365356      \n",
      "dev accuracy: 0.9375, loss: 0.14912882447242737      \n",
      "dev accuracy: 0.875, loss: 0.21859371662139893      \n",
      "dev accuracy:   1.0, loss: 0.035179704427719116     \n",
      "dev accuracy: 0.9375, loss: 0.08477151393890381      \n",
      "dev accuracy:   1.0, loss: 0.054552286863327026     \n",
      "dev accuracy:   1.0, loss: 0.04360964894294739      \n",
      "dev accuracy: 0.875, loss: 0.5444617867469788       \n",
      "dev accuracy:   1.0, loss: 0.08385157585144043      \n",
      "dev accuracy: 0.9375, loss: 0.15251928567886353      \n",
      "dev accuracy: 0.8125, loss: 0.6600519418716431       \n",
      "dev accuracy:   1.0, loss: 0.019996464252471924     \n",
      "dev accuracy: 0.875, loss: 0.23259982466697693      \n",
      "dev accuracy:   1.0, loss: 0.07725834846496582      \n",
      "dev accuracy: 0.9375, loss: 0.15607479214668274      \n",
      "dev accuracy: 0.875, loss: 0.395706444978714        \n",
      "dev accuracy: 0.8125, loss: 0.5901654958724976       \n",
      "dev accuracy: 0.9375, loss: 0.4216231405735016       \n",
      "dev accuracy:   1.0, loss: 0.04001086950302124      \n",
      "dev accuracy: 0.9375, loss: 0.36023256182670593      \n",
      "dev accuracy: 0.875, loss: 0.1961701363325119       \n",
      "dev accuracy: 0.9375, loss: 0.19836536049842834      \n",
      "dev accuracy: 0.8125, loss: 0.3728023171424866       \n",
      "dev accuracy: 0.875, loss: 0.29904693365097046      \n",
      "dev accuracy:  0.75, loss: 0.9247316122055054       \n",
      "dev accuracy: 0.9375, loss: 0.2810629904270172       \n",
      "dev accuracy: 0.9375, loss: 0.19570451974868774      \n",
      "dev accuracy: 0.8125, loss: 0.8805635571479797       \n",
      "dev accuracy: 0.9375, loss: 0.13285402953624725      \n",
      "dev accuracy: 0.875, loss: 0.40368586778640747      \n",
      "dev accuracy: 0.9375, loss: 0.16122370958328247      \n",
      "dev accuracy: 0.9375, loss: 0.11507552862167358      \n",
      "dev accuracy: 0.8125, loss: 0.5362117886543274       \n",
      "dev accuracy:   1.0, loss: 0.1399221271276474       \n",
      "dev accuracy: 0.9375, loss: 0.13465777039527893      \n",
      "dev accuracy: 0.9375, loss: 0.15395177900791168      \n",
      "dev accuracy:   1.0, loss: 0.09204865992069244      \n",
      "dev accuracy: 0.875, loss: 0.3315050005912781       \n",
      "dev accuracy: 0.875, loss: 0.48001277446746826      \n",
      "dev accuracy:   1.0, loss: 0.03925532102584839      \n",
      "dev accuracy:  0.75, loss: 0.5431472063064575       \n",
      "dev accuracy:   1.0, loss: 0.0504932701587677       \n",
      "dev accuracy: 0.6875, loss: 0.939681887626648        \n",
      "dev accuracy:   1.0, loss: 0.016434431076049805     \n",
      "dev accuracy:   1.0, loss: 0.07317747175693512      \n",
      "dev accuracy: 0.8125, loss: 0.56230628490448         \n",
      "dev accuracy: 0.9375, loss: 0.12960031628608704      \n",
      "dev accuracy: 0.875, loss: 0.25371885299682617      \n",
      "dev accuracy:   1.0, loss: 0.039809346199035645     \n",
      "dev accuracy: 0.9375, loss: 0.1514146775007248       \n",
      "dev accuracy:   1.0, loss: 0.08563527464866638      \n",
      "dev accuracy:   1.0, loss: 0.04859989881515503      \n",
      "dev accuracy: 0.8125, loss: 0.551907479763031        \n",
      "dev accuracy: 0.8125, loss: 0.8594949841499329       \n",
      "dev accuracy:   1.0, loss: 0.056774258613586426     \n",
      "dev accuracy: 0.9375, loss: 0.17422842979431152      \n",
      "dev accuracy: 0.6875, loss: 0.6264998316764832       \n",
      "dev accuracy: 0.875, loss: 0.5222322940826416       \n",
      "dev accuracy:   1.0, loss: 0.015117615461349487     \n",
      "dev accuracy: 0.875, loss: 0.1740921139717102       \n",
      "dev accuracy:   1.0, loss: 0.08405525982379913      \n",
      "dev accuracy: 0.8125, loss: 0.5326838493347168       \n",
      "dev accuracy:   1.0, loss: 0.07651397585868835      \n",
      "dev accuracy: 0.8125, loss: 0.4453182816505432       \n",
      "dev accuracy: 0.9375, loss: 0.060756534337997437     \n",
      "dev accuracy:   1.0, loss: 0.1357038915157318       \n",
      "dev accuracy: 0.9375, loss: 0.16026994585990906      \n",
      "dev accuracy: 0.8125, loss: 0.4573136270046234       \n",
      "dev accuracy:   1.0, loss: 0.05408389866352081      \n",
      "dev accuracy:   1.0, loss: 0.06396558880805969      \n",
      "dev accuracy:   1.0, loss: 0.030141979455947876     \n",
      "dev accuracy: 0.8125, loss: 0.3022564649581909       \n",
      "dev accuracy: 0.875, loss: 0.2886020541191101       \n",
      "dev accuracy:   1.0, loss: 0.058639347553253174     \n",
      "dev accuracy: 0.9375, loss: 0.1293957233428955       \n",
      "dev accuracy: 0.875, loss: 0.3078019917011261       \n",
      "dev accuracy: 0.9375, loss: 0.07701414823532104      \n",
      "dev accuracy:   1.0, loss: 0.03446388244628906      \n",
      "dev accuracy:   1.0, loss: 0.2642105519771576       \n",
      "final dev accuracy: 0.9126932989690721\n",
      "train step #2083 accuracy: 0.875, loss: 0.5949329137802124       \n",
      "train step #2084 accuracy: 0.984375, loss: 0.14948491752147675      \n",
      "train step #2085 accuracy: 0.96875, loss: 0.139731764793396        \n",
      "train step #2086 accuracy: 0.9375, loss: 0.23393988609313965      \n",
      "train step #2087 accuracy: 0.953125, loss: 0.20807252824306488      \n",
      "train step #2088 accuracy: 0.9375, loss: 0.20895357429981232      \n",
      "train step #2089 accuracy: 0.921875, loss: 0.22692164778709412      \n",
      "train step #2090 accuracy: 0.953125, loss: 0.170140340924263        \n",
      "train step #2091 accuracy: 0.921875, loss: 0.31306302547454834      \n",
      "train step #2092 accuracy: 0.921875, loss: 0.27066779136657715      \n",
      "train step #2093 accuracy: 0.90625, loss: 0.3039734363555908       \n",
      "train step #2094 accuracy: 0.890625, loss: 0.3525954484939575       \n",
      "train step #2095 accuracy: 0.9375, loss: 0.2903178334236145       \n",
      "train step #2096 accuracy: 0.875, loss: 0.3498653471469879       \n",
      "train step #2097 accuracy: 0.90625, loss: 0.3039054870605469       \n",
      "train step #2098 accuracy: 0.890625, loss: 0.39922896027565         \n",
      "train step #2099 accuracy: 0.921875, loss: 0.27889031171798706      \n",
      "train step #2100 accuracy: 0.96875, loss: 0.11660254746675491      \n",
      "train step #2101 accuracy: 0.875, loss: 0.33302178978919983      \n",
      "train step #2102 accuracy: 0.9375, loss: 0.1740739494562149       \n",
      "train step #2103 accuracy: 0.921875, loss: 0.2665553689002991       \n",
      "train step #2104 accuracy: 0.921875, loss: 0.2353316694498062       \n",
      "train step #2105 accuracy: 0.921875, loss: 0.29958340525627136      \n",
      "train step #2106 accuracy: 0.953125, loss: 0.16101835668087006      \n",
      "train step #2107 accuracy: 0.953125, loss: 0.1520228385925293       \n",
      "train step #2108 accuracy: 0.890625, loss: 0.30895882844924927      \n",
      "train step #2109 accuracy: 0.921875, loss: 0.18779459595680237      \n",
      "train step #2110 accuracy: 0.96875, loss: 0.1513393521308899       \n",
      "train step #2111 accuracy: 0.9375, loss: 0.22862575948238373      \n",
      "train step #2112 accuracy: 0.90625, loss: 0.28951358795166016      \n",
      "train step #2113 accuracy: 0.859375, loss: 0.4168698787689209       \n",
      "train step #2114 accuracy: 0.921875, loss: 0.2797195613384247       \n",
      "train step #2115 accuracy: 0.96875, loss: 0.1448293924331665       \n",
      "train step #2116 accuracy: 0.96875, loss: 0.09601426869630814      \n",
      "train step #2117 accuracy: 0.953125, loss: 0.21466463804244995      \n",
      "train step #2118 accuracy: 0.953125, loss: 0.13526460528373718      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #2119 accuracy: 0.953125, loss: 0.24059177935123444      \n",
      "train step #2120 accuracy: 0.90625, loss: 0.25753676891326904      \n",
      "train step #2121 accuracy: 0.9375, loss: 0.16771200299263         \n",
      "train step #2122 accuracy: 0.96875, loss: 0.1595279574394226       \n",
      "train step #2123 accuracy: 0.921875, loss: 0.13384918868541718      \n",
      "train step #2124 accuracy: 0.921875, loss: 0.44848042726516724      \n",
      "train step #2125 accuracy: 0.96875, loss: 0.11082034558057785      \n",
      "train step #2126 accuracy: 0.921875, loss: 0.40376460552215576      \n",
      "train step #2127 accuracy: 0.9375, loss: 0.23242469131946564      \n",
      "train step #2128 accuracy: 0.921875, loss: 0.2827228307723999       \n",
      "train step #2129 accuracy: 0.953125, loss: 0.1953137218952179       \n",
      "train step #2130 accuracy: 0.953125, loss: 0.1627611666917801       \n",
      "train step #2131 accuracy: 0.953125, loss: 0.11877164244651794      \n",
      "train step #2132 accuracy: 0.890625, loss: 0.36589622497558594      \n",
      "train step #2133 accuracy: 0.921875, loss: 0.2535708546638489       \n",
      "train step #2134 accuracy: 0.890625, loss: 0.32806384563446045      \n",
      "train step #2135 accuracy:   1.0, loss: 0.07320931553840637      \n",
      "train step #2136 accuracy: 0.96875, loss: 0.10487979650497437      \n",
      "train step #2137 accuracy: 0.90625, loss: 0.26829808950424194      \n",
      "train step #2138 accuracy: 0.90625, loss: 0.31268033385276794      \n",
      "train step #2139 accuracy: 0.96875, loss: 0.1408107727766037       \n",
      "train step #2140 accuracy: 0.96875, loss: 0.2014477699995041       \n",
      "train step #2141 accuracy: 0.90625, loss: 0.31663987040519714      \n",
      "train step #2142 accuracy: 0.9375, loss: 0.167028546333313        \n",
      "train step #2143 accuracy: 0.9375, loss: 0.2815077006816864       \n",
      "train step #2144 accuracy: 0.96875, loss: 0.19155295193195343      \n",
      "train step #2145 accuracy: 0.96875, loss: 0.2834431529045105       \n",
      "train step #2146 accuracy: 0.953125, loss: 0.21593709290027618      \n",
      "train step #2147 accuracy: 0.890625, loss: 0.2177276909351349       \n",
      "train step #2148 accuracy: 0.984375, loss: 0.0788884237408638       \n",
      "train step #2149 accuracy: 0.90625, loss: 0.30476468801498413      \n",
      "train step #2150 accuracy: 0.9375, loss: 0.22052311897277832      \n",
      "train step #2151 accuracy: 0.90625, loss: 0.37730810046195984      \n",
      "train step #2152 accuracy: 0.9375, loss: 0.19567826390266418      \n",
      "train step #2153 accuracy: 0.96875, loss: 0.08621405810117722      \n",
      "train step #2154 accuracy: 0.953125, loss: 0.16685891151428223      \n",
      "train step #2155 accuracy: 0.90625, loss: 0.19394385814666748      \n",
      "train step #2156 accuracy: 0.90625, loss: 0.3161502480506897       \n",
      "train step #2157 accuracy: 0.875, loss: 0.3021700978279114       \n",
      "train step #2158 accuracy: 0.90625, loss: 0.21554601192474365      \n",
      "train step #2159 accuracy: 0.921875, loss: 0.2196374386548996       \n",
      "train step #2160 accuracy: 0.953125, loss: 0.12281050533056259      \n",
      "train step #2161 accuracy: 0.890625, loss: 0.2623962163925171       \n",
      "train step #2162 accuracy: 0.859375, loss: 0.4661104679107666       \n",
      "train step #2163 accuracy: 0.921875, loss: 0.21950604021549225      \n",
      "train step #2164 accuracy: 0.953125, loss: 0.1696927696466446       \n",
      "train step #2165 accuracy: 0.9375, loss: 0.1884264498949051       \n",
      "train step #2166 accuracy: 0.96875, loss: 0.1327374279499054       \n",
      "train step #2167 accuracy: 0.859375, loss: 0.4608305096626282       \n",
      "train step #2168 accuracy: 0.953125, loss: 0.15743015706539154      \n",
      "train step #2169 accuracy: 0.953125, loss: 0.15922248363494873      \n",
      "train step #2170 accuracy: 0.90625, loss: 0.28731769323349         \n",
      "train step #2171 accuracy: 0.9375, loss: 0.12663748860359192      \n",
      "train step #2172 accuracy: 0.921875, loss: 0.2543397545814514       \n",
      "train step #2173 accuracy: 0.953125, loss: 0.13546711206436157      \n",
      "train step #2174 accuracy: 0.9375, loss: 0.273362934589386        \n",
      "train step #2175 accuracy: 0.9375, loss: 0.2236356884241104       \n",
      "train step #2176 accuracy: 0.984375, loss: 0.06451336294412613      \n",
      "train step #2177 accuracy: 0.9375, loss: 0.23349878191947937      \n",
      "train step #2178 accuracy: 0.90625, loss: 0.3367791175842285       \n",
      "train step #2179 accuracy: 0.859375, loss: 0.2914400100708008       \n",
      "train step #2180 accuracy: 0.921875, loss: 0.2297576367855072       \n",
      "train step #2181 accuracy: 0.9375, loss: 0.2640732228755951       \n",
      "train step #2182 accuracy: 0.96875, loss: 0.12740550935268402      \n",
      "train step #2183 accuracy: 0.890625, loss: 0.38677799701690674      \n",
      "train step #2184 accuracy: 0.9375, loss: 0.25552406907081604      \n",
      "train step #2185 accuracy: 0.890625, loss: 0.4474108815193176       \n",
      "train step #2186 accuracy: 0.9375, loss: 0.21454750001430511      \n",
      "train step #2187 accuracy: 0.953125, loss: 0.11761622875928879      \n",
      "train step #2188 accuracy: 0.96875, loss: 0.1506170928478241       \n",
      "train step #2189 accuracy: 0.9375, loss: 0.19190272688865662      \n",
      "train step #2190 accuracy: 0.90625, loss: 0.23097798228263855      \n",
      "train step #2191 accuracy: 0.890625, loss: 0.24098224937915802      \n",
      "train step #2192 accuracy: 0.953125, loss: 0.2441115379333496       \n",
      "train step #2193 accuracy: 0.953125, loss: 0.18614087998867035      \n",
      "train step #2194 accuracy: 0.921875, loss: 0.26760056614875793      \n",
      "train step #2195 accuracy: 0.90625, loss: 0.2418074905872345       \n",
      "train step #2196 accuracy: 0.921875, loss: 0.19395485520362854      \n",
      "train step #2197 accuracy: 0.921875, loss: 0.41356927156448364      \n",
      "train step #2198 accuracy: 0.921875, loss: 0.23556847870349884      \n",
      "train step #2199 accuracy: 0.9375, loss: 0.2986573576927185       \n",
      "train step #2200 accuracy: 0.9375, loss: 0.15015533566474915      \n",
      "train step #2201 accuracy: 0.921875, loss: 0.2926390767097473       \n",
      "train step #2202 accuracy: 0.953125, loss: 0.16554835438728333      \n",
      "train step #2203 accuracy: 0.9375, loss: 0.24586668610572815      \n",
      "train step #2204 accuracy: 0.9375, loss: 0.282166063785553        \n",
      "train step #2205 accuracy: 0.953125, loss: 0.13586126267910004      \n",
      "train step #2206 accuracy: 0.96875, loss: 0.1561601161956787       \n",
      "train step #2207 accuracy: 0.890625, loss: 0.3302900791168213       \n",
      "train step #2208 accuracy: 0.90625, loss: 0.29990458488464355      \n",
      "train step #2209 accuracy: 0.9375, loss: 0.25617343187332153      \n",
      "train step #2210 accuracy: 0.875, loss: 0.5523456931114197       \n",
      "train step #2211 accuracy: 0.921875, loss: 0.222310408949852        \n",
      "train step #2212 accuracy: 0.921875, loss: 0.21656259894371033      \n",
      "train step #2213 accuracy: 0.921875, loss: 0.28027087450027466      \n",
      "train step #2214 accuracy: 0.90625, loss: 0.24733313918113708      \n",
      "train step #2215 accuracy: 0.875, loss: 0.3304849863052368       \n",
      "train step #2216 accuracy: 0.890625, loss: 0.3140036463737488       \n",
      "train step #2217 accuracy: 0.9375, loss: 0.21676841378211975      \n",
      "train step #2218 accuracy: 0.9375, loss: 0.27061980962753296      \n",
      "train step #2219 accuracy: 0.96875, loss: 0.10157443583011627      \n",
      "train step #2220 accuracy: 0.875, loss: 0.29154595732688904      \n",
      "train step #2221 accuracy: 0.90625, loss: 0.2907950282096863       \n",
      "train step #2222 accuracy: 0.921875, loss: 0.260526180267334        \n",
      "train step #2223 accuracy: 0.9375, loss: 0.2607247233390808       \n",
      "train step #2224 accuracy: 0.96875, loss: 0.1867647022008896       \n",
      "train step #2225 accuracy: 0.9375, loss: 0.19168534874916077      \n",
      "train step #2226 accuracy: 0.953125, loss: 0.2567023038864136       \n",
      "train step #2227 accuracy: 0.953125, loss: 0.22015170753002167      \n",
      "train step #2228 accuracy: 0.953125, loss: 0.2043680101633072       \n",
      "train step #2229 accuracy: 0.953125, loss: 0.13303223252296448      \n",
      "train step #2230 accuracy: 0.90625, loss: 0.30685529112815857      \n",
      "train step #2231 accuracy: 0.9375, loss: 0.27947553992271423      \n",
      "train step #2232 accuracy: 0.921875, loss: 0.34089481830596924      \n",
      "train step #2233 accuracy: 0.9375, loss: 0.3676808476448059       \n",
      "train step #2234 accuracy: 0.921875, loss: 0.31000104546546936      \n",
      "train step #2235 accuracy: 0.9375, loss: 0.2249835729598999       \n",
      "train step #2236 accuracy: 0.84375, loss: 0.37155869603157043      \n",
      "train step #2237 accuracy: 0.9375, loss: 0.1900143325328827       \n",
      "train step #2238 accuracy: 0.9375, loss: 0.287997305393219        \n",
      "train step #2239 accuracy: 0.84375, loss: 0.49696114659309387      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #2240 accuracy:   1.0, loss: 0.04894676059484482      \n",
      "train step #2241 accuracy: 0.9375, loss: 0.1566319316625595       \n",
      "train step #2242 accuracy: 0.984375, loss: 0.0799124464392662       \n",
      "train step #2243 accuracy: 0.9375, loss: 0.2635705769062042       \n",
      "train step #2244 accuracy: 0.984375, loss: 0.10614529252052307      \n",
      "train step #2245 accuracy: 0.90625, loss: 0.36931079626083374      \n",
      "train step #2246 accuracy: 0.96875, loss: 0.08587421476840973      \n",
      "train step #2247 accuracy: 0.9375, loss: 0.2536194920539856       \n",
      "train step #2248 accuracy: 0.890625, loss: 0.38122424483299255      \n",
      "train step #2249 accuracy: 0.921875, loss: 0.25182777643203735      \n",
      "train step #2250 accuracy: 0.90625, loss: 0.27878010272979736      \n",
      "train step #2251 accuracy: 0.921875, loss: 0.2762264013290405       \n",
      "train step #2252 accuracy: 0.953125, loss: 0.1437874138355255       \n",
      "train step #2253 accuracy: 0.90625, loss: 0.3035724461078644       \n",
      "train step #2254 accuracy: 0.9375, loss: 0.19330638647079468      \n",
      "train step #2255 accuracy: 0.9375, loss: 0.16839683055877686      \n",
      "train step #2256 accuracy: 0.984375, loss: 0.1154671311378479       \n",
      "train step #2257 accuracy: 0.890625, loss: 0.5109652280807495       \n",
      "train step #2258 accuracy: 0.890625, loss: 0.30206388235092163      \n",
      "train step #2259 accuracy: 0.90625, loss: 0.2820582091808319       \n",
      "train step #2260 accuracy: 0.953125, loss: 0.16818328201770782      \n",
      "train step #2261 accuracy: 0.921875, loss: 0.21554142236709595      \n",
      "train step #2262 accuracy:   1.0, loss: 0.04523270204663277      \n",
      "train step #2263 accuracy: 0.96875, loss: 0.1803470402956009       \n",
      "train step #2264 accuracy: 0.921875, loss: 0.1924026608467102       \n",
      "train step #2265 accuracy: 0.890625, loss: 0.3542601466178894       \n",
      "train step #2266 accuracy: 0.953125, loss: 0.18724489212036133      \n",
      "train step #2267 accuracy: 0.96875, loss: 0.12469533830881119      \n",
      "train step #2268 accuracy: 0.984375, loss: 0.10897491872310638      \n",
      "train step #2269 accuracy: 0.984375, loss: 0.10116742551326752      \n",
      "train step #2270 accuracy: 0.921875, loss: 0.32239317893981934      \n",
      "train step #2271 accuracy: 0.953125, loss: 0.14781543612480164      \n",
      "train step #2272 accuracy:   1.0, loss: 0.05606316030025482      \n",
      "train step #2273 accuracy: 0.859375, loss: 0.4042070209980011       \n",
      "train step #2274 accuracy: 0.984375, loss: 0.08290340006351471      \n",
      "train step #2275 accuracy: 0.9375, loss: 0.15971234440803528      \n",
      "train step #2276 accuracy: 0.890625, loss: 0.2766765356063843       \n",
      "train step #2277 accuracy: 0.984375, loss: 0.0890117660164833       \n",
      "train step #2278 accuracy: 0.90625, loss: 0.31974583864212036      \n",
      "train step #2279 accuracy: 0.921875, loss: 0.2640918791294098       \n",
      "train step #2280 accuracy: 0.96875, loss: 0.09448897838592529      \n",
      "train step #2281 accuracy: 0.9375, loss: 0.17920321226119995      \n",
      "train step #2282 accuracy: 0.9375, loss: 0.2039766162633896       \n",
      "train step #2283 accuracy: 0.921875, loss: 0.2435741424560547       \n",
      "train step #2284 accuracy: 0.96875, loss: 0.1042286604642868       \n",
      "train step #2285 accuracy: 0.96875, loss: 0.14049355685710907      \n",
      "train step #2286 accuracy: 0.96875, loss: 0.1797603964805603       \n",
      "train step #2287 accuracy: 0.953125, loss: 0.15811502933502197      \n",
      "train step #2288 accuracy: 0.953125, loss: 0.2308545559644699       \n",
      "train step #2289 accuracy: 0.953125, loss: 0.15358570218086243      \n",
      "train step #2290 accuracy: 0.953125, loss: 0.1580440104007721       \n",
      "train step #2291 accuracy:   1.0, loss: 0.0537683442234993       \n",
      "train step #2292 accuracy: 0.90625, loss: 0.3047676682472229       \n",
      "train step #2293 accuracy: 0.921875, loss: 0.2867347002029419       \n",
      "train step #2294 accuracy: 0.921875, loss: 0.25330325961112976      \n",
      "train step #2295 accuracy: 0.9375, loss: 0.2561316192150116       \n",
      "train step #2296 accuracy: 0.90625, loss: 0.321932852268219        \n",
      "train step #2297 accuracy: 0.953125, loss: 0.27544716000556946      \n",
      "train step #2298 accuracy: 0.90625, loss: 0.26353803277015686      \n",
      "train step #2299 accuracy: 0.921875, loss: 0.28840935230255127      \n",
      "train step #2300 accuracy: 0.96875, loss: 0.1427273452281952       \n",
      "train step #2301 accuracy: 0.96875, loss: 0.10764998197555542      \n",
      "train step #2302 accuracy: 0.9375, loss: 0.323697566986084        \n",
      "train step #2303 accuracy: 0.96875, loss: 0.1669105589389801       \n",
      "train step #2304 accuracy: 0.84375, loss: 0.33410272002220154      \n",
      "train step #2305 accuracy: 0.921875, loss: 0.254135400056839        \n",
      "train step #2306 accuracy: 0.921875, loss: 0.27354270219802856      \n",
      "train step #2307 accuracy: 0.96875, loss: 0.11962375789880753      \n",
      "train step #2308 accuracy: 0.9375, loss: 0.17993374168872833      \n",
      "train step #2309 accuracy: 0.9375, loss: 0.13012705743312836      \n",
      "train step #2310 accuracy: 0.953125, loss: 0.16242501139640808      \n",
      "train step #2311 accuracy: 0.921875, loss: 0.3113518953323364       \n",
      "train step #2312 accuracy: 0.890625, loss: 0.39134544134140015      \n",
      "train step #2313 accuracy: 0.953125, loss: 0.15338164567947388      \n",
      "train step #2314 accuracy: 0.96875, loss: 0.09457626938819885      \n",
      "train step #2315 accuracy: 0.921875, loss: 0.2769230604171753       \n",
      "train step #2316 accuracy: 0.890625, loss: 0.3588270843029022       \n",
      "train step #2317 accuracy: 0.890625, loss: 0.42356956005096436      \n",
      "train step #2318 accuracy: 0.890625, loss: 0.3475480079650879       \n",
      "train step #2319 accuracy: 0.921875, loss: 0.25948983430862427      \n",
      "train step #2320 accuracy: 0.90625, loss: 0.27852633595466614      \n",
      "train step #2321 accuracy: 0.84375, loss: 0.41147300601005554      \n",
      "train step #2322 accuracy: 0.90625, loss: 0.2734532952308655       \n",
      "train step #2323 accuracy: 0.890625, loss: 0.2853921055793762       \n",
      "train step #2324 accuracy: 0.96875, loss: 0.10923589766025543      \n",
      "train step #2325 accuracy: 0.984375, loss: 0.06503792107105255      \n",
      "train step #2326 accuracy: 0.9375, loss: 0.13918820023536682      \n",
      "train step #2327 accuracy: 0.875, loss: 0.33499377965927124      \n",
      "train step #2328 accuracy: 0.90625, loss: 0.28940877318382263      \n",
      "train step #2329 accuracy: 0.875, loss: 0.42674168944358826      \n",
      "train step #2330 accuracy: 0.921875, loss: 0.23155146837234497      \n",
      "train step #2331 accuracy: 0.953125, loss: 0.2589927911758423       \n",
      "train step #2332 accuracy: 0.890625, loss: 0.24872328341007233      \n",
      "train step #2333 accuracy: 0.96875, loss: 0.12076953053474426      \n",
      "train step #2334 accuracy: 0.96875, loss: 0.11314617842435837      \n",
      "train step #2335 accuracy: 0.890625, loss: 0.33679622411727905      \n",
      "train step #2336 accuracy: 0.96875, loss: 0.1845455765724182       \n",
      "train step #2337 accuracy: 0.953125, loss: 0.16165843605995178      \n",
      "train step #2338 accuracy: 0.96875, loss: 0.14452916383743286      \n",
      "train step #2339 accuracy: 0.9375, loss: 0.13883203268051147      \n",
      "train step #2340 accuracy: 0.90625, loss: 0.34078240394592285      \n",
      "train step #2341 accuracy: 0.90625, loss: 0.40260642766952515      \n",
      "train step #2342 accuracy: 0.859375, loss: 0.4637945592403412       \n",
      "train step #2343 accuracy: 0.9375, loss: 0.20352068543434143      \n",
      "train step #2344 accuracy: 0.984375, loss: 0.12830239534378052      \n",
      "train step #2345 accuracy: 0.875, loss: 0.42730748653411865      \n",
      "train step #2346 accuracy: 0.96875, loss: 0.12784640491008759      \n",
      "train step #2347 accuracy: 0.90625, loss: 0.3531304597854614       \n",
      "train step #2348 accuracy: 0.890625, loss: 0.3432329297065735       \n",
      "train step #2349 accuracy: 0.953125, loss: 0.1841290146112442       \n",
      "train step #2350 accuracy: 0.9375, loss: 0.19708921015262604      \n",
      "train step #2351 accuracy: 0.984375, loss: 0.09626314789056778      \n",
      "train step #2352 accuracy: 0.921875, loss: 0.18305489420890808      \n",
      "train step #2353 accuracy: 0.9375, loss: 0.16796810925006866      \n",
      "train step #2354 accuracy: 0.953125, loss: 0.25608181953430176      \n",
      "train step #2355 accuracy: 0.953125, loss: 0.16620779037475586      \n",
      "train step #2356 accuracy: 0.90625, loss: 0.21554528176784515      \n",
      "train step #2357 accuracy: 0.9375, loss: 0.2032642364501953       \n",
      "train step #2358 accuracy: 0.953125, loss: 0.19076645374298096      \n",
      "train step #2359 accuracy: 0.921875, loss: 0.37124067544937134      \n",
      "train step #2360 accuracy: 0.953125, loss: 0.20643366873264313      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #2361 accuracy: 0.984375, loss: 0.1458454579114914       \n",
      "train step #2362 accuracy:   1.0, loss: 0.05402247980237007      \n",
      "train step #2363 accuracy: 0.84375, loss: 0.5098816752433777       \n",
      "train step #2364 accuracy: 0.953125, loss: 0.24122637510299683      \n",
      "train step #2365 accuracy: 0.953125, loss: 0.20345669984817505      \n",
      "train step #2366 accuracy: 0.96875, loss: 0.09456497430801392      \n",
      "train step #2367 accuracy: 0.953125, loss: 0.2928115129470825       \n",
      "train step #2368 accuracy: 0.953125, loss: 0.23230794072151184      \n",
      "train step #2369 accuracy: 0.921875, loss: 0.34709545969963074      \n",
      "train step #2370 accuracy: 0.921875, loss: 0.21594272553920746      \n",
      "train step #2371 accuracy: 0.96875, loss: 0.0889139473438263       \n",
      "train step #2372 accuracy: 0.890625, loss: 0.3311232924461365       \n",
      "train step #2373 accuracy: 0.96875, loss: 0.09493383020162582      \n",
      "train step #2374 accuracy: 0.953125, loss: 0.20020011067390442      \n",
      "train step #2375 accuracy: 0.953125, loss: 0.21629758179187775      \n",
      "train step #2376 accuracy: 0.90625, loss: 0.26064005494117737      \n",
      "train step #2377 accuracy: 0.953125, loss: 0.2109668254852295       \n",
      "train step #2378 accuracy: 0.921875, loss: 0.3333222270011902       \n",
      "train step #2379 accuracy: 0.921875, loss: 0.2828249931335449       \n",
      "train step #2380 accuracy: 0.84375, loss: 0.4667947590351105       \n",
      "train step #2381 accuracy: 0.921875, loss: 0.23709091544151306      \n",
      "train step #2382 accuracy: 0.96875, loss: 0.12887533009052277      \n",
      "train step #2383 accuracy: 0.921875, loss: 0.14667899906635284      \n",
      "train step #2384 accuracy: 0.90625, loss: 0.31772297620773315      \n",
      "train step #2385 accuracy: 0.953125, loss: 0.15267616510391235      \n",
      "train step #2386 accuracy: 0.96875, loss: 0.17543570697307587      \n",
      "train step #2387 accuracy: 0.96875, loss: 0.12990565598011017      \n",
      "train step #2388 accuracy: 0.953125, loss: 0.27539879083633423      \n",
      "train step #2389 accuracy: 0.953125, loss: 0.14264822006225586      \n",
      "train step #2390 accuracy: 0.9375, loss: 0.15627026557922363      \n",
      "train step #2391 accuracy: 0.9375, loss: 0.16180984675884247      \n",
      "train step #2392 accuracy: 0.9375, loss: 0.2083413302898407       \n",
      "train step #2393 accuracy: 0.984375, loss: 0.11836688220500946      \n",
      "train step #2394 accuracy: 0.953125, loss: 0.18501336872577667      \n",
      "train step #2395 accuracy: 0.9375, loss: 0.15649765729904175      \n",
      "train step #2396 accuracy: 0.921875, loss: 0.1649169623851776       \n",
      "train step #2397 accuracy: 0.984375, loss: 0.07754276692867279      \n",
      "train step #2398 accuracy: 0.828125, loss: 0.6064580678939819       \n",
      "train step #2399 accuracy: 0.921875, loss: 0.364133358001709        \n",
      "train step #2400 accuracy: 0.984375, loss: 0.08549053221940994      \n",
      "train step #2401 accuracy: 0.953125, loss: 0.22955745458602905      \n",
      "train step #2402 accuracy: 0.890625, loss: 0.3195812702178955       \n",
      "train step #2403 accuracy: 0.921875, loss: 0.1929100900888443       \n",
      "train step #2404 accuracy: 0.984375, loss: 0.11656155437231064      \n",
      "train step #2405 accuracy: 0.9375, loss: 0.24740108847618103      \n",
      "train step #2406 accuracy: 0.9375, loss: 0.1744358241558075       \n",
      "train step #2407 accuracy: 0.921875, loss: 0.1878051608800888       \n",
      "train step #2408 accuracy: 0.953125, loss: 0.18333381414413452      \n",
      "train step #2409 accuracy: 0.96875, loss: 0.14789718389511108      \n",
      "train step #2410 accuracy: 0.96875, loss: 0.1004435271024704       \n",
      "train step #2411 accuracy: 0.953125, loss: 0.20290057361125946      \n",
      "train step #2412 accuracy: 0.96875, loss: 0.18589553236961365      \n",
      "train step #2413 accuracy: 0.9375, loss: 0.21864068508148193      \n",
      "train step #2414 accuracy: 0.9375, loss: 0.19036436080932617      \n",
      "train step #2415 accuracy: 0.953125, loss: 0.18225249648094177      \n",
      "train step #2416 accuracy: 0.953125, loss: 0.20613613724708557      \n",
      "train step #2417 accuracy: 0.890625, loss: 0.4030988812446594       \n",
      "train step #2418 accuracy: 0.921875, loss: 0.16422131657600403      \n",
      "train step #2419 accuracy: 0.96875, loss: 0.13135486841201782      \n",
      "train step #2420 accuracy: 0.9375, loss: 0.2378581464290619       \n",
      "train step #2421 accuracy: 0.9375, loss: 0.1984032541513443       \n",
      "train step #2422 accuracy: 0.953125, loss: 0.1794337034225464       \n",
      "train step #2423 accuracy: 0.9375, loss: 0.1815779209136963       \n",
      "train step #2424 accuracy: 0.875, loss: 0.28368088603019714      \n",
      "train step #2425 accuracy: 0.9375, loss: 0.23754309117794037      \n",
      "train step #2426 accuracy: 0.9375, loss: 0.20510262250900269      \n",
      "train step #2427 accuracy: 0.921875, loss: 0.2267918884754181       \n",
      "train step #2428 accuracy: 0.9375, loss: 0.37015944719314575      \n",
      "train step #2429 accuracy: 0.921875, loss: 0.3134368062019348       \n",
      "dev accuracy: 0.9375, loss: 0.35461995005607605      \n",
      "dev accuracy: 0.9375, loss: 0.2297341227531433       \n",
      "dev accuracy: 0.8125, loss: 0.35669007897377014      \n",
      "dev accuracy:   1.0, loss: 0.02584800124168396      \n",
      "dev accuracy: 0.875, loss: 0.2893218398094177       \n",
      "dev accuracy:   1.0, loss: 0.022196143865585327     \n",
      "dev accuracy:   1.0, loss: 0.09742540121078491      \n",
      "dev accuracy:   1.0, loss: 0.02325063943862915      \n",
      "dev accuracy:   1.0, loss: 0.04609912633895874      \n",
      "dev accuracy: 0.875, loss: 0.37033671140670776      \n",
      "dev accuracy: 0.8125, loss: 0.843414843082428        \n",
      "dev accuracy: 0.9375, loss: 0.16460978984832764      \n",
      "dev accuracy: 0.9375, loss: 0.13159435987472534      \n",
      "dev accuracy: 0.875, loss: 0.3812686800956726       \n",
      "dev accuracy: 0.9375, loss: 0.13027918338775635      \n",
      "dev accuracy: 0.8125, loss: 0.6986393928527832       \n",
      "dev accuracy:   1.0, loss: 0.14082656800746918      \n",
      "dev accuracy: 0.875, loss: 0.2224416583776474       \n",
      "dev accuracy: 0.9375, loss: 0.20601357519626617      \n",
      "dev accuracy:   1.0, loss: 0.018554508686065674     \n",
      "dev accuracy: 0.9375, loss: 0.28055936098098755      \n",
      "dev accuracy: 0.9375, loss: 0.3483767807483673       \n",
      "dev accuracy: 0.875, loss: 0.5786552429199219       \n",
      "dev accuracy: 0.8125, loss: 0.4877585172653198       \n",
      "dev accuracy: 0.9375, loss: 0.14310181140899658      \n",
      "dev accuracy:   1.0, loss: 0.043251752853393555     \n",
      "dev accuracy:   1.0, loss: 0.023402392864227295     \n",
      "dev accuracy: 0.8125, loss: 0.6027490496635437       \n",
      "dev accuracy: 0.875, loss: 0.2923346757888794       \n",
      "dev accuracy: 0.9375, loss: 0.142425537109375        \n",
      "dev accuracy: 0.9375, loss: 0.14665649831295013      \n",
      "dev accuracy:   1.0, loss: 0.06741252541542053      \n",
      "dev accuracy: 0.8125, loss: 0.5978723764419556       \n",
      "dev accuracy:   1.0, loss: 0.01663607358932495      \n",
      "dev accuracy: 0.9375, loss: 0.11097633838653564      \n",
      "dev accuracy: 0.9375, loss: 0.2045595645904541       \n",
      "dev accuracy: 0.9375, loss: 0.3152585029602051       \n",
      "dev accuracy: 0.9375, loss: 0.21232163906097412      \n",
      "dev accuracy: 0.9375, loss: 0.13062843680381775      \n",
      "dev accuracy: 0.875, loss: 0.4249521791934967       \n",
      "dev accuracy: 0.8125, loss: 0.6276711225509644       \n",
      "dev accuracy:   1.0, loss: 0.07449343800544739      \n",
      "dev accuracy:   1.0, loss: 0.01879715919494629      \n",
      "dev accuracy: 0.875, loss: 0.17314660549163818      \n",
      "dev accuracy: 0.9375, loss: 0.2764047086238861       \n",
      "dev accuracy:   1.0, loss: 0.06629908084869385      \n",
      "dev accuracy: 0.9375, loss: 0.11410579085350037      \n",
      "dev accuracy: 0.875, loss: 0.3978942334651947       \n",
      "dev accuracy: 0.9375, loss: 0.43043869733810425      \n",
      "dev accuracy: 0.875, loss: 0.8218080997467041       \n",
      "dev accuracy:  0.75, loss: 0.5354777574539185       \n",
      "dev accuracy:   1.0, loss: 0.05030113458633423      \n",
      "dev accuracy:   1.0, loss: 0.0392155647277832       \n",
      "dev accuracy:   1.0, loss: 0.02040994167327881      \n",
      "dev accuracy: 0.8125, loss: 0.4998675584793091       \n",
      "dev accuracy: 0.875, loss: 0.539840579032898        \n",
      "dev accuracy:   1.0, loss: 0.06973691284656525      \n",
      "dev accuracy: 0.875, loss: 0.20906001329421997      \n",
      "dev accuracy: 0.9375, loss: 0.17139235138893127      \n",
      "dev accuracy: 0.9375, loss: 0.13694089651107788      \n",
      "dev accuracy:   1.0, loss: 0.019768446683883667     \n",
      "dev accuracy: 0.9375, loss: 0.1406208872795105       \n",
      "dev accuracy:   1.0, loss: 0.08576008677482605      \n",
      "dev accuracy: 0.9375, loss: 0.10234299302101135      \n",
      "dev accuracy:   1.0, loss: 0.022897660732269287     \n",
      "dev accuracy: 0.875, loss: 0.635534942150116        \n",
      "dev accuracy: 0.875, loss: 0.5854590535163879       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy: 0.875, loss: 0.3604118227958679       \n",
      "dev accuracy: 0.875, loss: 0.8419930338859558       \n",
      "dev accuracy:   1.0, loss: 0.07299163937568665      \n",
      "dev accuracy:   1.0, loss: 0.01773509383201599      \n",
      "dev accuracy:   1.0, loss: 0.10796685516834259      \n",
      "dev accuracy: 0.9375, loss: 0.19014370441436768      \n",
      "dev accuracy: 0.9375, loss: 0.3610663414001465       \n",
      "dev accuracy: 0.875, loss: 0.2218931019306183       \n",
      "dev accuracy:   1.0, loss: 0.039105236530303955     \n",
      "dev accuracy: 0.9375, loss: 0.10669785737991333      \n",
      "dev accuracy: 0.8125, loss: 0.565527617931366        \n",
      "dev accuracy: 0.9375, loss: 0.43672165274620056      \n",
      "dev accuracy: 0.9375, loss: 0.2053942084312439       \n",
      "dev accuracy: 0.875, loss: 0.2811514735221863       \n",
      "dev accuracy: 0.8125, loss: 0.8967019319534302       \n",
      "dev accuracy: 0.9375, loss: 0.10607334971427917      \n",
      "dev accuracy: 0.875, loss: 0.20062196254730225      \n",
      "dev accuracy:   1.0, loss: 0.03627185523509979      \n",
      "dev accuracy:   1.0, loss: 0.02216207981109619      \n",
      "dev accuracy: 0.875, loss: 0.1561761498451233       \n",
      "dev accuracy: 0.9375, loss: 0.11044278740882874      \n",
      "dev accuracy: 0.875, loss: 0.24600167572498322      \n",
      "dev accuracy: 0.875, loss: 0.5390400290489197       \n",
      "dev accuracy: 0.9375, loss: 0.2894674837589264       \n",
      "dev accuracy: 0.875, loss: 0.4262499511241913       \n",
      "dev accuracy: 0.9375, loss: 0.16212394833564758      \n",
      "dev accuracy: 0.9375, loss: 0.19566038250923157      \n",
      "dev accuracy: 0.9375, loss: 0.3858020007610321       \n",
      "dev accuracy: 0.8125, loss: 0.38009345531463623      \n",
      "dev accuracy: 0.9375, loss: 0.15694093704223633      \n",
      "dev accuracy:   1.0, loss: 0.006182491779327393     \n",
      "dev accuracy:   1.0, loss: 0.05785071849822998      \n",
      "dev accuracy: 0.875, loss: 0.33443954586982727      \n",
      "dev accuracy: 0.9375, loss: 0.10792979598045349      \n",
      "dev accuracy: 0.875, loss: 0.27615275979042053      \n",
      "dev accuracy: 0.625, loss: 1.1287164688110352       \n",
      "dev accuracy:   1.0, loss: 0.03897744417190552      \n",
      "dev accuracy: 0.8125, loss: 0.6612280607223511       \n",
      "dev accuracy: 0.875, loss: 0.4496647119522095       \n",
      "dev accuracy: 0.9375, loss: 0.14040815830230713      \n",
      "dev accuracy: 0.8125, loss: 0.47297704219818115      \n",
      "dev accuracy: 0.9375, loss: 0.12062789499759674      \n",
      "dev accuracy:   1.0, loss: 0.048632293939590454     \n",
      "dev accuracy: 0.875, loss: 0.15500672161579132      \n",
      "dev accuracy:   1.0, loss: 0.10335205495357513      \n",
      "dev accuracy: 0.9375, loss: 0.36356979608535767      \n",
      "dev accuracy: 0.875, loss: 0.20544204115867615      \n",
      "dev accuracy:   1.0, loss: 0.19034090638160706      \n",
      "dev accuracy:   1.0, loss: 0.05621948838233948      \n",
      "dev accuracy: 0.9375, loss: 0.22692467272281647      \n",
      "dev accuracy:   1.0, loss: 0.14530101418495178      \n",
      "dev accuracy:   1.0, loss: 0.007460922002792358     \n",
      "dev accuracy: 0.8125, loss: 0.44994595646858215      \n",
      "dev accuracy:   1.0, loss: 0.013922154903411865     \n",
      "dev accuracy: 0.9375, loss: 0.38852885365486145      \n",
      "dev accuracy: 0.875, loss: 0.2717822194099426       \n",
      "dev accuracy:   1.0, loss: 0.0278148353099823       \n",
      "dev accuracy:   1.0, loss: 0.038730621337890625     \n",
      "dev accuracy: 0.8125, loss: 0.255550742149353        \n",
      "dev accuracy:   1.0, loss: 0.037679314613342285     \n",
      "dev accuracy: 0.9375, loss: 0.08371950685977936      \n",
      "dev accuracy: 0.9375, loss: 0.32556793093681335      \n",
      "dev accuracy: 0.875, loss: 0.5344730019569397       \n",
      "dev accuracy:   1.0, loss: 0.05615895986557007      \n",
      "dev accuracy: 0.8125, loss: 0.6711812615394592       \n",
      "dev accuracy: 0.8125, loss: 0.35013455152511597      \n",
      "dev accuracy:   1.0, loss: 0.006385236978530884     \n",
      "dev accuracy: 0.8125, loss: 0.2796483635902405       \n",
      "dev accuracy: 0.9375, loss: 0.19261619448661804      \n",
      "dev accuracy: 0.9375, loss: 0.0816158652305603       \n",
      "dev accuracy: 0.9375, loss: 0.09032529592514038      \n",
      "dev accuracy: 0.875, loss: 0.3923256993293762       \n",
      "dev accuracy: 0.9375, loss: 0.11042845249176025      \n",
      "dev accuracy: 0.8125, loss: 0.3763084411621094       \n",
      "dev accuracy:   1.0, loss: 0.050980716943740845     \n",
      "dev accuracy:   1.0, loss: 0.03899994492530823      \n",
      "dev accuracy: 0.8125, loss: 0.5317369103431702       \n",
      "dev accuracy: 0.9375, loss: 0.12742924690246582      \n",
      "dev accuracy:   1.0, loss: 0.034084469079971313     \n",
      "dev accuracy: 0.9375, loss: 0.24202290177345276      \n",
      "dev accuracy: 0.9375, loss: 0.14309161901474         \n",
      "dev accuracy: 0.875, loss: 0.20441508293151855      \n",
      "dev accuracy: 0.9375, loss: 0.1340637505054474       \n",
      "dev accuracy: 0.875, loss: 0.2972649335861206       \n",
      "dev accuracy:   1.0, loss: 0.04808527231216431      \n",
      "dev accuracy: 0.9375, loss: 0.2676548957824707       \n",
      "dev accuracy:   1.0, loss: 0.03630492091178894      \n",
      "dev accuracy: 0.9375, loss: 0.14342665672302246      \n",
      "dev accuracy: 0.875, loss: 0.22733095288276672      \n",
      "dev accuracy: 0.9375, loss: 0.15036866068840027      \n",
      "dev accuracy:   1.0, loss: 0.118752121925354        \n",
      "dev accuracy: 0.9375, loss: 0.21987834572792053      \n",
      "dev accuracy:   1.0, loss: 0.04844707250595093      \n",
      "dev accuracy: 0.875, loss: 0.389784574508667        \n",
      "dev accuracy: 0.875, loss: 0.4856991469860077       \n",
      "dev accuracy: 0.875, loss: 0.5659077167510986       \n",
      "dev accuracy: 0.9375, loss: 0.12137144804000854      \n",
      "dev accuracy: 0.9375, loss: 0.2187516838312149       \n",
      "dev accuracy: 0.9375, loss: 0.28361302614212036      \n",
      "dev accuracy: 0.9375, loss: 0.24826553463935852      \n",
      "dev accuracy:   1.0, loss: 0.03711569309234619      \n",
      "dev accuracy:   1.0, loss: 0.1031431034207344       \n",
      "dev accuracy: 0.9375, loss: 0.15217870473861694      \n",
      "dev accuracy: 0.9375, loss: 0.30592015385627747      \n",
      "dev accuracy: 0.9375, loss: 0.10066297650337219      \n",
      "dev accuracy: 0.9375, loss: 0.20209914445877075      \n",
      "dev accuracy: 0.8125, loss: 0.3950956165790558       \n",
      "dev accuracy:   1.0, loss: 0.016804635524749756     \n",
      "dev accuracy: 0.875, loss: 0.22249343991279602      \n",
      "dev accuracy: 0.875, loss: 0.26846936345100403      \n",
      "dev accuracy: 0.8125, loss: 0.6880978345870972       \n",
      "dev accuracy:   1.0, loss: 0.10508082807064056      \n",
      "dev accuracy: 0.8125, loss: 0.6078541874885559       \n",
      "dev accuracy: 0.9375, loss: 0.1753002405166626       \n",
      "dev accuracy: 0.875, loss: 0.5010343790054321       \n",
      "dev accuracy: 0.9375, loss: 0.1869637817144394       \n",
      "dev accuracy: 0.9375, loss: 0.1355668306350708       \n",
      "dev accuracy: 0.9375, loss: 0.1643393337726593       \n",
      "dev accuracy: 0.875, loss: 0.40620359778404236      \n",
      "dev accuracy:   1.0, loss: 0.04763302206993103      \n",
      "dev accuracy:   1.0, loss: 0.11194014549255371      \n",
      "dev accuracy: 0.9375, loss: 0.18998472392559052      \n",
      "dev accuracy: 0.8125, loss: 0.3776353895664215       \n",
      "dev accuracy:   1.0, loss: 0.018230050802230835     \n",
      "dev accuracy: 0.9375, loss: 0.15833711624145508      \n",
      "dev accuracy: 0.9375, loss: 0.43956634402275085      \n",
      "dev accuracy: 0.3333333333333333, loss: 1.4775856733322144       \n",
      "final dev accuracy: 0.9211769759450171\n",
      "train step #2430 accuracy: 0.890625, loss: 0.2789651155471802       \n",
      "train step #2431 accuracy: 0.96875, loss: 0.16482117772102356      \n",
      "train step #2432 accuracy: 0.890625, loss: 0.32536429166793823      \n",
      "train step #2433 accuracy: 0.953125, loss: 0.1387421190738678       \n",
      "train step #2434 accuracy: 0.921875, loss: 0.3029809892177582       \n",
      "train step #2435 accuracy: 0.9375, loss: 0.2795294225215912       \n",
      "train step #2436 accuracy: 0.921875, loss: 0.17287318408489227      \n",
      "train step #2437 accuracy: 0.921875, loss: 0.19315692782402039      \n",
      "train step #2438 accuracy: 0.90625, loss: 0.2975786030292511       \n",
      "train step #2439 accuracy: 0.890625, loss: 0.38154321908950806      \n",
      "train step #2440 accuracy: 0.96875, loss: 0.1720273792743683       \n",
      "train step #2441 accuracy: 0.953125, loss: 0.22868186235427856      \n",
      "train step #2442 accuracy: 0.9375, loss: 0.18441253900527954      \n",
      "train step #2443 accuracy: 0.9375, loss: 0.18101613223552704      \n",
      "train step #2444 accuracy: 0.9375, loss: 0.1744983047246933       \n",
      "train step #2445 accuracy: 0.953125, loss: 0.14637304842472076      \n",
      "train step #2446 accuracy: 0.921875, loss: 0.24697455763816833      \n",
      "train step #2447 accuracy: 0.921875, loss: 0.19197970628738403      \n",
      "train step #2448 accuracy: 0.9375, loss: 0.1429699808359146       \n",
      "train step #2449 accuracy: 0.953125, loss: 0.14941230416297913      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #2450 accuracy: 0.84375, loss: 0.5267018675804138       \n",
      "train step #2451 accuracy: 0.921875, loss: 0.23073726892471313      \n",
      "train step #2452 accuracy: 0.953125, loss: 0.22307565808296204      \n",
      "train step #2453 accuracy: 0.953125, loss: 0.1744949221611023       \n",
      "train step #2454 accuracy: 0.984375, loss: 0.08228781074285507      \n",
      "train step #2455 accuracy: 0.921875, loss: 0.22355353832244873      \n",
      "train step #2456 accuracy: 0.90625, loss: 0.2777535319328308       \n",
      "train step #2457 accuracy:   1.0, loss: 0.10104800760746002      \n",
      "train step #2458 accuracy: 0.96875, loss: 0.12518230080604553      \n",
      "train step #2459 accuracy: 0.96875, loss: 0.22636079788208008      \n",
      "train step #2460 accuracy: 0.9375, loss: 0.1704477220773697       \n",
      "train step #2461 accuracy: 0.953125, loss: 0.16734765470027924      \n",
      "train step #2462 accuracy: 0.984375, loss: 0.08370880782604218      \n",
      "train step #2463 accuracy: 0.984375, loss: 0.10713957995176315      \n",
      "train step #2464 accuracy: 0.953125, loss: 0.30266064405441284      \n",
      "train step #2465 accuracy: 0.921875, loss: 0.3181791305541992       \n",
      "train step #2466 accuracy: 0.9375, loss: 0.18085408210754395      \n",
      "train step #2467 accuracy: 0.921875, loss: 0.3437045216560364       \n",
      "train step #2468 accuracy: 0.96875, loss: 0.23061831295490265      \n",
      "train step #2469 accuracy: 0.90625, loss: 0.25709784030914307      \n",
      "train step #2470 accuracy: 0.84375, loss: 0.4248792827129364       \n",
      "train step #2471 accuracy: 0.96875, loss: 0.1485193520784378       \n",
      "train step #2472 accuracy: 0.9375, loss: 0.25231480598449707      \n",
      "train step #2473 accuracy: 0.9375, loss: 0.298652321100235        \n",
      "train step #2474 accuracy: 0.890625, loss: 0.3436070382595062       \n",
      "train step #2475 accuracy: 0.9375, loss: 0.210379496216774        \n",
      "train step #2476 accuracy: 0.875, loss: 0.4733646810054779       \n",
      "train step #2477 accuracy: 0.90625, loss: 0.2715969681739807       \n",
      "train step #2478 accuracy: 0.984375, loss: 0.10911967605352402      \n",
      "train step #2479 accuracy: 0.921875, loss: 0.28153112530708313      \n",
      "train step #2480 accuracy: 0.953125, loss: 0.14765562117099762      \n",
      "train step #2481 accuracy: 0.9375, loss: 0.21813857555389404      \n",
      "train step #2482 accuracy: 0.953125, loss: 0.27190226316452026      \n",
      "train step #2483 accuracy: 0.96875, loss: 0.2227383255958557       \n",
      "train step #2484 accuracy: 0.9375, loss: 0.2963632345199585       \n",
      "train step #2485 accuracy: 0.984375, loss: 0.08068032562732697      \n",
      "train step #2486 accuracy: 0.921875, loss: 0.19818666577339172      \n",
      "train step #2487 accuracy: 0.96875, loss: 0.12893590331077576      \n",
      "train step #2488 accuracy: 0.953125, loss: 0.17800623178482056      \n",
      "train step #2489 accuracy: 0.9375, loss: 0.2605177164077759       \n",
      "train step #2490 accuracy: 0.96875, loss: 0.13175424933433533      \n",
      "train step #2491 accuracy: 0.984375, loss: 0.06772087514400482      \n",
      "train step #2492 accuracy: 0.953125, loss: 0.20091301202774048      \n",
      "train step #2493 accuracy: 0.953125, loss: 0.18296398222446442      \n",
      "train step #2494 accuracy: 0.953125, loss: 0.17662346363067627      \n",
      "train step #2495 accuracy: 0.984375, loss: 0.12106432020664215      \n",
      "train step #2496 accuracy: 0.96875, loss: 0.16001297533512115      \n",
      "train step #2497 accuracy: 0.953125, loss: 0.1639714539051056       \n",
      "train step #2498 accuracy:   1.0, loss: 0.08234275877475739      \n",
      "train step #2499 accuracy: 0.953125, loss: 0.1612139493227005       \n",
      "train step #2500 accuracy: 0.921875, loss: 0.1671406626701355       \n",
      "train step #2501 accuracy: 0.9375, loss: 0.17023660242557526      \n",
      "train step #2502 accuracy: 0.953125, loss: 0.2448396235704422       \n",
      "train step #2503 accuracy: 0.921875, loss: 0.2688447833061218       \n",
      "train step #2504 accuracy: 0.90625, loss: 0.2326931655406952       \n",
      "train step #2505 accuracy: 0.9375, loss: 0.4119805693626404       \n",
      "train step #2506 accuracy: 0.953125, loss: 0.19259440898895264      \n",
      "train step #2507 accuracy: 0.96875, loss: 0.16122138500213623      \n",
      "train step #2508 accuracy: 0.953125, loss: 0.18187926709651947      \n",
      "train step #2509 accuracy: 0.953125, loss: 0.14471641182899475      \n",
      "train step #2510 accuracy: 0.921875, loss: 0.19009274244308472      \n",
      "train step #2511 accuracy: 0.96875, loss: 0.1357814222574234       \n",
      "train step #2512 accuracy: 0.96875, loss: 0.09923479706048965      \n",
      "train step #2513 accuracy: 0.96875, loss: 0.14699597656726837      \n",
      "train step #2514 accuracy: 0.9375, loss: 0.32106733322143555      \n",
      "train step #2515 accuracy: 0.953125, loss: 0.27055269479751587      \n",
      "train step #2516 accuracy: 0.96875, loss: 0.20722241699695587      \n",
      "train step #2517 accuracy: 0.921875, loss: 0.20954717695713043      \n",
      "train step #2518 accuracy: 0.953125, loss: 0.1508026421070099       \n",
      "train step #2519 accuracy: 0.921875, loss: 0.33167344331741333      \n",
      "train step #2520 accuracy: 0.984375, loss: 0.13963109254837036      \n",
      "train step #2521 accuracy: 0.9375, loss: 0.2174932062625885       \n",
      "train step #2522 accuracy: 0.96875, loss: 0.112108014523983        \n",
      "train step #2523 accuracy: 0.96875, loss: 0.10405184328556061      \n",
      "train step #2524 accuracy: 0.859375, loss: 0.6215119361877441       \n",
      "train step #2525 accuracy: 0.96875, loss: 0.10220979899168015      \n",
      "train step #2526 accuracy: 0.921875, loss: 0.2983117401599884       \n",
      "train step #2527 accuracy: 0.953125, loss: 0.20879992842674255      \n",
      "train step #2528 accuracy: 0.921875, loss: 0.2382502555847168       \n",
      "train step #2529 accuracy: 0.9375, loss: 0.28584760427474976      \n",
      "train step #2530 accuracy: 0.9375, loss: 0.16920366883277893      \n",
      "train step #2531 accuracy: 0.953125, loss: 0.26859715580940247      \n",
      "train step #2532 accuracy: 0.984375, loss: 0.13309738039970398      \n",
      "train step #2533 accuracy: 0.96875, loss: 0.15392926335334778      \n",
      "train step #2534 accuracy: 0.96875, loss: 0.08665847778320312      \n",
      "train step #2535 accuracy: 0.984375, loss: 0.10706446319818497      \n",
      "train step #2536 accuracy: 0.96875, loss: 0.10765443742275238      \n",
      "train step #2537 accuracy: 0.875, loss: 0.37447601556777954      \n",
      "train step #2538 accuracy: 0.96875, loss: 0.12393509596586227      \n",
      "train step #2539 accuracy: 0.953125, loss: 0.1915048509836197       \n",
      "train step #2540 accuracy: 0.953125, loss: 0.2625792920589447       \n",
      "train step #2541 accuracy: 0.953125, loss: 0.2546406686306          \n",
      "train step #2542 accuracy: 0.90625, loss: 0.49315395951271057      \n",
      "train step #2543 accuracy: 0.9375, loss: 0.2914162278175354       \n",
      "train step #2544 accuracy: 0.984375, loss: 0.09053915739059448      \n",
      "train step #2545 accuracy: 0.96875, loss: 0.08740758895874023      \n",
      "train step #2546 accuracy: 0.96875, loss: 0.10735006630420685      \n",
      "train step #2547 accuracy: 0.859375, loss: 0.40493762493133545      \n",
      "train step #2548 accuracy: 0.96875, loss: 0.14739660918712616      \n",
      "train step #2549 accuracy: 0.8125, loss: 0.5139929056167603       \n",
      "train step #2550 accuracy: 0.890625, loss: 0.3985515236854553       \n",
      "train step #2551 accuracy: 0.953125, loss: 0.14165687561035156      \n",
      "train step #2552 accuracy: 0.96875, loss: 0.11038582772016525      \n",
      "train step #2553 accuracy:   1.0, loss: 0.04802052676677704      \n",
      "train step #2554 accuracy: 0.90625, loss: 0.3386567533016205       \n",
      "train step #2555 accuracy: 0.9375, loss: 0.2782050669193268       \n",
      "train step #2556 accuracy: 0.9375, loss: 0.18952223658561707      \n",
      "train step #2557 accuracy: 0.953125, loss: 0.2186422348022461       \n",
      "train step #2558 accuracy: 0.921875, loss: 0.2891852557659149       \n",
      "train step #2559 accuracy: 0.953125, loss: 0.12895643711090088      \n",
      "train step #2560 accuracy: 0.890625, loss: 0.353031724691391        \n",
      "train step #2561 accuracy: 0.96875, loss: 0.12400026619434357      \n",
      "train step #2562 accuracy: 0.921875, loss: 0.19970978796482086      \n",
      "train step #2563 accuracy: 0.890625, loss: 0.2773607075214386       \n",
      "train step #2564 accuracy: 0.90625, loss: 0.2551013231277466       \n",
      "train step #2565 accuracy: 0.96875, loss: 0.08346303552389145      \n",
      "train step #2566 accuracy: 0.890625, loss: 0.33514925837516785      \n",
      "train step #2567 accuracy: 0.96875, loss: 0.14269956946372986      \n",
      "train step #2568 accuracy: 0.953125, loss: 0.16324067115783691      \n",
      "train step #2569 accuracy: 0.953125, loss: 0.13527722656726837      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #2570 accuracy: 0.9375, loss: 0.27945825457572937      \n",
      "train step #2571 accuracy: 0.90625, loss: 0.2437368631362915       \n",
      "train step #2572 accuracy: 0.96875, loss: 0.12854966521263123      \n",
      "train step #2573 accuracy: 0.96875, loss: 0.12769150733947754      \n",
      "train step #2574 accuracy: 0.9375, loss: 0.19582390785217285      \n",
      "train step #2575 accuracy: 0.96875, loss: 0.17119964957237244      \n",
      "train step #2576 accuracy: 0.9375, loss: 0.21632586419582367      \n",
      "train step #2577 accuracy: 0.953125, loss: 0.13880442082881927      \n",
      "train step #2578 accuracy: 0.953125, loss: 0.18090924620628357      \n",
      "train step #2579 accuracy: 0.921875, loss: 0.21874406933784485      \n",
      "train step #2580 accuracy: 0.921875, loss: 0.1958557814359665       \n",
      "train step #2581 accuracy: 0.953125, loss: 0.0964122787117958       \n",
      "train step #2582 accuracy: 0.9375, loss: 0.2347986251115799       \n",
      "train step #2583 accuracy: 0.953125, loss: 0.13754555583000183      \n",
      "train step #2584 accuracy: 0.90625, loss: 0.3662544786930084       \n",
      "train step #2585 accuracy: 0.953125, loss: 0.07716511934995651      \n",
      "train step #2586 accuracy: 0.90625, loss: 0.3568176329135895       \n",
      "train step #2587 accuracy: 0.921875, loss: 0.26596304774284363      \n",
      "train step #2588 accuracy: 0.9375, loss: 0.2261943370103836       \n",
      "train step #2589 accuracy: 0.921875, loss: 0.2957855463027954       \n",
      "train step #2590 accuracy:   1.0, loss: 0.14761628210544586      \n",
      "train step #2591 accuracy: 0.890625, loss: 0.3981130123138428       \n",
      "train step #2592 accuracy: 0.9375, loss: 0.21757766604423523      \n",
      "train step #2593 accuracy: 0.921875, loss: 0.25417011976242065      \n",
      "train step #2594 accuracy:   1.0, loss: 0.025729507207870483     \n",
      "train step #2595 accuracy: 0.953125, loss: 0.21511408686637878      \n",
      "train step #2596 accuracy: 0.96875, loss: 0.0968191996216774       \n",
      "train step #2597 accuracy: 0.921875, loss: 0.3198114335536957       \n",
      "train step #2598 accuracy: 0.953125, loss: 0.22004583477973938      \n",
      "train step #2599 accuracy: 0.984375, loss: 0.05211413651704788      \n",
      "train step #2600 accuracy: 0.953125, loss: 0.07215259969234467      \n",
      "train step #2601 accuracy: 0.90625, loss: 0.3118349313735962       \n",
      "train step #2602 accuracy: 0.96875, loss: 0.12148822844028473      \n",
      "train step #2603 accuracy: 0.9375, loss: 0.19445529580116272      \n",
      "train step #2604 accuracy: 0.953125, loss: 0.11362587660551071      \n",
      "train step #2605 accuracy: 0.921875, loss: 0.2639395594596863       \n",
      "train step #2606 accuracy: 0.90625, loss: 0.27650582790374756      \n",
      "train step #2607 accuracy: 0.921875, loss: 0.24872219562530518      \n",
      "train step #2608 accuracy: 0.921875, loss: 0.23080798983573914      \n",
      "train step #2609 accuracy: 0.96875, loss: 0.13701960444450378      \n",
      "train step #2610 accuracy: 0.953125, loss: 0.16586580872535706      \n",
      "train step #2611 accuracy: 0.9375, loss: 0.14632539451122284      \n",
      "train step #2612 accuracy: 0.921875, loss: 0.24467727541923523      \n",
      "train step #2613 accuracy: 0.953125, loss: 0.1974327713251114       \n",
      "train step #2614 accuracy: 0.9375, loss: 0.23313377797603607      \n",
      "train step #2615 accuracy: 0.859375, loss: 0.3556002378463745       \n",
      "train step #2616 accuracy: 0.984375, loss: 0.08701641112565994      \n",
      "train step #2617 accuracy: 0.9375, loss: 0.2652260661125183       \n",
      "train step #2618 accuracy: 0.9375, loss: 0.21439123153686523      \n",
      "train step #2619 accuracy: 0.953125, loss: 0.30050238966941833      \n",
      "train step #2620 accuracy: 0.90625, loss: 0.305833101272583        \n",
      "train step #2621 accuracy: 0.90625, loss: 0.2951573133468628       \n",
      "train step #2622 accuracy:   1.0, loss: 0.055825360119342804     \n",
      "train step #2623 accuracy: 0.96875, loss: 0.07399249821901321      \n",
      "train step #2624 accuracy: 0.953125, loss: 0.1307402104139328       \n",
      "train step #2625 accuracy: 0.890625, loss: 0.40581655502319336      \n",
      "train step #2626 accuracy: 0.953125, loss: 0.15037500858306885      \n",
      "train step #2627 accuracy: 0.921875, loss: 0.2916226387023926       \n",
      "train step #2628 accuracy: 0.9375, loss: 0.3167884647846222       \n",
      "train step #2629 accuracy: 0.921875, loss: 0.2819622755050659       \n",
      "train step #2630 accuracy: 0.9375, loss: 0.3538252115249634       \n",
      "train step #2631 accuracy: 0.9375, loss: 0.2271251082420349       \n",
      "train step #2632 accuracy: 0.90625, loss: 0.2691860496997833       \n",
      "train step #2633 accuracy: 0.890625, loss: 0.41092589497566223      \n",
      "train step #2634 accuracy: 0.90625, loss: 0.3792777955532074       \n",
      "train step #2635 accuracy: 0.9375, loss: 0.22467929124832153      \n",
      "train step #2636 accuracy: 0.953125, loss: 0.21629837155342102      \n",
      "train step #2637 accuracy: 0.921875, loss: 0.3105129301548004       \n",
      "train step #2638 accuracy: 0.953125, loss: 0.11465117335319519      \n",
      "train step #2639 accuracy: 0.96875, loss: 0.08367884159088135      \n",
      "train step #2640 accuracy: 0.921875, loss: 0.24325361847877502      \n",
      "train step #2641 accuracy: 0.9375, loss: 0.17342567443847656      \n",
      "train step #2642 accuracy: 0.96875, loss: 0.10092420130968094      \n",
      "train step #2643 accuracy: 0.921875, loss: 0.2767973840236664       \n",
      "train step #2644 accuracy: 0.9375, loss: 0.28364628553390503      \n",
      "train step #2645 accuracy: 0.953125, loss: 0.23361998796463013      \n",
      "train step #2646 accuracy: 0.921875, loss: 0.25017309188842773      \n",
      "train step #2647 accuracy: 0.9375, loss: 0.23850224912166595      \n",
      "train step #2648 accuracy: 0.921875, loss: 0.4234299063682556       \n",
      "train step #2649 accuracy: 0.953125, loss: 0.12097188830375671      \n",
      "train step #2650 accuracy: 0.953125, loss: 0.13909101486206055      \n",
      "train step #2651 accuracy: 0.953125, loss: 0.19196833670139313      \n",
      "train step #2652 accuracy: 0.890625, loss: 0.31570255756378174      \n",
      "train step #2653 accuracy: 0.9375, loss: 0.1535763144493103       \n",
      "train step #2654 accuracy: 0.9375, loss: 0.19598448276519775      \n",
      "train step #2655 accuracy: 0.9375, loss: 0.2034701257944107       \n",
      "train step #2656 accuracy: 0.984375, loss: 0.12856553494930267      \n",
      "train step #2657 accuracy: 0.921875, loss: 0.29655322432518005      \n",
      "train step #2658 accuracy: 0.9375, loss: 0.15960001945495605      \n",
      "train step #2659 accuracy: 0.953125, loss: 0.19933363795280457      \n",
      "train step #2660 accuracy: 0.921875, loss: 0.29494547843933105      \n",
      "train step #2661 accuracy: 0.8125, loss: 0.5227528214454651       \n",
      "train step #2662 accuracy: 0.90625, loss: 0.2644421458244324       \n",
      "train step #2663 accuracy: 0.921875, loss: 0.2573729455471039       \n",
      "train step #2664 accuracy: 0.96875, loss: 0.21968726813793182      \n",
      "train step #2665 accuracy: 0.984375, loss: 0.10156098008155823      \n",
      "train step #2666 accuracy: 0.96875, loss: 0.09659172594547272      \n",
      "train step #2667 accuracy: 0.953125, loss: 0.24441924691200256      \n",
      "train step #2668 accuracy: 0.90625, loss: 0.38918161392211914      \n",
      "train step #2669 accuracy: 0.953125, loss: 0.21351006627082825      \n",
      "train step #2670 accuracy: 0.921875, loss: 0.2601333558559418       \n",
      "train step #2671 accuracy: 0.9375, loss: 0.16905376315116882      \n",
      "train step #2672 accuracy: 0.9375, loss: 0.20074772834777832      \n",
      "train step #2673 accuracy: 0.9375, loss: 0.26672396063804626      \n",
      "train step #2674 accuracy: 0.9375, loss: 0.24358104169368744      \n",
      "train step #2675 accuracy: 0.953125, loss: 0.21643447875976562      \n",
      "train step #2676 accuracy: 0.90625, loss: 0.32378268241882324      \n",
      "train step #2677 accuracy: 0.953125, loss: 0.17362338304519653      \n",
      "train step #2678 accuracy: 0.984375, loss: 0.0645691454410553       \n",
      "train step #2679 accuracy: 0.921875, loss: 0.2722497880458832       \n",
      "train step #2680 accuracy: 0.953125, loss: 0.23576217889785767      \n",
      "train step #2681 accuracy: 0.890625, loss: 0.4168780446052551       \n",
      "train step #2682 accuracy: 0.984375, loss: 0.07047669589519501      \n",
      "train step #2683 accuracy: 0.96875, loss: 0.1257113367319107       \n",
      "train step #2684 accuracy: 0.890625, loss: 0.4099247455596924       \n",
      "train step #2685 accuracy: 0.953125, loss: 0.1775699257850647       \n",
      "train step #2686 accuracy: 0.890625, loss: 0.32950249314308167      \n",
      "train step #2687 accuracy: 0.9375, loss: 0.18473263084888458      \n",
      "train step #2688 accuracy: 0.890625, loss: 0.2979527711868286       \n",
      "train step #2689 accuracy: 0.953125, loss: 0.19707544147968292      \n",
      "train step #2690 accuracy: 0.90625, loss: 0.2995781898498535       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #2691 accuracy: 0.953125, loss: 0.22542870044708252      \n",
      "train step #2692 accuracy: 0.9375, loss: 0.20791347324848175      \n",
      "train step #2693 accuracy: 0.984375, loss: 0.10692887008190155      \n",
      "train step #2694 accuracy: 0.96875, loss: 0.17399384081363678      \n",
      "train step #2695 accuracy: 0.953125, loss: 0.19860410690307617      \n",
      "train step #2696 accuracy: 0.9375, loss: 0.19255012273788452      \n",
      "train step #2697 accuracy: 0.859375, loss: 0.30920663475990295      \n",
      "train step #2698 accuracy: 0.953125, loss: 0.23443014919757843      \n",
      "train step #2699 accuracy: 0.90625, loss: 0.2513686418533325       \n",
      "train step #2700 accuracy: 0.859375, loss: 0.41801393032073975      \n",
      "train step #2701 accuracy: 0.875, loss: 0.4980396032333374       \n",
      "train step #2702 accuracy: 0.9375, loss: 0.22564321756362915      \n",
      "train step #2703 accuracy: 0.953125, loss: 0.21567173302173615      \n",
      "train step #2704 accuracy: 0.96875, loss: 0.12264379858970642      \n",
      "train step #2705 accuracy: 0.828125, loss: 0.46216416358947754      \n",
      "train step #2706 accuracy: 0.921875, loss: 0.3786458373069763       \n",
      "train step #2707 accuracy: 0.984375, loss: 0.1450739949941635       \n",
      "train step #2708 accuracy: 0.953125, loss: 0.18883751332759857      \n",
      "train step #2709 accuracy: 0.859375, loss: 0.39260298013687134      \n",
      "train step #2710 accuracy: 0.921875, loss: 0.31701529026031494      \n",
      "train step #2711 accuracy: 0.96875, loss: 0.14216947555541992      \n",
      "train step #2712 accuracy: 0.953125, loss: 0.18209056556224823      \n",
      "train step #2713 accuracy: 0.90625, loss: 0.24908053874969482      \n",
      "train step #2714 accuracy: 0.984375, loss: 0.10244755446910858      \n",
      "train step #2715 accuracy: 0.953125, loss: 0.16794148087501526      \n",
      "train step #2716 accuracy: 0.953125, loss: 0.17841248214244843      \n",
      "train step #2717 accuracy: 0.90625, loss: 0.42187339067459106      \n",
      "train step #2718 accuracy: 0.90625, loss: 0.26386648416519165      \n",
      "train step #2719 accuracy: 0.90625, loss: 0.32893499732017517      \n",
      "train step #2720 accuracy: 0.90625, loss: 0.4043812155723572       \n",
      "train step #2721 accuracy: 0.90625, loss: 0.203708216547966        \n",
      "train step #2722 accuracy: 0.921875, loss: 0.24848760664463043      \n",
      "train step #2723 accuracy: 0.96875, loss: 0.11143390834331512      \n",
      "train step #2724 accuracy: 0.921875, loss: 0.2535805106163025       \n",
      "train step #2725 accuracy: 0.96875, loss: 0.08820074051618576      \n",
      "train step #2726 accuracy: 0.90625, loss: 0.31049424409866333      \n",
      "train step #2727 accuracy: 0.953125, loss: 0.2086925506591797       \n",
      "train step #2728 accuracy: 0.875, loss: 0.32238292694091797      \n",
      "train step #2729 accuracy: 0.921875, loss: 0.3181409239768982       \n",
      "train step #2730 accuracy: 0.9375, loss: 0.13775797188282013      \n",
      "train step #2731 accuracy: 0.96875, loss: 0.11797098070383072      \n",
      "train step #2732 accuracy: 0.953125, loss: 0.336954265832901        \n",
      "train step #2733 accuracy: 0.90625, loss: 0.30402839183807373      \n",
      "train step #2734 accuracy: 0.96875, loss: 0.09146109968423843      \n",
      "train step #2735 accuracy: 0.984375, loss: 0.06944457441568375      \n",
      "train step #2736 accuracy:   1.0, loss: 0.059068713337183        \n",
      "train step #2737 accuracy: 0.953125, loss: 0.168737530708313        \n",
      "train step #2738 accuracy: 0.953125, loss: 0.0877210944890976       \n",
      "train step #2739 accuracy: 0.8125, loss: 0.5791293978691101       \n",
      "train step #2740 accuracy: 0.984375, loss: 0.10687962919473648      \n",
      "train step #2741 accuracy: 0.90625, loss: 0.2790186107158661       \n",
      "train step #2742 accuracy: 0.953125, loss: 0.22555133700370789      \n",
      "train step #2743 accuracy: 0.953125, loss: 0.1697404384613037       \n",
      "train step #2744 accuracy: 0.953125, loss: 0.15945681929588318      \n",
      "train step #2745 accuracy: 0.984375, loss: 0.15298202633857727      \n",
      "train step #2746 accuracy: 0.96875, loss: 0.1346372812986374       \n",
      "train step #2747 accuracy: 0.96875, loss: 0.12855763733386993      \n",
      "train step #2748 accuracy: 0.90625, loss: 0.29503750801086426      \n",
      "train step #2749 accuracy: 0.90625, loss: 0.32488811016082764      \n",
      "train step #2750 accuracy: 0.921875, loss: 0.29129767417907715      \n",
      "train step #2751 accuracy: 0.90625, loss: 0.1698620617389679       \n",
      "train step #2752 accuracy: 0.90625, loss: 0.2669900059700012       \n",
      "train step #2753 accuracy:   1.0, loss: 0.05463990569114685      \n",
      "train step #2754 accuracy: 0.9375, loss: 0.2512024939060211       \n",
      "train step #2755 accuracy: 0.90625, loss: 0.25746455788612366      \n",
      "train step #2756 accuracy: 0.921875, loss: 0.27516475319862366      \n",
      "train step #2757 accuracy: 0.96875, loss: 0.10465355217456818      \n",
      "train step #2758 accuracy: 0.90625, loss: 0.2786323130130768       \n",
      "train step #2759 accuracy: 0.9375, loss: 0.22321805357933044      \n",
      "train step #2760 accuracy: 0.96875, loss: 0.09743925929069519      \n",
      "train step #2761 accuracy: 0.90625, loss: 0.2955588102340698       \n",
      "train step #2762 accuracy: 0.953125, loss: 0.16572444140911102      \n",
      "train step #2763 accuracy: 0.953125, loss: 0.17082065343856812      \n",
      "train step #2764 accuracy: 0.96875, loss: 0.16388630867004395      \n",
      "train step #2765 accuracy: 0.890625, loss: 0.24955111742019653      \n",
      "train step #2766 accuracy: 0.875, loss: 0.3287046551704407       \n",
      "train step #2767 accuracy: 0.90625, loss: 0.40743279457092285      \n",
      "train step #2768 accuracy: 0.921875, loss: 0.12237800657749176      \n",
      "train step #2769 accuracy:   1.0, loss: 0.06335615366697311      \n",
      "train step #2770 accuracy: 0.984375, loss: 0.06393122673034668      \n",
      "train step #2771 accuracy: 0.984375, loss: 0.12992215156555176      \n",
      "train step #2772 accuracy: 0.96875, loss: 0.11090683192014694      \n",
      "train step #2773 accuracy: 0.984375, loss: 0.11453131586313248      \n",
      "train step #2774 accuracy: 0.96875, loss: 0.18330635130405426      \n",
      "train step #2775 accuracy: 0.84375, loss: 0.4714174270629883       \n",
      "train step #2776 accuracy: 0.921875, loss: 0.32339221239089966      \n",
      "dev accuracy:   1.0, loss: 0.010061681270599365     \n",
      "dev accuracy:   1.0, loss: 0.029258131980895996     \n",
      "dev accuracy: 0.9375, loss: 0.16782893240451813      \n",
      "dev accuracy: 0.9375, loss: 0.19480934739112854      \n",
      "dev accuracy: 0.875, loss: 0.2901838719844818       \n",
      "dev accuracy: 0.8125, loss: 0.3807818293571472       \n",
      "dev accuracy: 0.9375, loss: 0.10804038494825363      \n",
      "dev accuracy: 0.875, loss: 0.2338775396347046       \n",
      "dev accuracy:   1.0, loss: 0.004680603742599487     \n",
      "dev accuracy: 0.8125, loss: 0.5043501853942871       \n",
      "dev accuracy:   1.0, loss: 0.03581860661506653      \n",
      "dev accuracy: 0.875, loss: 0.27882373332977295      \n",
      "dev accuracy: 0.8125, loss: 0.7783339023590088       \n",
      "dev accuracy: 0.9375, loss: 0.21153044700622559      \n",
      "dev accuracy: 0.875, loss: 0.3039931058883667       \n",
      "dev accuracy:   1.0, loss: 0.0021924376487731934    \n",
      "dev accuracy:   1.0, loss: 0.15030507743358612      \n",
      "dev accuracy: 0.9375, loss: 0.08175511658191681      \n",
      "dev accuracy:   1.0, loss: 0.04280373454093933      \n",
      "dev accuracy:   1.0, loss: 0.060962408781051636     \n",
      "dev accuracy:   1.0, loss: 0.017751336097717285     \n",
      "dev accuracy: 0.875, loss: 0.29941582679748535      \n",
      "dev accuracy: 0.875, loss: 0.53696209192276         \n",
      "dev accuracy:   1.0, loss: 0.007149428129196167     \n",
      "dev accuracy: 0.8125, loss: 0.634134829044342        \n",
      "dev accuracy: 0.875, loss: 0.6919347643852234       \n",
      "dev accuracy: 0.8125, loss: 0.530372679233551        \n",
      "dev accuracy: 0.9375, loss: 0.27474844455718994      \n",
      "dev accuracy: 0.8125, loss: 0.38746753334999084      \n",
      "dev accuracy:   1.0, loss: 0.03926485776901245      \n",
      "dev accuracy: 0.9375, loss: 0.10903036594390869      \n",
      "dev accuracy: 0.9375, loss: 0.30339381098747253      \n",
      "dev accuracy:   1.0, loss: 0.0019354522228240967    \n",
      "dev accuracy: 0.9375, loss: 0.23678618669509888      \n",
      "dev accuracy: 0.875, loss: 0.3550323247909546       \n",
      "dev accuracy: 0.9375, loss: 0.1228988766670227       \n",
      "dev accuracy: 0.875, loss: 0.1614096462726593       \n",
      "dev accuracy:   1.0, loss: 0.0603184700012207       \n",
      "dev accuracy: 0.875, loss: 0.4443749785423279       \n",
      "dev accuracy: 0.875, loss: 0.15604077279567719      \n",
      "dev accuracy:   1.0, loss: 0.01861429214477539      \n",
      "dev accuracy: 0.9375, loss: 0.24274000525474548      \n",
      "dev accuracy: 0.9375, loss: 0.2164931744337082       \n",
      "dev accuracy: 0.9375, loss: 0.15864723920822144      \n",
      "dev accuracy: 0.9375, loss: 0.11691217124462128      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy:   1.0, loss: 0.013109743595123291     \n",
      "dev accuracy: 0.9375, loss: 0.15431305766105652      \n",
      "dev accuracy: 0.9375, loss: 0.10746157169342041      \n",
      "dev accuracy: 0.8125, loss: 0.8856987953186035       \n",
      "dev accuracy:   1.0, loss: 0.04645121097564697      \n",
      "dev accuracy:   1.0, loss: 0.005660742521286011     \n",
      "dev accuracy: 0.9375, loss: 0.1532074511051178       \n",
      "dev accuracy:   1.0, loss: 0.12436144053936005      \n",
      "dev accuracy:  0.75, loss: 1.21307373046875         \n",
      "dev accuracy: 0.9375, loss: 0.16380640864372253      \n",
      "dev accuracy: 0.875, loss: 0.33315712213516235      \n",
      "dev accuracy:   1.0, loss: 0.08373197913169861      \n",
      "dev accuracy: 0.9375, loss: 0.14918747544288635      \n",
      "dev accuracy: 0.875, loss: 0.21155264973640442      \n",
      "dev accuracy: 0.875, loss: 0.18247991800308228      \n",
      "dev accuracy: 0.9375, loss: 0.19773033261299133      \n",
      "dev accuracy: 0.875, loss: 0.22855597734451294      \n",
      "dev accuracy: 0.9375, loss: 0.21534907817840576      \n",
      "dev accuracy:   1.0, loss: 0.06821712851524353      \n",
      "dev accuracy: 0.9375, loss: 0.07352480292320251      \n",
      "dev accuracy:   1.0, loss: 0.05287069082260132      \n",
      "dev accuracy: 0.875, loss: 0.49758854508399963      \n",
      "dev accuracy: 0.9375, loss: 0.2413087785243988       \n",
      "dev accuracy: 0.9375, loss: 0.08788451552391052      \n",
      "dev accuracy:   1.0, loss: 0.07283785939216614      \n",
      "dev accuracy:   1.0, loss: 0.016980290412902832     \n",
      "dev accuracy:   1.0, loss: 0.006467074155807495     \n",
      "dev accuracy:   1.0, loss: 0.01447063684463501      \n",
      "dev accuracy:   1.0, loss: 0.024714946746826172     \n",
      "dev accuracy:   1.0, loss: 0.018831491470336914     \n",
      "dev accuracy:   1.0, loss: 0.10703474283218384      \n",
      "dev accuracy: 0.875, loss: 0.277670681476593        \n",
      "dev accuracy: 0.875, loss: 0.4266078770160675       \n",
      "dev accuracy: 0.875, loss: 0.3737393319606781       \n",
      "dev accuracy: 0.9375, loss: 0.12896165251731873      \n",
      "dev accuracy:   1.0, loss: 0.04544803500175476      \n",
      "dev accuracy: 0.9375, loss: 0.2518233060836792       \n",
      "dev accuracy: 0.9375, loss: 0.18092921376228333      \n",
      "dev accuracy:   1.0, loss: 0.05011376738548279      \n",
      "dev accuracy: 0.9375, loss: 0.19205093383789062      \n",
      "dev accuracy: 0.9375, loss: 0.13321448862552643      \n",
      "dev accuracy: 0.8125, loss: 0.5063598155975342       \n",
      "dev accuracy: 0.9375, loss: 0.16837894916534424      \n",
      "dev accuracy: 0.875, loss: 0.35749632120132446      \n",
      "dev accuracy:   1.0, loss: 0.06481264531612396      \n",
      "dev accuracy: 0.9375, loss: 0.4028783440589905       \n",
      "dev accuracy: 0.9375, loss: 0.1413169801235199       \n",
      "dev accuracy: 0.875, loss: 0.2580186128616333       \n",
      "dev accuracy: 0.6875, loss: 0.7086259126663208       \n",
      "dev accuracy: 0.875, loss: 0.21737316250801086      \n",
      "dev accuracy:   1.0, loss: 0.07261866331100464      \n",
      "dev accuracy: 0.9375, loss: 0.137529194355011        \n",
      "dev accuracy: 0.9375, loss: 0.26588502526283264      \n",
      "dev accuracy: 0.875, loss: 0.41306406259536743      \n",
      "dev accuracy: 0.875, loss: 0.54008549451828         \n",
      "dev accuracy:   1.0, loss: 0.10271592438220978      \n",
      "dev accuracy: 0.9375, loss: 0.09651631116867065      \n",
      "dev accuracy: 0.9375, loss: 0.17352724075317383      \n",
      "dev accuracy: 0.9375, loss: 0.09433259069919586      \n",
      "dev accuracy: 0.9375, loss: 0.2967248558998108       \n",
      "dev accuracy:   1.0, loss: 0.06583952903747559      \n",
      "dev accuracy: 0.8125, loss: 0.27116596698760986      \n",
      "dev accuracy: 0.9375, loss: 0.13158860802650452      \n",
      "dev accuracy: 0.875, loss: 0.22608155012130737      \n",
      "dev accuracy:   1.0, loss: 0.032873183488845825     \n",
      "dev accuracy:   1.0, loss: 0.05459505319595337      \n",
      "dev accuracy:   1.0, loss: 0.053937047719955444     \n",
      "dev accuracy: 0.875, loss: 0.49698901176452637      \n",
      "dev accuracy: 0.8125, loss: 0.47100698947906494      \n",
      "dev accuracy: 0.9375, loss: 0.21053652465343475      \n",
      "dev accuracy: 0.9375, loss: 0.14176595211029053      \n",
      "dev accuracy:   1.0, loss: 0.07289472222328186      \n",
      "dev accuracy:   1.0, loss: 0.06447362899780273      \n",
      "dev accuracy: 0.9375, loss: 0.2100900113582611       \n",
      "dev accuracy:   1.0, loss: 0.03767308592796326      \n",
      "dev accuracy:   1.0, loss: 0.017153292894363403     \n",
      "dev accuracy: 0.9375, loss: 0.4899507462978363       \n",
      "dev accuracy: 0.875, loss: 0.5233058333396912       \n",
      "dev accuracy: 0.9375, loss: 0.3050220012664795       \n",
      "dev accuracy: 0.9375, loss: 0.21749170124530792      \n",
      "dev accuracy:  0.75, loss: 0.6084190607070923       \n",
      "dev accuracy:   1.0, loss: 0.001118481159210205     \n",
      "dev accuracy: 0.875, loss: 0.3453863561153412       \n",
      "dev accuracy: 0.9375, loss: 0.06900325417518616      \n",
      "dev accuracy:   1.0, loss: 0.03728024661540985      \n",
      "dev accuracy: 0.875, loss: 0.44528692960739136      \n",
      "dev accuracy: 0.875, loss: 0.4852796196937561       \n",
      "dev accuracy: 0.8125, loss: 0.44282639026641846      \n",
      "dev accuracy: 0.9375, loss: 0.25952398777008057      \n",
      "dev accuracy: 0.9375, loss: 0.13426423072814941      \n",
      "dev accuracy:   1.0, loss: 0.014921218156814575     \n",
      "dev accuracy: 0.9375, loss: 0.13459879159927368      \n",
      "dev accuracy: 0.875, loss: 0.33707064390182495      \n",
      "dev accuracy: 0.9375, loss: 0.2175048589706421       \n",
      "dev accuracy: 0.9375, loss: 0.12064704298973083      \n",
      "dev accuracy: 0.9375, loss: 0.2168707698583603       \n",
      "dev accuracy: 0.9375, loss: 0.3809944987297058       \n",
      "dev accuracy:   1.0, loss: 0.008124977350234985     \n",
      "dev accuracy: 0.9375, loss: 0.23254293203353882      \n",
      "dev accuracy:   1.0, loss: 0.07796478271484375      \n",
      "dev accuracy: 0.9375, loss: 0.29032349586486816      \n",
      "dev accuracy: 0.875, loss: 0.4091460108757019       \n",
      "dev accuracy:   1.0, loss: 0.10079552978277206      \n",
      "dev accuracy: 0.9375, loss: 0.3688840866088867       \n",
      "dev accuracy: 0.875, loss: 0.6548898816108704       \n",
      "dev accuracy: 0.9375, loss: 0.08684983849525452      \n",
      "dev accuracy: 0.9375, loss: 0.09956532716751099      \n",
      "dev accuracy:   1.0, loss: 0.09132078289985657      \n",
      "dev accuracy:   1.0, loss: 0.05850234627723694      \n",
      "dev accuracy:   1.0, loss: 0.06787213683128357      \n",
      "dev accuracy: 0.9375, loss: 0.2566741108894348       \n",
      "dev accuracy: 0.9375, loss: 0.10615749657154083      \n",
      "dev accuracy: 0.9375, loss: 0.21767312288284302      \n",
      "dev accuracy: 0.8125, loss: 0.20725078880786896      \n",
      "dev accuracy: 0.9375, loss: 0.202434241771698        \n",
      "dev accuracy: 0.875, loss: 0.577272355556488        \n",
      "dev accuracy:   1.0, loss: 0.009605437517166138     \n",
      "dev accuracy: 0.8125, loss: 0.297366738319397        \n",
      "dev accuracy: 0.9375, loss: 0.2914009690284729       \n",
      "dev accuracy:   1.0, loss: 0.10433432459831238      \n",
      "dev accuracy:   1.0, loss: 0.06413105130195618      \n",
      "dev accuracy: 0.9375, loss: 0.12980343401432037      \n",
      "dev accuracy: 0.9375, loss: 0.12234705686569214      \n",
      "dev accuracy: 0.9375, loss: 0.5901551842689514       \n",
      "dev accuracy: 0.9375, loss: 0.31644678115844727      \n",
      "dev accuracy:   1.0, loss: 0.03364992141723633      \n",
      "dev accuracy: 0.9375, loss: 0.1552550196647644       \n",
      "dev accuracy: 0.8125, loss: 0.3727283775806427       \n",
      "dev accuracy: 0.875, loss: 0.18294665217399597      \n",
      "dev accuracy:   1.0, loss: 0.035563915967941284     \n",
      "dev accuracy: 0.9375, loss: 0.17191627621650696      \n",
      "dev accuracy: 0.8125, loss: 0.3086260259151459       \n",
      "dev accuracy: 0.9375, loss: 0.11590468883514404      \n",
      "dev accuracy: 0.9375, loss: 0.1126183271408081       \n",
      "dev accuracy:   1.0, loss: 0.034708067774772644     \n",
      "dev accuracy: 0.9375, loss: 0.15967726707458496      \n",
      "dev accuracy: 0.9375, loss: 0.22824200987815857      \n",
      "dev accuracy: 0.9375, loss: 0.33950620889663696      \n",
      "dev accuracy: 0.875, loss: 0.16610030829906464      \n",
      "dev accuracy: 0.9375, loss: 0.259840726852417        \n",
      "dev accuracy: 0.9375, loss: 0.320654958486557        \n",
      "dev accuracy:   1.0, loss: 0.10120583325624466      \n",
      "dev accuracy: 0.9375, loss: 0.2412916123867035       \n",
      "dev accuracy: 0.9375, loss: 0.20397640764713287      \n",
      "dev accuracy: 0.9375, loss: 0.3768288493156433       \n",
      "dev accuracy: 0.875, loss: 0.3657379448413849       \n",
      "dev accuracy: 0.875, loss: 0.3852916359901428       \n",
      "dev accuracy: 0.9375, loss: 0.18912486732006073      \n",
      "dev accuracy:   1.0, loss: 0.017373085021972656     \n",
      "final dev accuracy: 0.9310567010309279\n",
      "saving best model...\n",
      "train step #2777 accuracy: 0.953125, loss: 0.19065725803375244      \n",
      "train step #2778 accuracy: 0.921875, loss: 0.22000600397586823      \n",
      "train step #2779 accuracy: 0.984375, loss: 0.10316568613052368      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #2780 accuracy: 0.921875, loss: 0.21029017865657806      \n",
      "train step #2781 accuracy: 0.90625, loss: 0.3040958046913147       \n",
      "train step #2782 accuracy: 0.90625, loss: 0.31018248200416565      \n",
      "train step #2783 accuracy: 0.953125, loss: 0.2213825285434723       \n",
      "train step #2784 accuracy: 0.953125, loss: 0.17187795042991638      \n",
      "train step #2785 accuracy: 0.9375, loss: 0.20912164449691772      \n",
      "train step #2786 accuracy: 0.9375, loss: 0.20568445324897766      \n",
      "train step #2787 accuracy: 0.96875, loss: 0.08410293608903885      \n",
      "train step #2788 accuracy: 0.953125, loss: 0.17092131078243256      \n",
      "train step #2789 accuracy: 0.921875, loss: 0.21225351095199585      \n",
      "train step #2790 accuracy: 0.96875, loss: 0.12703359127044678      \n",
      "train step #2791 accuracy: 0.96875, loss: 0.1428348869085312       \n",
      "train step #2792 accuracy: 0.90625, loss: 0.24289144575595856      \n",
      "train step #2793 accuracy: 0.953125, loss: 0.18342013657093048      \n",
      "train step #2794 accuracy: 0.9375, loss: 0.15077656507492065      \n",
      "train step #2795 accuracy: 0.9375, loss: 0.21779757738113403      \n",
      "train step #2796 accuracy: 0.953125, loss: 0.18880361318588257      \n",
      "train step #2797 accuracy: 0.96875, loss: 0.2121814638376236       \n",
      "train step #2798 accuracy: 0.921875, loss: 0.31535255908966064      \n",
      "train step #2799 accuracy: 0.953125, loss: 0.21104834973812103      \n",
      "train step #2800 accuracy: 0.984375, loss: 0.1430346667766571       \n",
      "train step #2801 accuracy: 0.9375, loss: 0.2772880792617798       \n",
      "train step #2802 accuracy: 0.953125, loss: 0.18765152990818024      \n",
      "train step #2803 accuracy: 0.953125, loss: 0.2618291974067688       \n",
      "train step #2804 accuracy: 0.9375, loss: 0.17093637585639954      \n",
      "train step #2805 accuracy: 0.921875, loss: 0.2720247507095337       \n",
      "train step #2806 accuracy: 0.953125, loss: 0.14199522137641907      \n",
      "train step #2807 accuracy: 0.96875, loss: 0.20921656489372253      \n",
      "train step #2808 accuracy: 0.921875, loss: 0.26445621252059937      \n",
      "train step #2809 accuracy: 0.9375, loss: 0.26949721574783325      \n",
      "train step #2810 accuracy: 0.984375, loss: 0.05913390964269638      \n",
      "train step #2811 accuracy: 0.953125, loss: 0.11030372232198715      \n",
      "train step #2812 accuracy: 0.953125, loss: 0.18690218031406403      \n",
      "train step #2813 accuracy: 0.953125, loss: 0.10282451659440994      \n",
      "train step #2814 accuracy: 0.9375, loss: 0.20489080250263214      \n",
      "train step #2815 accuracy: 0.90625, loss: 0.3392626643180847       \n",
      "train step #2816 accuracy: 0.96875, loss: 0.19486862421035767      \n",
      "train step #2817 accuracy: 0.953125, loss: 0.30845344066619873      \n",
      "train step #2818 accuracy: 0.96875, loss: 0.13177914917469025      \n",
      "train step #2819 accuracy: 0.96875, loss: 0.16661281883716583      \n",
      "train step #2820 accuracy: 0.953125, loss: 0.2885311543941498       \n",
      "train step #2821 accuracy: 0.890625, loss: 0.4681457281112671       \n",
      "train step #2822 accuracy: 0.953125, loss: 0.1781846284866333       \n",
      "train step #2823 accuracy: 0.890625, loss: 0.35489773750305176      \n",
      "train step #2824 accuracy: 0.921875, loss: 0.2040550857782364       \n",
      "train step #2825 accuracy: 0.953125, loss: 0.17555229365825653      \n",
      "train step #2826 accuracy: 0.9375, loss: 0.2089623510837555       \n",
      "train step #2827 accuracy: 0.9375, loss: 0.1777213215827942       \n",
      "train step #2828 accuracy: 0.9375, loss: 0.32948416471481323      \n",
      "train step #2829 accuracy: 0.9375, loss: 0.20464184880256653      \n",
      "train step #2830 accuracy: 0.953125, loss: 0.12077352404594421      \n",
      "train step #2831 accuracy: 0.953125, loss: 0.21362808346748352      \n",
      "train step #2832 accuracy: 0.984375, loss: 0.12748654186725616      \n",
      "train step #2833 accuracy: 0.984375, loss: 0.06960679590702057      \n",
      "train step #2834 accuracy: 0.984375, loss: 0.09648627042770386      \n",
      "train step #2835 accuracy: 0.953125, loss: 0.19260400533676147      \n",
      "train step #2836 accuracy: 0.984375, loss: 0.07951579988002777      \n",
      "train step #2837 accuracy: 0.921875, loss: 0.3034910559654236       \n",
      "train step #2838 accuracy: 0.90625, loss: 0.3199465870857239       \n",
      "train step #2839 accuracy: 0.984375, loss: 0.07246193289756775      \n",
      "train step #2840 accuracy: 0.9375, loss: 0.2684510052204132       \n",
      "train step #2841 accuracy: 0.984375, loss: 0.10225030034780502      \n",
      "train step #2842 accuracy: 0.984375, loss: 0.1152782216668129       \n",
      "train step #2843 accuracy: 0.9375, loss: 0.19681473076343536      \n",
      "train step #2844 accuracy: 0.9375, loss: 0.1791854202747345       \n",
      "train step #2845 accuracy: 0.921875, loss: 0.2491590678691864       \n",
      "train step #2846 accuracy: 0.953125, loss: 0.10540412366390228      \n",
      "train step #2847 accuracy: 0.921875, loss: 0.23914411664009094      \n",
      "train step #2848 accuracy: 0.921875, loss: 0.24323363602161407      \n",
      "train step #2849 accuracy: 0.9375, loss: 0.2070246934890747       \n",
      "train step #2850 accuracy: 0.9375, loss: 0.2190181016921997       \n",
      "train step #2851 accuracy: 0.921875, loss: 0.3358941078186035       \n",
      "train step #2852 accuracy: 0.96875, loss: 0.16796326637268066      \n",
      "train step #2853 accuracy: 0.921875, loss: 0.17097008228302002      \n",
      "train step #2854 accuracy: 0.90625, loss: 0.3451754152774811       \n",
      "train step #2855 accuracy: 0.953125, loss: 0.2156156748533249       \n",
      "train step #2856 accuracy: 0.953125, loss: 0.20595254004001617      \n",
      "train step #2857 accuracy: 0.921875, loss: 0.2156841903924942       \n",
      "train step #2858 accuracy: 0.984375, loss: 0.1593785583972931       \n",
      "train step #2859 accuracy: 0.96875, loss: 0.08303441852331161      \n",
      "train step #2860 accuracy: 0.953125, loss: 0.20267213881015778      \n",
      "train step #2861 accuracy: 0.953125, loss: 0.2166079878807068       \n",
      "train step #2862 accuracy: 0.921875, loss: 0.28709542751312256      \n",
      "train step #2863 accuracy: 0.953125, loss: 0.17663809657096863      \n",
      "train step #2864 accuracy: 0.9375, loss: 0.213548943400383        \n",
      "train step #2865 accuracy: 0.9375, loss: 0.24948301911354065      \n",
      "train step #2866 accuracy: 0.921875, loss: 0.2312295138835907       \n",
      "train step #2867 accuracy: 0.96875, loss: 0.11288978904485703      \n",
      "train step #2868 accuracy: 0.96875, loss: 0.14819654822349548      \n",
      "train step #2869 accuracy: 0.953125, loss: 0.21656395494937897      \n",
      "train step #2870 accuracy: 0.984375, loss: 0.1354525238275528       \n",
      "train step #2871 accuracy: 0.953125, loss: 0.16359984874725342      \n",
      "train step #2872 accuracy: 0.96875, loss: 0.13938425481319427      \n",
      "train step #2873 accuracy: 0.9375, loss: 0.22839057445526123      \n",
      "train step #2874 accuracy: 0.921875, loss: 0.2008621245622635       \n",
      "train step #2875 accuracy: 0.984375, loss: 0.09962981194257736      \n",
      "train step #2876 accuracy: 0.9375, loss: 0.18246905505657196      \n",
      "train step #2877 accuracy: 0.953125, loss: 0.23618705570697784      \n",
      "train step #2878 accuracy: 0.921875, loss: 0.31150299310684204      \n",
      "train step #2879 accuracy: 0.9375, loss: 0.35952335596084595      \n",
      "train step #2880 accuracy: 0.921875, loss: 0.21722412109375         \n",
      "train step #2881 accuracy: 0.9375, loss: 0.2557815909385681       \n",
      "train step #2882 accuracy: 0.953125, loss: 0.23126038908958435      \n",
      "train step #2883 accuracy: 0.9375, loss: 0.18489986658096313      \n",
      "train step #2884 accuracy: 0.96875, loss: 0.1628127098083496       \n",
      "train step #2885 accuracy: 0.9375, loss: 0.1979956328868866       \n",
      "train step #2886 accuracy: 0.9375, loss: 0.2536171078681946       \n",
      "train step #2887 accuracy: 0.9375, loss: 0.2738398313522339       \n",
      "train step #2888 accuracy: 0.953125, loss: 0.17802727222442627      \n",
      "train step #2889 accuracy: 0.921875, loss: 0.3746868371963501       \n",
      "train step #2890 accuracy: 0.953125, loss: 0.1654137372970581       \n",
      "train step #2891 accuracy: 0.984375, loss: 0.07426334917545319      \n",
      "train step #2892 accuracy: 0.96875, loss: 0.09218014031648636      \n",
      "train step #2893 accuracy: 0.921875, loss: 0.1766866147518158       \n",
      "train step #2894 accuracy: 0.9375, loss: 0.25631511211395264      \n",
      "train step #2895 accuracy: 0.96875, loss: 0.1540665328502655       \n",
      "train step #2896 accuracy: 0.9375, loss: 0.21487829089164734      \n",
      "train step #2897 accuracy: 0.921875, loss: 0.1514790952205658       \n",
      "train step #2898 accuracy: 0.859375, loss: 0.4007408916950226       \n",
      "train step #2899 accuracy: 0.953125, loss: 0.17449241876602173      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #2900 accuracy: 0.96875, loss: 0.1544559746980667       \n",
      "train step #2901 accuracy: 0.984375, loss: 0.06766197830438614      \n",
      "train step #2902 accuracy: 0.921875, loss: 0.276180624961853        \n",
      "train step #2903 accuracy: 0.9375, loss: 0.20499414205551147      \n",
      "train step #2904 accuracy:   1.0, loss: 0.0844520553946495       \n",
      "train step #2905 accuracy: 0.96875, loss: 0.17689135670661926      \n",
      "train step #2906 accuracy: 0.90625, loss: 0.31885185837745667      \n",
      "train step #2907 accuracy: 0.9375, loss: 0.243546724319458        \n",
      "train step #2908 accuracy: 0.984375, loss: 0.10833334177732468      \n",
      "train step #2909 accuracy: 0.9375, loss: 0.21257808804512024      \n",
      "train step #2910 accuracy: 0.953125, loss: 0.18035437166690826      \n",
      "train step #2911 accuracy: 0.921875, loss: 0.33759164810180664      \n",
      "train step #2912 accuracy: 0.984375, loss: 0.13688014447689056      \n",
      "train step #2913 accuracy: 0.9375, loss: 0.2534477114677429       \n",
      "train step #2914 accuracy: 0.953125, loss: 0.2068711817264557       \n",
      "train step #2915 accuracy: 0.984375, loss: 0.07903163135051727      \n",
      "train step #2916 accuracy: 0.9375, loss: 0.2869911789894104       \n",
      "train step #2917 accuracy: 0.953125, loss: 0.17548073828220367      \n",
      "train step #2918 accuracy: 0.921875, loss: 0.25394853949546814      \n",
      "train step #2919 accuracy: 0.9375, loss: 0.1442999392747879       \n",
      "train step #2920 accuracy: 0.96875, loss: 0.1374344825744629       \n",
      "train step #2921 accuracy: 0.9375, loss: 0.19215896725654602      \n",
      "train step #2922 accuracy: 0.9375, loss: 0.17123034596443176      \n",
      "train step #2923 accuracy: 0.96875, loss: 0.11929228156805038      \n",
      "train step #2924 accuracy: 0.890625, loss: 0.3307635486125946       \n",
      "train step #2925 accuracy: 0.9375, loss: 0.1782834529876709       \n",
      "train step #2926 accuracy: 0.921875, loss: 0.2739237844944          \n",
      "train step #2927 accuracy: 0.953125, loss: 0.1378578394651413       \n",
      "train step #2928 accuracy: 0.9375, loss: 0.14501169323921204      \n",
      "train step #2929 accuracy: 0.96875, loss: 0.1271466463804245       \n",
      "train step #2930 accuracy: 0.96875, loss: 0.1744282841682434       \n",
      "train step #2931 accuracy: 0.96875, loss: 0.17968599498271942      \n",
      "train step #2932 accuracy: 0.953125, loss: 0.2289097160100937       \n",
      "train step #2933 accuracy: 0.96875, loss: 0.14838579297065735      \n",
      "train step #2934 accuracy: 0.953125, loss: 0.15951627492904663      \n",
      "train step #2935 accuracy: 0.953125, loss: 0.18788838386535645      \n",
      "train step #2936 accuracy: 0.96875, loss: 0.1022733524441719       \n",
      "train step #2937 accuracy: 0.953125, loss: 0.196555033326149        \n",
      "train step #2938 accuracy: 0.890625, loss: 0.30823659896850586      \n",
      "train step #2939 accuracy: 0.90625, loss: 0.30067259073257446      \n",
      "train step #2940 accuracy: 0.953125, loss: 0.2665402293205261       \n",
      "train step #2941 accuracy: 0.890625, loss: 0.21309912204742432      \n",
      "train step #2942 accuracy: 0.890625, loss: 0.3015611171722412       \n",
      "train step #2943 accuracy: 0.984375, loss: 0.08807653188705444      \n",
      "train step #2944 accuracy: 0.96875, loss: 0.23234930634498596      \n",
      "train step #2945 accuracy: 0.921875, loss: 0.186637282371521        \n",
      "train step #2946 accuracy: 0.890625, loss: 0.37418484687805176      \n",
      "train step #2947 accuracy: 0.953125, loss: 0.14613720774650574      \n",
      "train step #2948 accuracy: 0.90625, loss: 0.3251994848251343       \n",
      "train step #2949 accuracy: 0.890625, loss: 0.26602503657341003      \n",
      "train step #2950 accuracy: 0.9375, loss: 0.1797097623348236       \n",
      "train step #2951 accuracy: 0.9375, loss: 0.21664303541183472      \n",
      "train step #2952 accuracy: 0.9375, loss: 0.1688026785850525       \n",
      "train step #2953 accuracy: 0.90625, loss: 0.2386266440153122       \n",
      "train step #2954 accuracy: 0.921875, loss: 0.226097971200943        \n",
      "train step #2955 accuracy: 0.90625, loss: 0.22207313776016235      \n",
      "train step #2956 accuracy: 0.953125, loss: 0.16368262469768524      \n",
      "train step #2957 accuracy: 0.96875, loss: 0.2056955099105835       \n",
      "train step #2958 accuracy: 0.953125, loss: 0.16196610033512115      \n",
      "train step #2959 accuracy: 0.921875, loss: 0.27549293637275696      \n",
      "train step #2960 accuracy: 0.90625, loss: 0.25849437713623047      \n",
      "train step #2961 accuracy: 0.953125, loss: 0.09809336811304092      \n",
      "train step #2962 accuracy: 0.96875, loss: 0.08032839000225067      \n",
      "train step #2963 accuracy: 0.953125, loss: 0.2110052853822708       \n",
      "train step #2964 accuracy: 0.953125, loss: 0.1553126573562622       \n",
      "train step #2965 accuracy: 0.859375, loss: 0.41257011890411377      \n",
      "train step #2966 accuracy: 0.96875, loss: 0.17796474695205688      \n",
      "train step #2967 accuracy: 0.953125, loss: 0.15534687042236328      \n",
      "train step #2968 accuracy: 0.953125, loss: 0.29335588216781616      \n",
      "train step #2969 accuracy: 0.921875, loss: 0.19842542707920074      \n",
      "train step #2970 accuracy: 0.96875, loss: 0.11832781136035919      \n",
      "train step #2971 accuracy: 0.953125, loss: 0.17477424442768097      \n",
      "train step #2972 accuracy: 0.953125, loss: 0.2386469542980194       \n",
      "train step #2973 accuracy: 0.96875, loss: 0.18013688921928406      \n",
      "train step #2974 accuracy: 0.9375, loss: 0.27581554651260376      \n",
      "train step #2975 accuracy: 0.90625, loss: 0.37240761518478394      \n",
      "train step #2976 accuracy: 0.90625, loss: 0.2045983076095581       \n",
      "train step #2977 accuracy: 0.96875, loss: 0.14024408161640167      \n",
      "train step #2978 accuracy: 0.921875, loss: 0.2672992944717407       \n",
      "train step #2979 accuracy: 0.96875, loss: 0.18566708266735077      \n",
      "train step #2980 accuracy: 0.953125, loss: 0.20429107546806335      \n",
      "train step #2981 accuracy: 0.96875, loss: 0.0949394702911377       \n",
      "train step #2982 accuracy: 0.921875, loss: 0.2424696385860443       \n",
      "train step #2983 accuracy: 0.96875, loss: 0.13868281245231628      \n",
      "train step #2984 accuracy: 0.953125, loss: 0.16507624089717865      \n",
      "train step #2985 accuracy: 0.953125, loss: 0.11888952553272247      \n",
      "train step #2986 accuracy: 0.90625, loss: 0.28814563155174255      \n",
      "train step #2987 accuracy: 0.890625, loss: 0.4141491651535034       \n",
      "train step #2988 accuracy: 0.9375, loss: 0.19711531698703766      \n",
      "train step #2989 accuracy: 0.9375, loss: 0.1874232292175293       \n",
      "train step #2990 accuracy: 0.984375, loss: 0.07117731869220734      \n",
      "train step #2991 accuracy: 0.96875, loss: 0.09422533959150314      \n",
      "train step #2992 accuracy: 0.953125, loss: 0.20937830209732056      \n",
      "train step #2993 accuracy: 0.953125, loss: 0.2804926931858063       \n",
      "train step #2994 accuracy: 0.9375, loss: 0.19317930936813354      \n",
      "train step #2995 accuracy: 0.921875, loss: 0.24421510100364685      \n",
      "train step #2996 accuracy: 0.921875, loss: 0.19075360894203186      \n",
      "train step #2997 accuracy: 0.9375, loss: 0.1825685352087021       \n",
      "train step #2998 accuracy: 0.953125, loss: 0.11584766954183578      \n",
      "train step #2999 accuracy: 0.921875, loss: 0.23926585912704468      \n",
      "train step #3000 accuracy: 0.984375, loss: 0.07267308235168457      \n",
      "changing learning rate to 0.01\n",
      "train step #3001 accuracy: 0.9375, loss: 0.21722303330898285      \n",
      "train step #3002 accuracy: 0.921875, loss: 0.22536620497703552      \n",
      "train step #3003 accuracy: 0.953125, loss: 0.08978916704654694      \n",
      "train step #3004 accuracy: 0.9375, loss: 0.25740164518356323      \n",
      "train step #3005 accuracy: 0.9375, loss: 0.19147996604442596      \n",
      "train step #3006 accuracy: 0.953125, loss: 0.26450908184051514      \n",
      "train step #3007 accuracy: 0.9375, loss: 0.25460508465766907      \n",
      "train step #3008 accuracy: 0.90625, loss: 0.3179587125778198       \n",
      "train step #3009 accuracy: 0.96875, loss: 0.07305342704057693      \n",
      "train step #3010 accuracy: 0.921875, loss: 0.2889028489589691       \n",
      "train step #3011 accuracy: 0.921875, loss: 0.30048370361328125      \n",
      "train step #3012 accuracy: 0.9375, loss: 0.1569218635559082       \n",
      "train step #3013 accuracy: 0.96875, loss: 0.0989958643913269       \n",
      "train step #3014 accuracy: 0.953125, loss: 0.12400495260953903      \n",
      "train step #3015 accuracy: 0.9375, loss: 0.1608818918466568       \n",
      "train step #3016 accuracy: 0.90625, loss: 0.3350840210914612       \n",
      "train step #3017 accuracy: 0.984375, loss: 0.11851091682910919      \n",
      "train step #3018 accuracy: 0.96875, loss: 0.11066748946905136      \n",
      "train step #3019 accuracy: 0.9375, loss: 0.17760419845581055      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #3020 accuracy: 0.9375, loss: 0.31369900703430176      \n",
      "train step #3021 accuracy: 0.921875, loss: 0.16383524239063263      \n",
      "train step #3022 accuracy: 0.9375, loss: 0.20915141701698303      \n",
      "train step #3023 accuracy: 0.890625, loss: 0.454181432723999        \n",
      "train step #3024 accuracy: 0.9375, loss: 0.2692543864250183       \n",
      "train step #3025 accuracy: 0.9375, loss: 0.2162887156009674       \n",
      "train step #3026 accuracy: 0.96875, loss: 0.12333410233259201      \n",
      "train step #3027 accuracy: 0.921875, loss: 0.25510966777801514      \n",
      "train step #3028 accuracy: 0.953125, loss: 0.20500481128692627      \n",
      "train step #3029 accuracy: 0.953125, loss: 0.18225215375423431      \n",
      "train step #3030 accuracy: 0.96875, loss: 0.06256145238876343      \n",
      "train step #3031 accuracy: 0.921875, loss: 0.26157504320144653      \n",
      "train step #3032 accuracy:   1.0, loss: 0.03302788361907005      \n",
      "train step #3033 accuracy: 0.984375, loss: 0.06684338301420212      \n",
      "train step #3034 accuracy: 0.953125, loss: 0.1617763489484787       \n",
      "train step #3035 accuracy: 0.921875, loss: 0.2771175503730774       \n",
      "train step #3036 accuracy: 0.9375, loss: 0.1761525273323059       \n",
      "train step #3037 accuracy:   1.0, loss: 0.05084013193845749      \n",
      "train step #3038 accuracy: 0.921875, loss: 0.1655324101448059       \n",
      "train step #3039 accuracy: 0.953125, loss: 0.10063695162534714      \n",
      "train step #3040 accuracy: 0.921875, loss: 0.26080122590065         \n",
      "train step #3041 accuracy: 0.953125, loss: 0.13081198930740356      \n",
      "train step #3042 accuracy: 0.96875, loss: 0.11861197650432587      \n",
      "train step #3043 accuracy: 0.921875, loss: 0.2631242275238037       \n",
      "train step #3044 accuracy: 0.9375, loss: 0.30418771505355835      \n",
      "train step #3045 accuracy: 0.96875, loss: 0.10806562751531601      \n",
      "train step #3046 accuracy: 0.96875, loss: 0.08832747489213943      \n",
      "train step #3047 accuracy: 0.890625, loss: 0.21115370094776154      \n",
      "train step #3048 accuracy: 0.96875, loss: 0.2075219601392746       \n",
      "train step #3049 accuracy: 0.9375, loss: 0.225010484457016        \n",
      "train step #3050 accuracy: 0.96875, loss: 0.13472290337085724      \n",
      "train step #3051 accuracy: 0.9375, loss: 0.22201450169086456      \n",
      "train step #3052 accuracy: 0.984375, loss: 0.08865005522966385      \n",
      "train step #3053 accuracy: 0.953125, loss: 0.16422083973884583      \n",
      "train step #3054 accuracy: 0.96875, loss: 0.13396736979484558      \n",
      "train step #3055 accuracy: 0.96875, loss: 0.1813882291316986       \n",
      "train step #3056 accuracy: 0.953125, loss: 0.14041820168495178      \n",
      "train step #3057 accuracy: 0.9375, loss: 0.2074078470468521       \n",
      "train step #3058 accuracy: 0.90625, loss: 0.3045364022254944       \n",
      "train step #3059 accuracy: 0.9375, loss: 0.25420236587524414      \n",
      "train step #3060 accuracy: 0.953125, loss: 0.17336884140968323      \n",
      "train step #3061 accuracy: 0.953125, loss: 0.20134375989437103      \n",
      "train step #3062 accuracy: 0.953125, loss: 0.14771127700805664      \n",
      "train step #3063 accuracy: 0.890625, loss: 0.3299171030521393       \n",
      "train step #3064 accuracy: 0.984375, loss: 0.08779013156890869      \n",
      "train step #3065 accuracy:   1.0, loss: 0.05452139675617218      \n",
      "train step #3066 accuracy: 0.9375, loss: 0.18199625611305237      \n",
      "train step #3067 accuracy: 0.921875, loss: 0.23775073885917664      \n",
      "train step #3068 accuracy: 0.96875, loss: 0.12384337931871414      \n",
      "train step #3069 accuracy: 0.9375, loss: 0.16008299589157104      \n",
      "train step #3070 accuracy: 0.90625, loss: 0.2971246540546417       \n",
      "train step #3071 accuracy: 0.9375, loss: 0.17236298322677612      \n",
      "train step #3072 accuracy: 0.953125, loss: 0.1998632848262787       \n",
      "train step #3073 accuracy: 0.953125, loss: 0.1280481517314911       \n",
      "train step #3074 accuracy: 0.96875, loss: 0.13228660821914673      \n",
      "train step #3075 accuracy: 0.96875, loss: 0.11275135725736618      \n",
      "train step #3076 accuracy: 0.984375, loss: 0.14976054430007935      \n",
      "train step #3077 accuracy: 0.90625, loss: 0.3086012005805969       \n",
      "train step #3078 accuracy: 0.921875, loss: 0.2593141496181488       \n",
      "train step #3079 accuracy: 0.96875, loss: 0.07339014112949371      \n",
      "train step #3080 accuracy: 0.953125, loss: 0.10648778825998306      \n",
      "train step #3081 accuracy: 0.90625, loss: 0.41935548186302185      \n",
      "train step #3082 accuracy: 0.984375, loss: 0.1519956737756729       \n",
      "train step #3083 accuracy: 0.9375, loss: 0.15186932682991028      \n",
      "train step #3084 accuracy: 0.953125, loss: 0.23043732345104218      \n",
      "train step #3085 accuracy: 0.96875, loss: 0.15278694033622742      \n",
      "train step #3086 accuracy: 0.90625, loss: 0.2570372223854065       \n",
      "train step #3087 accuracy: 0.9375, loss: 0.2474726140499115       \n",
      "train step #3088 accuracy:   1.0, loss: 0.09836327284574509      \n",
      "train step #3089 accuracy: 0.984375, loss: 0.1138242557644844       \n",
      "train step #3090 accuracy: 0.96875, loss: 0.14952680468559265      \n",
      "train step #3091 accuracy: 0.953125, loss: 0.12744681537151337      \n",
      "train step #3092 accuracy: 0.96875, loss: 0.060082174837589264     \n",
      "train step #3093 accuracy: 0.96875, loss: 0.12755189836025238      \n",
      "train step #3094 accuracy: 0.984375, loss: 0.04530046135187149      \n",
      "train step #3095 accuracy: 0.953125, loss: 0.1542823314666748       \n",
      "train step #3096 accuracy: 0.9375, loss: 0.2721193730831146       \n",
      "train step #3097 accuracy: 0.96875, loss: 0.10869288444519043      \n",
      "train step #3098 accuracy: 0.953125, loss: 0.11891361325979233      \n",
      "train step #3099 accuracy: 0.921875, loss: 0.24117383360862732      \n",
      "train step #3100 accuracy: 0.984375, loss: 0.08792005479335785      \n",
      "train step #3101 accuracy: 0.953125, loss: 0.0786566212773323       \n",
      "train step #3102 accuracy: 0.9375, loss: 0.23071755468845367      \n",
      "train step #3103 accuracy: 0.96875, loss: 0.1461479663848877       \n",
      "train step #3104 accuracy: 0.96875, loss: 0.10446489602327347      \n",
      "train step #3105 accuracy: 0.953125, loss: 0.1560354232788086       \n",
      "train step #3106 accuracy: 0.875, loss: 0.33911699056625366      \n",
      "train step #3107 accuracy: 0.96875, loss: 0.13547146320343018      \n",
      "train step #3108 accuracy: 0.96875, loss: 0.13409888744354248      \n",
      "train step #3109 accuracy: 0.984375, loss: 0.09601930528879166      \n",
      "train step #3110 accuracy: 0.9375, loss: 0.18470390141010284      \n",
      "train step #3111 accuracy: 0.96875, loss: 0.1433529108762741       \n",
      "train step #3112 accuracy: 0.9375, loss: 0.2613397240638733       \n",
      "train step #3113 accuracy: 0.953125, loss: 0.13954980671405792      \n",
      "train step #3114 accuracy: 0.953125, loss: 0.1811876893043518       \n",
      "train step #3115 accuracy: 0.984375, loss: 0.07510091364383698      \n",
      "train step #3116 accuracy: 0.953125, loss: 0.10262651741504669      \n",
      "train step #3117 accuracy: 0.9375, loss: 0.2084435373544693       \n",
      "train step #3118 accuracy: 0.9375, loss: 0.2638501226902008       \n",
      "train step #3119 accuracy: 0.984375, loss: 0.07490013539791107      \n",
      "train step #3120 accuracy: 0.921875, loss: 0.2560521364212036       \n",
      "train step #3121 accuracy: 0.96875, loss: 0.1765909641981125       \n",
      "train step #3122 accuracy: 0.984375, loss: 0.1611022651195526       \n",
      "train step #3123 accuracy: 0.921875, loss: 0.24403707683086395      \n",
      "dev accuracy:   1.0, loss: 0.008057951927185059     \n",
      "dev accuracy:   1.0, loss: 0.1072332113981247       \n",
      "dev accuracy:   1.0, loss: 0.0038340985774993896    \n",
      "dev accuracy:   1.0, loss: 0.0084611177444458       \n",
      "dev accuracy:   1.0, loss: 0.11144866049289703      \n",
      "dev accuracy:   1.0, loss: 0.030988037586212158     \n",
      "dev accuracy: 0.9375, loss: 0.18727117776870728      \n",
      "dev accuracy: 0.8125, loss: 0.7609959840774536       \n",
      "dev accuracy:   1.0, loss: 0.05795559287071228      \n",
      "dev accuracy:   1.0, loss: 0.026293665170669556     \n",
      "dev accuracy: 0.875, loss: 0.35240060091018677      \n",
      "dev accuracy:   1.0, loss: 0.001492917537689209     \n",
      "dev accuracy: 0.9375, loss: 0.1552741825580597       \n",
      "dev accuracy: 0.8125, loss: 0.7477396726608276       \n",
      "dev accuracy:   1.0, loss: 0.025673091411590576     \n",
      "dev accuracy:   1.0, loss: 0.04986327886581421      \n",
      "dev accuracy: 0.9375, loss: 0.08554890751838684      \n",
      "dev accuracy: 0.875, loss: 0.25995513796806335      \n",
      "dev accuracy: 0.9375, loss: 0.15727581083774567      \n",
      "dev accuracy: 0.875, loss: 0.3656127154827118       \n",
      "dev accuracy:   1.0, loss: 0.007264673709869385     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy: 0.9375, loss: 0.15523570775985718      \n",
      "dev accuracy:   1.0, loss: 0.03770849108695984      \n",
      "dev accuracy: 0.875, loss: 0.1969819813966751       \n",
      "dev accuracy:   1.0, loss: 0.04541853070259094      \n",
      "dev accuracy:   1.0, loss: 0.013702094554901123     \n",
      "dev accuracy: 0.8125, loss: 0.4611934423446655       \n",
      "dev accuracy: 0.875, loss: 0.2894343137741089       \n",
      "dev accuracy: 0.9375, loss: 0.4462059438228607       \n",
      "dev accuracy: 0.8125, loss: 0.3517889976501465       \n",
      "dev accuracy:   1.0, loss: 0.04793006181716919      \n",
      "dev accuracy: 0.9375, loss: 0.0836864709854126       \n",
      "dev accuracy:   1.0, loss: 0.03719690442085266      \n",
      "dev accuracy: 0.9375, loss: 0.2318563014268875       \n",
      "dev accuracy:   1.0, loss: 0.0017844438552856445    \n",
      "dev accuracy:   1.0, loss: 0.09698036313056946      \n",
      "dev accuracy: 0.9375, loss: 0.22719994187355042      \n",
      "dev accuracy:   1.0, loss: 0.05993497371673584      \n",
      "dev accuracy: 0.9375, loss: 0.07870447635650635      \n",
      "dev accuracy: 0.9375, loss: 0.1685519516468048       \n",
      "dev accuracy:   1.0, loss: 0.008967012166976929     \n",
      "dev accuracy: 0.875, loss: 0.17942345142364502      \n",
      "dev accuracy: 0.9375, loss: 0.10867148637771606      \n",
      "dev accuracy: 0.9375, loss: 0.20345854759216309      \n",
      "dev accuracy: 0.9375, loss: 0.09010964632034302      \n",
      "dev accuracy: 0.8125, loss: 0.7306406497955322       \n",
      "dev accuracy: 0.9375, loss: 0.1914241760969162       \n",
      "dev accuracy: 0.875, loss: 0.2640080749988556       \n",
      "dev accuracy: 0.9375, loss: 0.2816864252090454       \n",
      "dev accuracy:   1.0, loss: 0.1165892705321312       \n",
      "dev accuracy: 0.875, loss: 0.6881519556045532       \n",
      "dev accuracy: 0.9375, loss: 0.10209617018699646      \n",
      "dev accuracy:   1.0, loss: 0.006134510040283203     \n",
      "dev accuracy:   1.0, loss: 0.005328357219696045     \n",
      "dev accuracy: 0.9375, loss: 0.13581787049770355      \n",
      "dev accuracy: 0.875, loss: 0.49571287631988525      \n",
      "dev accuracy:   1.0, loss: 0.02906656265258789      \n",
      "dev accuracy:   1.0, loss: 0.0066356658935546875    \n",
      "dev accuracy: 0.9375, loss: 0.19952084124088287      \n",
      "dev accuracy:   1.0, loss: 0.021486103534698486     \n",
      "dev accuracy: 0.9375, loss: 0.1367027759552002       \n",
      "dev accuracy: 0.9375, loss: 0.1547061800956726       \n",
      "dev accuracy: 0.9375, loss: 0.38358384370803833      \n",
      "dev accuracy:   1.0, loss: 0.009039849042892456     \n",
      "dev accuracy:   1.0, loss: 0.04574030637741089      \n",
      "dev accuracy:   1.0, loss: 0.028293848037719727     \n",
      "dev accuracy:   1.0, loss: 0.005422234535217285     \n",
      "dev accuracy: 0.875, loss: 0.34186896681785583      \n",
      "dev accuracy: 0.9375, loss: 0.385123610496521        \n",
      "dev accuracy:   1.0, loss: 0.002696692943572998     \n",
      "dev accuracy: 0.9375, loss: 0.16020555794239044      \n",
      "dev accuracy: 0.9375, loss: 0.16455429792404175      \n",
      "dev accuracy: 0.9375, loss: 0.17060476541519165      \n",
      "dev accuracy:   1.0, loss: 0.007234901189804077     \n",
      "dev accuracy:   1.0, loss: 0.041141778230667114     \n",
      "dev accuracy: 0.9375, loss: 0.3944755494594574       \n",
      "dev accuracy:   1.0, loss: 0.1376933753490448       \n",
      "dev accuracy: 0.8125, loss: 0.4836750030517578       \n",
      "dev accuracy: 0.9375, loss: 0.38792791962623596      \n",
      "dev accuracy: 0.9375, loss: 0.05737048387527466      \n",
      "dev accuracy: 0.9375, loss: 0.2758752703666687       \n",
      "dev accuracy: 0.9375, loss: 0.0653485357761383       \n",
      "dev accuracy: 0.9375, loss: 0.1660689413547516       \n",
      "dev accuracy: 0.9375, loss: 0.14254817366600037      \n",
      "dev accuracy: 0.8125, loss: 0.7284912467002869       \n",
      "dev accuracy:   1.0, loss: 0.04567563533782959      \n",
      "dev accuracy:   1.0, loss: 0.0337563157081604       \n",
      "dev accuracy: 0.9375, loss: 0.23183158040046692      \n",
      "dev accuracy: 0.9375, loss: 0.11742621660232544      \n",
      "dev accuracy:   1.0, loss: 0.056055814027786255     \n",
      "dev accuracy:   1.0, loss: 0.03535863757133484      \n",
      "dev accuracy: 0.9375, loss: 0.16244587302207947      \n",
      "dev accuracy: 0.9375, loss: 0.11467711627483368      \n",
      "dev accuracy: 0.875, loss: 0.460959255695343        \n",
      "dev accuracy: 0.9375, loss: 0.14954577386379242      \n",
      "dev accuracy: 0.9375, loss: 0.2075396329164505       \n",
      "dev accuracy: 0.9375, loss: 0.062283217906951904     \n",
      "dev accuracy: 0.9375, loss: 0.11086896061897278      \n",
      "dev accuracy: 0.9375, loss: 0.43800097703933716      \n",
      "dev accuracy:   1.0, loss: 0.041095227003097534     \n",
      "dev accuracy:   1.0, loss: 0.00943291187286377      \n",
      "dev accuracy:   1.0, loss: 0.05164057016372681      \n",
      "dev accuracy: 0.9375, loss: 0.09145998954772949      \n",
      "dev accuracy:   1.0, loss: 0.005045890808105469     \n",
      "dev accuracy: 0.875, loss: 0.57347172498703         \n",
      "dev accuracy:   1.0, loss: 0.1083628386259079       \n",
      "dev accuracy:   1.0, loss: 0.01130378246307373      \n",
      "dev accuracy: 0.9375, loss: 0.13029466569423676      \n",
      "dev accuracy: 0.9375, loss: 0.2031913697719574       \n",
      "dev accuracy:   1.0, loss: 0.03597858548164368      \n",
      "dev accuracy:   1.0, loss: 0.016339868307113647     \n",
      "dev accuracy: 0.875, loss: 0.2049904763698578       \n",
      "dev accuracy:   1.0, loss: 0.06209549307823181      \n",
      "dev accuracy: 0.9375, loss: 0.21014390885829926      \n",
      "dev accuracy: 0.875, loss: 0.29888415336608887      \n",
      "dev accuracy: 0.9375, loss: 0.12439948320388794      \n",
      "dev accuracy:   1.0, loss: 0.020117521286010742     \n",
      "dev accuracy: 0.9375, loss: 0.22139611840248108      \n",
      "dev accuracy: 0.9375, loss: 0.09194871783256531      \n",
      "dev accuracy:   1.0, loss: 0.004754930734634399     \n",
      "dev accuracy: 0.875, loss: 0.5508840680122375       \n",
      "dev accuracy: 0.9375, loss: 0.13690820336341858      \n",
      "dev accuracy: 0.875, loss: 0.229842409491539        \n",
      "dev accuracy: 0.9375, loss: 0.09932059049606323      \n",
      "dev accuracy:   1.0, loss: 0.08300361037254333      \n",
      "dev accuracy:   1.0, loss: 0.03678010404109955      \n",
      "dev accuracy:   1.0, loss: 0.03286147117614746      \n",
      "dev accuracy: 0.8125, loss: 0.7290051579475403       \n",
      "dev accuracy:   1.0, loss: 0.01927599310874939      \n",
      "dev accuracy:   1.0, loss: 0.007022053003311157     \n",
      "dev accuracy: 0.875, loss: 0.24280059337615967      \n",
      "dev accuracy: 0.9375, loss: 0.06510540843009949      \n",
      "dev accuracy:   1.0, loss: 0.011504709720611572     \n",
      "dev accuracy: 0.9375, loss: 0.13676932454109192      \n",
      "dev accuracy:   1.0, loss: 0.009819865226745605     \n",
      "dev accuracy: 0.9375, loss: 0.21115753054618835      \n",
      "dev accuracy:   1.0, loss: 0.009985923767089844     \n",
      "dev accuracy: 0.875, loss: 0.3857649266719818       \n",
      "dev accuracy: 0.9375, loss: 0.508875846862793        \n",
      "dev accuracy: 0.875, loss: 0.4226577579975128       \n",
      "dev accuracy: 0.875, loss: 0.17980286478996277      \n",
      "dev accuracy: 0.9375, loss: 0.34629353880882263      \n",
      "dev accuracy: 0.9375, loss: 0.14560842514038086      \n",
      "dev accuracy:   1.0, loss: 0.004522860050201416     \n",
      "dev accuracy:   1.0, loss: 0.005033373832702637     \n",
      "dev accuracy:   1.0, loss: 0.0067986249923706055    \n",
      "dev accuracy:   1.0, loss: 0.02213764190673828      \n",
      "dev accuracy: 0.875, loss: 0.4697372019290924       \n",
      "dev accuracy: 0.8125, loss: 0.7779693007469177       \n",
      "dev accuracy: 0.9375, loss: 0.26242706179618835      \n",
      "dev accuracy: 0.9375, loss: 0.09067192673683167      \n",
      "dev accuracy:   1.0, loss: 0.07050436735153198      \n",
      "dev accuracy: 0.9375, loss: 0.11121813952922821      \n",
      "dev accuracy: 0.9375, loss: 0.06049719452857971      \n",
      "dev accuracy: 0.9375, loss: 0.12405616044998169      \n",
      "dev accuracy: 0.875, loss: 0.37670567631721497      \n",
      "dev accuracy: 0.9375, loss: 0.16678012907505035      \n",
      "dev accuracy: 0.9375, loss: 0.5801112651824951       \n",
      "dev accuracy: 0.9375, loss: 0.385313481092453        \n",
      "dev accuracy:   1.0, loss: 0.029601603746414185     \n",
      "dev accuracy: 0.9375, loss: 0.30682122707366943      \n",
      "dev accuracy: 0.9375, loss: 0.25086283683776855      \n",
      "dev accuracy:   1.0, loss: 0.004658937454223633     \n",
      "dev accuracy:   1.0, loss: 0.055404454469680786     \n",
      "dev accuracy:   1.0, loss: 0.02023559808731079      \n",
      "dev accuracy:   1.0, loss: 0.015245169401168823     \n",
      "dev accuracy:   1.0, loss: 0.0005706548690795898    \n",
      "dev accuracy:   1.0, loss: 0.046569645404815674     \n",
      "dev accuracy:   1.0, loss: 0.044416725635528564     \n",
      "dev accuracy: 0.875, loss: 0.7872031331062317       \n",
      "dev accuracy: 0.875, loss: 0.14537787437438965      \n",
      "dev accuracy: 0.9375, loss: 0.2343708723783493       \n",
      "dev accuracy: 0.8125, loss: 0.6327117085456848       \n",
      "dev accuracy:   1.0, loss: 0.037142664194107056     \n",
      "dev accuracy: 0.9375, loss: 0.2926623821258545       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy:   1.0, loss: 0.05579903721809387      \n",
      "dev accuracy:  0.75, loss: 0.41246163845062256      \n",
      "dev accuracy: 0.875, loss: 0.2187284231185913       \n",
      "dev accuracy:   1.0, loss: 0.007580280303955078     \n",
      "dev accuracy: 0.875, loss: 0.326755553483963        \n",
      "dev accuracy: 0.9375, loss: 0.2082662284374237       \n",
      "dev accuracy: 0.875, loss: 0.4017694890499115       \n",
      "dev accuracy:   1.0, loss: 0.03406389057636261      \n",
      "dev accuracy: 0.9375, loss: 0.26837313175201416      \n",
      "dev accuracy:   1.0, loss: 0.023754805326461792     \n",
      "dev accuracy:   1.0, loss: 0.04785206913948059      \n",
      "dev accuracy:   1.0, loss: 0.06384193897247314      \n",
      "dev accuracy:   1.0, loss: 0.008936047554016113     \n",
      "dev accuracy:   1.0, loss: 0.05725647509098053      \n",
      "dev accuracy: 0.875, loss: 0.13625556230545044      \n",
      "dev accuracy:   1.0, loss: 0.035515040159225464     \n",
      "dev accuracy: 0.9375, loss: 0.175498366355896        \n",
      "dev accuracy:   1.0, loss: 0.11223894357681274      \n",
      "dev accuracy:   1.0, loss: 0.0036172866821289062    \n",
      "final dev accuracy: 0.9478092783505154\n",
      "saving best model...\n",
      "train step #3124 accuracy: 0.953125, loss: 0.12485413253307343      \n",
      "train step #3125 accuracy:   1.0, loss: 0.025973118841648102     \n",
      "train step #3126 accuracy: 0.9375, loss: 0.2672538459300995       \n",
      "train step #3127 accuracy: 0.953125, loss: 0.10291947424411774      \n",
      "train step #3128 accuracy: 0.984375, loss: 0.07553011178970337      \n",
      "train step #3129 accuracy: 0.9375, loss: 0.25766557455062866      \n",
      "train step #3130 accuracy: 0.984375, loss: 0.08872861415147781      \n",
      "train step #3131 accuracy: 0.96875, loss: 0.15488563477993011      \n",
      "train step #3132 accuracy: 0.953125, loss: 0.174611896276474        \n",
      "train step #3133 accuracy: 0.953125, loss: 0.23969678580760956      \n",
      "train step #3134 accuracy: 0.96875, loss: 0.10914310812950134      \n",
      "train step #3135 accuracy: 0.96875, loss: 0.11233849078416824      \n",
      "train step #3136 accuracy: 0.96875, loss: 0.150697261095047        \n",
      "train step #3137 accuracy: 0.921875, loss: 0.36447134613990784      \n",
      "train step #3138 accuracy: 0.984375, loss: 0.08912397176027298      \n",
      "train step #3139 accuracy: 0.921875, loss: 0.2251521795988083       \n",
      "train step #3140 accuracy: 0.96875, loss: 0.16320812702178955      \n",
      "train step #3141 accuracy: 0.984375, loss: 0.10094838589429855      \n",
      "train step #3142 accuracy: 0.984375, loss: 0.08770723640918732      \n",
      "train step #3143 accuracy: 0.96875, loss: 0.15927669405937195      \n",
      "train step #3144 accuracy: 0.9375, loss: 0.35766154527664185      \n",
      "train step #3145 accuracy: 0.96875, loss: 0.12391418218612671      \n",
      "train step #3146 accuracy: 0.9375, loss: 0.2559291124343872       \n",
      "train step #3147 accuracy:   1.0, loss: 0.04696495831012726      \n",
      "train step #3148 accuracy: 0.953125, loss: 0.15099509060382843      \n",
      "train step #3149 accuracy: 0.9375, loss: 0.20089346170425415      \n",
      "train step #3150 accuracy: 0.9375, loss: 0.14846356213092804      \n",
      "train step #3151 accuracy: 0.984375, loss: 0.11099531501531601      \n",
      "train step #3152 accuracy: 0.984375, loss: 0.11616513878107071      \n",
      "train step #3153 accuracy: 0.9375, loss: 0.18426010012626648      \n",
      "train step #3154 accuracy: 0.953125, loss: 0.19584324955940247      \n",
      "train step #3155 accuracy: 0.984375, loss: 0.08799409866333008      \n",
      "train step #3156 accuracy: 0.953125, loss: 0.23316389322280884      \n",
      "train step #3157 accuracy: 0.9375, loss: 0.12846077978610992      \n",
      "train step #3158 accuracy: 0.921875, loss: 0.29362595081329346      \n",
      "train step #3159 accuracy: 0.9375, loss: 0.1737118810415268       \n",
      "train step #3160 accuracy: 0.953125, loss: 0.15810534358024597      \n",
      "train step #3161 accuracy:   1.0, loss: 0.03519803285598755      \n",
      "train step #3162 accuracy: 0.90625, loss: 0.22530123591423035      \n",
      "train step #3163 accuracy: 0.984375, loss: 0.0747256726026535       \n",
      "train step #3164 accuracy: 0.9375, loss: 0.1823655515909195       \n",
      "train step #3165 accuracy: 0.921875, loss: 0.1664753556251526       \n",
      "train step #3166 accuracy: 0.9375, loss: 0.2416304051876068       \n",
      "train step #3167 accuracy: 0.984375, loss: 0.0583052784204483       \n",
      "train step #3168 accuracy: 0.953125, loss: 0.15953493118286133      \n",
      "train step #3169 accuracy: 0.9375, loss: 0.256581574678421        \n",
      "train step #3170 accuracy: 0.921875, loss: 0.1922510266304016       \n",
      "train step #3171 accuracy: 0.953125, loss: 0.16734442114830017      \n",
      "train step #3172 accuracy: 0.953125, loss: 0.18421095609664917      \n",
      "train step #3173 accuracy: 0.984375, loss: 0.05356389284133911      \n",
      "train step #3174 accuracy: 0.984375, loss: 0.04027482122182846      \n",
      "train step #3175 accuracy:   1.0, loss: 0.010436110198497772     \n",
      "train step #3176 accuracy: 0.921875, loss: 0.18144315481185913      \n",
      "train step #3177 accuracy: 0.953125, loss: 0.18265704810619354      \n",
      "train step #3178 accuracy: 0.9375, loss: 0.2899158000946045       \n",
      "train step #3179 accuracy:   1.0, loss: 0.04086390137672424      \n",
      "train step #3180 accuracy: 0.96875, loss: 0.11450985074043274      \n",
      "train step #3181 accuracy: 0.90625, loss: 0.32019174098968506      \n",
      "train step #3182 accuracy: 0.984375, loss: 0.08548314869403839      \n",
      "train step #3183 accuracy: 0.96875, loss: 0.1673579216003418       \n",
      "train step #3184 accuracy:   1.0, loss: 0.04859863221645355      \n",
      "train step #3185 accuracy: 0.984375, loss: 0.09613658487796783      \n",
      "train step #3186 accuracy: 0.96875, loss: 0.1990966498851776       \n",
      "train step #3187 accuracy: 0.953125, loss: 0.13776898384094238      \n",
      "train step #3188 accuracy: 0.921875, loss: 0.21247723698616028      \n",
      "train step #3189 accuracy: 0.953125, loss: 0.125615656375885        \n",
      "train step #3190 accuracy: 0.984375, loss: 0.056308962404727936     \n",
      "train step #3191 accuracy: 0.96875, loss: 0.13807469606399536      \n",
      "train step #3192 accuracy: 0.953125, loss: 0.18355509638786316      \n",
      "train step #3193 accuracy: 0.96875, loss: 0.19474051892757416      \n",
      "train step #3194 accuracy: 0.96875, loss: 0.1580214649438858       \n",
      "train step #3195 accuracy:   1.0, loss: 0.032369717955589294     \n",
      "train step #3196 accuracy: 0.96875, loss: 0.14999328553676605      \n",
      "train step #3197 accuracy:   1.0, loss: 0.06009729206562042      \n",
      "train step #3198 accuracy: 0.96875, loss: 0.07677634805440903      \n",
      "train step #3199 accuracy: 0.90625, loss: 0.32958412170410156      \n",
      "train step #3200 accuracy: 0.96875, loss: 0.20308266580104828      \n",
      "train step #3201 accuracy: 0.96875, loss: 0.06528669595718384      \n",
      "train step #3202 accuracy: 0.984375, loss: 0.06421644985675812      \n",
      "train step #3203 accuracy: 0.984375, loss: 0.08929220587015152      \n",
      "train step #3204 accuracy: 0.96875, loss: 0.12291701138019562      \n",
      "train step #3205 accuracy: 0.96875, loss: 0.15643222630023956      \n",
      "train step #3206 accuracy: 0.953125, loss: 0.15728390216827393      \n",
      "train step #3207 accuracy: 0.9375, loss: 0.29054853320121765      \n",
      "train step #3208 accuracy: 0.953125, loss: 0.15906362235546112      \n",
      "train step #3209 accuracy: 0.96875, loss: 0.14182749390602112      \n",
      "train step #3210 accuracy: 0.96875, loss: 0.09390844404697418      \n",
      "train step #3211 accuracy: 0.984375, loss: 0.0732133686542511       \n",
      "train step #3212 accuracy:   1.0, loss: 0.07563970237970352      \n",
      "train step #3213 accuracy: 0.953125, loss: 0.14835530519485474      \n",
      "train step #3214 accuracy: 0.984375, loss: 0.11731827259063721      \n",
      "train step #3215 accuracy: 0.921875, loss: 0.24336914718151093      \n",
      "train step #3216 accuracy: 0.90625, loss: 0.25272417068481445      \n",
      "train step #3217 accuracy: 0.96875, loss: 0.0657556802034378       \n",
      "train step #3218 accuracy: 0.984375, loss: 0.13270632922649384      \n",
      "train step #3219 accuracy: 0.96875, loss: 0.10482895374298096      \n",
      "train step #3220 accuracy: 0.96875, loss: 0.10802040249109268      \n",
      "train step #3221 accuracy: 0.9375, loss: 0.14827120304107666      \n",
      "train step #3222 accuracy: 0.953125, loss: 0.21046032011508942      \n",
      "train step #3223 accuracy: 0.984375, loss: 0.06694823503494263      \n",
      "train step #3224 accuracy: 0.984375, loss: 0.06197627633810043      \n",
      "train step #3225 accuracy: 0.984375, loss: 0.10933702439069748      \n",
      "train step #3226 accuracy: 0.9375, loss: 0.1891082376241684       \n",
      "train step #3227 accuracy: 0.96875, loss: 0.14099889993667603      \n",
      "train step #3228 accuracy: 0.953125, loss: 0.19707302749156952      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #3229 accuracy: 0.9375, loss: 0.2611315846443176       \n",
      "train step #3230 accuracy: 0.9375, loss: 0.2147621214389801       \n",
      "train step #3231 accuracy: 0.921875, loss: 0.3051956593990326       \n",
      "train step #3232 accuracy: 0.953125, loss: 0.19230154156684875      \n",
      "train step #3233 accuracy: 0.984375, loss: 0.10807580500841141      \n",
      "train step #3234 accuracy: 0.9375, loss: 0.20683294534683228      \n",
      "train step #3235 accuracy: 0.96875, loss: 0.08761800080537796      \n",
      "train step #3236 accuracy: 0.953125, loss: 0.2000138908624649       \n",
      "train step #3237 accuracy: 0.9375, loss: 0.19695596396923065      \n",
      "train step #3238 accuracy: 0.96875, loss: 0.06945127248764038      \n",
      "train step #3239 accuracy: 0.9375, loss: 0.2193683534860611       \n",
      "train step #3240 accuracy: 0.953125, loss: 0.14929339289665222      \n",
      "train step #3241 accuracy: 0.984375, loss: 0.03853510692715645      \n",
      "train step #3242 accuracy: 0.953125, loss: 0.3053176999092102       \n",
      "train step #3243 accuracy: 0.90625, loss: 0.2724103331565857       \n",
      "train step #3244 accuracy: 0.984375, loss: 0.04131809249520302      \n",
      "train step #3245 accuracy: 0.96875, loss: 0.0987405776977539       \n",
      "train step #3246 accuracy:   1.0, loss: 0.04767832159996033      \n",
      "train step #3247 accuracy: 0.96875, loss: 0.07942085713148117      \n",
      "train step #3248 accuracy: 0.984375, loss: 0.08917518705129623      \n",
      "train step #3249 accuracy:   1.0, loss: 0.050077568739652634     \n",
      "train step #3250 accuracy: 0.953125, loss: 0.1328551471233368       \n",
      "train step #3251 accuracy: 0.96875, loss: 0.12863676249980927      \n",
      "train step #3252 accuracy: 0.953125, loss: 0.20705191791057587      \n",
      "train step #3253 accuracy:   1.0, loss: 0.04748879373073578      \n",
      "train step #3254 accuracy: 0.953125, loss: 0.1962786763906479       \n",
      "train step #3255 accuracy: 0.953125, loss: 0.14860963821411133      \n",
      "train step #3256 accuracy: 0.953125, loss: 0.1683700680732727       \n",
      "train step #3257 accuracy: 0.96875, loss: 0.19110487401485443      \n",
      "train step #3258 accuracy: 0.984375, loss: 0.07956350594758987      \n",
      "train step #3259 accuracy: 0.984375, loss: 0.08179734647274017      \n",
      "train step #3260 accuracy: 0.90625, loss: 0.2621369957923889       \n",
      "train step #3261 accuracy: 0.953125, loss: 0.19390571117401123      \n",
      "train step #3262 accuracy: 0.953125, loss: 0.16082432866096497      \n",
      "train step #3263 accuracy: 0.953125, loss: 0.23057328164577484      \n",
      "train step #3264 accuracy: 0.953125, loss: 0.17768914997577667      \n",
      "train step #3265 accuracy: 0.890625, loss: 0.5011743903160095       \n",
      "train step #3266 accuracy: 0.953125, loss: 0.27772533893585205      \n",
      "train step #3267 accuracy: 0.890625, loss: 0.37449216842651367      \n",
      "train step #3268 accuracy:   1.0, loss: 0.04506291076540947      \n",
      "train step #3269 accuracy: 0.96875, loss: 0.20161928236484528      \n",
      "train step #3270 accuracy: 0.921875, loss: 0.2678834795951843       \n",
      "train step #3271 accuracy: 0.96875, loss: 0.197978213429451        \n",
      "train step #3272 accuracy: 0.953125, loss: 0.19032344222068787      \n",
      "train step #3273 accuracy: 0.96875, loss: 0.1216968521475792       \n",
      "train step #3274 accuracy: 0.984375, loss: 0.14258256554603577      \n",
      "train step #3275 accuracy: 0.953125, loss: 0.16212749481201172      \n",
      "train step #3276 accuracy: 0.921875, loss: 0.31608450412750244      \n",
      "train step #3277 accuracy: 0.9375, loss: 0.1722341924905777       \n",
      "train step #3278 accuracy: 0.9375, loss: 0.17150186002254486      \n",
      "train step #3279 accuracy: 0.953125, loss: 0.14604929089546204      \n",
      "train step #3280 accuracy: 0.96875, loss: 0.1671411395072937       \n",
      "train step #3281 accuracy: 0.984375, loss: 0.08052770793437958      \n",
      "train step #3282 accuracy: 0.9375, loss: 0.24293199181556702      \n",
      "train step #3283 accuracy: 0.96875, loss: 0.14318238198757172      \n",
      "train step #3284 accuracy: 0.953125, loss: 0.141221284866333        \n",
      "train step #3285 accuracy: 0.984375, loss: 0.0677754282951355       \n",
      "train step #3286 accuracy: 0.96875, loss: 0.14568030834197998      \n",
      "train step #3287 accuracy: 0.9375, loss: 0.22243112325668335      \n",
      "train step #3288 accuracy: 0.921875, loss: 0.2822098731994629       \n",
      "train step #3289 accuracy: 0.96875, loss: 0.09581497311592102      \n",
      "train step #3290 accuracy: 0.984375, loss: 0.04066779464483261      \n",
      "train step #3291 accuracy: 0.953125, loss: 0.13614360988140106      \n",
      "train step #3292 accuracy: 0.953125, loss: 0.13418865203857422      \n",
      "train step #3293 accuracy: 0.96875, loss: 0.18259358406066895      \n",
      "train step #3294 accuracy: 0.96875, loss: 0.1338251382112503       \n",
      "train step #3295 accuracy: 0.984375, loss: 0.11858899891376495      \n",
      "train step #3296 accuracy: 0.984375, loss: 0.1069008857011795       \n",
      "train step #3297 accuracy: 0.953125, loss: 0.19488731026649475      \n",
      "train step #3298 accuracy: 0.953125, loss: 0.07273056358098984      \n",
      "train step #3299 accuracy: 0.96875, loss: 0.10130439698696136      \n",
      "train step #3300 accuracy: 0.9375, loss: 0.22175928950309753      \n",
      "train step #3301 accuracy: 0.875, loss: 0.3817432224750519       \n",
      "train step #3302 accuracy: 0.984375, loss: 0.12831059098243713      \n",
      "train step #3303 accuracy: 0.984375, loss: 0.12570063769817352      \n",
      "train step #3304 accuracy: 0.96875, loss: 0.15380920469760895      \n",
      "train step #3305 accuracy: 0.984375, loss: 0.09333667904138565      \n",
      "train step #3306 accuracy: 0.96875, loss: 0.17603591084480286      \n",
      "train step #3307 accuracy: 0.984375, loss: 0.0564250722527504       \n",
      "train step #3308 accuracy: 0.953125, loss: 0.20688439905643463      \n",
      "train step #3309 accuracy: 0.984375, loss: 0.07953761518001556      \n",
      "train step #3310 accuracy: 0.953125, loss: 0.13201947510242462      \n",
      "train step #3311 accuracy: 0.96875, loss: 0.1374528855085373       \n",
      "train step #3312 accuracy: 0.953125, loss: 0.16648876667022705      \n",
      "train step #3313 accuracy: 0.953125, loss: 0.16215723752975464      \n",
      "train step #3314 accuracy:   1.0, loss: 0.05534980818629265      \n",
      "train step #3315 accuracy: 0.984375, loss: 0.08143293112516403      \n",
      "train step #3316 accuracy: 0.96875, loss: 0.10442695766687393      \n",
      "train step #3317 accuracy: 0.921875, loss: 0.3040621876716614       \n",
      "train step #3318 accuracy: 0.9375, loss: 0.28038424253463745      \n",
      "train step #3319 accuracy: 0.96875, loss: 0.16115029156208038      \n",
      "train step #3320 accuracy: 0.984375, loss: 0.07671336829662323      \n",
      "train step #3321 accuracy: 0.953125, loss: 0.19420917332172394      \n",
      "train step #3322 accuracy: 0.953125, loss: 0.14935682713985443      \n",
      "train step #3323 accuracy: 0.953125, loss: 0.22396622598171234      \n",
      "train step #3324 accuracy: 0.984375, loss: 0.03302984684705734      \n",
      "train step #3325 accuracy:   1.0, loss: 0.04939498007297516      \n",
      "train step #3326 accuracy: 0.953125, loss: 0.14592601358890533      \n",
      "train step #3327 accuracy: 0.953125, loss: 0.15832987427711487      \n",
      "train step #3328 accuracy: 0.9375, loss: 0.09216516464948654      \n",
      "train step #3329 accuracy:   1.0, loss: 0.032782621681690216     \n",
      "train step #3330 accuracy: 0.953125, loss: 0.1707489937543869       \n",
      "train step #3331 accuracy: 0.953125, loss: 0.14452871680259705      \n",
      "train step #3332 accuracy: 0.96875, loss: 0.12231738120317459      \n",
      "train step #3333 accuracy: 0.984375, loss: 0.06526077538728714      \n",
      "train step #3334 accuracy: 0.96875, loss: 0.08255938440561295      \n",
      "train step #3335 accuracy: 0.953125, loss: 0.19035837054252625      \n",
      "train step #3336 accuracy: 0.984375, loss: 0.08474020659923553      \n",
      "train step #3337 accuracy: 0.96875, loss: 0.16725456714630127      \n",
      "train step #3338 accuracy: 0.984375, loss: 0.09608085453510284      \n",
      "train step #3339 accuracy: 0.921875, loss: 0.18295960128307343      \n",
      "train step #3340 accuracy: 0.984375, loss: 0.1591636836528778       \n",
      "train step #3341 accuracy: 0.9375, loss: 0.1323821097612381       \n",
      "train step #3342 accuracy: 0.953125, loss: 0.16878463327884674      \n",
      "train step #3343 accuracy: 0.96875, loss: 0.10921615362167358      \n",
      "train step #3344 accuracy: 0.984375, loss: 0.049351006746292114     \n",
      "train step #3345 accuracy: 0.921875, loss: 0.1692240834236145       \n",
      "train step #3346 accuracy: 0.96875, loss: 0.17277930676937103      \n",
      "train step #3347 accuracy: 0.984375, loss: 0.052202194929122925     \n",
      "train step #3348 accuracy: 0.96875, loss: 0.08382809162139893      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #3349 accuracy: 0.953125, loss: 0.12404023110866547      \n",
      "train step #3350 accuracy: 0.984375, loss: 0.10310447216033936      \n",
      "train step #3351 accuracy: 0.984375, loss: 0.09925378859043121      \n",
      "train step #3352 accuracy: 0.984375, loss: 0.1308746337890625       \n",
      "train step #3353 accuracy: 0.96875, loss: 0.10744491964578629      \n",
      "train step #3354 accuracy: 0.984375, loss: 0.05514006316661835      \n",
      "train step #3355 accuracy: 0.9375, loss: 0.28121352195739746      \n",
      "train step #3356 accuracy: 0.9375, loss: 0.18207788467407227      \n",
      "train step #3357 accuracy: 0.984375, loss: 0.11426225304603577      \n",
      "train step #3358 accuracy: 0.9375, loss: 0.15169765055179596      \n",
      "train step #3359 accuracy: 0.984375, loss: 0.11361058801412582      \n",
      "train step #3360 accuracy: 0.953125, loss: 0.1866425722837448       \n",
      "train step #3361 accuracy: 0.953125, loss: 0.1803579330444336       \n",
      "train step #3362 accuracy: 0.953125, loss: 0.13198243081569672      \n",
      "train step #3363 accuracy:   1.0, loss: 0.027670584619045258     \n",
      "train step #3364 accuracy:   1.0, loss: 0.06432533264160156      \n",
      "train step #3365 accuracy: 0.96875, loss: 0.169586181640625        \n",
      "train step #3366 accuracy: 0.984375, loss: 0.1192919909954071       \n",
      "train step #3367 accuracy: 0.9375, loss: 0.23364287614822388      \n",
      "train step #3368 accuracy: 0.96875, loss: 0.09882941097021103      \n",
      "train step #3369 accuracy: 0.96875, loss: 0.0811915174126625       \n",
      "train step #3370 accuracy: 0.953125, loss: 0.15935951471328735      \n",
      "train step #3371 accuracy: 0.953125, loss: 0.2213849127292633       \n",
      "train step #3372 accuracy: 0.96875, loss: 0.20488183200359344      \n",
      "train step #3373 accuracy:   1.0, loss: 0.0639055147767067       \n",
      "train step #3374 accuracy: 0.9375, loss: 0.19412316381931305      \n",
      "train step #3375 accuracy: 0.953125, loss: 0.22287099063396454      \n",
      "train step #3376 accuracy: 0.984375, loss: 0.048935383558273315     \n",
      "train step #3377 accuracy: 0.984375, loss: 0.09474997222423553      \n",
      "train step #3378 accuracy: 0.90625, loss: 0.30943888425827026      \n",
      "train step #3379 accuracy: 0.984375, loss: 0.07105594128370285      \n",
      "train step #3380 accuracy: 0.96875, loss: 0.21895605325698853      \n",
      "train step #3381 accuracy: 0.9375, loss: 0.17516307532787323      \n",
      "train step #3382 accuracy: 0.96875, loss: 0.1850963830947876       \n",
      "train step #3383 accuracy: 0.9375, loss: 0.22299614548683167      \n",
      "train step #3384 accuracy: 0.9375, loss: 0.2929098606109619       \n",
      "train step #3385 accuracy: 0.890625, loss: 0.4277843236923218       \n",
      "train step #3386 accuracy:   1.0, loss: 0.03357984125614166      \n",
      "train step #3387 accuracy: 0.921875, loss: 0.2517342269420624       \n",
      "train step #3388 accuracy: 0.859375, loss: 0.4270368814468384       \n",
      "train step #3389 accuracy: 0.984375, loss: 0.06560799479484558      \n",
      "train step #3390 accuracy: 0.921875, loss: 0.15763410925865173      \n",
      "train step #3391 accuracy: 0.984375, loss: 0.058411676436662674     \n",
      "train step #3392 accuracy: 0.984375, loss: 0.12083964049816132      \n",
      "train step #3393 accuracy:   1.0, loss: 0.048255108296871185     \n",
      "train step #3394 accuracy: 0.9375, loss: 0.22734437882900238      \n",
      "train step #3395 accuracy: 0.9375, loss: 0.2141021341085434       \n",
      "train step #3396 accuracy:   1.0, loss: 0.0857795849442482       \n",
      "train step #3397 accuracy: 0.984375, loss: 0.04823371022939682      \n",
      "train step #3398 accuracy: 0.96875, loss: 0.16307424008846283      \n",
      "train step #3399 accuracy: 0.984375, loss: 0.045877985656261444     \n",
      "train step #3400 accuracy: 0.9375, loss: 0.20325708389282227      \n",
      "train step #3401 accuracy: 0.921875, loss: 0.21214532852172852      \n",
      "train step #3402 accuracy: 0.96875, loss: 0.14744611084461212      \n",
      "train step #3403 accuracy:   1.0, loss: 0.04814060404896736      \n",
      "train step #3404 accuracy: 0.953125, loss: 0.1589679718017578       \n",
      "train step #3405 accuracy: 0.96875, loss: 0.12646609544754028      \n",
      "train step #3406 accuracy: 0.96875, loss: 0.09489946067333221      \n",
      "train step #3407 accuracy: 0.96875, loss: 0.2447715699672699       \n",
      "train step #3408 accuracy: 0.96875, loss: 0.07495243102312088      \n",
      "train step #3409 accuracy:   1.0, loss: 0.03469778597354889      \n",
      "train step #3410 accuracy: 0.984375, loss: 0.10783078521490097      \n",
      "train step #3411 accuracy: 0.90625, loss: 0.29407480359077454      \n",
      "train step #3412 accuracy: 0.953125, loss: 0.16666942834854126      \n",
      "train step #3413 accuracy:   1.0, loss: 0.07500233501195908      \n",
      "train step #3414 accuracy: 0.96875, loss: 0.1416526436805725       \n",
      "train step #3415 accuracy: 0.953125, loss: 0.16003145277500153      \n",
      "train step #3416 accuracy: 0.9375, loss: 0.1503850519657135       \n",
      "train step #3417 accuracy: 0.984375, loss: 0.04277966916561127      \n",
      "train step #3418 accuracy: 0.96875, loss: 0.17130953073501587      \n",
      "train step #3419 accuracy: 0.921875, loss: 0.1264321357011795       \n",
      "train step #3420 accuracy: 0.953125, loss: 0.16246569156646729      \n",
      "train step #3421 accuracy: 0.96875, loss: 0.13430334627628326      \n",
      "train step #3422 accuracy:   1.0, loss: 0.041529104113578796     \n",
      "train step #3423 accuracy: 0.953125, loss: 0.19803522527217865      \n",
      "train step #3424 accuracy: 0.984375, loss: 0.10251730680465698      \n",
      "train step #3425 accuracy: 0.921875, loss: 0.22229218482971191      \n",
      "train step #3426 accuracy:   1.0, loss: 0.022432584315538406     \n",
      "train step #3427 accuracy: 0.984375, loss: 0.06394587457180023      \n",
      "train step #3428 accuracy: 0.953125, loss: 0.14844171702861786      \n",
      "train step #3429 accuracy: 0.96875, loss: 0.0847836509346962       \n",
      "train step #3430 accuracy: 0.984375, loss: 0.04422128200531006      \n",
      "train step #3431 accuracy: 0.984375, loss: 0.08583632856607437      \n",
      "train step #3432 accuracy: 0.921875, loss: 0.23011183738708496      \n",
      "train step #3433 accuracy: 0.953125, loss: 0.10036759078502655      \n",
      "train step #3434 accuracy: 0.921875, loss: 0.18523840606212616      \n",
      "train step #3435 accuracy: 0.96875, loss: 0.13827839493751526      \n",
      "train step #3436 accuracy: 0.9375, loss: 0.3304707109928131       \n",
      "train step #3437 accuracy: 0.953125, loss: 0.13983777165412903      \n",
      "train step #3438 accuracy: 0.953125, loss: 0.19426856935024261      \n",
      "train step #3439 accuracy: 0.984375, loss: 0.07478968799114227      \n",
      "train step #3440 accuracy: 0.9375, loss: 0.16970273852348328      \n",
      "train step #3441 accuracy: 0.90625, loss: 0.21764697134494781      \n",
      "train step #3442 accuracy: 0.984375, loss: 0.056848764419555664     \n",
      "train step #3443 accuracy:   1.0, loss: 0.032992325723171234     \n",
      "train step #3444 accuracy: 0.96875, loss: 0.0869242250919342       \n",
      "train step #3445 accuracy: 0.96875, loss: 0.14653676748275757      \n",
      "train step #3446 accuracy: 0.9375, loss: 0.23505795001983643      \n",
      "train step #3447 accuracy: 0.9375, loss: 0.16345436871051788      \n",
      "train step #3448 accuracy: 0.96875, loss: 0.08269070088863373      \n",
      "train step #3449 accuracy: 0.90625, loss: 0.3603641986846924       \n",
      "train step #3450 accuracy: 0.96875, loss: 0.156281977891922        \n",
      "train step #3451 accuracy: 0.984375, loss: 0.05427557975053787      \n",
      "train step #3452 accuracy: 0.9375, loss: 0.21511045098304749      \n",
      "train step #3453 accuracy: 0.890625, loss: 0.3205319046974182       \n",
      "train step #3454 accuracy: 0.96875, loss: 0.19355016946792603      \n",
      "train step #3455 accuracy: 0.953125, loss: 0.13553473353385925      \n",
      "train step #3456 accuracy:   1.0, loss: 0.03740622103214264      \n",
      "train step #3457 accuracy: 0.984375, loss: 0.10945885628461838      \n",
      "train step #3458 accuracy: 0.953125, loss: 0.11732549220323563      \n",
      "train step #3459 accuracy: 0.9375, loss: 0.1789618283510208       \n",
      "train step #3460 accuracy:   1.0, loss: 0.05343179404735565      \n",
      "train step #3461 accuracy: 0.984375, loss: 0.09361519664525986      \n",
      "train step #3462 accuracy: 0.96875, loss: 0.1400144398212433       \n",
      "train step #3463 accuracy: 0.953125, loss: 0.12083408981561661      \n",
      "train step #3464 accuracy: 0.953125, loss: 0.18049824237823486      \n",
      "train step #3465 accuracy: 0.90625, loss: 0.33190304040908813      \n",
      "train step #3466 accuracy: 0.96875, loss: 0.12667091190814972      \n",
      "train step #3467 accuracy: 0.9375, loss: 0.12379452586174011      \n",
      "train step #3468 accuracy: 0.984375, loss: 0.09553398191928864      \n",
      "train step #3469 accuracy: 0.953125, loss: 0.18218499422073364      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #3470 accuracy: 0.96875, loss: 0.1583373099565506       \n",
      "dev accuracy: 0.9375, loss: 0.46238839626312256      \n",
      "dev accuracy: 0.9375, loss: 0.08516120910644531      \n",
      "dev accuracy: 0.9375, loss: 0.07840868830680847      \n",
      "dev accuracy:   1.0, loss: 0.0735611766576767       \n",
      "dev accuracy: 0.8125, loss: 0.6548024415969849       \n",
      "dev accuracy: 0.9375, loss: 0.37341657280921936      \n",
      "dev accuracy: 0.8125, loss: 0.3123745620250702       \n",
      "dev accuracy:   1.0, loss: 0.026959240436553955     \n",
      "dev accuracy:   1.0, loss: 0.0038364529609680176    \n",
      "dev accuracy:   1.0, loss: 0.02418971061706543      \n",
      "dev accuracy: 0.9375, loss: 0.10565352439880371      \n",
      "dev accuracy:   1.0, loss: 0.0006976723670959473    \n",
      "dev accuracy:   1.0, loss: 0.0069983601570129395    \n",
      "dev accuracy:   1.0, loss: 0.023881077766418457     \n",
      "dev accuracy:   1.0, loss: 0.011651933193206787     \n",
      "dev accuracy:   1.0, loss: 0.017617106437683105     \n",
      "dev accuracy: 0.875, loss: 0.5232993364334106       \n",
      "dev accuracy:   1.0, loss: 0.037631452083587646     \n",
      "dev accuracy: 0.875, loss: 0.5304431319236755       \n",
      "dev accuracy:   1.0, loss: 0.04532712697982788      \n",
      "dev accuracy: 0.875, loss: 0.20981289446353912      \n",
      "dev accuracy: 0.9375, loss: 0.18160641193389893      \n",
      "dev accuracy: 0.9375, loss: 0.14030249416828156      \n",
      "dev accuracy:  0.75, loss: 0.6056963205337524       \n",
      "dev accuracy: 0.9375, loss: 0.2502678334712982       \n",
      "dev accuracy: 0.9375, loss: 0.06276628375053406      \n",
      "dev accuracy:   1.0, loss: 0.04466238617897034      \n",
      "dev accuracy:   1.0, loss: 0.05106636881828308      \n",
      "dev accuracy: 0.9375, loss: 0.2609252631664276       \n",
      "dev accuracy: 0.8125, loss: 0.23721943795681         \n",
      "dev accuracy:   1.0, loss: 0.04456081986427307      \n",
      "dev accuracy:   1.0, loss: 0.11058644950389862      \n",
      "dev accuracy: 0.875, loss: 0.35132238268852234      \n",
      "dev accuracy:   1.0, loss: 0.11229710280895233      \n",
      "dev accuracy:   1.0, loss: 0.006131231784820557     \n",
      "dev accuracy: 0.9375, loss: 0.16222897171974182      \n",
      "dev accuracy: 0.875, loss: 0.49506136775016785      \n",
      "dev accuracy: 0.9375, loss: 0.22938092052936554      \n",
      "dev accuracy: 0.9375, loss: 0.2916884422302246       \n",
      "dev accuracy: 0.9375, loss: 0.23070965707302094      \n",
      "dev accuracy: 0.9375, loss: 0.3372066617012024       \n",
      "dev accuracy: 0.875, loss: 0.15091753005981445      \n",
      "dev accuracy: 0.875, loss: 0.416912704706192        \n",
      "dev accuracy: 0.875, loss: 0.34364616870880127      \n",
      "dev accuracy: 0.9375, loss: 0.4566417336463928       \n",
      "dev accuracy:   1.0, loss: 0.003426790237426758     \n",
      "dev accuracy: 0.9375, loss: 0.2524375319480896       \n",
      "dev accuracy: 0.875, loss: 0.22579549252986908      \n",
      "dev accuracy:   1.0, loss: 0.06131315231323242      \n",
      "dev accuracy:   1.0, loss: 0.006579041481018066     \n",
      "dev accuracy: 0.875, loss: 0.37552979588508606      \n",
      "dev accuracy: 0.9375, loss: 0.19047044217586517      \n",
      "dev accuracy:   1.0, loss: 0.028010517358779907     \n",
      "dev accuracy: 0.9375, loss: 0.07202580571174622      \n",
      "dev accuracy: 0.9375, loss: 0.27320027351379395      \n",
      "dev accuracy: 0.9375, loss: 0.3046363890171051       \n",
      "dev accuracy: 0.9375, loss: 0.1306591033935547       \n",
      "dev accuracy:   1.0, loss: 0.020808368921279907     \n",
      "dev accuracy: 0.9375, loss: 0.09078061580657959      \n",
      "dev accuracy:   1.0, loss: 0.015226960182189941     \n",
      "dev accuracy: 0.9375, loss: 0.11550834774971008      \n",
      "dev accuracy: 0.9375, loss: 0.18824033439159393      \n",
      "dev accuracy: 0.875, loss: 0.3356558084487915       \n",
      "dev accuracy: 0.9375, loss: 0.06597825884819031      \n",
      "dev accuracy: 0.9375, loss: 0.19536615908145905      \n",
      "dev accuracy: 0.9375, loss: 0.20242799818515778      \n",
      "dev accuracy:   1.0, loss: 0.06095224618911743      \n",
      "dev accuracy: 0.9375, loss: 0.2532394230365753       \n",
      "dev accuracy: 0.875, loss: 0.8086853623390198       \n",
      "dev accuracy: 0.9375, loss: 0.08902092278003693      \n",
      "dev accuracy:   1.0, loss: 0.030947357416152954     \n",
      "dev accuracy:   1.0, loss: 0.0033306777477264404    \n",
      "dev accuracy:   1.0, loss: 0.004465013742446899     \n",
      "dev accuracy: 0.875, loss: 0.5564702153205872       \n",
      "dev accuracy: 0.8125, loss: 0.6890761852264404       \n",
      "dev accuracy:   1.0, loss: 0.045061349868774414     \n",
      "dev accuracy:   1.0, loss: 0.009517520666122437     \n",
      "dev accuracy: 0.9375, loss: 0.25997549295425415      \n",
      "dev accuracy: 0.875, loss: 0.4432874917984009       \n",
      "dev accuracy: 0.875, loss: 0.55189448595047         \n",
      "dev accuracy:   1.0, loss: 0.05557054281234741      \n",
      "dev accuracy: 0.9375, loss: 0.5395972728729248       \n",
      "dev accuracy: 0.9375, loss: 0.06781664490699768      \n",
      "dev accuracy: 0.9375, loss: 0.1445106714963913       \n",
      "dev accuracy: 0.875, loss: 0.18166595697402954      \n",
      "dev accuracy:   1.0, loss: 0.04487021267414093      \n",
      "dev accuracy: 0.9375, loss: 0.13310109078884125      \n",
      "dev accuracy:   1.0, loss: 0.016763627529144287     \n",
      "dev accuracy: 0.875, loss: 0.32159194350242615      \n",
      "dev accuracy: 0.9375, loss: 0.08615037798881531      \n",
      "dev accuracy:   1.0, loss: 0.015684902667999268     \n",
      "dev accuracy:   1.0, loss: 0.009974181652069092     \n",
      "dev accuracy: 0.9375, loss: 0.32466790080070496      \n",
      "dev accuracy: 0.9375, loss: 0.12859183549880981      \n",
      "dev accuracy:   1.0, loss: 0.017360687255859375     \n",
      "dev accuracy:   1.0, loss: 0.08750230073928833      \n",
      "dev accuracy:   1.0, loss: 0.09438872337341309      \n",
      "dev accuracy:   1.0, loss: 0.02411523461341858      \n",
      "dev accuracy:   1.0, loss: 0.005120337009429932     \n",
      "dev accuracy: 0.9375, loss: 0.09251144528388977      \n",
      "dev accuracy: 0.875, loss: 0.40195775032043457      \n",
      "dev accuracy: 0.9375, loss: 0.4094246029853821       \n",
      "dev accuracy: 0.9375, loss: 0.147353395819664        \n",
      "dev accuracy:   1.0, loss: 0.024344712495803833     \n",
      "dev accuracy:   1.0, loss: 0.02023729681968689      \n",
      "dev accuracy: 0.9375, loss: 0.12372848391532898      \n",
      "dev accuracy:   1.0, loss: 0.005251109600067139     \n",
      "dev accuracy:   1.0, loss: 0.050443634390830994     \n",
      "dev accuracy: 0.9375, loss: 0.11078496277332306      \n",
      "dev accuracy: 0.875, loss: 0.3887580931186676       \n",
      "dev accuracy:   1.0, loss: 0.02342084050178528      \n",
      "dev accuracy:   1.0, loss: 0.008415788412094116     \n",
      "dev accuracy:   1.0, loss: 0.006765872240066528     \n",
      "dev accuracy:   1.0, loss: 0.005088686943054199     \n",
      "dev accuracy:   1.0, loss: 0.02767685055732727      \n",
      "dev accuracy: 0.9375, loss: 0.09616197645664215      \n",
      "dev accuracy:   1.0, loss: 0.033114343881607056     \n",
      "dev accuracy: 0.9375, loss: 0.3102966547012329       \n",
      "dev accuracy: 0.9375, loss: 0.19261470437049866      \n",
      "dev accuracy: 0.9375, loss: 0.08378720283508301      \n",
      "dev accuracy:   1.0, loss: 0.02803817391395569      \n",
      "dev accuracy: 0.9375, loss: 0.12403623759746552      \n",
      "dev accuracy: 0.9375, loss: 0.17870120704174042      \n",
      "dev accuracy: 0.875, loss: 0.378476619720459        \n",
      "dev accuracy:   1.0, loss: 0.002483934164047241     \n",
      "dev accuracy: 0.9375, loss: 0.16639304161071777      \n",
      "dev accuracy:   1.0, loss: 0.01796737313270569      \n",
      "dev accuracy: 0.9375, loss: 0.44730713963508606      \n",
      "dev accuracy:   1.0, loss: 0.055620789527893066     \n",
      "dev accuracy:   1.0, loss: 0.031223446130752563     \n",
      "dev accuracy:   1.0, loss: 0.0077950358390808105    \n",
      "dev accuracy: 0.9375, loss: 0.11092305183410645      \n",
      "dev accuracy: 0.875, loss: 0.497946560382843        \n",
      "dev accuracy: 0.875, loss: 0.4752393960952759       \n",
      "dev accuracy: 0.875, loss: 0.6702558994293213       \n",
      "dev accuracy:   1.0, loss: 0.0036425888538360596    \n",
      "dev accuracy: 0.9375, loss: 0.2600429058074951       \n",
      "dev accuracy: 0.9375, loss: 0.09905332326889038      \n",
      "dev accuracy: 0.875, loss: 0.3269723057746887       \n",
      "dev accuracy:   1.0, loss: 0.0333477258682251       \n",
      "dev accuracy:   1.0, loss: 0.027630329132080078     \n",
      "dev accuracy: 0.875, loss: 0.28726446628570557      \n",
      "dev accuracy: 0.9375, loss: 0.1636532098054886       \n",
      "dev accuracy: 0.875, loss: 0.46016138792037964      \n",
      "dev accuracy: 0.9375, loss: 0.45423424243927         \n",
      "dev accuracy: 0.9375, loss: 0.48195913434028625      \n",
      "dev accuracy:   1.0, loss: 0.011393249034881592     \n",
      "dev accuracy: 0.9375, loss: 0.14131414890289307      \n",
      "dev accuracy:   1.0, loss: 0.012123078107833862     \n",
      "dev accuracy:   1.0, loss: 0.005414247512817383     \n",
      "dev accuracy: 0.875, loss: 0.42598140239715576      \n",
      "dev accuracy:   1.0, loss: 0.0037420988082885742    \n",
      "dev accuracy:   1.0, loss: 0.013311237096786499     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy:   1.0, loss: 0.004177898168563843     \n",
      "dev accuracy:   1.0, loss: 0.164450004696846        \n",
      "dev accuracy:   1.0, loss: 0.06502178311347961      \n",
      "dev accuracy: 0.8125, loss: 0.4591144025325775       \n",
      "dev accuracy: 0.9375, loss: 0.09545236825942993      \n",
      "dev accuracy: 0.9375, loss: 0.3923204839229584       \n",
      "dev accuracy: 0.8125, loss: 0.5025646686553955       \n",
      "dev accuracy: 0.8125, loss: 0.37625861167907715      \n",
      "dev accuracy: 0.9375, loss: 0.10927307605743408      \n",
      "dev accuracy:   1.0, loss: 0.04448208212852478      \n",
      "dev accuracy:   1.0, loss: 0.0020351409912109375    \n",
      "dev accuracy:   1.0, loss: 0.14774905145168304      \n",
      "dev accuracy: 0.9375, loss: 0.12545956671237946      \n",
      "dev accuracy:   1.0, loss: 0.007784098386764526     \n",
      "dev accuracy: 0.9375, loss: 0.19770877063274384      \n",
      "dev accuracy:   1.0, loss: 0.0435217022895813       \n",
      "dev accuracy:   1.0, loss: 0.02350333333015442      \n",
      "dev accuracy: 0.9375, loss: 0.09560823440551758      \n",
      "dev accuracy:   1.0, loss: 0.02095174789428711      \n",
      "dev accuracy:   1.0, loss: 0.011662006378173828     \n",
      "dev accuracy:   1.0, loss: 0.008367449045181274     \n",
      "dev accuracy:   1.0, loss: 0.007466703653335571     \n",
      "dev accuracy:   1.0, loss: 0.001639723777770996     \n",
      "dev accuracy:   1.0, loss: 0.0032681524753570557    \n",
      "dev accuracy:   1.0, loss: 0.01698535680770874      \n",
      "dev accuracy:   1.0, loss: 0.047644853591918945     \n",
      "dev accuracy:   1.0, loss: 0.01227480173110962      \n",
      "dev accuracy: 0.875, loss: 0.2557234466075897       \n",
      "dev accuracy: 0.8125, loss: 0.48715847730636597      \n",
      "dev accuracy: 0.9375, loss: 0.0718274712562561       \n",
      "dev accuracy:   1.0, loss: 0.017677217721939087     \n",
      "dev accuracy:   1.0, loss: 0.0014339685440063477    \n",
      "dev accuracy: 0.8125, loss: 0.4590648412704468       \n",
      "dev accuracy: 0.875, loss: 0.39471811056137085      \n",
      "dev accuracy: 0.9375, loss: 0.11258572340011597      \n",
      "dev accuracy:   1.0, loss: 0.0632413923740387       \n",
      "dev accuracy: 0.8125, loss: 0.3764357268810272       \n",
      "dev accuracy:   1.0, loss: 0.026317179203033447     \n",
      "dev accuracy: 0.9375, loss: 0.06575626134872437      \n",
      "dev accuracy:   1.0, loss: 0.0034453868865966797    \n",
      "dev accuracy:   1.0, loss: 0.0030320484656840563    \n",
      "final dev accuracy: 0.9487757731958762\n",
      "saving best model...\n",
      "train step #3471 accuracy:   1.0, loss: 0.03681366890668869      \n",
      "train step #3472 accuracy: 0.984375, loss: 0.0775415450334549       \n",
      "train step #3473 accuracy: 0.953125, loss: 0.15483899414539337      \n",
      "train step #3474 accuracy: 0.96875, loss: 0.0681169256567955       \n",
      "train step #3475 accuracy: 0.984375, loss: 0.11647959798574448      \n",
      "train step #3476 accuracy: 0.875, loss: 0.46127450466156006      \n",
      "train step #3477 accuracy: 0.984375, loss: 0.10589088499546051      \n",
      "train step #3478 accuracy: 0.984375, loss: 0.11155863851308823      \n",
      "train step #3479 accuracy: 0.953125, loss: 0.2503156363964081       \n",
      "train step #3480 accuracy: 0.96875, loss: 0.10893680155277252      \n",
      "train step #3481 accuracy: 0.984375, loss: 0.04600922763347626      \n",
      "train step #3482 accuracy: 0.984375, loss: 0.11558615416288376      \n",
      "train step #3483 accuracy: 0.953125, loss: 0.16609415411949158      \n",
      "train step #3484 accuracy: 0.953125, loss: 0.1412440687417984       \n",
      "train step #3485 accuracy: 0.953125, loss: 0.15778230130672455      \n",
      "train step #3486 accuracy: 0.984375, loss: 0.09056491404771805      \n",
      "train step #3487 accuracy: 0.984375, loss: 0.04002416878938675      \n",
      "train step #3488 accuracy: 0.953125, loss: 0.12873201072216034      \n",
      "train step #3489 accuracy:   1.0, loss: 0.0355202853679657       \n",
      "train step #3490 accuracy: 0.953125, loss: 0.207116037607193        \n",
      "train step #3491 accuracy: 0.953125, loss: 0.1367938071489334       \n",
      "train step #3492 accuracy: 0.9375, loss: 0.28350380063056946      \n",
      "train step #3493 accuracy:   1.0, loss: 0.03503623604774475      \n",
      "train step #3494 accuracy: 0.96875, loss: 0.06854567676782608      \n",
      "train step #3495 accuracy: 0.953125, loss: 0.15952284634113312      \n",
      "train step #3496 accuracy: 0.984375, loss: 0.05881313979625702      \n",
      "train step #3497 accuracy: 0.984375, loss: 0.13321232795715332      \n",
      "train step #3498 accuracy: 0.9375, loss: 0.3133451044559479       \n",
      "train step #3499 accuracy: 0.984375, loss: 0.06106684356927872      \n",
      "train step #3500 accuracy: 0.96875, loss: 0.09046576917171478      \n",
      "train step #3501 accuracy: 0.96875, loss: 0.10395602136850357      \n",
      "train step #3502 accuracy: 0.984375, loss: 0.12001150846481323      \n",
      "train step #3503 accuracy: 0.9375, loss: 0.16362948715686798      \n",
      "train step #3504 accuracy: 0.9375, loss: 0.14499667286872864      \n",
      "train step #3505 accuracy: 0.953125, loss: 0.14776673913002014      \n",
      "train step #3506 accuracy:   1.0, loss: 0.047779809683561325     \n",
      "train step #3507 accuracy: 0.96875, loss: 0.12192029505968094      \n",
      "train step #3508 accuracy: 0.96875, loss: 0.1283615678548813       \n",
      "train step #3509 accuracy: 0.9375, loss: 0.2340240329504013       \n",
      "train step #3510 accuracy: 0.984375, loss: 0.0627734363079071       \n",
      "train step #3511 accuracy: 0.921875, loss: 0.16616122424602509      \n",
      "train step #3512 accuracy: 0.953125, loss: 0.13774339854717255      \n",
      "train step #3513 accuracy: 0.9375, loss: 0.23110659420490265      \n",
      "train step #3514 accuracy: 0.96875, loss: 0.1069004014134407       \n",
      "train step #3515 accuracy: 0.953125, loss: 0.12268075346946716      \n",
      "train step #3516 accuracy: 0.890625, loss: 0.28966590762138367      \n",
      "train step #3517 accuracy: 0.96875, loss: 0.12070117145776749      \n",
      "train step #3518 accuracy: 0.984375, loss: 0.04652456194162369      \n",
      "train step #3519 accuracy:   1.0, loss: 0.05441439151763916      \n",
      "train step #3520 accuracy: 0.96875, loss: 0.11288806796073914      \n",
      "train step #3521 accuracy: 0.9375, loss: 0.3045778274536133       \n",
      "train step #3522 accuracy: 0.984375, loss: 0.08689916133880615      \n",
      "train step #3523 accuracy: 0.984375, loss: 0.10092540830373764      \n",
      "train step #3524 accuracy: 0.984375, loss: 0.09410139918327332      \n",
      "train step #3525 accuracy: 0.953125, loss: 0.15703879296779633      \n",
      "train step #3526 accuracy: 0.953125, loss: 0.2178451418876648       \n",
      "train step #3527 accuracy: 0.96875, loss: 0.06246747821569443      \n",
      "train step #3528 accuracy:   1.0, loss: 0.04244668409228325      \n",
      "train step #3529 accuracy: 0.9375, loss: 0.14112336933612823      \n",
      "train step #3530 accuracy: 0.984375, loss: 0.0622897744178772       \n",
      "train step #3531 accuracy: 0.9375, loss: 0.25963908433914185      \n",
      "train step #3532 accuracy: 0.953125, loss: 0.18902920186519623      \n",
      "train step #3533 accuracy: 0.96875, loss: 0.1684640347957611       \n",
      "train step #3534 accuracy: 0.96875, loss: 0.06613916158676147      \n",
      "train step #3535 accuracy: 0.9375, loss: 0.2570383548736572       \n",
      "train step #3536 accuracy: 0.953125, loss: 0.13897457718849182      \n",
      "train step #3537 accuracy: 0.953125, loss: 0.18514753878116608      \n",
      "train step #3538 accuracy: 0.9375, loss: 0.22152641415596008      \n",
      "train step #3539 accuracy: 0.9375, loss: 0.24096587300300598      \n",
      "train step #3540 accuracy: 0.984375, loss: 0.06322183459997177      \n",
      "train step #3541 accuracy: 0.953125, loss: 0.12863080203533173      \n",
      "train step #3542 accuracy: 0.984375, loss: 0.11391610652208328      \n",
      "train step #3543 accuracy: 0.96875, loss: 0.14861489832401276      \n",
      "train step #3544 accuracy: 0.984375, loss: 0.058967169374227524     \n",
      "train step #3545 accuracy: 0.96875, loss: 0.16828183829784393      \n",
      "train step #3546 accuracy: 0.984375, loss: 0.03437540680170059      \n",
      "train step #3547 accuracy: 0.96875, loss: 0.18167150020599365      \n",
      "train step #3548 accuracy: 0.96875, loss: 0.13471004366874695      \n",
      "train step #3549 accuracy: 0.984375, loss: 0.08252869546413422      \n",
      "train step #3550 accuracy: 0.953125, loss: 0.15321418642997742      \n",
      "train step #3551 accuracy:   1.0, loss: 0.014096859842538834     \n",
      "train step #3552 accuracy: 0.984375, loss: 0.06513592600822449      \n",
      "train step #3553 accuracy:   1.0, loss: 0.049372751265764236     \n",
      "train step #3554 accuracy: 0.9375, loss: 0.23009522259235382      \n",
      "train step #3555 accuracy:   1.0, loss: 0.03405194729566574      \n",
      "train step #3556 accuracy: 0.96875, loss: 0.16742481291294098      \n",
      "train step #3557 accuracy: 0.9375, loss: 0.3041279911994934       \n",
      "train step #3558 accuracy: 0.984375, loss: 0.04156171530485153      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #3559 accuracy: 0.984375, loss: 0.08426696807146072      \n",
      "train step #3560 accuracy: 0.9375, loss: 0.1206575334072113       \n",
      "train step #3561 accuracy: 0.96875, loss: 0.21307480335235596      \n",
      "train step #3562 accuracy: 0.984375, loss: 0.039953235536813736     \n",
      "train step #3563 accuracy: 0.953125, loss: 0.1731404811143875       \n",
      "train step #3564 accuracy: 0.96875, loss: 0.14382155239582062      \n",
      "train step #3565 accuracy: 0.96875, loss: 0.0953931212425232       \n",
      "train step #3566 accuracy: 0.984375, loss: 0.058731116354465485     \n",
      "train step #3567 accuracy: 0.96875, loss: 0.10193914920091629      \n",
      "train step #3568 accuracy: 0.96875, loss: 0.1436309963464737       \n",
      "train step #3569 accuracy:   1.0, loss: 0.036507926881313324     \n",
      "train step #3570 accuracy: 0.921875, loss: 0.29696810245513916      \n",
      "train step #3571 accuracy: 0.96875, loss: 0.14635375142097473      \n",
      "train step #3572 accuracy: 0.921875, loss: 0.27320706844329834      \n",
      "train step #3573 accuracy: 0.96875, loss: 0.10133646428585052      \n",
      "train step #3574 accuracy: 0.9375, loss: 0.20291848480701447      \n",
      "train step #3575 accuracy: 0.9375, loss: 0.21675309538841248      \n",
      "train step #3576 accuracy: 0.96875, loss: 0.17653882503509521      \n",
      "train step #3577 accuracy: 0.96875, loss: 0.12604036927223206      \n",
      "train step #3578 accuracy: 0.953125, loss: 0.20387199521064758      \n",
      "train step #3579 accuracy: 0.9375, loss: 0.20900939404964447      \n",
      "train step #3580 accuracy: 0.984375, loss: 0.09104060381650925      \n",
      "train step #3581 accuracy: 0.9375, loss: 0.13411454856395721      \n",
      "train step #3582 accuracy: 0.953125, loss: 0.26154372096061707      \n",
      "train step #3583 accuracy: 0.921875, loss: 0.1700185388326645       \n",
      "train step #3584 accuracy: 0.953125, loss: 0.14389824867248535      \n",
      "train step #3585 accuracy: 0.953125, loss: 0.1599595695734024       \n",
      "train step #3586 accuracy: 0.921875, loss: 0.2175724059343338       \n",
      "train step #3587 accuracy: 0.9375, loss: 0.17735901474952698      \n",
      "train step #3588 accuracy:   1.0, loss: 0.07114394009113312      \n",
      "train step #3589 accuracy:   1.0, loss: 0.02777819335460663      \n",
      "train step #3590 accuracy: 0.953125, loss: 0.16949602961540222      \n",
      "train step #3591 accuracy: 0.953125, loss: 0.23921333253383636      \n",
      "train step #3592 accuracy: 0.953125, loss: 0.2280074506998062       \n",
      "train step #3593 accuracy: 0.96875, loss: 0.08459391444921494      \n",
      "train step #3594 accuracy: 0.984375, loss: 0.07874904572963715      \n",
      "train step #3595 accuracy:   1.0, loss: 0.05698423087596893      \n",
      "train step #3596 accuracy: 0.921875, loss: 0.23937983810901642      \n",
      "train step #3597 accuracy: 0.921875, loss: 0.21148554980754852      \n",
      "train step #3598 accuracy: 0.9375, loss: 0.13977770507335663      \n",
      "train step #3599 accuracy: 0.953125, loss: 0.10073118656873703      \n",
      "train step #3600 accuracy: 0.953125, loss: 0.19574414193630219      \n",
      "train step #3601 accuracy: 0.953125, loss: 0.11753898113965988      \n",
      "train step #3602 accuracy: 0.96875, loss: 0.1203579306602478       \n",
      "train step #3603 accuracy: 0.921875, loss: 0.20344480872154236      \n",
      "train step #3604 accuracy: 0.953125, loss: 0.15732821822166443      \n",
      "train step #3605 accuracy: 0.96875, loss: 0.17222505807876587      \n",
      "train step #3606 accuracy: 0.9375, loss: 0.1224144995212555       \n",
      "train step #3607 accuracy: 0.953125, loss: 0.11379215121269226      \n",
      "train step #3608 accuracy: 0.984375, loss: 0.07395754009485245      \n",
      "train step #3609 accuracy: 0.90625, loss: 0.2290407419204712       \n",
      "train step #3610 accuracy: 0.96875, loss: 0.12195158749818802      \n",
      "train step #3611 accuracy: 0.96875, loss: 0.0990704670548439       \n",
      "train step #3612 accuracy: 0.984375, loss: 0.07772437483072281      \n",
      "train step #3613 accuracy: 0.96875, loss: 0.13910764455795288      \n",
      "train step #3614 accuracy: 0.984375, loss: 0.10553400963544846      \n",
      "train step #3615 accuracy: 0.96875, loss: 0.10241036117076874      \n",
      "train step #3616 accuracy: 0.96875, loss: 0.1722969114780426       \n",
      "train step #3617 accuracy: 0.96875, loss: 0.1263751983642578       \n",
      "train step #3618 accuracy: 0.9375, loss: 0.21411462128162384      \n",
      "train step #3619 accuracy:   1.0, loss: 0.020656906068325043     \n",
      "train step #3620 accuracy: 0.953125, loss: 0.1220637708902359       \n",
      "train step #3621 accuracy: 0.9375, loss: 0.2796153426170349       \n",
      "train step #3622 accuracy: 0.953125, loss: 0.20027944445610046      \n",
      "train step #3623 accuracy: 0.9375, loss: 0.19151639938354492      \n",
      "train step #3624 accuracy: 0.984375, loss: 0.0832018330693245       \n",
      "train step #3625 accuracy:   1.0, loss: 0.0233028382062912       \n",
      "train step #3626 accuracy: 0.984375, loss: 0.09945011138916016      \n",
      "train step #3627 accuracy: 0.921875, loss: 0.18634185194969177      \n",
      "train step #3628 accuracy: 0.96875, loss: 0.1298396736383438       \n",
      "train step #3629 accuracy: 0.9375, loss: 0.17703236639499664      \n",
      "train step #3630 accuracy: 0.96875, loss: 0.10496123880147934      \n",
      "train step #3631 accuracy: 0.953125, loss: 0.20099975168704987      \n",
      "train step #3632 accuracy: 0.96875, loss: 0.0744294598698616       \n",
      "train step #3633 accuracy: 0.9375, loss: 0.274811714887619        \n",
      "train step #3634 accuracy: 0.90625, loss: 0.3816811442375183       \n",
      "train step #3635 accuracy: 0.953125, loss: 0.13798849284648895      \n",
      "train step #3636 accuracy: 0.96875, loss: 0.09953531622886658      \n",
      "train step #3637 accuracy:   1.0, loss: 0.020137719810009003     \n",
      "train step #3638 accuracy: 0.984375, loss: 0.12077532708644867      \n",
      "train step #3639 accuracy: 0.984375, loss: 0.10946624726057053      \n",
      "train step #3640 accuracy: 0.953125, loss: 0.24947130680084229      \n",
      "train step #3641 accuracy:   1.0, loss: 0.026612356305122375     \n",
      "train step #3642 accuracy: 0.96875, loss: 0.12977610528469086      \n",
      "train step #3643 accuracy: 0.96875, loss: 0.1417108178138733       \n",
      "train step #3644 accuracy: 0.9375, loss: 0.13818924129009247      \n",
      "train step #3645 accuracy: 0.9375, loss: 0.16096913814544678      \n",
      "train step #3646 accuracy: 0.96875, loss: 0.1427939534187317       \n",
      "train step #3647 accuracy: 0.953125, loss: 0.17302092909812927      \n",
      "train step #3648 accuracy: 0.96875, loss: 0.13835695385932922      \n",
      "train step #3649 accuracy: 0.984375, loss: 0.08613089472055435      \n",
      "train step #3650 accuracy: 0.96875, loss: 0.19876697659492493      \n",
      "train step #3651 accuracy: 0.96875, loss: 0.1415940523147583       \n",
      "train step #3652 accuracy: 0.984375, loss: 0.040052786469459534     \n",
      "train step #3653 accuracy: 0.921875, loss: 0.2483224719762802       \n",
      "train step #3654 accuracy: 0.953125, loss: 0.12492520362138748      \n",
      "train step #3655 accuracy: 0.96875, loss: 0.10455166548490524      \n",
      "train step #3656 accuracy: 0.921875, loss: 0.2765961289405823       \n",
      "train step #3657 accuracy: 0.875, loss: 0.3959732949733734       \n",
      "train step #3658 accuracy: 0.984375, loss: 0.0919167548418045       \n",
      "train step #3659 accuracy: 0.921875, loss: 0.286251425743103        \n",
      "train step #3660 accuracy: 0.953125, loss: 0.2347409427165985       \n",
      "train step #3661 accuracy: 0.96875, loss: 0.1132412925362587       \n",
      "train step #3662 accuracy:   1.0, loss: 0.06666181981563568      \n",
      "train step #3663 accuracy: 0.984375, loss: 0.07870981097221375      \n",
      "train step #3664 accuracy: 0.984375, loss: 0.13785405457019806      \n",
      "train step #3665 accuracy: 0.9375, loss: 0.2746984362602234       \n",
      "train step #3666 accuracy: 0.96875, loss: 0.10579250752925873      \n",
      "train step #3667 accuracy: 0.984375, loss: 0.07572793960571289      \n",
      "train step #3668 accuracy: 0.984375, loss: 0.0375349223613739       \n",
      "train step #3669 accuracy: 0.953125, loss: 0.2713494300842285       \n",
      "train step #3670 accuracy: 0.953125, loss: 0.1853245496749878       \n",
      "train step #3671 accuracy: 0.984375, loss: 0.06422131508588791      \n",
      "train step #3672 accuracy: 0.984375, loss: 0.06620298326015472      \n",
      "train step #3673 accuracy: 0.96875, loss: 0.10218670219182968      \n",
      "train step #3674 accuracy: 0.96875, loss: 0.10164864361286163      \n",
      "train step #3675 accuracy: 0.984375, loss: 0.06746295094490051      \n",
      "train step #3676 accuracy: 0.96875, loss: 0.15516191720962524      \n",
      "train step #3677 accuracy: 0.96875, loss: 0.13496218621730804      \n",
      "train step #3678 accuracy: 0.984375, loss: 0.09313271194696426      \n",
      "train step #3679 accuracy: 0.953125, loss: 0.20086853206157684      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #3680 accuracy: 0.96875, loss: 0.11835940927267075      \n",
      "train step #3681 accuracy: 0.96875, loss: 0.22488607466220856      \n",
      "train step #3682 accuracy: 0.984375, loss: 0.05411569029092789      \n",
      "train step #3683 accuracy: 0.96875, loss: 0.1885293871164322       \n",
      "train step #3684 accuracy: 0.953125, loss: 0.1458788365125656       \n",
      "train step #3685 accuracy: 0.875, loss: 0.2718968987464905       \n",
      "train step #3686 accuracy: 0.90625, loss: 0.3413228392601013       \n",
      "train step #3687 accuracy: 0.953125, loss: 0.13558727502822876      \n",
      "train step #3688 accuracy: 0.9375, loss: 0.1517074555158615       \n",
      "train step #3689 accuracy: 0.96875, loss: 0.12015952169895172      \n",
      "train step #3690 accuracy: 0.953125, loss: 0.13407252728939056      \n",
      "train step #3691 accuracy: 0.953125, loss: 0.23234188556671143      \n",
      "train step #3692 accuracy: 0.96875, loss: 0.13179491460323334      \n",
      "train step #3693 accuracy: 0.9375, loss: 0.18404598534107208      \n",
      "train step #3694 accuracy: 0.984375, loss: 0.08927275240421295      \n",
      "train step #3695 accuracy: 0.9375, loss: 0.16945192217826843      \n",
      "train step #3696 accuracy: 0.96875, loss: 0.16353748738765717      \n",
      "train step #3697 accuracy:   1.0, loss: 0.022989075630903244     \n",
      "train step #3698 accuracy: 0.984375, loss: 0.13843926787376404      \n",
      "train step #3699 accuracy: 0.9375, loss: 0.228048637509346        \n",
      "train step #3700 accuracy: 0.9375, loss: 0.18434423208236694      \n",
      "train step #3701 accuracy: 0.96875, loss: 0.1217668280005455       \n",
      "train step #3702 accuracy: 0.953125, loss: 0.22898638248443604      \n",
      "train step #3703 accuracy: 0.953125, loss: 0.17142130434513092      \n",
      "train step #3704 accuracy:   1.0, loss: 0.020549051463603973     \n",
      "train step #3705 accuracy:   1.0, loss: 0.06822895258665085      \n",
      "train step #3706 accuracy: 0.953125, loss: 0.14615195989608765      \n",
      "train step #3707 accuracy: 0.96875, loss: 0.13859353959560394      \n",
      "train step #3708 accuracy: 0.96875, loss: 0.11066009104251862      \n",
      "train step #3709 accuracy: 0.9375, loss: 0.13307885825634003      \n",
      "train step #3710 accuracy: 0.96875, loss: 0.05869593843817711      \n",
      "train step #3711 accuracy: 0.953125, loss: 0.1699173003435135       \n",
      "train step #3712 accuracy: 0.953125, loss: 0.17949557304382324      \n",
      "train step #3713 accuracy: 0.9375, loss: 0.2046046406030655       \n",
      "train step #3714 accuracy: 0.921875, loss: 0.3201241195201874       \n",
      "train step #3715 accuracy: 0.953125, loss: 0.19359621405601501      \n",
      "train step #3716 accuracy: 0.9375, loss: 0.26101741194725037      \n",
      "train step #3717 accuracy: 0.921875, loss: 0.25278574228286743      \n",
      "train step #3718 accuracy: 0.9375, loss: 0.21254317462444305      \n",
      "train step #3719 accuracy: 0.984375, loss: 0.07973587512969971      \n",
      "train step #3720 accuracy: 0.953125, loss: 0.1488884538412094       \n",
      "train step #3721 accuracy: 0.984375, loss: 0.0963716134428978       \n",
      "train step #3722 accuracy: 0.96875, loss: 0.1664719432592392       \n",
      "train step #3723 accuracy: 0.953125, loss: 0.14247062802314758      \n",
      "train step #3724 accuracy: 0.875, loss: 0.3356219530105591       \n",
      "train step #3725 accuracy:   1.0, loss: 0.02376587688922882      \n",
      "train step #3726 accuracy: 0.96875, loss: 0.09721650183200836      \n",
      "train step #3727 accuracy: 0.953125, loss: 0.19954869151115417      \n",
      "train step #3728 accuracy: 0.96875, loss: 0.08328928053379059      \n",
      "train step #3729 accuracy: 0.984375, loss: 0.08889670670032501      \n",
      "train step #3730 accuracy: 0.90625, loss: 0.29098641872406006      \n",
      "train step #3731 accuracy: 0.953125, loss: 0.13402464985847473      \n",
      "train step #3732 accuracy: 0.9375, loss: 0.21815592050552368      \n",
      "train step #3733 accuracy: 0.9375, loss: 0.2395476996898651       \n",
      "train step #3734 accuracy: 0.96875, loss: 0.1375310719013214       \n",
      "train step #3735 accuracy: 0.953125, loss: 0.21064801514148712      \n",
      "train step #3736 accuracy:   1.0, loss: 0.05528014525771141      \n",
      "train step #3737 accuracy: 0.953125, loss: 0.21510156989097595      \n",
      "train step #3738 accuracy: 0.96875, loss: 0.1653291881084442       \n",
      "train step #3739 accuracy: 0.953125, loss: 0.18005241453647614      \n",
      "train step #3740 accuracy: 0.984375, loss: 0.10205695033073425      \n",
      "train step #3741 accuracy: 0.890625, loss: 0.3783321976661682       \n",
      "train step #3742 accuracy: 0.9375, loss: 0.23983635008335114      \n",
      "train step #3743 accuracy: 0.953125, loss: 0.11024047434329987      \n",
      "train step #3744 accuracy: 0.96875, loss: 0.05711141228675842      \n",
      "train step #3745 accuracy: 0.9375, loss: 0.2417304515838623       \n",
      "train step #3746 accuracy: 0.96875, loss: 0.1052158772945404       \n",
      "train step #3747 accuracy: 0.984375, loss: 0.08961781114339828      \n",
      "train step #3748 accuracy: 0.90625, loss: 0.2368064671754837       \n",
      "train step #3749 accuracy:   1.0, loss: 0.043299634009599686     \n",
      "train step #3750 accuracy: 0.984375, loss: 0.07103243470191956      \n",
      "train step #3751 accuracy: 0.953125, loss: 0.19434088468551636      \n",
      "train step #3752 accuracy: 0.96875, loss: 0.1745905727148056       \n",
      "train step #3753 accuracy: 0.984375, loss: 0.06278839707374573      \n",
      "train step #3754 accuracy: 0.984375, loss: 0.07504826039075851      \n",
      "train step #3755 accuracy: 0.921875, loss: 0.17681165039539337      \n",
      "train step #3756 accuracy: 0.96875, loss: 0.14252251386642456      \n",
      "train step #3757 accuracy:   1.0, loss: 0.028096619993448257     \n",
      "train step #3758 accuracy: 0.921875, loss: 0.2391963005065918       \n",
      "train step #3759 accuracy: 0.953125, loss: 0.12691660225391388      \n",
      "train step #3760 accuracy: 0.953125, loss: 0.11920884251594543      \n",
      "train step #3761 accuracy: 0.921875, loss: 0.21495160460472107      \n",
      "train step #3762 accuracy: 0.921875, loss: 0.3495439291000366       \n",
      "train step #3763 accuracy: 0.96875, loss: 0.09444458782672882      \n",
      "train step #3764 accuracy:   1.0, loss: 0.06030021980404854      \n",
      "train step #3765 accuracy: 0.984375, loss: 0.08039293438196182      \n",
      "train step #3766 accuracy: 0.9375, loss: 0.21050536632537842      \n",
      "train step #3767 accuracy: 0.90625, loss: 0.3287680149078369       \n",
      "train step #3768 accuracy: 0.953125, loss: 0.1475468873977661       \n",
      "train step #3769 accuracy: 0.953125, loss: 0.20646192133426666      \n",
      "train step #3770 accuracy: 0.984375, loss: 0.09828434884548187      \n",
      "train step #3771 accuracy: 0.9375, loss: 0.26796406507492065      \n",
      "train step #3772 accuracy: 0.953125, loss: 0.1713820844888687       \n",
      "train step #3773 accuracy: 0.921875, loss: 0.14691728353500366      \n",
      "train step #3774 accuracy: 0.9375, loss: 0.20607861876487732      \n",
      "train step #3775 accuracy: 0.96875, loss: 0.12963217496871948      \n",
      "train step #3776 accuracy: 0.96875, loss: 0.17697392404079437      \n",
      "train step #3777 accuracy: 0.96875, loss: 0.11559522151947021      \n",
      "train step #3778 accuracy: 0.984375, loss: 0.042038656771183014     \n",
      "train step #3779 accuracy: 0.96875, loss: 0.15688808262348175      \n",
      "train step #3780 accuracy: 0.953125, loss: 0.18778882920742035      \n",
      "train step #3781 accuracy:   1.0, loss: 0.032723844051361084     \n",
      "train step #3782 accuracy: 0.953125, loss: 0.16863635182380676      \n",
      "train step #3783 accuracy: 0.921875, loss: 0.1912258416414261       \n",
      "train step #3784 accuracy: 0.953125, loss: 0.09974756091833115      \n",
      "train step #3785 accuracy: 0.90625, loss: 0.3116929233074188       \n",
      "train step #3786 accuracy: 0.9375, loss: 0.12234601378440857      \n",
      "train step #3787 accuracy: 0.9375, loss: 0.2075115293264389       \n",
      "train step #3788 accuracy: 0.96875, loss: 0.08772057294845581      \n",
      "train step #3789 accuracy: 0.953125, loss: 0.1838855743408203       \n",
      "train step #3790 accuracy: 0.953125, loss: 0.20042183995246887      \n",
      "train step #3791 accuracy: 0.9375, loss: 0.19468891620635986      \n",
      "train step #3792 accuracy:   1.0, loss: 0.034406743943691254     \n",
      "train step #3793 accuracy: 0.96875, loss: 0.17097333073616028      \n",
      "train step #3794 accuracy: 0.953125, loss: 0.18951831758022308      \n",
      "train step #3795 accuracy: 0.9375, loss: 0.18077094852924347      \n",
      "train step #3796 accuracy: 0.96875, loss: 0.1267399936914444       \n",
      "train step #3797 accuracy: 0.953125, loss: 0.1938168853521347       \n",
      "train step #3798 accuracy: 0.9375, loss: 0.24614813923835754      \n",
      "train step #3799 accuracy: 0.953125, loss: 0.1765970140695572       \n",
      "train step #3800 accuracy: 0.96875, loss: 0.07952723652124405      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #3801 accuracy: 0.984375, loss: 0.05054135620594025      \n",
      "train step #3802 accuracy:   1.0, loss: 0.03319180756807327      \n",
      "train step #3803 accuracy: 0.953125, loss: 0.1268559843301773       \n",
      "train step #3804 accuracy: 0.96875, loss: 0.06762368977069855      \n",
      "train step #3805 accuracy: 0.96875, loss: 0.11086992919445038      \n",
      "train step #3806 accuracy: 0.984375, loss: 0.10124948620796204      \n",
      "train step #3807 accuracy: 0.96875, loss: 0.17003993690013885      \n",
      "train step #3808 accuracy: 0.96875, loss: 0.08687011152505875      \n",
      "train step #3809 accuracy: 0.9375, loss: 0.2504938840866089       \n",
      "train step #3810 accuracy: 0.96875, loss: 0.09258878976106644      \n",
      "train step #3811 accuracy: 0.953125, loss: 0.1871068775653839       \n",
      "train step #3812 accuracy: 0.96875, loss: 0.15247689187526703      \n",
      "train step #3813 accuracy: 0.984375, loss: 0.08531872183084488      \n",
      "train step #3814 accuracy: 0.96875, loss: 0.15148814022541046      \n",
      "train step #3815 accuracy:   1.0, loss: 0.03091062605381012      \n",
      "train step #3816 accuracy: 0.890625, loss: 0.26420891284942627      \n",
      "train step #3817 accuracy: 0.96875, loss: 0.10068488121032715      \n",
      "dev accuracy:   1.0, loss: 0.04356983304023743      \n",
      "dev accuracy:   1.0, loss: 0.008267581462860107     \n",
      "dev accuracy:   1.0, loss: 0.009579181671142578     \n",
      "dev accuracy: 0.9375, loss: 0.17572611570358276      \n",
      "dev accuracy:   1.0, loss: 0.031332701444625854     \n",
      "dev accuracy:   1.0, loss: 0.045936912298202515     \n",
      "dev accuracy: 0.9375, loss: 0.09370675683021545      \n",
      "dev accuracy:   1.0, loss: 0.03109574317932129      \n",
      "dev accuracy:   1.0, loss: 0.01184496283531189      \n",
      "dev accuracy: 0.875, loss: 0.527459442615509        \n",
      "dev accuracy:   1.0, loss: 0.024092376232147217     \n",
      "dev accuracy: 0.9375, loss: 0.24092896282672882      \n",
      "dev accuracy:   1.0, loss: 0.050188690423965454     \n",
      "dev accuracy:   1.0, loss: 0.15044207870960236      \n",
      "dev accuracy:   1.0, loss: 0.004317790269851685     \n",
      "dev accuracy: 0.9375, loss: 0.11503994464874268      \n",
      "dev accuracy: 0.9375, loss: 0.11114814877510071      \n",
      "dev accuracy: 0.9375, loss: 0.06925569474697113      \n",
      "dev accuracy:   1.0, loss: 0.03052687644958496      \n",
      "dev accuracy:   1.0, loss: 0.037639468908309937     \n",
      "dev accuracy: 0.875, loss: 0.24438926577568054      \n",
      "dev accuracy: 0.875, loss: 0.23331379890441895      \n",
      "dev accuracy:   1.0, loss: 0.0017926692962646484    \n",
      "dev accuracy:   1.0, loss: 0.03278064727783203      \n",
      "dev accuracy: 0.9375, loss: 0.34312182664871216      \n",
      "dev accuracy: 0.9375, loss: 0.09279978275299072      \n",
      "dev accuracy: 0.9375, loss: 0.5016511678695679       \n",
      "dev accuracy:   1.0, loss: 0.027431368827819824     \n",
      "dev accuracy: 0.9375, loss: 0.11612814664840698      \n",
      "dev accuracy:   1.0, loss: 0.06059157848358154      \n",
      "dev accuracy: 0.875, loss: 0.15224668383598328      \n",
      "dev accuracy: 0.8125, loss: 0.8973564505577087       \n",
      "dev accuracy: 0.875, loss: 0.8344042301177979       \n",
      "dev accuracy:   1.0, loss: 0.007330089807510376     \n",
      "dev accuracy:   1.0, loss: 0.05469253659248352      \n",
      "dev accuracy:   1.0, loss: 0.008259326219558716     \n",
      "dev accuracy: 0.9375, loss: 0.24298200011253357      \n",
      "dev accuracy: 0.875, loss: 0.3925166428089142       \n",
      "dev accuracy: 0.9375, loss: 0.29804083704948425      \n",
      "dev accuracy: 0.875, loss: 0.4740372896194458       \n",
      "dev accuracy: 0.9375, loss: 0.12758579850196838      \n",
      "dev accuracy: 0.875, loss: 0.4025651514530182       \n",
      "dev accuracy: 0.9375, loss: 0.3209988474845886       \n",
      "dev accuracy: 0.9375, loss: 0.30990999937057495      \n",
      "dev accuracy: 0.9375, loss: 0.1929655373096466       \n",
      "dev accuracy: 0.875, loss: 0.09930551052093506      \n",
      "dev accuracy: 0.9375, loss: 0.24445760250091553      \n",
      "dev accuracy:   1.0, loss: 0.002215743064880371     \n",
      "dev accuracy: 0.9375, loss: 0.3095075786113739       \n",
      "dev accuracy: 0.9375, loss: 0.21668437123298645      \n",
      "dev accuracy: 0.9375, loss: 0.09101472795009613      \n",
      "dev accuracy:   1.0, loss: 0.03008139133453369      \n",
      "dev accuracy:   1.0, loss: 0.002268552780151367     \n",
      "dev accuracy: 0.9375, loss: 0.17353732883930206      \n",
      "dev accuracy: 0.875, loss: 0.5487075448036194       \n",
      "dev accuracy:   1.0, loss: 0.033049434423446655     \n",
      "dev accuracy:   1.0, loss: 0.014190346002578735     \n",
      "dev accuracy:   1.0, loss: 0.0022388100624084473    \n",
      "dev accuracy: 0.875, loss: 0.423990398645401        \n",
      "dev accuracy: 0.8125, loss: 0.8784768581390381       \n",
      "dev accuracy:   1.0, loss: 0.059888750314712524     \n",
      "dev accuracy:   1.0, loss: 0.013954341411590576     \n",
      "dev accuracy: 0.9375, loss: 0.16013045608997345      \n",
      "dev accuracy:   1.0, loss: 0.05035695433616638      \n",
      "dev accuracy: 0.9375, loss: 0.09200704097747803      \n",
      "dev accuracy: 0.9375, loss: 0.08541105687618256      \n",
      "dev accuracy: 0.9375, loss: 0.13604095578193665      \n",
      "dev accuracy: 0.8125, loss: 0.7035905122756958       \n",
      "dev accuracy: 0.9375, loss: 0.24172034859657288      \n",
      "dev accuracy: 0.9375, loss: 0.17984196543693542      \n",
      "dev accuracy:   1.0, loss: 0.026896566152572632     \n",
      "dev accuracy: 0.9375, loss: 0.10487934201955795      \n",
      "dev accuracy: 0.875, loss: 0.7088173627853394       \n",
      "dev accuracy: 0.9375, loss: 0.20142430067062378      \n",
      "dev accuracy:   1.0, loss: 0.10112425684928894      \n",
      "dev accuracy: 0.9375, loss: 0.17824214696884155      \n",
      "dev accuracy:   1.0, loss: 0.0013135671615600586    \n",
      "dev accuracy:   1.0, loss: 0.003808438777923584     \n",
      "dev accuracy: 0.875, loss: 0.41625967621803284      \n",
      "dev accuracy: 0.9375, loss: 0.29917147755622864      \n",
      "dev accuracy: 0.9375, loss: 0.17977242171764374      \n",
      "dev accuracy:   1.0, loss: 0.025728464126586914     \n",
      "dev accuracy:   1.0, loss: 0.010035276412963867     \n",
      "dev accuracy:   1.0, loss: 0.013589948415756226     \n",
      "dev accuracy: 0.9375, loss: 0.1142517626285553       \n",
      "dev accuracy: 0.875, loss: 0.2715936005115509       \n",
      "dev accuracy:   1.0, loss: 0.009540200233459473     \n",
      "dev accuracy:   1.0, loss: 0.0532282292842865       \n",
      "dev accuracy: 0.9375, loss: 0.07840882241725922      \n",
      "dev accuracy:  0.75, loss: 0.5531178712844849       \n",
      "dev accuracy:   1.0, loss: 0.005593150854110718     \n",
      "dev accuracy:   1.0, loss: 0.002999722957611084     \n",
      "dev accuracy:   1.0, loss: 0.003833174705505371     \n",
      "dev accuracy: 0.875, loss: 0.42403092980384827      \n",
      "dev accuracy:   1.0, loss: 0.020954489707946777     \n",
      "dev accuracy:   1.0, loss: 0.020587384700775146     \n",
      "dev accuracy:   1.0, loss: 0.017141669988632202     \n",
      "dev accuracy:   1.0, loss: 0.0044408440589904785    \n",
      "dev accuracy: 0.875, loss: 0.29864269495010376      \n",
      "dev accuracy: 0.9375, loss: 0.19910846650600433      \n",
      "dev accuracy:   1.0, loss: 0.0461277961730957       \n",
      "dev accuracy: 0.875, loss: 0.3571123480796814       \n",
      "dev accuracy:   1.0, loss: 0.03614884614944458      \n",
      "dev accuracy:   1.0, loss: 0.04346972703933716      \n",
      "dev accuracy: 0.9375, loss: 0.09148240089416504      \n",
      "dev accuracy: 0.9375, loss: 0.13955774903297424      \n",
      "dev accuracy:   1.0, loss: 0.003234386444091797     \n",
      "dev accuracy: 0.9375, loss: 0.200815349817276        \n",
      "dev accuracy: 0.9375, loss: 0.25517427921295166      \n",
      "dev accuracy: 0.9375, loss: 0.13382618129253387      \n",
      "dev accuracy:   1.0, loss: 0.02708849310874939      \n",
      "dev accuracy: 0.875, loss: 0.33275046944618225      \n",
      "dev accuracy:   1.0, loss: 0.0028914213180541992    \n",
      "dev accuracy: 0.875, loss: 0.20937152206897736      \n",
      "dev accuracy:   1.0, loss: 0.013276785612106323     \n",
      "dev accuracy:   1.0, loss: 0.010716497898101807     \n",
      "dev accuracy: 0.9375, loss: 0.08245772123336792      \n",
      "dev accuracy:   1.0, loss: 0.012307554483413696     \n",
      "dev accuracy: 0.9375, loss: 0.139478400349617        \n",
      "dev accuracy: 0.8125, loss: 0.5773320198059082       \n",
      "dev accuracy:   1.0, loss: 0.04815790057182312      \n",
      "dev accuracy: 0.9375, loss: 0.17789903283119202      \n",
      "dev accuracy:   1.0, loss: 0.03542622923851013      \n",
      "dev accuracy:   1.0, loss: 0.04062676429748535      \n",
      "dev accuracy:   1.0, loss: 0.03835403919219971      \n",
      "dev accuracy: 0.9375, loss: 0.18457801640033722      \n",
      "dev accuracy:   1.0, loss: 0.0038076043128967285    \n",
      "dev accuracy: 0.9375, loss: 0.07797673344612122      \n",
      "dev accuracy: 0.9375, loss: 0.15680363774299622      \n",
      "dev accuracy:   1.0, loss: 0.00021219253540039062   \n",
      "dev accuracy:   1.0, loss: 0.0004886984825134277    \n",
      "dev accuracy:   1.0, loss: 0.005293726921081543     \n",
      "dev accuracy:   1.0, loss: 0.02681782841682434      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy: 0.875, loss: 0.18288134038448334      \n",
      "dev accuracy:   1.0, loss: 0.06609082221984863      \n",
      "dev accuracy:   1.0, loss: 0.17860618233680725      \n",
      "dev accuracy: 0.875, loss: 0.16078117489814758      \n",
      "dev accuracy: 0.9375, loss: 0.0940917432308197       \n",
      "dev accuracy: 0.9375, loss: 0.31914740800857544      \n",
      "dev accuracy: 0.9375, loss: 0.06139940023422241      \n",
      "dev accuracy:   1.0, loss: 0.014971762895584106     \n",
      "dev accuracy: 0.9375, loss: 0.21491451561450958      \n",
      "dev accuracy: 0.9375, loss: 0.12844493985176086      \n",
      "dev accuracy: 0.9375, loss: 0.31803175806999207      \n",
      "dev accuracy:   1.0, loss: 0.006569623947143555     \n",
      "dev accuracy:   1.0, loss: 0.007019162178039551     \n",
      "dev accuracy: 0.9375, loss: 0.17475533485412598      \n",
      "dev accuracy: 0.9375, loss: 0.10012134909629822      \n",
      "dev accuracy:   1.0, loss: 0.008364617824554443     \n",
      "dev accuracy: 0.9375, loss: 0.16497746109962463      \n",
      "dev accuracy:   1.0, loss: 0.0054486095905303955    \n",
      "dev accuracy: 0.875, loss: 0.5299867391586304       \n",
      "dev accuracy: 0.875, loss: 0.3857478201389313       \n",
      "dev accuracy: 0.9375, loss: 0.19499889016151428      \n",
      "dev accuracy: 0.8125, loss: 0.5520347356796265       \n",
      "dev accuracy: 0.9375, loss: 0.42214152216911316      \n",
      "dev accuracy: 0.875, loss: 0.3258558213710785       \n",
      "dev accuracy: 0.9375, loss: 0.1115497350692749       \n",
      "dev accuracy: 0.9375, loss: 0.35828697681427         \n",
      "dev accuracy: 0.9375, loss: 0.2128768414258957       \n",
      "dev accuracy: 0.875, loss: 0.25762850046157837      \n",
      "dev accuracy: 0.9375, loss: 0.30167147517204285      \n",
      "dev accuracy:   1.0, loss: 0.028640031814575195     \n",
      "dev accuracy:   1.0, loss: 0.007244527339935303     \n",
      "dev accuracy:   1.0, loss: 0.09978719800710678      \n",
      "dev accuracy: 0.9375, loss: 0.15877053141593933      \n",
      "dev accuracy: 0.9375, loss: 0.3147534728050232       \n",
      "dev accuracy:   1.0, loss: 0.03881999850273132      \n",
      "dev accuracy: 0.9375, loss: 0.38076746463775635      \n",
      "dev accuracy: 0.9375, loss: 0.12335038185119629      \n",
      "dev accuracy:   1.0, loss: 0.08224725723266602      \n",
      "dev accuracy: 0.9375, loss: 0.41193687915802         \n",
      "dev accuracy:   1.0, loss: 0.038937270641326904     \n",
      "dev accuracy:  0.75, loss: 0.373760849237442        \n",
      "dev accuracy:   1.0, loss: 0.0512884259223938       \n",
      "dev accuracy: 0.875, loss: 0.5090354084968567       \n",
      "dev accuracy: 0.9375, loss: 0.41306957602500916      \n",
      "dev accuracy: 0.9375, loss: 0.25658679008483887      \n",
      "dev accuracy:   1.0, loss: 0.01824486255645752      \n",
      "dev accuracy: 0.9375, loss: 0.10722991824150085      \n",
      "dev accuracy: 0.9375, loss: 0.276231586933136        \n",
      "dev accuracy:   1.0, loss: 0.05582204461097717      \n",
      "dev accuracy: 0.9375, loss: 0.4653424322605133       \n",
      "dev accuracy:   1.0, loss: 0.11081111431121826      \n",
      "dev accuracy: 0.9375, loss: 0.13329121470451355      \n",
      "dev accuracy: 0.9375, loss: 0.2972925901412964       \n",
      "dev accuracy:   1.0, loss: 0.030586183071136475     \n",
      "dev accuracy: 0.9375, loss: 0.12358388304710388      \n",
      "dev accuracy:   1.0, loss: 0.0056687891483306885    \n",
      "dev accuracy: 0.9375, loss: 0.13303571939468384      \n",
      "dev accuracy:   1.0, loss: 0.011012494564056396     \n",
      "dev accuracy: 0.8125, loss: 0.4499633014202118       \n",
      "dev accuracy:   1.0, loss: 0.0061127543449401855    \n",
      "dev accuracy:   1.0, loss: 0.0020335514564067125    \n",
      "final dev accuracy: 0.9507087628865979\n",
      "saving best model...\n",
      "train step #3818 accuracy: 0.953125, loss: 0.17659921944141388      \n",
      "train step #3819 accuracy: 0.953125, loss: 0.15260712802410126      \n",
      "train step #3820 accuracy: 0.890625, loss: 0.40759214758872986      \n",
      "train step #3821 accuracy: 0.9375, loss: 0.233902707695961        \n",
      "train step #3822 accuracy: 0.9375, loss: 0.2884220480918884       \n",
      "train step #3823 accuracy: 0.953125, loss: 0.1351252794265747       \n",
      "train step #3824 accuracy: 0.984375, loss: 0.045352645218372345     \n",
      "train step #3825 accuracy: 0.890625, loss: 0.35106486082077026      \n",
      "train step #3826 accuracy: 0.9375, loss: 0.19778594374656677      \n",
      "train step #3827 accuracy: 0.96875, loss: 0.19522742927074432      \n",
      "train step #3828 accuracy: 0.984375, loss: 0.10409911721944809      \n",
      "train step #3829 accuracy: 0.953125, loss: 0.10688716918230057      \n",
      "train step #3830 accuracy: 0.953125, loss: 0.10382568091154099      \n",
      "train step #3831 accuracy: 0.96875, loss: 0.12890133261680603      \n",
      "train step #3832 accuracy: 0.96875, loss: 0.14906316995620728      \n",
      "train step #3833 accuracy: 0.953125, loss: 0.2290322184562683       \n",
      "train step #3834 accuracy: 0.984375, loss: 0.03784988820552826      \n",
      "train step #3835 accuracy: 0.984375, loss: 0.12590445578098297      \n",
      "train step #3836 accuracy: 0.953125, loss: 0.19113175570964813      \n",
      "train step #3837 accuracy: 0.953125, loss: 0.18855790793895721      \n",
      "train step #3838 accuracy: 0.984375, loss: 0.09284038096666336      \n",
      "train step #3839 accuracy: 0.953125, loss: 0.14654570817947388      \n",
      "train step #3840 accuracy: 0.984375, loss: 0.08517608046531677      \n",
      "train step #3841 accuracy: 0.984375, loss: 0.08729589730501175      \n",
      "train step #3842 accuracy:   1.0, loss: 0.038976430892944336     \n",
      "train step #3843 accuracy: 0.96875, loss: 0.09120718389749527      \n",
      "train step #3844 accuracy: 0.9375, loss: 0.17760483920574188      \n",
      "train step #3845 accuracy: 0.953125, loss: 0.1454032063484192       \n",
      "train step #3846 accuracy: 0.96875, loss: 0.1474415808916092       \n",
      "train step #3847 accuracy: 0.96875, loss: 0.11995909363031387      \n",
      "train step #3848 accuracy: 0.953125, loss: 0.10222873091697693      \n",
      "train step #3849 accuracy: 0.953125, loss: 0.16919758915901184      \n",
      "train step #3850 accuracy: 0.9375, loss: 0.17086130380630493      \n",
      "train step #3851 accuracy: 0.953125, loss: 0.164167582988739        \n",
      "train step #3852 accuracy: 0.921875, loss: 0.2977782189846039       \n",
      "train step #3853 accuracy: 0.921875, loss: 0.17423324286937714      \n",
      "train step #3854 accuracy:   1.0, loss: 0.03530801832675934      \n",
      "train step #3855 accuracy:   1.0, loss: 0.03368233144283295      \n",
      "train step #3856 accuracy: 0.96875, loss: 0.0969756469130516       \n",
      "train step #3857 accuracy:   1.0, loss: 0.07746578007936478      \n",
      "train step #3858 accuracy: 0.953125, loss: 0.18314556777477264      \n",
      "train step #3859 accuracy: 0.953125, loss: 0.0886152908205986       \n",
      "train step #3860 accuracy: 0.96875, loss: 0.14116857945919037      \n",
      "train step #3861 accuracy: 0.96875, loss: 0.1408647745847702       \n",
      "train step #3862 accuracy: 0.953125, loss: 0.1633060872554779       \n",
      "train step #3863 accuracy: 0.96875, loss: 0.09955455362796783      \n",
      "train step #3864 accuracy: 0.984375, loss: 0.10112519562244415      \n",
      "train step #3865 accuracy: 0.9375, loss: 0.16227272152900696      \n",
      "train step #3866 accuracy: 0.921875, loss: 0.3039480447769165       \n",
      "train step #3867 accuracy: 0.953125, loss: 0.1875169277191162       \n",
      "train step #3868 accuracy: 0.984375, loss: 0.05271587520837784      \n",
      "train step #3869 accuracy: 0.953125, loss: 0.09579096734523773      \n",
      "train step #3870 accuracy: 0.984375, loss: 0.130781888961792        \n",
      "train step #3871 accuracy: 0.953125, loss: 0.16499336063861847      \n",
      "train step #3872 accuracy:   1.0, loss: 0.05311001092195511      \n",
      "train step #3873 accuracy: 0.96875, loss: 0.1267140805721283       \n",
      "train step #3874 accuracy: 0.984375, loss: 0.10890589654445648      \n",
      "train step #3875 accuracy: 0.984375, loss: 0.06669865548610687      \n",
      "train step #3876 accuracy: 0.96875, loss: 0.09727456420660019      \n",
      "train step #3877 accuracy: 0.984375, loss: 0.04210004210472107      \n",
      "train step #3878 accuracy: 0.984375, loss: 0.05049685016274452      \n",
      "train step #3879 accuracy: 0.9375, loss: 0.16417311131954193      \n",
      "train step #3880 accuracy: 0.921875, loss: 0.21511904895305634      \n",
      "train step #3881 accuracy: 0.984375, loss: 0.08329946547746658      \n",
      "train step #3882 accuracy: 0.9375, loss: 0.19659200310707092      \n",
      "train step #3883 accuracy: 0.96875, loss: 0.10231263190507889      \n",
      "train step #3884 accuracy: 0.984375, loss: 0.10427618771791458      \n",
      "train step #3885 accuracy: 0.953125, loss: 0.17053887248039246      \n",
      "train step #3886 accuracy: 0.96875, loss: 0.16891714930534363      \n",
      "train step #3887 accuracy: 0.984375, loss: 0.0686391294002533       \n",
      "train step #3888 accuracy: 0.96875, loss: 0.1123436912894249       \n",
      "train step #3889 accuracy: 0.90625, loss: 0.252370685338974        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #3890 accuracy: 0.9375, loss: 0.23084388673305511      \n",
      "train step #3891 accuracy: 0.953125, loss: 0.2129623293876648       \n",
      "train step #3892 accuracy: 0.984375, loss: 0.10155680775642395      \n",
      "train step #3893 accuracy: 0.953125, loss: 0.12015719711780548      \n",
      "train step #3894 accuracy: 0.9375, loss: 0.12934455275535583      \n",
      "train step #3895 accuracy: 0.9375, loss: 0.28374606370925903      \n",
      "train step #3896 accuracy: 0.96875, loss: 0.1402401477098465       \n",
      "train step #3897 accuracy: 0.953125, loss: 0.08881061524152756      \n",
      "train step #3898 accuracy: 0.9375, loss: 0.20694144070148468      \n",
      "train step #3899 accuracy: 0.96875, loss: 0.1320151388645172       \n",
      "train step #3900 accuracy: 0.9375, loss: 0.15320779383182526      \n",
      "train step #3901 accuracy: 0.9375, loss: 0.24103385210037231      \n",
      "train step #3902 accuracy:   1.0, loss: 0.05110858008265495      \n",
      "train step #3903 accuracy: 0.953125, loss: 0.1720532774925232       \n",
      "train step #3904 accuracy: 0.96875, loss: 0.06159915030002594      \n",
      "train step #3905 accuracy: 0.96875, loss: 0.07483566552400589      \n",
      "train step #3906 accuracy: 0.96875, loss: 0.12875066697597504      \n",
      "train step #3907 accuracy: 0.96875, loss: 0.09026411175727844      \n",
      "train step #3908 accuracy: 0.953125, loss: 0.2889285683631897       \n",
      "train step #3909 accuracy:   1.0, loss: 0.029009893536567688     \n",
      "train step #3910 accuracy: 0.96875, loss: 0.15873831510543823      \n",
      "train step #3911 accuracy: 0.9375, loss: 0.18295714259147644      \n",
      "train step #3912 accuracy:   1.0, loss: 0.02717594802379608      \n",
      "train step #3913 accuracy: 0.96875, loss: 0.13772571086883545      \n",
      "train step #3914 accuracy: 0.9375, loss: 0.16421453654766083      \n",
      "train step #3915 accuracy: 0.96875, loss: 0.0950082391500473       \n",
      "train step #3916 accuracy: 0.96875, loss: 0.1455305516719818       \n",
      "train step #3917 accuracy: 0.96875, loss: 0.19012537598609924      \n",
      "train step #3918 accuracy: 0.953125, loss: 0.2092495709657669       \n",
      "train step #3919 accuracy: 0.953125, loss: 0.18544495105743408      \n",
      "train step #3920 accuracy: 0.953125, loss: 0.18553343415260315      \n",
      "train step #3921 accuracy: 0.96875, loss: 0.12035994976758957      \n",
      "train step #3922 accuracy: 0.984375, loss: 0.07199159264564514      \n",
      "train step #3923 accuracy: 0.953125, loss: 0.1414038985967636       \n",
      "train step #3924 accuracy: 0.984375, loss: 0.0515388622879982       \n",
      "train step #3925 accuracy: 0.96875, loss: 0.21595077216625214      \n",
      "train step #3926 accuracy: 0.984375, loss: 0.09043107181787491      \n",
      "train step #3927 accuracy:   1.0, loss: 0.05173743516206741      \n",
      "train step #3928 accuracy: 0.9375, loss: 0.2414710521697998       \n",
      "train step #3929 accuracy: 0.9375, loss: 0.1619274914264679       \n",
      "train step #3930 accuracy: 0.921875, loss: 0.17471082508563995      \n",
      "train step #3931 accuracy: 0.9375, loss: 0.2577921152114868       \n",
      "train step #3932 accuracy: 0.984375, loss: 0.10098955780267715      \n",
      "train step #3933 accuracy: 0.859375, loss: 0.41150641441345215      \n",
      "train step #3934 accuracy: 0.984375, loss: 0.1223234236240387       \n",
      "train step #3935 accuracy: 0.9375, loss: 0.23910409212112427      \n",
      "train step #3936 accuracy: 0.953125, loss: 0.11740140616893768      \n",
      "train step #3937 accuracy: 0.96875, loss: 0.05667875334620476      \n",
      "train step #3938 accuracy: 0.96875, loss: 0.17802715301513672      \n",
      "train step #3939 accuracy:   1.0, loss: 0.028864774852991104     \n",
      "train step #3940 accuracy: 0.921875, loss: 0.18552908301353455      \n",
      "train step #3941 accuracy: 0.96875, loss: 0.06667460501194         \n",
      "train step #3942 accuracy: 0.984375, loss: 0.10784933716058731      \n",
      "train step #3943 accuracy: 0.96875, loss: 0.13922029733657837      \n",
      "train step #3944 accuracy: 0.96875, loss: 0.17661629617214203      \n",
      "train step #3945 accuracy: 0.9375, loss: 0.20646944642066956      \n",
      "train step #3946 accuracy: 0.984375, loss: 0.06776535511016846      \n",
      "train step #3947 accuracy: 0.984375, loss: 0.10870447009801865      \n",
      "train step #3948 accuracy: 0.953125, loss: 0.18650628626346588      \n",
      "train step #3949 accuracy: 0.984375, loss: 0.137620747089386        \n",
      "train step #3950 accuracy: 0.984375, loss: 0.037602055817842484     \n",
      "train step #3951 accuracy: 0.9375, loss: 0.11128480732440948      \n",
      "train step #3952 accuracy: 0.96875, loss: 0.07369635254144669      \n",
      "train step #3953 accuracy: 0.9375, loss: 0.18267811834812164      \n",
      "train step #3954 accuracy: 0.953125, loss: 0.12211295962333679      \n",
      "train step #3955 accuracy: 0.953125, loss: 0.2028457224369049       \n",
      "train step #3956 accuracy: 0.96875, loss: 0.18486683070659637      \n",
      "train step #3957 accuracy: 0.953125, loss: 0.1570771336555481       \n",
      "train step #3958 accuracy: 0.9375, loss: 0.22533640265464783      \n",
      "train step #3959 accuracy: 0.9375, loss: 0.19899596273899078      \n",
      "train step #3960 accuracy: 0.9375, loss: 0.18783070147037506      \n",
      "train step #3961 accuracy: 0.9375, loss: 0.15012294054031372      \n",
      "train step #3962 accuracy: 0.96875, loss: 0.16827596724033356      \n",
      "train step #3963 accuracy:   1.0, loss: 0.04282476007938385      \n",
      "train step #3964 accuracy: 0.96875, loss: 0.10039319097995758      \n",
      "train step #3965 accuracy: 0.9375, loss: 0.194366455078125        \n",
      "train step #3966 accuracy: 0.96875, loss: 0.16436409950256348      \n",
      "train step #3967 accuracy: 0.96875, loss: 0.1856946498155594       \n",
      "train step #3968 accuracy: 0.953125, loss: 0.20275121927261353      \n",
      "train step #3969 accuracy: 0.96875, loss: 0.1549709141254425       \n",
      "train step #3970 accuracy: 0.96875, loss: 0.09209082275629044      \n",
      "train step #3971 accuracy: 0.953125, loss: 0.1785297393798828       \n",
      "train step #3972 accuracy: 0.984375, loss: 0.04248661920428276      \n",
      "train step #3973 accuracy: 0.96875, loss: 0.11058095842599869      \n",
      "train step #3974 accuracy: 0.953125, loss: 0.18506944179534912      \n",
      "train step #3975 accuracy: 0.96875, loss: 0.12972784042358398      \n",
      "train step #3976 accuracy: 0.953125, loss: 0.1586819887161255       \n",
      "train step #3977 accuracy: 0.984375, loss: 0.10843996703624725      \n",
      "train step #3978 accuracy: 0.9375, loss: 0.12346650660037994      \n",
      "train step #3979 accuracy: 0.96875, loss: 0.09828660637140274      \n",
      "train step #3980 accuracy: 0.9375, loss: 0.24380719661712646      \n",
      "train step #3981 accuracy: 0.96875, loss: 0.14559826254844666      \n",
      "train step #3982 accuracy:   1.0, loss: 0.0922245979309082       \n",
      "train step #3983 accuracy: 0.96875, loss: 0.12108445912599564      \n",
      "train step #3984 accuracy: 0.90625, loss: 0.2623385787010193       \n",
      "train step #3985 accuracy: 0.953125, loss: 0.19175413250923157      \n",
      "train step #3986 accuracy: 0.953125, loss: 0.12705375254154205      \n",
      "train step #3987 accuracy: 0.984375, loss: 0.1032186970114708       \n",
      "train step #3988 accuracy: 0.984375, loss: 0.12120719999074936      \n",
      "train step #3989 accuracy: 0.96875, loss: 0.1677650809288025       \n",
      "train step #3990 accuracy: 0.953125, loss: 0.25079625844955444      \n",
      "train step #3991 accuracy: 0.984375, loss: 0.08800529688596725      \n",
      "train step #3992 accuracy: 0.96875, loss: 0.16142545640468597      \n",
      "train step #3993 accuracy: 0.921875, loss: 0.21076305210590363      \n",
      "train step #3994 accuracy: 0.96875, loss: 0.18111130595207214      \n",
      "train step #3995 accuracy: 0.984375, loss: 0.07951658964157104      \n",
      "train step #3996 accuracy: 0.953125, loss: 0.10235656797885895      \n",
      "train step #3997 accuracy: 0.890625, loss: 0.40416938066482544      \n",
      "train step #3998 accuracy: 0.96875, loss: 0.18906816840171814      \n",
      "train step #3999 accuracy: 0.96875, loss: 0.20222008228302002      \n",
      "train step #4000 accuracy: 0.984375, loss: 0.04405783489346504      \n",
      "train step #4001 accuracy: 0.921875, loss: 0.2288837432861328       \n",
      "train step #4002 accuracy: 0.984375, loss: 0.09349710494279861      \n",
      "train step #4003 accuracy: 0.984375, loss: 0.0635378360748291       \n",
      "train step #4004 accuracy: 0.96875, loss: 0.09346354752779007      \n",
      "train step #4005 accuracy: 0.953125, loss: 0.21038199961185455      \n",
      "train step #4006 accuracy: 0.953125, loss: 0.15341010689735413      \n",
      "train step #4007 accuracy: 0.96875, loss: 0.10368227958679199      \n",
      "train step #4008 accuracy: 0.96875, loss: 0.14667485654354095      \n",
      "train step #4009 accuracy: 0.953125, loss: 0.13591942191123962      \n",
      "train step #4010 accuracy: 0.96875, loss: 0.15449562668800354      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #4011 accuracy:   1.0, loss: 0.016498588025569916     \n",
      "train step #4012 accuracy: 0.953125, loss: 0.10763601958751678      \n",
      "train step #4013 accuracy:   1.0, loss: 0.027046486735343933     \n",
      "train step #4014 accuracy: 0.9375, loss: 0.2575177848339081       \n",
      "train step #4015 accuracy: 0.984375, loss: 0.1356489658355713       \n",
      "train step #4016 accuracy: 0.953125, loss: 0.19052153825759888      \n",
      "train step #4017 accuracy: 0.921875, loss: 0.2625390291213989       \n",
      "train step #4018 accuracy: 0.921875, loss: 0.27755987644195557      \n",
      "train step #4019 accuracy:   1.0, loss: 0.06873574107885361      \n",
      "train step #4020 accuracy: 0.984375, loss: 0.056685470044612885     \n",
      "train step #4021 accuracy: 0.9375, loss: 0.22406920790672302      \n",
      "train step #4022 accuracy: 0.9375, loss: 0.13431400060653687      \n",
      "train step #4023 accuracy:   1.0, loss: 0.025258749723434448     \n",
      "train step #4024 accuracy: 0.96875, loss: 0.15116623044013977      \n",
      "train step #4025 accuracy: 0.984375, loss: 0.08390263468027115      \n",
      "train step #4026 accuracy: 0.953125, loss: 0.14841541647911072      \n",
      "train step #4027 accuracy: 0.96875, loss: 0.1427898406982422       \n",
      "train step #4028 accuracy:   1.0, loss: 0.028632599860429764     \n",
      "train step #4029 accuracy: 0.953125, loss: 0.20313924551010132      \n",
      "train step #4030 accuracy: 0.9375, loss: 0.2957162857055664       \n",
      "train step #4031 accuracy: 0.9375, loss: 0.11249709129333496      \n",
      "train step #4032 accuracy: 0.953125, loss: 0.21459895372390747      \n",
      "train step #4033 accuracy: 0.984375, loss: 0.06304123997688293      \n",
      "train step #4034 accuracy: 0.9375, loss: 0.27485188841819763      \n",
      "train step #4035 accuracy: 0.9375, loss: 0.20132184028625488      \n",
      "train step #4036 accuracy: 0.953125, loss: 0.15442371368408203      \n",
      "train step #4037 accuracy: 0.953125, loss: 0.13753095269203186      \n",
      "train step #4038 accuracy: 0.9375, loss: 0.11928921937942505      \n",
      "train step #4039 accuracy: 0.984375, loss: 0.042887791991233826     \n",
      "train step #4040 accuracy: 0.953125, loss: 0.15202395617961884      \n",
      "train step #4041 accuracy: 0.984375, loss: 0.04570278152823448      \n",
      "train step #4042 accuracy: 0.96875, loss: 0.14192911982536316      \n",
      "train step #4043 accuracy: 0.96875, loss: 0.12784332036972046      \n",
      "train step #4044 accuracy: 0.984375, loss: 0.04738045483827591      \n",
      "train step #4045 accuracy: 0.984375, loss: 0.07336893677711487      \n",
      "train step #4046 accuracy:   1.0, loss: 0.051926955580711365     \n",
      "train step #4047 accuracy: 0.96875, loss: 0.24228981137275696      \n",
      "train step #4048 accuracy: 0.96875, loss: 0.12714974582195282      \n",
      "train step #4049 accuracy: 0.96875, loss: 0.127305805683136        \n",
      "train step #4050 accuracy: 0.9375, loss: 0.22642701864242554      \n",
      "train step #4051 accuracy: 0.9375, loss: 0.19054391980171204      \n",
      "train step #4052 accuracy:   1.0, loss: 0.04005882516503334      \n",
      "train step #4053 accuracy:   1.0, loss: 0.032338373363018036     \n",
      "train step #4054 accuracy: 0.984375, loss: 0.07070140540599823      \n",
      "train step #4055 accuracy: 0.96875, loss: 0.19424566626548767      \n",
      "train step #4056 accuracy:   1.0, loss: 0.02830050140619278      \n",
      "train step #4057 accuracy: 0.921875, loss: 0.16562288999557495      \n",
      "train step #4058 accuracy:   1.0, loss: 0.019583869725465775     \n",
      "train step #4059 accuracy: 0.953125, loss: 0.13189566135406494      \n",
      "train step #4060 accuracy: 0.90625, loss: 0.29462534189224243      \n",
      "train step #4061 accuracy: 0.96875, loss: 0.12591888010501862      \n",
      "train step #4062 accuracy: 0.96875, loss: 0.13193169236183167      \n",
      "train step #4063 accuracy: 0.9375, loss: 0.21829207241535187      \n",
      "train step #4064 accuracy: 0.984375, loss: 0.058476924896240234     \n",
      "train step #4065 accuracy: 0.921875, loss: 0.3152618706226349       \n",
      "train step #4066 accuracy: 0.96875, loss: 0.0935581848025322       \n",
      "train step #4067 accuracy: 0.984375, loss: 0.11776189506053925      \n",
      "train step #4068 accuracy:   1.0, loss: 0.023450784385204315     \n",
      "train step #4069 accuracy: 0.96875, loss: 0.08529570698738098      \n",
      "train step #4070 accuracy: 0.9375, loss: 0.16252602636814117      \n",
      "train step #4071 accuracy: 0.875, loss: 0.30681100487709045      \n",
      "train step #4072 accuracy: 0.984375, loss: 0.06704876571893692      \n",
      "train step #4073 accuracy: 0.96875, loss: 0.1547837108373642       \n",
      "train step #4074 accuracy: 0.9375, loss: 0.2206633985042572       \n",
      "train step #4075 accuracy: 0.96875, loss: 0.11083370447158813      \n",
      "train step #4076 accuracy: 0.96875, loss: 0.15771204233169556      \n",
      "train step #4077 accuracy: 0.953125, loss: 0.2832190990447998       \n",
      "train step #4078 accuracy: 0.953125, loss: 0.21357277035713196      \n",
      "train step #4079 accuracy: 0.96875, loss: 0.18623721599578857      \n",
      "train step #4080 accuracy: 0.96875, loss: 0.15372522175312042      \n",
      "train step #4081 accuracy: 0.921875, loss: 0.24733573198318481      \n",
      "train step #4082 accuracy: 0.9375, loss: 0.2741682529449463       \n",
      "train step #4083 accuracy: 0.96875, loss: 0.16266454756259918      \n",
      "train step #4084 accuracy: 0.953125, loss: 0.19006496667861938      \n",
      "train step #4085 accuracy:   1.0, loss: 0.0707867220044136       \n",
      "train step #4086 accuracy: 0.984375, loss: 0.10445583611726761      \n",
      "train step #4087 accuracy: 0.953125, loss: 0.14593134820461273      \n",
      "train step #4088 accuracy: 0.9375, loss: 0.21334704756736755      \n",
      "train step #4089 accuracy: 0.96875, loss: 0.09853309392929077      \n",
      "train step #4090 accuracy:   1.0, loss: 0.03571389988064766      \n",
      "train step #4091 accuracy: 0.90625, loss: 0.3848994970321655       \n",
      "train step #4092 accuracy: 0.96875, loss: 0.09013380110263824      \n",
      "train step #4093 accuracy: 0.953125, loss: 0.17760956287384033      \n",
      "train step #4094 accuracy: 0.9375, loss: 0.10016372799873352      \n",
      "train step #4095 accuracy: 0.953125, loss: 0.14298921823501587      \n",
      "train step #4096 accuracy: 0.96875, loss: 0.08563031256198883      \n",
      "train step #4097 accuracy: 0.984375, loss: 0.07280609756708145      \n",
      "train step #4098 accuracy: 0.953125, loss: 0.20862075686454773      \n",
      "train step #4099 accuracy: 0.96875, loss: 0.08944988995790482      \n",
      "train step #4100 accuracy: 0.96875, loss: 0.08613242208957672      \n",
      "train step #4101 accuracy: 0.953125, loss: 0.130756676197052        \n",
      "train step #4102 accuracy: 0.984375, loss: 0.07277746498584747      \n",
      "train step #4103 accuracy: 0.984375, loss: 0.07897473126649857      \n",
      "train step #4104 accuracy:   1.0, loss: 0.05041541904211044      \n",
      "train step #4105 accuracy: 0.984375, loss: 0.07927755266427994      \n",
      "train step #4106 accuracy: 0.96875, loss: 0.16251029074192047      \n",
      "train step #4107 accuracy: 0.921875, loss: 0.3302847743034363       \n",
      "train step #4108 accuracy: 0.921875, loss: 0.22495272755622864      \n",
      "train step #4109 accuracy:   1.0, loss: 0.018746688961982727     \n",
      "train step #4110 accuracy: 0.9375, loss: 0.1848679482936859       \n",
      "train step #4111 accuracy: 0.921875, loss: 0.1599486917257309       \n",
      "train step #4112 accuracy: 0.984375, loss: 0.03204544633626938      \n",
      "train step #4113 accuracy: 0.9375, loss: 0.2060537189245224       \n",
      "train step #4114 accuracy: 0.984375, loss: 0.05279533565044403      \n",
      "train step #4115 accuracy: 0.984375, loss: 0.06779474765062332      \n",
      "train step #4116 accuracy: 0.96875, loss: 0.08301403373479843      \n",
      "train step #4117 accuracy: 0.984375, loss: 0.07661529630422592      \n",
      "train step #4118 accuracy: 0.9375, loss: 0.19344815611839294      \n",
      "train step #4119 accuracy: 0.9375, loss: 0.17769992351531982      \n",
      "train step #4120 accuracy: 0.96875, loss: 0.17024657130241394      \n",
      "train step #4121 accuracy:   1.0, loss: 0.036967575550079346     \n",
      "train step #4122 accuracy: 0.96875, loss: 0.09144987910985947      \n",
      "train step #4123 accuracy: 0.921875, loss: 0.4149150848388672       \n",
      "train step #4124 accuracy: 0.984375, loss: 0.08174155652523041      \n",
      "train step #4125 accuracy: 0.921875, loss: 0.30130553245544434      \n",
      "train step #4126 accuracy: 0.984375, loss: 0.08665421605110168      \n",
      "train step #4127 accuracy:   1.0, loss: 0.062055617570877075     \n",
      "train step #4128 accuracy: 0.953125, loss: 0.16914798319339752      \n",
      "train step #4129 accuracy: 0.984375, loss: 0.10378187149763107      \n",
      "train step #4130 accuracy: 0.953125, loss: 0.211395263671875        \n",
      "train step #4131 accuracy: 0.921875, loss: 0.28469642996788025      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #4132 accuracy: 0.96875, loss: 0.10316977649927139      \n",
      "train step #4133 accuracy: 0.953125, loss: 0.15889085829257965      \n",
      "train step #4134 accuracy:   1.0, loss: 0.03855238854885101      \n",
      "train step #4135 accuracy: 0.96875, loss: 0.1768135279417038       \n",
      "train step #4136 accuracy: 0.96875, loss: 0.1777358204126358       \n",
      "train step #4137 accuracy: 0.953125, loss: 0.12787675857543945      \n",
      "train step #4138 accuracy: 0.96875, loss: 0.16748695075511932      \n",
      "train step #4139 accuracy: 0.96875, loss: 0.13095518946647644      \n",
      "train step #4140 accuracy: 0.96875, loss: 0.12833863496780396      \n",
      "train step #4141 accuracy: 0.984375, loss: 0.0919640064239502       \n",
      "train step #4142 accuracy: 0.9375, loss: 0.3194414973258972       \n",
      "train step #4143 accuracy: 0.90625, loss: 0.39945507049560547      \n",
      "train step #4144 accuracy: 0.984375, loss: 0.09355638921260834      \n",
      "train step #4145 accuracy:   1.0, loss: 0.03234557807445526      \n",
      "train step #4146 accuracy: 0.953125, loss: 0.11269482225179672      \n",
      "train step #4147 accuracy: 0.953125, loss: 0.16638194024562836      \n",
      "train step #4148 accuracy: 0.96875, loss: 0.1566017121076584       \n",
      "train step #4149 accuracy: 0.953125, loss: 0.18934331834316254      \n",
      "train step #4150 accuracy: 0.953125, loss: 0.2395085245370865       \n",
      "train step #4151 accuracy: 0.953125, loss: 0.11411421746015549      \n",
      "train step #4152 accuracy: 0.96875, loss: 0.0875999704003334       \n",
      "train step #4153 accuracy:   1.0, loss: 0.033266112208366394     \n",
      "train step #4154 accuracy: 0.96875, loss: 0.13996195793151855      \n",
      "train step #4155 accuracy: 0.96875, loss: 0.06687451899051666      \n",
      "train step #4156 accuracy: 0.96875, loss: 0.0988679826259613       \n",
      "train step #4157 accuracy: 0.96875, loss: 0.11632512509822845      \n",
      "train step #4158 accuracy: 0.984375, loss: 0.047528475522994995     \n",
      "train step #4159 accuracy: 0.9375, loss: 0.17229267954826355      \n",
      "train step #4160 accuracy: 0.953125, loss: 0.12280390411615372      \n",
      "train step #4161 accuracy: 0.9375, loss: 0.2570631206035614       \n",
      "train step #4162 accuracy: 0.984375, loss: 0.07856802642345428      \n",
      "train step #4163 accuracy: 0.96875, loss: 0.09024696797132492      \n",
      "train step #4164 accuracy: 0.984375, loss: 0.0879848301410675       \n",
      "dev accuracy:   1.0, loss: 0.003238856792449951     \n",
      "dev accuracy:   1.0, loss: 0.002226114273071289     \n",
      "dev accuracy:   1.0, loss: 0.03123706579208374      \n",
      "dev accuracy:   1.0, loss: 0.009321898221969604     \n",
      "dev accuracy:   1.0, loss: 0.03897497057914734      \n",
      "dev accuracy:   1.0, loss: 0.00541648268699646      \n",
      "dev accuracy:   1.0, loss: 0.06725840270519257      \n",
      "dev accuracy: 0.875, loss: 0.47248905897140503      \n",
      "dev accuracy:   1.0, loss: 0.002815723419189453     \n",
      "dev accuracy: 0.875, loss: 0.8004035353660583       \n",
      "dev accuracy: 0.9375, loss: 0.09840971231460571      \n",
      "dev accuracy: 0.9375, loss: 0.08427360653877258      \n",
      "dev accuracy: 0.9375, loss: 0.4926010072231293       \n",
      "dev accuracy: 0.875, loss: 0.20978811383247375      \n",
      "dev accuracy: 0.9375, loss: 0.12210400402545929      \n",
      "dev accuracy: 0.9375, loss: 0.27352234721183777      \n",
      "dev accuracy: 0.9375, loss: 0.13703015446662903      \n",
      "dev accuracy:   1.0, loss: 0.0006462335586547852    \n",
      "dev accuracy: 0.9375, loss: 0.20399443805217743      \n",
      "dev accuracy: 0.9375, loss: 0.3500564694404602       \n",
      "dev accuracy:   1.0, loss: 0.04327625036239624      \n",
      "dev accuracy: 0.875, loss: 0.2667475938796997       \n",
      "dev accuracy: 0.9375, loss: 0.4845787584781647       \n",
      "dev accuracy:   1.0, loss: 0.08378259837627411      \n",
      "dev accuracy: 0.9375, loss: 0.2902166247367859       \n",
      "dev accuracy: 0.9375, loss: 0.15090768039226532      \n",
      "dev accuracy:  0.75, loss: 1.1783658266067505       \n",
      "dev accuracy: 0.875, loss: 0.15764759480953217      \n",
      "dev accuracy:   1.0, loss: 0.020321249961853027     \n",
      "dev accuracy:   1.0, loss: 0.02873554825782776      \n",
      "dev accuracy:   1.0, loss: 0.012147367000579834     \n",
      "dev accuracy: 0.9375, loss: 0.5891148447990417       \n",
      "dev accuracy:   1.0, loss: 0.0031439661979675293    \n",
      "dev accuracy: 0.9375, loss: 0.25165390968322754      \n",
      "dev accuracy: 0.9375, loss: 0.3125353455543518       \n",
      "dev accuracy:   1.0, loss: 0.022750288248062134     \n",
      "dev accuracy: 0.9375, loss: 0.1648690104484558       \n",
      "dev accuracy:   1.0, loss: 0.0029537081718444824    \n",
      "dev accuracy: 0.8125, loss: 0.513253927230835        \n",
      "dev accuracy: 0.875, loss: 0.2283254712820053       \n",
      "dev accuracy:   1.0, loss: 0.0050019919872283936    \n",
      "dev accuracy:   1.0, loss: 0.026371806859970093     \n",
      "dev accuracy:   1.0, loss: 0.007478147745132446     \n",
      "dev accuracy: 0.9375, loss: 0.1464044153690338       \n",
      "dev accuracy: 0.9375, loss: 0.3291531503200531       \n",
      "dev accuracy:  0.75, loss: 0.646483838558197        \n",
      "dev accuracy: 0.9375, loss: 0.28526511788368225      \n",
      "dev accuracy: 0.9375, loss: 0.25102874636650085      \n",
      "dev accuracy:   1.0, loss: 0.03932356834411621      \n",
      "dev accuracy:   1.0, loss: 0.07546757906675339      \n",
      "dev accuracy:   1.0, loss: 0.010852307081222534     \n",
      "dev accuracy: 0.875, loss: 0.6274383068084717       \n",
      "dev accuracy:   1.0, loss: 0.0013045072555541992    \n",
      "dev accuracy:   1.0, loss: 0.005396902561187744     \n",
      "dev accuracy: 0.9375, loss: 0.3609180450439453       \n",
      "dev accuracy: 0.9375, loss: 0.23367443680763245      \n",
      "dev accuracy: 0.9375, loss: 0.2521950900554657       \n",
      "dev accuracy:   1.0, loss: 0.019152045249938965     \n",
      "dev accuracy: 0.9375, loss: 0.23898211121559143      \n",
      "dev accuracy:   1.0, loss: 0.009761571884155273     \n",
      "dev accuracy:   1.0, loss: 0.03792092204093933      \n",
      "dev accuracy:   1.0, loss: 0.011336714029312134     \n",
      "dev accuracy: 0.9375, loss: 0.3193942606449127       \n",
      "dev accuracy:   1.0, loss: 0.055795758962631226     \n",
      "dev accuracy:   1.0, loss: 0.001500844955444336     \n",
      "dev accuracy:   1.0, loss: 0.06568023562431335      \n",
      "dev accuracy:   1.0, loss: 0.021396532654762268     \n",
      "dev accuracy:   1.0, loss: 0.03220069408416748      \n",
      "dev accuracy: 0.8125, loss: 0.4044906497001648       \n",
      "dev accuracy:   1.0, loss: 0.029955536127090454     \n",
      "dev accuracy:   1.0, loss: 0.039864033460617065     \n",
      "dev accuracy: 0.9375, loss: 0.33514294028282166      \n",
      "dev accuracy: 0.9375, loss: 0.3434053957462311       \n",
      "dev accuracy: 0.9375, loss: 0.09676098823547363      \n",
      "dev accuracy: 0.9375, loss: 0.40745866298675537      \n",
      "dev accuracy: 0.875, loss: 0.27435946464538574      \n",
      "dev accuracy:   1.0, loss: 0.07197985053062439      \n",
      "dev accuracy: 0.9375, loss: 0.08692215383052826      \n",
      "dev accuracy: 0.875, loss: 0.3428073823451996       \n",
      "dev accuracy: 0.9375, loss: 0.17261144518852234      \n",
      "dev accuracy:   1.0, loss: 0.013422787189483643     \n",
      "dev accuracy: 0.875, loss: 0.24067945778369904      \n",
      "dev accuracy: 0.9375, loss: 0.0901789516210556       \n",
      "dev accuracy:   1.0, loss: 0.0019327998161315918    \n",
      "dev accuracy: 0.9375, loss: 0.12831160426139832      \n",
      "dev accuracy: 0.875, loss: 0.290907621383667        \n",
      "dev accuracy:   1.0, loss: 0.001343846321105957     \n",
      "dev accuracy:   1.0, loss: 0.0899018794298172       \n",
      "dev accuracy:   1.0, loss: 0.020087242126464844     \n",
      "dev accuracy: 0.875, loss: 0.16863517463207245      \n",
      "dev accuracy:   1.0, loss: 0.0134352445602417       \n",
      "dev accuracy:   1.0, loss: 0.009229391813278198     \n",
      "dev accuracy: 0.875, loss: 0.22955402731895447      \n",
      "dev accuracy: 0.9375, loss: 0.21848945319652557      \n",
      "dev accuracy:   1.0, loss: 0.08864477276802063      \n",
      "dev accuracy: 0.9375, loss: 0.17771509289741516      \n",
      "dev accuracy: 0.9375, loss: 0.15246783196926117      \n",
      "dev accuracy:   1.0, loss: 0.028141915798187256     \n",
      "dev accuracy: 0.9375, loss: 0.14495548605918884      \n",
      "dev accuracy:   1.0, loss: 0.005004972219467163     \n",
      "dev accuracy:   1.0, loss: 0.08542047441005707      \n",
      "dev accuracy:   1.0, loss: 0.05665302276611328      \n",
      "dev accuracy:   1.0, loss: 0.0035442709922790527    \n",
      "dev accuracy: 0.9375, loss: 0.29538053274154663      \n",
      "dev accuracy:   1.0, loss: 0.06983071565628052      \n",
      "dev accuracy:   1.0, loss: 0.009964019060134888     \n",
      "dev accuracy: 0.9375, loss: 0.18170863389968872      \n",
      "dev accuracy:   1.0, loss: 0.04737505316734314      \n",
      "dev accuracy: 0.875, loss: 0.39499571919441223      \n",
      "dev accuracy:   1.0, loss: 0.009897440671920776     \n",
      "dev accuracy: 0.9375, loss: 0.16832175850868225      \n",
      "dev accuracy: 0.875, loss: 0.4730445444583893       \n",
      "dev accuracy: 0.875, loss: 0.20590263605117798      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy:   1.0, loss: 0.08565083146095276      \n",
      "dev accuracy:   1.0, loss: 0.01144835352897644      \n",
      "dev accuracy:   1.0, loss: 0.039845943450927734     \n",
      "dev accuracy: 0.875, loss: 0.25061389803886414      \n",
      "dev accuracy: 0.9375, loss: 0.12579280138015747      \n",
      "dev accuracy: 0.9375, loss: 0.2347492128610611       \n",
      "dev accuracy: 0.875, loss: 0.2241573929786682       \n",
      "dev accuracy:   1.0, loss: 0.024410516023635864     \n",
      "dev accuracy:   1.0, loss: 0.0018117427825927734    \n",
      "dev accuracy: 0.875, loss: 0.37643975019454956      \n",
      "dev accuracy:   1.0, loss: 0.09086428582668304      \n",
      "dev accuracy:   1.0, loss: 0.061465173959732056     \n",
      "dev accuracy:   1.0, loss: 0.0006180405616760254    \n",
      "dev accuracy: 0.9375, loss: 0.41458895802497864      \n",
      "dev accuracy: 0.9375, loss: 0.049928635358810425     \n",
      "dev accuracy:   1.0, loss: 0.004205197095870972     \n",
      "dev accuracy: 0.875, loss: 0.4799210727214813       \n",
      "dev accuracy:   1.0, loss: 0.0008015632629394531    \n",
      "dev accuracy: 0.875, loss: 0.30877983570098877      \n",
      "dev accuracy:   1.0, loss: 0.01833820343017578      \n",
      "dev accuracy: 0.9375, loss: 0.19854111969470978      \n",
      "dev accuracy:   1.0, loss: 0.03454728424549103      \n",
      "dev accuracy: 0.9375, loss: 0.15234923362731934      \n",
      "dev accuracy:   1.0, loss: 0.03401648998260498      \n",
      "dev accuracy: 0.875, loss: 0.3734743893146515       \n",
      "dev accuracy:   1.0, loss: 0.038604736328125        \n",
      "dev accuracy:   1.0, loss: 0.007595539093017578     \n",
      "dev accuracy:   1.0, loss: 0.03845590353012085      \n",
      "dev accuracy:   1.0, loss: 0.06506815552711487      \n",
      "dev accuracy: 0.875, loss: 0.45195838809013367      \n",
      "dev accuracy:   1.0, loss: 0.003326892852783203     \n",
      "dev accuracy: 0.8125, loss: 0.5298230051994324       \n",
      "dev accuracy: 0.9375, loss: 0.28217989206314087      \n",
      "dev accuracy: 0.875, loss: 0.18065255880355835      \n",
      "dev accuracy:   1.0, loss: 0.025653451681137085     \n",
      "dev accuracy:   1.0, loss: 0.006125032901763916     \n",
      "dev accuracy:   1.0, loss: 0.034440696239471436     \n",
      "dev accuracy:   1.0, loss: 0.01080632209777832      \n",
      "dev accuracy:   1.0, loss: 0.03850133717060089      \n",
      "dev accuracy: 0.9375, loss: 0.09815119206905365      \n",
      "dev accuracy: 0.9375, loss: 0.10203298926353455      \n",
      "dev accuracy: 0.9375, loss: 0.3192295730113983       \n",
      "dev accuracy: 0.9375, loss: 0.1919274628162384       \n",
      "dev accuracy:   1.0, loss: 0.005553007125854492     \n",
      "dev accuracy: 0.9375, loss: 0.2596723735332489       \n",
      "dev accuracy: 0.8125, loss: 0.9587428569793701       \n",
      "dev accuracy:   1.0, loss: 0.04325449466705322      \n",
      "dev accuracy:   1.0, loss: 0.015630364418029785     \n",
      "dev accuracy: 0.875, loss: 0.4397623538970947       \n",
      "dev accuracy: 0.9375, loss: 0.19782665371894836      \n",
      "dev accuracy: 0.875, loss: 0.136553555727005        \n",
      "dev accuracy:   1.0, loss: 0.04200226068496704      \n",
      "dev accuracy: 0.9375, loss: 0.1688758134841919       \n",
      "dev accuracy:  0.75, loss: 0.5593768358230591       \n",
      "dev accuracy: 0.9375, loss: 0.21782562136650085      \n",
      "dev accuracy:   1.0, loss: 0.06724882125854492      \n",
      "dev accuracy:   1.0, loss: 0.023329198360443115     \n",
      "dev accuracy: 0.9375, loss: 0.20016995072364807      \n",
      "dev accuracy: 0.875, loss: 0.3479718267917633       \n",
      "dev accuracy:   1.0, loss: 0.009886205196380615     \n",
      "dev accuracy: 0.9375, loss: 0.26556870341300964      \n",
      "dev accuracy: 0.875, loss: 0.38245660066604614      \n",
      "dev accuracy:   1.0, loss: 0.008653461933135986     \n",
      "dev accuracy: 0.9375, loss: 0.2287503480911255       \n",
      "dev accuracy: 0.9375, loss: 0.10627520084381104      \n",
      "dev accuracy: 0.9375, loss: 0.4050675630569458       \n",
      "dev accuracy: 0.9375, loss: 0.13939523696899414      \n",
      "dev accuracy:   1.0, loss: 0.007420867681503296     \n",
      "dev accuracy:   1.0, loss: 0.016818702220916748     \n",
      "dev accuracy:   1.0, loss: 0.02825590968132019      \n",
      "dev accuracy: 0.9375, loss: 0.09960553050041199      \n",
      "dev accuracy: 0.9375, loss: 0.18691405653953552      \n",
      "dev accuracy:   1.0, loss: 0.06049904227256775      \n",
      "dev accuracy:   1.0, loss: 0.01930832862854004      \n",
      "dev accuracy: 0.9375, loss: 0.27642855048179626      \n",
      "dev accuracy: 0.8125, loss: 0.6693235635757446       \n",
      "dev accuracy: 0.9375, loss: 0.13704118132591248      \n",
      "dev accuracy: 0.9375, loss: 0.11060753464698792      \n",
      "dev accuracy: 0.875, loss: 0.455863893032074        \n",
      "dev accuracy: 0.9375, loss: 0.5026935338973999       \n",
      "dev accuracy: 0.6666666666666666, loss: 0.9503586888313293       \n",
      "final dev accuracy: 0.949634879725086\n",
      "train step #4165 accuracy:   1.0, loss: 0.014608010649681091     \n",
      "train step #4166 accuracy: 0.984375, loss: 0.07420056313276291      \n",
      "train step #4167 accuracy: 0.984375, loss: 0.10141614824533463      \n",
      "train step #4168 accuracy: 0.90625, loss: 0.3133383095264435       \n",
      "train step #4169 accuracy: 0.984375, loss: 0.061780720949172974     \n",
      "train step #4170 accuracy: 0.96875, loss: 0.11450739949941635      \n",
      "train step #4171 accuracy: 0.953125, loss: 0.11732491105794907      \n",
      "train step #4172 accuracy: 0.953125, loss: 0.23140792548656464      \n",
      "train step #4173 accuracy: 0.984375, loss: 0.07168261706829071      \n",
      "train step #4174 accuracy: 0.9375, loss: 0.16197746992111206      \n",
      "train step #4175 accuracy: 0.953125, loss: 0.22458355128765106      \n",
      "train step #4176 accuracy: 0.90625, loss: 0.199893057346344        \n",
      "train step #4177 accuracy: 0.890625, loss: 0.39147549867630005      \n",
      "train step #4178 accuracy: 0.953125, loss: 0.1375819593667984       \n",
      "train step #4179 accuracy: 0.984375, loss: 0.049561526626348495     \n",
      "train step #4180 accuracy: 0.96875, loss: 0.12076130509376526      \n",
      "train step #4181 accuracy: 0.96875, loss: 0.10365854203701019      \n",
      "train step #4182 accuracy: 0.96875, loss: 0.11230969429016113      \n",
      "train step #4183 accuracy: 0.984375, loss: 0.08726681768894196      \n",
      "train step #4184 accuracy: 0.96875, loss: 0.1604296714067459       \n",
      "train step #4185 accuracy: 0.984375, loss: 0.08539306372404099      \n",
      "train step #4186 accuracy: 0.9375, loss: 0.28015732765197754      \n",
      "train step #4187 accuracy: 0.953125, loss: 0.12113383412361145      \n",
      "train step #4188 accuracy:   1.0, loss: 0.043760765343904495     \n",
      "train step #4189 accuracy: 0.984375, loss: 0.08993128687143326      \n",
      "train step #4190 accuracy: 0.953125, loss: 0.13089312613010406      \n",
      "train step #4191 accuracy: 0.9375, loss: 0.14499148726463318      \n",
      "train step #4192 accuracy: 0.984375, loss: 0.13204549252986908      \n",
      "train step #4193 accuracy: 0.9375, loss: 0.16491855680942535      \n",
      "train step #4194 accuracy:   1.0, loss: 0.05214834213256836      \n",
      "train step #4195 accuracy:   1.0, loss: 0.054792940616607666     \n",
      "train step #4196 accuracy: 0.984375, loss: 0.13410186767578125      \n",
      "train step #4197 accuracy: 0.96875, loss: 0.14446978271007538      \n",
      "train step #4198 accuracy: 0.9375, loss: 0.25803056359291077      \n",
      "train step #4199 accuracy: 0.96875, loss: 0.10775510221719742      \n",
      "train step #4200 accuracy: 0.953125, loss: 0.12298908829689026      \n",
      "train step #4201 accuracy: 0.953125, loss: 0.13755805790424347      \n",
      "train step #4202 accuracy: 0.96875, loss: 0.3030059337615967       \n",
      "train step #4203 accuracy: 0.96875, loss: 0.15106691420078278      \n",
      "train step #4204 accuracy: 0.984375, loss: 0.025767043232917786     \n",
      "train step #4205 accuracy: 0.96875, loss: 0.11567416787147522      \n",
      "train step #4206 accuracy: 0.953125, loss: 0.14710447192192078      \n",
      "train step #4207 accuracy: 0.96875, loss: 0.13808441162109375      \n",
      "train step #4208 accuracy: 0.953125, loss: 0.1516735851764679       \n",
      "train step #4209 accuracy: 0.953125, loss: 0.19191473722457886      \n",
      "train step #4210 accuracy: 0.953125, loss: 0.14143207669258118      \n",
      "train step #4211 accuracy: 0.96875, loss: 0.1537289321422577       \n",
      "train step #4212 accuracy: 0.9375, loss: 0.18822486698627472      \n",
      "train step #4213 accuracy:   1.0, loss: 0.020297087728977203     \n",
      "train step #4214 accuracy: 0.984375, loss: 0.06514179706573486      \n",
      "train step #4215 accuracy: 0.953125, loss: 0.18129508197307587      \n",
      "train step #4216 accuracy: 0.96875, loss: 0.11945707350969315      \n",
      "train step #4217 accuracy: 0.953125, loss: 0.11515916883945465      \n",
      "train step #4218 accuracy: 0.96875, loss: 0.1346491277217865       \n",
      "train step #4219 accuracy: 0.953125, loss: 0.1872764378786087       \n",
      "train step #4220 accuracy: 0.96875, loss: 0.13531279563903809      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #4221 accuracy: 0.96875, loss: 0.13511136174201965      \n",
      "train step #4222 accuracy: 0.953125, loss: 0.15373186767101288      \n",
      "train step #4223 accuracy:   1.0, loss: 0.02854049950838089      \n",
      "train step #4224 accuracy: 0.984375, loss: 0.10303758829832077      \n",
      "train step #4225 accuracy: 0.953125, loss: 0.14816182851791382      \n",
      "train step #4226 accuracy: 0.984375, loss: 0.08871474862098694      \n",
      "train step #4227 accuracy: 0.984375, loss: 0.07324448227882385      \n",
      "train step #4228 accuracy: 0.96875, loss: 0.13076649606227875      \n",
      "train step #4229 accuracy:   1.0, loss: 0.037475332617759705     \n",
      "train step #4230 accuracy: 0.984375, loss: 0.10806995630264282      \n",
      "train step #4231 accuracy: 0.953125, loss: 0.2838534116744995       \n",
      "train step #4232 accuracy: 0.921875, loss: 0.24930573999881744      \n",
      "train step #4233 accuracy: 0.984375, loss: 0.10063383728265762      \n",
      "train step #4234 accuracy: 0.984375, loss: 0.07940340787172318      \n",
      "train step #4235 accuracy: 0.921875, loss: 0.3213135600090027       \n",
      "train step #4236 accuracy: 0.984375, loss: 0.07279129326343536      \n",
      "train step #4237 accuracy: 0.984375, loss: 0.057974912226200104     \n",
      "train step #4238 accuracy: 0.984375, loss: 0.058714017271995544     \n",
      "train step #4239 accuracy: 0.984375, loss: 0.031594183295965195     \n",
      "train step #4240 accuracy: 0.953125, loss: 0.16421642899513245      \n",
      "train step #4241 accuracy: 0.9375, loss: 0.2065889686346054       \n",
      "train step #4242 accuracy: 0.9375, loss: 0.1882287561893463       \n",
      "train step #4243 accuracy: 0.96875, loss: 0.11395886540412903      \n",
      "train step #4244 accuracy: 0.953125, loss: 0.105712890625           \n",
      "train step #4245 accuracy: 0.96875, loss: 0.07900894433259964      \n",
      "train step #4246 accuracy: 0.953125, loss: 0.31947648525238037      \n",
      "train step #4247 accuracy: 0.96875, loss: 0.20135030150413513      \n",
      "train step #4248 accuracy: 0.96875, loss: 0.13950780034065247      \n",
      "train step #4249 accuracy: 0.96875, loss: 0.1338530331850052       \n",
      "train step #4250 accuracy: 0.953125, loss: 0.16623970866203308      \n",
      "train step #4251 accuracy: 0.984375, loss: 0.11926417797803879      \n",
      "train step #4252 accuracy: 0.921875, loss: 0.2676736116409302       \n",
      "train step #4253 accuracy: 0.96875, loss: 0.12820011377334595      \n",
      "train step #4254 accuracy: 0.984375, loss: 0.0633452907204628       \n",
      "train step #4255 accuracy: 0.9375, loss: 0.2679619789123535       \n",
      "train step #4256 accuracy: 0.953125, loss: 0.1350506693124771       \n",
      "train step #4257 accuracy: 0.984375, loss: 0.07334356009960175      \n",
      "train step #4258 accuracy: 0.984375, loss: 0.04013989120721817      \n",
      "train step #4259 accuracy: 0.984375, loss: 0.07667811214923859      \n",
      "train step #4260 accuracy: 0.953125, loss: 0.11893219500780106      \n",
      "train step #4261 accuracy: 0.953125, loss: 0.14097566902637482      \n",
      "train step #4262 accuracy: 0.96875, loss: 0.09152007848024368      \n",
      "train step #4263 accuracy: 0.953125, loss: 0.21045397222042084      \n",
      "train step #4264 accuracy: 0.90625, loss: 0.2718470096588135       \n",
      "train step #4265 accuracy: 0.953125, loss: 0.16588588058948517      \n",
      "train step #4266 accuracy: 0.96875, loss: 0.12422794103622437      \n",
      "train step #4267 accuracy: 0.984375, loss: 0.07159294188022614      \n",
      "train step #4268 accuracy:   1.0, loss: 0.019023429602384567     \n",
      "train step #4269 accuracy: 0.953125, loss: 0.1606433391571045       \n",
      "train step #4270 accuracy: 0.984375, loss: 0.10213252902030945      \n",
      "train step #4271 accuracy: 0.96875, loss: 0.11240127682685852      \n",
      "train step #4272 accuracy:   1.0, loss: 0.05593746528029442      \n",
      "train step #4273 accuracy: 0.953125, loss: 0.15693651139736176      \n",
      "train step #4274 accuracy: 0.96875, loss: 0.10818347334861755      \n",
      "train step #4275 accuracy: 0.984375, loss: 0.052326738834381104     \n",
      "train step #4276 accuracy: 0.890625, loss: 0.21995139122009277      \n",
      "train step #4277 accuracy: 0.90625, loss: 0.3549770414829254       \n",
      "train step #4278 accuracy: 0.96875, loss: 0.158797025680542        \n",
      "train step #4279 accuracy:   1.0, loss: 0.021645687520503998     \n",
      "train step #4280 accuracy: 0.96875, loss: 0.12338537722826004      \n",
      "train step #4281 accuracy: 0.96875, loss: 0.1441763937473297       \n",
      "train step #4282 accuracy: 0.953125, loss: 0.12991303205490112      \n",
      "train step #4283 accuracy: 0.921875, loss: 0.18838447332382202      \n",
      "train step #4284 accuracy: 0.953125, loss: 0.20433571934700012      \n",
      "train step #4285 accuracy:   1.0, loss: 0.04148115962743759      \n",
      "train step #4286 accuracy: 0.953125, loss: 0.1701875776052475       \n",
      "train step #4287 accuracy: 0.9375, loss: 0.15150481462478638      \n",
      "train step #4288 accuracy: 0.90625, loss: 0.3461264967918396       \n",
      "train step #4289 accuracy: 0.9375, loss: 0.17798078060150146      \n",
      "train step #4290 accuracy: 0.9375, loss: 0.2759494483470917       \n",
      "train step #4291 accuracy: 0.953125, loss: 0.10029947012662888      \n",
      "train step #4292 accuracy:   1.0, loss: 0.016452528536319733     \n",
      "train step #4293 accuracy: 0.9375, loss: 0.11454558372497559      \n",
      "train step #4294 accuracy: 0.96875, loss: 0.11715270578861237      \n",
      "train step #4295 accuracy: 0.96875, loss: 0.1986413598060608       \n",
      "train step #4296 accuracy: 0.953125, loss: 0.1470463126897812       \n",
      "train step #4297 accuracy:   1.0, loss: 0.04706503823399544      \n",
      "train step #4298 accuracy: 0.9375, loss: 0.17854705452919006      \n",
      "train step #4299 accuracy: 0.953125, loss: 0.2246033400297165       \n",
      "train step #4300 accuracy: 0.953125, loss: 0.1555083841085434       \n",
      "train step #4301 accuracy: 0.953125, loss: 0.22512592375278473      \n",
      "train step #4302 accuracy: 0.984375, loss: 0.05201094597578049      \n",
      "train step #4303 accuracy: 0.953125, loss: 0.1416209638118744       \n",
      "train step #4304 accuracy: 0.96875, loss: 0.08045771718025208      \n",
      "train step #4305 accuracy: 0.9375, loss: 0.2184881567955017       \n",
      "train step #4306 accuracy: 0.9375, loss: 0.2749115526676178       \n",
      "train step #4307 accuracy: 0.96875, loss: 0.14445848762989044      \n",
      "train step #4308 accuracy: 0.984375, loss: 0.11597944051027298      \n",
      "train step #4309 accuracy: 0.96875, loss: 0.12266427278518677      \n",
      "train step #4310 accuracy: 0.96875, loss: 0.1313643604516983       \n",
      "train step #4311 accuracy: 0.96875, loss: 0.1469992995262146       \n",
      "train step #4312 accuracy: 0.96875, loss: 0.09003275632858276      \n",
      "train step #4313 accuracy:   1.0, loss: 0.024162687361240387     \n",
      "train step #4314 accuracy: 0.984375, loss: 0.14799422025680542      \n",
      "train step #4315 accuracy: 0.953125, loss: 0.24527409672737122      \n",
      "train step #4316 accuracy: 0.984375, loss: 0.12209434807300568      \n",
      "train step #4317 accuracy: 0.984375, loss: 0.055221520364284515     \n",
      "train step #4318 accuracy: 0.953125, loss: 0.17506292462348938      \n",
      "train step #4319 accuracy:   1.0, loss: 0.05132989212870598      \n",
      "train step #4320 accuracy: 0.890625, loss: 0.32071417570114136      \n",
      "train step #4321 accuracy: 0.96875, loss: 0.20483921468257904      \n",
      "train step #4322 accuracy: 0.9375, loss: 0.19878710806369781      \n",
      "train step #4323 accuracy: 0.96875, loss: 0.14864641427993774      \n",
      "train step #4324 accuracy: 0.96875, loss: 0.12064839154481888      \n",
      "train step #4325 accuracy: 0.9375, loss: 0.25787848234176636      \n",
      "train step #4326 accuracy: 0.953125, loss: 0.15573365986347198      \n",
      "train step #4327 accuracy:   1.0, loss: 0.053167782723903656     \n",
      "train step #4328 accuracy: 0.9375, loss: 0.23920491337776184      \n",
      "train step #4329 accuracy: 0.96875, loss: 0.10590998828411102      \n",
      "train step #4330 accuracy: 0.9375, loss: 0.15252666175365448      \n",
      "train step #4331 accuracy: 0.9375, loss: 0.2425999492406845       \n",
      "train step #4332 accuracy: 0.984375, loss: 0.10528141260147095      \n",
      "train step #4333 accuracy: 0.984375, loss: 0.11606146395206451      \n",
      "train step #4334 accuracy: 0.953125, loss: 0.22617825865745544      \n",
      "train step #4335 accuracy: 0.984375, loss: 0.09498675912618637      \n",
      "train step #4336 accuracy: 0.984375, loss: 0.03233136236667633      \n",
      "train step #4337 accuracy: 0.96875, loss: 0.10643670707941055      \n",
      "train step #4338 accuracy:   1.0, loss: 0.02707495167851448      \n",
      "train step #4339 accuracy: 0.984375, loss: 0.09653230011463165      \n",
      "train step #4340 accuracy: 0.96875, loss: 0.10387031733989716      \n",
      "train step #4341 accuracy: 0.96875, loss: 0.11214502900838852      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #4342 accuracy: 0.984375, loss: 0.11534465104341507      \n",
      "train step #4343 accuracy: 0.90625, loss: 0.2756722569465637       \n",
      "train step #4344 accuracy: 0.96875, loss: 0.07786349952220917      \n",
      "train step #4345 accuracy: 0.96875, loss: 0.10235245525836945      \n",
      "train step #4346 accuracy: 0.953125, loss: 0.21530696749687195      \n",
      "train step #4347 accuracy: 0.984375, loss: 0.1130194142460823       \n",
      "train step #4348 accuracy: 0.9375, loss: 0.16303062438964844      \n",
      "train step #4349 accuracy: 0.96875, loss: 0.22909638285636902      \n",
      "train step #4350 accuracy: 0.96875, loss: 0.13588756322860718      \n",
      "train step #4351 accuracy: 0.96875, loss: 0.1714959442615509       \n",
      "train step #4352 accuracy: 0.890625, loss: 0.27572616934776306      \n",
      "train step #4353 accuracy: 0.953125, loss: 0.11454074829816818      \n",
      "train step #4354 accuracy: 0.984375, loss: 0.041977658867836        \n",
      "train step #4355 accuracy: 0.953125, loss: 0.1163717731833458       \n",
      "train step #4356 accuracy: 0.984375, loss: 0.08401530236005783      \n",
      "train step #4357 accuracy: 0.984375, loss: 0.06110141798853874      \n",
      "train step #4358 accuracy: 0.953125, loss: 0.1400074064731598       \n",
      "train step #4359 accuracy: 0.96875, loss: 0.08920534700155258      \n",
      "train step #4360 accuracy: 0.9375, loss: 0.32035332918167114      \n",
      "train step #4361 accuracy: 0.96875, loss: 0.16067029535770416      \n",
      "train step #4362 accuracy: 0.9375, loss: 0.11944790929555893      \n",
      "train step #4363 accuracy: 0.921875, loss: 0.2249051332473755       \n",
      "train step #4364 accuracy: 0.984375, loss: 0.029615387320518494     \n",
      "train step #4365 accuracy: 0.96875, loss: 0.07771656662225723      \n",
      "train step #4366 accuracy:   1.0, loss: 0.0294417105615139       \n",
      "train step #4367 accuracy: 0.984375, loss: 0.06370222568511963      \n",
      "train step #4368 accuracy: 0.96875, loss: 0.14315876364707947      \n",
      "train step #4369 accuracy: 0.953125, loss: 0.11332549154758453      \n",
      "train step #4370 accuracy: 0.9375, loss: 0.23455214500427246      \n",
      "train step #4371 accuracy: 0.9375, loss: 0.16277500987052917      \n",
      "train step #4372 accuracy: 0.96875, loss: 0.06268663704395294      \n",
      "train step #4373 accuracy: 0.9375, loss: 0.27321290969848633      \n",
      "train step #4374 accuracy: 0.96875, loss: 0.07146115601062775      \n",
      "train step #4375 accuracy: 0.9375, loss: 0.23723217844963074      \n",
      "train step #4376 accuracy: 0.90625, loss: 0.39638519287109375      \n",
      "train step #4377 accuracy: 0.96875, loss: 0.054059721529483795     \n",
      "train step #4378 accuracy: 0.96875, loss: 0.06191360577940941      \n",
      "train step #4379 accuracy: 0.890625, loss: 0.25166648626327515      \n",
      "train step #4380 accuracy: 0.953125, loss: 0.15787892043590546      \n",
      "train step #4381 accuracy: 0.96875, loss: 0.13039064407348633      \n",
      "train step #4382 accuracy: 0.984375, loss: 0.15954110026359558      \n",
      "train step #4383 accuracy: 0.984375, loss: 0.1165793240070343       \n",
      "train step #4384 accuracy:   1.0, loss: 0.026703380048274994     \n",
      "train step #4385 accuracy: 0.96875, loss: 0.12778973579406738      \n",
      "train step #4386 accuracy: 0.984375, loss: 0.11338354647159576      \n",
      "train step #4387 accuracy: 0.96875, loss: 0.14426405727863312      \n",
      "train step #4388 accuracy:   1.0, loss: 0.02494540810585022      \n",
      "train step #4389 accuracy: 0.953125, loss: 0.17486292123794556      \n",
      "train step #4390 accuracy:   1.0, loss: 0.03810140863060951      \n",
      "train step #4391 accuracy: 0.984375, loss: 0.05267810821533203      \n",
      "train step #4392 accuracy: 0.921875, loss: 0.22657647728919983      \n",
      "train step #4393 accuracy: 0.984375, loss: 0.08809076249599457      \n",
      "train step #4394 accuracy: 0.953125, loss: 0.2174818217754364       \n",
      "train step #4395 accuracy: 0.953125, loss: 0.17550796270370483      \n",
      "train step #4396 accuracy: 0.953125, loss: 0.1192278191447258       \n",
      "train step #4397 accuracy: 0.90625, loss: 0.25739023089408875      \n",
      "train step #4398 accuracy: 0.96875, loss: 0.10416686534881592      \n",
      "train step #4399 accuracy: 0.9375, loss: 0.28802400827407837      \n",
      "train step #4400 accuracy: 0.96875, loss: 0.14880868792533875      \n",
      "train step #4401 accuracy: 0.953125, loss: 0.19680264592170715      \n",
      "train step #4402 accuracy:   1.0, loss: 0.040232524275779724     \n",
      "train step #4403 accuracy: 0.96875, loss: 0.12321478128433228      \n",
      "train step #4404 accuracy: 0.96875, loss: 0.0541483610868454       \n",
      "train step #4405 accuracy: 0.984375, loss: 0.08226140588521957      \n",
      "train step #4406 accuracy: 0.96875, loss: 0.10731155425310135      \n",
      "train step #4407 accuracy: 0.953125, loss: 0.2049379199743271       \n",
      "train step #4408 accuracy:   1.0, loss: 0.024447239935398102     \n",
      "train step #4409 accuracy: 0.953125, loss: 0.15673425793647766      \n",
      "train step #4410 accuracy: 0.953125, loss: 0.10321448743343353      \n",
      "train step #4411 accuracy: 0.984375, loss: 0.050337716937065125     \n",
      "train step #4412 accuracy:   1.0, loss: 0.018369413912296295     \n",
      "train step #4413 accuracy: 0.96875, loss: 0.1645253598690033       \n",
      "train step #4414 accuracy: 0.96875, loss: 0.1594727486371994       \n",
      "train step #4415 accuracy: 0.96875, loss: 0.1357533484697342       \n",
      "train step #4416 accuracy: 0.9375, loss: 0.2793871760368347       \n",
      "train step #4417 accuracy: 0.96875, loss: 0.1210193857550621       \n",
      "train step #4418 accuracy: 0.953125, loss: 0.1171518936753273       \n",
      "train step #4419 accuracy:   1.0, loss: 0.055686548352241516     \n",
      "train step #4420 accuracy: 0.953125, loss: 0.16645702719688416      \n",
      "train step #4421 accuracy: 0.9375, loss: 0.20881403982639313      \n",
      "train step #4422 accuracy: 0.953125, loss: 0.2006945163011551       \n",
      "train step #4423 accuracy: 0.9375, loss: 0.19146382808685303      \n",
      "train step #4424 accuracy: 0.96875, loss: 0.11422135680913925      \n",
      "train step #4425 accuracy: 0.921875, loss: 0.24139858782291412      \n",
      "train step #4426 accuracy: 0.953125, loss: 0.181156188249588        \n",
      "train step #4427 accuracy: 0.9375, loss: 0.15593139827251434      \n",
      "train step #4428 accuracy: 0.953125, loss: 0.1582804173231125       \n",
      "train step #4429 accuracy: 0.96875, loss: 0.13165442645549774      \n",
      "train step #4430 accuracy: 0.96875, loss: 0.10766785591840744      \n",
      "train step #4431 accuracy: 0.9375, loss: 0.2196846455335617       \n",
      "train step #4432 accuracy: 0.96875, loss: 0.1846895068883896       \n",
      "train step #4433 accuracy: 0.984375, loss: 0.03379078581929207      \n",
      "train step #4434 accuracy: 0.921875, loss: 0.24258527159690857      \n",
      "train step #4435 accuracy: 0.9375, loss: 0.20224018394947052      \n",
      "train step #4436 accuracy: 0.953125, loss: 0.19822649657726288      \n",
      "train step #4437 accuracy: 0.953125, loss: 0.24150879681110382      \n",
      "train step #4438 accuracy: 0.90625, loss: 0.23096045851707458      \n",
      "train step #4439 accuracy: 0.921875, loss: 0.22260107100009918      \n",
      "train step #4440 accuracy: 0.96875, loss: 0.14265760779380798      \n",
      "train step #4441 accuracy: 0.9375, loss: 0.14472690224647522      \n",
      "train step #4442 accuracy: 0.96875, loss: 0.13037176430225372      \n",
      "train step #4443 accuracy: 0.96875, loss: 0.1068631261587143       \n",
      "train step #4444 accuracy: 0.921875, loss: 0.24872182309627533      \n",
      "train step #4445 accuracy: 0.90625, loss: 0.25356602668762207      \n",
      "train step #4446 accuracy: 0.984375, loss: 0.046059709042310715     \n",
      "train step #4447 accuracy:   1.0, loss: 0.03644772991538048      \n",
      "train step #4448 accuracy: 0.96875, loss: 0.11007269471883774      \n",
      "train step #4449 accuracy: 0.953125, loss: 0.14478302001953125      \n",
      "train step #4450 accuracy: 0.984375, loss: 0.04024045541882515      \n",
      "train step #4451 accuracy: 0.96875, loss: 0.05500619485974312      \n",
      "train step #4452 accuracy: 0.9375, loss: 0.17185302078723907      \n",
      "train step #4453 accuracy: 0.984375, loss: 0.10012184083461761      \n",
      "train step #4454 accuracy: 0.953125, loss: 0.20345483720302582      \n",
      "train step #4455 accuracy: 0.953125, loss: 0.10553459078073502      \n",
      "train step #4456 accuracy: 0.921875, loss: 0.1868116706609726       \n",
      "train step #4457 accuracy: 0.984375, loss: 0.07796688377857208      \n",
      "train step #4458 accuracy: 0.984375, loss: 0.10519735515117645      \n",
      "train step #4459 accuracy: 0.9375, loss: 0.28393444418907166      \n",
      "train step #4460 accuracy: 0.921875, loss: 0.2711738646030426       \n",
      "train step #4461 accuracy: 0.984375, loss: 0.09724574536085129      \n",
      "train step #4462 accuracy: 0.984375, loss: 0.11360479891300201      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #4463 accuracy: 0.9375, loss: 0.262202650308609        \n",
      "train step #4464 accuracy: 0.96875, loss: 0.12368176877498627      \n",
      "train step #4465 accuracy: 0.984375, loss: 0.11516565829515457      \n",
      "train step #4466 accuracy: 0.984375, loss: 0.09885182976722717      \n",
      "train step #4467 accuracy: 0.984375, loss: 0.09380660951137543      \n",
      "train step #4468 accuracy:   1.0, loss: 0.038348518311977386     \n",
      "train step #4469 accuracy: 0.875, loss: 0.3906032145023346       \n",
      "train step #4470 accuracy: 0.921875, loss: 0.18839436769485474      \n",
      "train step #4471 accuracy: 0.984375, loss: 0.056465812027454376     \n",
      "train step #4472 accuracy: 0.953125, loss: 0.1728716641664505       \n",
      "train step #4473 accuracy:   1.0, loss: 0.02602892369031906      \n",
      "train step #4474 accuracy: 0.953125, loss: 0.1303713023662567       \n",
      "train step #4475 accuracy: 0.9375, loss: 0.2894901931285858       \n",
      "train step #4476 accuracy: 0.890625, loss: 0.32206398248672485      \n",
      "train step #4477 accuracy: 0.984375, loss: 0.08861949294805527      \n",
      "train step #4478 accuracy: 0.953125, loss: 0.15999653935432434      \n",
      "train step #4479 accuracy: 0.953125, loss: 0.13726693391799927      \n",
      "train step #4480 accuracy: 0.96875, loss: 0.1764519214630127       \n",
      "train step #4481 accuracy: 0.984375, loss: 0.15583723783493042      \n",
      "train step #4482 accuracy: 0.96875, loss: 0.09748771041631699      \n",
      "train step #4483 accuracy: 0.984375, loss: 0.07232732325792313      \n",
      "train step #4484 accuracy: 0.953125, loss: 0.22056013345718384      \n",
      "train step #4485 accuracy: 0.96875, loss: 0.139572411775589        \n",
      "train step #4486 accuracy: 0.953125, loss: 0.0849161148071289       \n",
      "train step #4487 accuracy: 0.953125, loss: 0.1841995120048523       \n",
      "train step #4488 accuracy: 0.953125, loss: 0.14264312386512756      \n",
      "train step #4489 accuracy: 0.953125, loss: 0.15879875421524048      \n",
      "train step #4490 accuracy:   1.0, loss: 0.04719509556889534      \n",
      "train step #4491 accuracy: 0.953125, loss: 0.23988786339759827      \n",
      "train step #4492 accuracy: 0.9375, loss: 0.25992465019226074      \n",
      "train step #4493 accuracy: 0.90625, loss: 0.29570475220680237      \n",
      "train step #4494 accuracy: 0.953125, loss: 0.1916528195142746       \n",
      "train step #4495 accuracy:   1.0, loss: 0.06982678920030594      \n",
      "train step #4496 accuracy: 0.984375, loss: 0.049697767943143845     \n",
      "train step #4497 accuracy: 0.953125, loss: 0.13472308218479156      \n",
      "train step #4498 accuracy: 0.953125, loss: 0.14694371819496155      \n",
      "train step #4499 accuracy: 0.984375, loss: 0.058284275233745575     \n",
      "train step #4500 accuracy: 0.984375, loss: 0.09538394957780838      \n",
      "train step #4501 accuracy: 0.953125, loss: 0.16042736172676086      \n",
      "train step #4502 accuracy: 0.984375, loss: 0.05404430255293846      \n",
      "train step #4503 accuracy: 0.96875, loss: 0.13546596467494965      \n",
      "train step #4504 accuracy: 0.9375, loss: 0.18791882693767548      \n",
      "train step #4505 accuracy: 0.984375, loss: 0.08019603788852692      \n",
      "train step #4506 accuracy: 0.890625, loss: 0.4396021366119385       \n",
      "train step #4507 accuracy: 0.9375, loss: 0.3001220226287842       \n",
      "train step #4508 accuracy: 0.9375, loss: 0.12922850251197815      \n",
      "train step #4509 accuracy: 0.96875, loss: 0.10419687628746033      \n",
      "train step #4510 accuracy:   1.0, loss: 0.046569302678108215     \n",
      "train step #4511 accuracy: 0.9375, loss: 0.20587843656539917      \n",
      "dev accuracy:   1.0, loss: 0.002793729305267334     \n",
      "dev accuracy: 0.8125, loss: 0.37282103300094604      \n",
      "dev accuracy:   1.0, loss: 0.008447855710983276     \n",
      "dev accuracy:   1.0, loss: 0.030127495527267456     \n",
      "dev accuracy: 0.875, loss: 0.3389476239681244       \n",
      "dev accuracy:   1.0, loss: 0.01072472333908081      \n",
      "dev accuracy:   1.0, loss: 0.014460980892181396     \n",
      "dev accuracy: 0.9375, loss: 0.245047464966774        \n",
      "dev accuracy: 0.9375, loss: 0.26820123195648193      \n",
      "dev accuracy: 0.9375, loss: 0.06937655806541443      \n",
      "dev accuracy:   1.0, loss: 0.01266944408416748      \n",
      "dev accuracy: 0.9375, loss: 0.1075141429901123       \n",
      "dev accuracy:   1.0, loss: 0.019520938396453857     \n",
      "dev accuracy: 0.875, loss: 0.6195756196975708       \n",
      "dev accuracy: 0.9375, loss: 0.24483200907707214      \n",
      "dev accuracy: 0.875, loss: 0.5240293741226196       \n",
      "dev accuracy: 0.9375, loss: 0.349793016910553        \n",
      "dev accuracy: 0.9375, loss: 0.22477616369724274      \n",
      "dev accuracy:   1.0, loss: 0.011182844638824463     \n",
      "dev accuracy: 0.9375, loss: 0.16408655047416687      \n",
      "dev accuracy: 0.9375, loss: 0.13746371865272522      \n",
      "dev accuracy: 0.9375, loss: 0.16448475420475006      \n",
      "dev accuracy:   1.0, loss: 0.021218925714492798     \n",
      "dev accuracy:   1.0, loss: 0.07151858508586884      \n",
      "dev accuracy: 0.8125, loss: 0.41772621870040894      \n",
      "dev accuracy: 0.9375, loss: 0.07750031352043152      \n",
      "dev accuracy:   1.0, loss: 0.10628682374954224      \n",
      "dev accuracy:   1.0, loss: 0.12363244593143463      \n",
      "dev accuracy: 0.9375, loss: 0.06224226951599121      \n",
      "dev accuracy: 0.875, loss: 0.28629738092422485      \n",
      "dev accuracy:   1.0, loss: 0.0373762845993042       \n",
      "dev accuracy: 0.9375, loss: 0.5662214159965515       \n",
      "dev accuracy:   1.0, loss: 0.002625882625579834     \n",
      "dev accuracy: 0.875, loss: 0.2021920382976532       \n",
      "dev accuracy: 0.9375, loss: 0.10089072585105896      \n",
      "dev accuracy:   1.0, loss: 0.04086564481258392      \n",
      "dev accuracy: 0.9375, loss: 0.24752770364284515      \n",
      "dev accuracy: 0.875, loss: 0.28877201676368713      \n",
      "dev accuracy: 0.9375, loss: 0.42488253116607666      \n",
      "dev accuracy:   1.0, loss: 0.001157224178314209     \n",
      "dev accuracy:   1.0, loss: 0.003330230712890625     \n",
      "dev accuracy:   1.0, loss: 0.0010237693786621094    \n",
      "dev accuracy:   1.0, loss: 0.06414851546287537      \n",
      "dev accuracy: 0.8125, loss: 0.3315424919128418       \n",
      "dev accuracy: 0.9375, loss: 0.11909258365631104      \n",
      "dev accuracy: 0.875, loss: 0.3504714071750641       \n",
      "dev accuracy: 0.875, loss: 0.7506343722343445       \n",
      "dev accuracy: 0.9375, loss: 0.16587549448013306      \n",
      "dev accuracy:   1.0, loss: 0.005514293909072876     \n",
      "dev accuracy: 0.875, loss: 0.21769773960113525      \n",
      "dev accuracy: 0.9375, loss: 0.213004469871521        \n",
      "dev accuracy:   1.0, loss: 0.01318410038948059      \n",
      "dev accuracy: 0.9375, loss: 0.11024543642997742      \n",
      "dev accuracy: 0.9375, loss: 0.06849810481071472      \n",
      "dev accuracy:   1.0, loss: 0.05558544397354126      \n",
      "dev accuracy: 0.9375, loss: 0.1440044492483139       \n",
      "dev accuracy:   1.0, loss: 0.028849482536315918     \n",
      "dev accuracy: 0.9375, loss: 0.25260141491889954      \n",
      "dev accuracy: 0.9375, loss: 0.07072103023529053      \n",
      "dev accuracy: 0.875, loss: 0.5998039245605469       \n",
      "dev accuracy:   1.0, loss: 0.060486555099487305     \n",
      "dev accuracy:   1.0, loss: 0.0157603919506073       \n",
      "dev accuracy:   1.0, loss: 0.02124759554862976      \n",
      "dev accuracy: 0.9375, loss: 0.056496649980545044     \n",
      "dev accuracy:   1.0, loss: 0.054115235805511475     \n",
      "dev accuracy: 0.9375, loss: 0.5328804850578308       \n",
      "dev accuracy:   1.0, loss: 0.01663386821746826      \n",
      "dev accuracy: 0.9375, loss: 0.18679004907608032      \n",
      "dev accuracy: 0.9375, loss: 0.06364321708679199      \n",
      "dev accuracy: 0.9375, loss: 0.3380255401134491       \n",
      "dev accuracy: 0.875, loss: 0.17787571251392365      \n",
      "dev accuracy: 0.9375, loss: 0.3386731743812561       \n",
      "dev accuracy:   1.0, loss: 0.0888327956199646       \n",
      "dev accuracy: 0.9375, loss: 0.2626682221889496       \n",
      "dev accuracy:   1.0, loss: 0.00961795449256897      \n",
      "dev accuracy: 0.9375, loss: 0.36941051483154297      \n",
      "dev accuracy: 0.9375, loss: 0.12314677238464355      \n",
      "dev accuracy: 0.9375, loss: 0.14738424122333527      \n",
      "dev accuracy: 0.9375, loss: 0.20373135805130005      \n",
      "dev accuracy:   1.0, loss: 0.011618077754974365     \n",
      "dev accuracy: 0.9375, loss: 0.17170590162277222      \n",
      "dev accuracy: 0.9375, loss: 0.5433052182197571       \n",
      "dev accuracy:   1.0, loss: 0.0005960464477539062    \n",
      "dev accuracy: 0.875, loss: 0.34798741340637207      \n",
      "dev accuracy: 0.9375, loss: 0.22461216151714325      \n",
      "dev accuracy:   1.0, loss: 0.026601165533065796     \n",
      "dev accuracy: 0.875, loss: 0.1966327726840973       \n",
      "dev accuracy: 0.9375, loss: 0.26151466369628906      \n",
      "dev accuracy:   1.0, loss: 0.024912774562835693     \n",
      "dev accuracy: 0.875, loss: 0.7919845581054688       \n",
      "dev accuracy:   1.0, loss: 0.024875342845916748     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy: 0.875, loss: 0.6402831673622131       \n",
      "dev accuracy:   1.0, loss: 0.06814226508140564      \n",
      "dev accuracy: 0.9375, loss: 0.10582776367664337      \n",
      "dev accuracy: 0.875, loss: 0.5743741393089294       \n",
      "dev accuracy:   1.0, loss: 0.0005437135696411133    \n",
      "dev accuracy: 0.9375, loss: 0.13516274094581604      \n",
      "dev accuracy:   1.0, loss: 0.03757941722869873      \n",
      "dev accuracy:   1.0, loss: 0.008365929126739502     \n",
      "dev accuracy: 0.9375, loss: 0.32847633957862854      \n",
      "dev accuracy: 0.9375, loss: 0.18961769342422485      \n",
      "dev accuracy:   1.0, loss: 0.004434704780578613     \n",
      "dev accuracy:   1.0, loss: 0.04294055700302124      \n",
      "dev accuracy:   1.0, loss: 0.015132725238800049     \n",
      "dev accuracy: 0.875, loss: 0.8960036039352417       \n",
      "dev accuracy:   1.0, loss: 0.05061286687850952      \n",
      "dev accuracy:   1.0, loss: 0.0014161467552185059    \n",
      "dev accuracy: 0.9375, loss: 0.08415251970291138      \n",
      "dev accuracy: 0.8125, loss: 0.5704669952392578       \n",
      "dev accuracy:   1.0, loss: 0.011206597089767456     \n",
      "dev accuracy: 0.9375, loss: 0.10692594945430756      \n",
      "dev accuracy:   1.0, loss: 0.02130630612373352      \n",
      "dev accuracy: 0.9375, loss: 0.15559552609920502      \n",
      "dev accuracy:   1.0, loss: 0.02513021230697632      \n",
      "dev accuracy: 0.9375, loss: 0.22618801891803741      \n",
      "dev accuracy:   1.0, loss: 0.00891605019569397      \n",
      "dev accuracy: 0.9375, loss: 0.24763497710227966      \n",
      "dev accuracy:   1.0, loss: 0.0065593421459198       \n",
      "dev accuracy:   1.0, loss: 0.01818948984146118      \n",
      "dev accuracy: 0.9375, loss: 0.07564306259155273      \n",
      "dev accuracy:   1.0, loss: 0.09099498391151428      \n",
      "dev accuracy: 0.875, loss: 0.5074810981750488       \n",
      "dev accuracy: 0.9375, loss: 0.3616839647293091       \n",
      "dev accuracy: 0.875, loss: 0.3483734726905823       \n",
      "dev accuracy: 0.9375, loss: 0.08946821093559265      \n",
      "dev accuracy:   1.0, loss: 0.08640393614768982      \n",
      "dev accuracy: 0.9375, loss: 0.16886164247989655      \n",
      "dev accuracy:   1.0, loss: 0.01697385311126709      \n",
      "dev accuracy:   1.0, loss: 0.0069277286529541016    \n",
      "dev accuracy: 0.9375, loss: 0.30133581161499023      \n",
      "dev accuracy:   1.0, loss: 0.0032352209091186523    \n",
      "dev accuracy:   1.0, loss: 0.04585257172584534      \n",
      "dev accuracy: 0.9375, loss: 0.14400644600391388      \n",
      "dev accuracy: 0.9375, loss: 0.2476232647895813       \n",
      "dev accuracy:   1.0, loss: 0.04081454873085022      \n",
      "dev accuracy: 0.9375, loss: 0.10740050673484802      \n",
      "dev accuracy: 0.9375, loss: 0.05031594634056091      \n",
      "dev accuracy: 0.9375, loss: 0.19939838349819183      \n",
      "dev accuracy: 0.9375, loss: 0.19013428688049316      \n",
      "dev accuracy:   1.0, loss: 0.08711586892604828      \n",
      "dev accuracy:   1.0, loss: 0.03508108854293823      \n",
      "dev accuracy:   1.0, loss: 0.0037734508514404297    \n",
      "dev accuracy:   1.0, loss: 0.031263887882232666     \n",
      "dev accuracy: 0.875, loss: 0.20404088497161865      \n",
      "dev accuracy: 0.8125, loss: 0.7562800645828247       \n",
      "dev accuracy: 0.875, loss: 0.3674244284629822       \n",
      "dev accuracy: 0.9375, loss: 0.15064388513565063      \n",
      "dev accuracy: 0.875, loss: 0.3114292621612549       \n",
      "dev accuracy: 0.9375, loss: 0.4341336488723755       \n",
      "dev accuracy: 0.9375, loss: 0.16642692685127258      \n",
      "dev accuracy: 0.9375, loss: 0.20501232147216797      \n",
      "dev accuracy: 0.9375, loss: 0.11822226643562317      \n",
      "dev accuracy: 0.9375, loss: 0.22669582068920135      \n",
      "dev accuracy: 0.9375, loss: 0.33152779936790466      \n",
      "dev accuracy: 0.9375, loss: 0.2792320251464844       \n",
      "dev accuracy:   1.0, loss: 0.0143776535987854       \n",
      "dev accuracy:   1.0, loss: 0.010844886302947998     \n",
      "dev accuracy: 0.9375, loss: 0.254165381193161        \n",
      "dev accuracy:   1.0, loss: 0.05023542046546936      \n",
      "dev accuracy:   1.0, loss: 0.10746936500072479      \n",
      "dev accuracy: 0.9375, loss: 0.3492569625377655       \n",
      "dev accuracy:   1.0, loss: 0.02053394913673401      \n",
      "dev accuracy: 0.9375, loss: 0.19291037321090698      \n",
      "dev accuracy: 0.875, loss: 0.5458781719207764       \n",
      "dev accuracy: 0.9375, loss: 0.14062732458114624      \n",
      "dev accuracy: 0.875, loss: 0.24109122157096863      \n",
      "dev accuracy:   1.0, loss: 0.12059542536735535      \n",
      "dev accuracy: 0.9375, loss: 0.17222192883491516      \n",
      "dev accuracy:   1.0, loss: 0.006627678871154785     \n",
      "dev accuracy:   1.0, loss: 0.005161762237548828     \n",
      "dev accuracy: 0.9375, loss: 0.15557491779327393      \n",
      "dev accuracy: 0.9375, loss: 0.10969410836696625      \n",
      "dev accuracy: 0.9375, loss: 0.11198049783706665      \n",
      "dev accuracy:   1.0, loss: 0.032813310623168945     \n",
      "dev accuracy: 0.9375, loss: 0.280941903591156        \n",
      "dev accuracy:   1.0, loss: 0.014223307371139526     \n",
      "dev accuracy: 0.9375, loss: 0.09744241833686829      \n",
      "dev accuracy:   1.0, loss: 0.05233749747276306      \n",
      "dev accuracy:   1.0, loss: 0.09464994072914124      \n",
      "dev accuracy: 0.9375, loss: 0.09486232697963715      \n",
      "dev accuracy:   1.0, loss: 0.022765040397644043     \n",
      "dev accuracy:   1.0, loss: 0.03414881229400635      \n",
      "dev accuracy:   1.0, loss: 0.041861146688461304     \n",
      "dev accuracy: 0.875, loss: 0.37885183095932007      \n",
      "dev accuracy: 0.875, loss: 0.2880529761314392       \n",
      "dev accuracy: 0.9375, loss: 0.3661324381828308       \n",
      "dev accuracy: 0.9375, loss: 0.12275326251983643      \n",
      "dev accuracy: 0.9375, loss: 0.13642948865890503      \n",
      "dev accuracy: 0.875, loss: 0.25605863332748413      \n",
      "dev accuracy: 0.9375, loss: 0.09788891673088074      \n",
      "dev accuracy: 0.9375, loss: 0.08370739221572876      \n",
      "dev accuracy: 0.9375, loss: 0.09178905189037323      \n",
      "dev accuracy:   1.0, loss: 0.0016382932662963867    \n",
      "dev accuracy:   1.0, loss: 0.0005706151132471859    \n",
      "final dev accuracy: 0.9507087628865979\n",
      "train step #4512 accuracy: 0.921875, loss: 0.20447903871536255      \n",
      "train step #4513 accuracy: 0.9375, loss: 0.1258082091808319       \n",
      "train step #4514 accuracy: 0.984375, loss: 0.07773828506469727      \n",
      "train step #4515 accuracy: 0.984375, loss: 0.031162627041339874     \n",
      "train step #4516 accuracy: 0.953125, loss: 0.18630000948905945      \n",
      "train step #4517 accuracy: 0.96875, loss: 0.1479220986366272       \n",
      "train step #4518 accuracy: 0.90625, loss: 0.3206785321235657       \n",
      "train step #4519 accuracy: 0.9375, loss: 0.15552875399589539      \n",
      "train step #4520 accuracy: 0.984375, loss: 0.11772722005844116      \n",
      "train step #4521 accuracy: 0.921875, loss: 0.2953398823738098       \n",
      "train step #4522 accuracy: 0.953125, loss: 0.18130990862846375      \n",
      "train step #4523 accuracy: 0.953125, loss: 0.12917183339595795      \n",
      "train step #4524 accuracy: 0.953125, loss: 0.19375228881835938      \n",
      "train step #4525 accuracy: 0.9375, loss: 0.24766182899475098      \n",
      "train step #4526 accuracy: 0.96875, loss: 0.11017198115587234      \n",
      "train step #4527 accuracy: 0.96875, loss: 0.05699111893773079      \n",
      "train step #4528 accuracy: 0.984375, loss: 0.1127110943198204       \n",
      "train step #4529 accuracy: 0.953125, loss: 0.1341170221567154       \n",
      "train step #4530 accuracy: 0.96875, loss: 0.04899665713310242      \n",
      "train step #4531 accuracy: 0.9375, loss: 0.23163318634033203      \n",
      "train step #4532 accuracy: 0.9375, loss: 0.17073671519756317      \n",
      "train step #4533 accuracy: 0.984375, loss: 0.0986299067735672       \n",
      "train step #4534 accuracy: 0.96875, loss: 0.09279602020978928      \n",
      "train step #4535 accuracy: 0.9375, loss: 0.24467383325099945      \n",
      "train step #4536 accuracy: 0.9375, loss: 0.1849726289510727       \n",
      "train step #4537 accuracy: 0.890625, loss: 0.43467891216278076      \n",
      "train step #4538 accuracy: 0.96875, loss: 0.1036892756819725       \n",
      "train step #4539 accuracy: 0.953125, loss: 0.20279227197170258      \n",
      "train step #4540 accuracy: 0.953125, loss: 0.17463436722755432      \n",
      "train step #4541 accuracy: 0.96875, loss: 0.17681097984313965      \n",
      "train step #4542 accuracy: 0.96875, loss: 0.0837986171245575       \n",
      "train step #4543 accuracy: 0.984375, loss: 0.10508974641561508      \n",
      "train step #4544 accuracy: 0.984375, loss: 0.08912041038274765      \n",
      "train step #4545 accuracy: 0.96875, loss: 0.14420554041862488      \n",
      "train step #4546 accuracy: 0.984375, loss: 0.10105375945568085      \n",
      "train step #4547 accuracy: 0.984375, loss: 0.028186187148094177     \n",
      "train step #4548 accuracy: 0.9375, loss: 0.2147817760705948       \n",
      "train step #4549 accuracy: 0.984375, loss: 0.07382382452487946      \n",
      "train step #4550 accuracy: 0.96875, loss: 0.12052428722381592      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #4551 accuracy: 0.921875, loss: 0.25060340762138367      \n",
      "train step #4552 accuracy: 0.984375, loss: 0.10730676352977753      \n",
      "train step #4553 accuracy: 0.90625, loss: 0.26683443784713745      \n",
      "train step #4554 accuracy: 0.96875, loss: 0.122425377368927        \n",
      "train step #4555 accuracy: 0.96875, loss: 0.12211279571056366      \n",
      "train step #4556 accuracy:   1.0, loss: 0.017552442848682404     \n",
      "train step #4557 accuracy: 0.9375, loss: 0.19964180886745453      \n",
      "train step #4558 accuracy: 0.96875, loss: 0.12392466515302658      \n",
      "train step #4559 accuracy: 0.96875, loss: 0.0942886546254158       \n",
      "train step #4560 accuracy: 0.9375, loss: 0.3219955265522003       \n",
      "train step #4561 accuracy: 0.984375, loss: 0.08911438286304474      \n",
      "train step #4562 accuracy: 0.953125, loss: 0.20620781183242798      \n",
      "train step #4563 accuracy: 0.96875, loss: 0.16219907999038696      \n",
      "train step #4564 accuracy: 0.984375, loss: 0.050460249185562134     \n",
      "train step #4565 accuracy: 0.984375, loss: 0.07203729450702667      \n",
      "train step #4566 accuracy:   1.0, loss: 0.029591336846351624     \n",
      "train step #4567 accuracy:   1.0, loss: 0.04776957631111145      \n",
      "train step #4568 accuracy: 0.984375, loss: 0.13606645166873932      \n",
      "train step #4569 accuracy: 0.9375, loss: 0.2083715796470642       \n",
      "train step #4570 accuracy: 0.9375, loss: 0.2464800477027893       \n",
      "train step #4571 accuracy: 0.96875, loss: 0.09451339393854141      \n",
      "train step #4572 accuracy: 0.921875, loss: 0.21131575107574463      \n",
      "train step #4573 accuracy: 0.953125, loss: 0.18405833840370178      \n",
      "train step #4574 accuracy: 0.9375, loss: 0.19473794102668762      \n",
      "train step #4575 accuracy:   1.0, loss: 0.05306142568588257      \n",
      "train step #4576 accuracy: 0.953125, loss: 0.2696043848991394       \n",
      "train step #4577 accuracy: 0.96875, loss: 0.18079906702041626      \n",
      "train step #4578 accuracy: 0.953125, loss: 0.11089253425598145      \n",
      "train step #4579 accuracy: 0.984375, loss: 0.09778348356485367      \n",
      "train step #4580 accuracy: 0.953125, loss: 0.11987334489822388      \n",
      "train step #4581 accuracy: 0.96875, loss: 0.09335267543792725      \n",
      "train step #4582 accuracy: 0.9375, loss: 0.22663000226020813      \n",
      "train step #4583 accuracy: 0.9375, loss: 0.29088830947875977      \n",
      "train step #4584 accuracy: 0.984375, loss: 0.05374555289745331      \n",
      "train step #4585 accuracy: 0.984375, loss: 0.07526270300149918      \n",
      "train step #4586 accuracy: 0.953125, loss: 0.19692961871623993      \n",
      "train step #4587 accuracy: 0.96875, loss: 0.11151415854692459      \n",
      "train step #4588 accuracy: 0.984375, loss: 0.1095983237028122       \n",
      "train step #4589 accuracy: 0.953125, loss: 0.12251589447259903      \n",
      "train step #4590 accuracy: 0.96875, loss: 0.19686898589134216      \n",
      "train step #4591 accuracy: 0.9375, loss: 0.252384752035141        \n",
      "train step #4592 accuracy: 0.9375, loss: 0.204264834523201        \n",
      "train step #4593 accuracy: 0.953125, loss: 0.15009471774101257      \n",
      "train step #4594 accuracy: 0.984375, loss: 0.0959726870059967       \n",
      "train step #4595 accuracy: 0.9375, loss: 0.2707550525665283       \n",
      "train step #4596 accuracy: 0.984375, loss: 0.07646070420742035      \n",
      "train step #4597 accuracy:   1.0, loss: 0.021930616348981857     \n",
      "train step #4598 accuracy: 0.984375, loss: 0.0871618464589119       \n",
      "train step #4599 accuracy: 0.96875, loss: 0.12682193517684937      \n",
      "train step #4600 accuracy: 0.953125, loss: 0.15089181065559387      \n",
      "train step #4601 accuracy: 0.96875, loss: 0.10575789213180542      \n",
      "train step #4602 accuracy:   1.0, loss: 0.022826433181762695     \n",
      "train step #4603 accuracy: 0.921875, loss: 0.198895663022995        \n",
      "train step #4604 accuracy: 0.984375, loss: 0.09959615767002106      \n",
      "train step #4605 accuracy: 0.9375, loss: 0.1799452006816864       \n",
      "train step #4606 accuracy: 0.953125, loss: 0.11980723589658737      \n",
      "train step #4607 accuracy: 0.96875, loss: 0.18705272674560547      \n",
      "train step #4608 accuracy: 0.96875, loss: 0.19490735232830048      \n",
      "train step #4609 accuracy: 0.9375, loss: 0.2158031463623047       \n",
      "train step #4610 accuracy:   1.0, loss: 0.04622504860162735      \n",
      "train step #4611 accuracy: 0.953125, loss: 0.1421879231929779       \n",
      "train step #4612 accuracy: 0.96875, loss: 0.2265857458114624       \n",
      "train step #4613 accuracy: 0.921875, loss: 0.2421017289161682       \n",
      "train step #4614 accuracy: 0.984375, loss: 0.09016966819763184      \n",
      "train step #4615 accuracy: 0.984375, loss: 0.1055092066526413       \n",
      "train step #4616 accuracy: 0.984375, loss: 0.05172507464885712      \n",
      "train step #4617 accuracy: 0.984375, loss: 0.040803298354148865     \n",
      "train step #4618 accuracy: 0.984375, loss: 0.113612100481987        \n",
      "train step #4619 accuracy: 0.953125, loss: 0.0880262479186058       \n",
      "train step #4620 accuracy: 0.96875, loss: 0.11903412640094757      \n",
      "train step #4621 accuracy: 0.921875, loss: 0.147823765873909        \n",
      "train step #4622 accuracy: 0.96875, loss: 0.1183885931968689       \n",
      "train step #4623 accuracy:   1.0, loss: 0.02711121365427971      \n",
      "train step #4624 accuracy: 0.9375, loss: 0.22910791635513306      \n",
      "train step #4625 accuracy:   1.0, loss: 0.018556848168373108     \n",
      "train step #4626 accuracy: 0.90625, loss: 0.3728930950164795       \n",
      "train step #4627 accuracy: 0.96875, loss: 0.15129081904888153      \n",
      "train step #4628 accuracy: 0.984375, loss: 0.0826723501086235       \n",
      "train step #4629 accuracy: 0.96875, loss: 0.13828438520431519      \n",
      "train step #4630 accuracy: 0.984375, loss: 0.04521002620458603      \n",
      "train step #4631 accuracy: 0.96875, loss: 0.09114416688680649      \n",
      "train step #4632 accuracy: 0.984375, loss: 0.0900062695145607       \n",
      "train step #4633 accuracy:   1.0, loss: 0.0352667011320591       \n",
      "train step #4634 accuracy: 0.96875, loss: 0.11730874329805374      \n",
      "train step #4635 accuracy: 0.953125, loss: 0.15636204183101654      \n",
      "train step #4636 accuracy: 0.890625, loss: 0.22230643033981323      \n",
      "train step #4637 accuracy: 0.984375, loss: 0.060445237904787064     \n",
      "train step #4638 accuracy: 0.9375, loss: 0.19504031538963318      \n",
      "train step #4639 accuracy: 0.921875, loss: 0.16858559846878052      \n",
      "train step #4640 accuracy: 0.953125, loss: 0.2580778896808624       \n",
      "train step #4641 accuracy: 0.984375, loss: 0.08881489187479019      \n",
      "train step #4642 accuracy:   1.0, loss: 0.03973538428544998      \n",
      "train step #4643 accuracy: 0.96875, loss: 0.18957234919071198      \n",
      "train step #4644 accuracy: 0.984375, loss: 0.06441839039325714      \n",
      "train step #4645 accuracy: 0.984375, loss: 0.10337219387292862      \n",
      "train step #4646 accuracy: 0.953125, loss: 0.20768998563289642      \n",
      "train step #4647 accuracy: 0.96875, loss: 0.09289898723363876      \n",
      "train step #4648 accuracy: 0.9375, loss: 0.19689854979515076      \n",
      "train step #4649 accuracy: 0.921875, loss: 0.20754654705524445      \n",
      "train step #4650 accuracy: 0.96875, loss: 0.14283953607082367      \n",
      "train step #4651 accuracy: 0.953125, loss: 0.23390640318393707      \n",
      "train step #4652 accuracy: 0.984375, loss: 0.09949135780334473      \n",
      "train step #4653 accuracy: 0.96875, loss: 0.1416916847229004       \n",
      "train step #4654 accuracy: 0.96875, loss: 0.15038785338401794      \n",
      "train step #4655 accuracy: 0.953125, loss: 0.17708538472652435      \n",
      "train step #4656 accuracy: 0.96875, loss: 0.11284788697957993      \n",
      "train step #4657 accuracy: 0.96875, loss: 0.09195835888385773      \n",
      "train step #4658 accuracy:   1.0, loss: 0.06254605948925018      \n",
      "train step #4659 accuracy: 0.953125, loss: 0.1875157356262207       \n",
      "train step #4660 accuracy: 0.96875, loss: 0.1301676630973816       \n",
      "train step #4661 accuracy: 0.96875, loss: 0.10449624061584473      \n",
      "train step #4662 accuracy: 0.984375, loss: 0.08613283932209015      \n",
      "train step #4663 accuracy: 0.984375, loss: 0.07930473238229752      \n",
      "train step #4664 accuracy: 0.9375, loss: 0.1992759108543396       \n",
      "train step #4665 accuracy: 0.9375, loss: 0.20538756251335144      \n",
      "train step #4666 accuracy: 0.953125, loss: 0.20319487154483795      \n",
      "train step #4667 accuracy: 0.953125, loss: 0.17502643167972565      \n",
      "train step #4668 accuracy: 0.984375, loss: 0.08917558938264847      \n",
      "train step #4669 accuracy:   1.0, loss: 0.09081192314624786      \n",
      "train step #4670 accuracy: 0.96875, loss: 0.07002216577529907      \n",
      "train step #4671 accuracy: 0.984375, loss: 0.08875692635774612      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #4672 accuracy: 0.96875, loss: 0.11495474725961685      \n",
      "train step #4673 accuracy: 0.96875, loss: 0.0690605565905571       \n",
      "train step #4674 accuracy: 0.96875, loss: 0.16801762580871582      \n",
      "train step #4675 accuracy: 0.921875, loss: 0.2716233432292938       \n",
      "train step #4676 accuracy: 0.984375, loss: 0.11955061554908752      \n",
      "train step #4677 accuracy: 0.953125, loss: 0.22054405510425568      \n",
      "train step #4678 accuracy: 0.984375, loss: 0.06388431787490845      \n",
      "train step #4679 accuracy: 0.9375, loss: 0.25976914167404175      \n",
      "train step #4680 accuracy: 0.9375, loss: 0.1251388043165207       \n",
      "train step #4681 accuracy: 0.96875, loss: 0.11435248702764511      \n",
      "train step #4682 accuracy: 0.984375, loss: 0.06993713229894638      \n",
      "train step #4683 accuracy: 0.96875, loss: 0.12441820651292801      \n",
      "train step #4684 accuracy: 0.984375, loss: 0.042651474475860596     \n",
      "train step #4685 accuracy: 0.953125, loss: 0.16664625704288483      \n",
      "train step #4686 accuracy: 0.921875, loss: 0.24916641414165497      \n",
      "train step #4687 accuracy: 0.984375, loss: 0.15231050550937653      \n",
      "train step #4688 accuracy: 0.96875, loss: 0.20159779489040375      \n",
      "train step #4689 accuracy: 0.9375, loss: 0.2189761996269226       \n",
      "train step #4690 accuracy: 0.9375, loss: 0.1655190885066986       \n",
      "train step #4691 accuracy: 0.953125, loss: 0.3455011248588562       \n",
      "train step #4692 accuracy: 0.984375, loss: 0.047916412353515625     \n",
      "train step #4693 accuracy: 0.96875, loss: 0.09346367418766022      \n",
      "train step #4694 accuracy: 0.984375, loss: 0.03260663151741028      \n",
      "train step #4695 accuracy: 0.984375, loss: 0.05732925981283188      \n",
      "train step #4696 accuracy: 0.96875, loss: 0.12098318338394165      \n",
      "train step #4697 accuracy: 0.90625, loss: 0.2900792360305786       \n",
      "train step #4698 accuracy: 0.953125, loss: 0.12489929050207138      \n",
      "train step #4699 accuracy: 0.984375, loss: 0.05868503451347351      \n",
      "train step #4700 accuracy: 0.984375, loss: 0.08727890253067017      \n",
      "train step #4701 accuracy: 0.921875, loss: 0.1429854929447174       \n",
      "train step #4702 accuracy: 0.96875, loss: 0.08405446261167526      \n",
      "train step #4703 accuracy: 0.953125, loss: 0.13967470824718475      \n",
      "train step #4704 accuracy:   1.0, loss: 0.033727698028087616     \n",
      "train step #4705 accuracy: 0.90625, loss: 0.32878896594047546      \n",
      "train step #4706 accuracy: 0.96875, loss: 0.11303401738405228      \n",
      "train step #4707 accuracy: 0.984375, loss: 0.06308206915855408      \n",
      "train step #4708 accuracy: 0.9375, loss: 0.19946953654289246      \n",
      "train step #4709 accuracy: 0.953125, loss: 0.2150338590145111       \n",
      "train step #4710 accuracy:   1.0, loss: 0.02308271825313568      \n",
      "train step #4711 accuracy: 0.96875, loss: 0.12575851380825043      \n",
      "train step #4712 accuracy: 0.9375, loss: 0.13044360280036926      \n",
      "train step #4713 accuracy: 0.96875, loss: 0.1515224575996399       \n",
      "train step #4714 accuracy: 0.9375, loss: 0.14167748391628265      \n",
      "train step #4715 accuracy: 0.96875, loss: 0.1279776394367218       \n",
      "train step #4716 accuracy: 0.921875, loss: 0.18304380774497986      \n",
      "train step #4717 accuracy: 0.921875, loss: 0.4040193259716034       \n",
      "train step #4718 accuracy: 0.96875, loss: 0.13606061041355133      \n",
      "train step #4719 accuracy: 0.984375, loss: 0.06609805673360825      \n",
      "train step #4720 accuracy: 0.953125, loss: 0.18760395050048828      \n",
      "train step #4721 accuracy:   1.0, loss: 0.06255245208740234      \n",
      "train step #4722 accuracy: 0.984375, loss: 0.07584036141633987      \n",
      "train step #4723 accuracy: 0.984375, loss: 0.10224177688360214      \n",
      "train step #4724 accuracy: 0.96875, loss: 0.18237510323524475      \n",
      "train step #4725 accuracy: 0.96875, loss: 0.17295832931995392      \n",
      "train step #4726 accuracy: 0.921875, loss: 0.2501927614212036       \n",
      "train step #4727 accuracy: 0.96875, loss: 0.1357596516609192       \n",
      "train step #4728 accuracy: 0.984375, loss: 0.06602200120687485      \n",
      "train step #4729 accuracy:   1.0, loss: 0.0279415100812912       \n",
      "train step #4730 accuracy:   1.0, loss: 0.0312860906124115       \n",
      "train step #4731 accuracy: 0.984375, loss: 0.05736195668578148      \n",
      "train step #4732 accuracy: 0.921875, loss: 0.23169797658920288      \n",
      "train step #4733 accuracy: 0.953125, loss: 0.1799381822347641       \n",
      "train step #4734 accuracy: 0.984375, loss: 0.04277592524886131      \n",
      "train step #4735 accuracy: 0.96875, loss: 0.10261844843626022      \n",
      "train step #4736 accuracy: 0.953125, loss: 0.2064501941204071       \n",
      "train step #4737 accuracy: 0.984375, loss: 0.05384812504053116      \n",
      "train step #4738 accuracy: 0.9375, loss: 0.2886722981929779       \n",
      "train step #4739 accuracy: 0.90625, loss: 0.3257683515548706       \n",
      "train step #4740 accuracy: 0.96875, loss: 0.12995249032974243      \n",
      "train step #4741 accuracy: 0.96875, loss: 0.08675923943519592      \n",
      "train step #4742 accuracy: 0.96875, loss: 0.09228402376174927      \n",
      "train step #4743 accuracy: 0.953125, loss: 0.16776129603385925      \n",
      "train step #4744 accuracy: 0.9375, loss: 0.26720064878463745      \n",
      "train step #4745 accuracy: 0.96875, loss: 0.11438954621553421      \n",
      "train step #4746 accuracy: 0.953125, loss: 0.19960139691829681      \n",
      "train step #4747 accuracy: 0.96875, loss: 0.06724453717470169      \n",
      "train step #4748 accuracy: 0.953125, loss: 0.16408771276474         \n",
      "train step #4749 accuracy: 0.953125, loss: 0.15743106603622437      \n",
      "train step #4750 accuracy: 0.96875, loss: 0.06246205419301987      \n",
      "train step #4751 accuracy: 0.96875, loss: 0.14660274982452393      \n",
      "train step #4752 accuracy: 0.96875, loss: 0.12598395347595215      \n",
      "train step #4753 accuracy: 0.9375, loss: 0.1990964561700821       \n",
      "train step #4754 accuracy: 0.953125, loss: 0.21361199021339417      \n",
      "train step #4755 accuracy: 0.9375, loss: 0.17672216892242432      \n",
      "train step #4756 accuracy: 0.96875, loss: 0.1645081639289856       \n",
      "train step #4757 accuracy: 0.953125, loss: 0.12704724073410034      \n",
      "train step #4758 accuracy: 0.96875, loss: 0.13174916803836823      \n",
      "train step #4759 accuracy: 0.96875, loss: 0.08736958354711533      \n",
      "train step #4760 accuracy: 0.984375, loss: 0.07087263464927673      \n",
      "train step #4761 accuracy: 0.96875, loss: 0.11696836352348328      \n",
      "train step #4762 accuracy: 0.953125, loss: 0.06865856051445007      \n",
      "train step #4763 accuracy: 0.9375, loss: 0.2482997477054596       \n",
      "train step #4764 accuracy: 0.984375, loss: 0.11052724719047546      \n",
      "train step #4765 accuracy: 0.953125, loss: 0.1885351687669754       \n",
      "train step #4766 accuracy: 0.984375, loss: 0.13593649864196777      \n",
      "train step #4767 accuracy: 0.953125, loss: 0.1461046040058136       \n",
      "train step #4768 accuracy: 0.90625, loss: 0.30184271931648254      \n",
      "train step #4769 accuracy: 0.984375, loss: 0.07188744843006134      \n",
      "train step #4770 accuracy: 0.984375, loss: 0.13308720290660858      \n",
      "train step #4771 accuracy: 0.9375, loss: 0.18405762314796448      \n",
      "train step #4772 accuracy: 0.96875, loss: 0.11011269688606262      \n",
      "train step #4773 accuracy: 0.984375, loss: 0.0350736528635025       \n",
      "train step #4774 accuracy: 0.984375, loss: 0.1029013991355896       \n",
      "train step #4775 accuracy: 0.9375, loss: 0.11737629771232605      \n",
      "train step #4776 accuracy: 0.953125, loss: 0.14936359226703644      \n",
      "train step #4777 accuracy: 0.921875, loss: 0.24437296390533447      \n",
      "train step #4778 accuracy: 0.953125, loss: 0.10739897936582565      \n",
      "train step #4779 accuracy:   1.0, loss: 0.045513737946748734     \n",
      "train step #4780 accuracy: 0.953125, loss: 0.19298718869686127      \n",
      "train step #4781 accuracy: 0.953125, loss: 0.18724456429481506      \n",
      "train step #4782 accuracy:   1.0, loss: 0.07791078835725784      \n",
      "train step #4783 accuracy: 0.96875, loss: 0.15066272020339966      \n",
      "train step #4784 accuracy: 0.953125, loss: 0.19017501175403595      \n",
      "train step #4785 accuracy: 0.9375, loss: 0.14338652789592743      \n",
      "train step #4786 accuracy: 0.9375, loss: 0.15287411212921143      \n",
      "train step #4787 accuracy: 0.9375, loss: 0.21693047881126404      \n",
      "train step #4788 accuracy: 0.96875, loss: 0.06304675340652466      \n",
      "train step #4789 accuracy: 0.984375, loss: 0.13872574269771576      \n",
      "train step #4790 accuracy: 0.984375, loss: 0.09819852560758591      \n",
      "train step #4791 accuracy: 0.953125, loss: 0.21157962083816528      \n",
      "train step #4792 accuracy: 0.96875, loss: 0.13557212054729462      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #4793 accuracy: 0.953125, loss: 0.2072426825761795       \n",
      "train step #4794 accuracy: 0.96875, loss: 0.09126567095518112      \n",
      "train step #4795 accuracy: 0.9375, loss: 0.151482492685318        \n",
      "train step #4796 accuracy:   1.0, loss: 0.048066750168800354     \n",
      "train step #4797 accuracy: 0.96875, loss: 0.10850045830011368      \n",
      "train step #4798 accuracy: 0.96875, loss: 0.10562703758478165      \n",
      "train step #4799 accuracy: 0.984375, loss: 0.09084809571504593      \n",
      "train step #4800 accuracy: 0.953125, loss: 0.2897529900074005       \n",
      "train step #4801 accuracy: 0.9375, loss: 0.11354444175958633      \n",
      "train step #4802 accuracy: 0.96875, loss: 0.11543406546115875      \n",
      "train step #4803 accuracy:   1.0, loss: 0.03245566040277481      \n",
      "train step #4804 accuracy: 0.953125, loss: 0.17760008573532104      \n",
      "train step #4805 accuracy: 0.96875, loss: 0.12288714945316315      \n",
      "train step #4806 accuracy: 0.96875, loss: 0.1777021288871765       \n",
      "train step #4807 accuracy: 0.96875, loss: 0.05003408342599869      \n",
      "train step #4808 accuracy: 0.953125, loss: 0.17425814270973206      \n",
      "train step #4809 accuracy: 0.984375, loss: 0.08097299188375473      \n",
      "train step #4810 accuracy: 0.9375, loss: 0.20009845495224         \n",
      "train step #4811 accuracy: 0.96875, loss: 0.08464767783880234      \n",
      "train step #4812 accuracy: 0.953125, loss: 0.17731153964996338      \n",
      "train step #4813 accuracy: 0.984375, loss: 0.039922986179590225     \n",
      "train step #4814 accuracy: 0.96875, loss: 0.12613947689533234      \n",
      "train step #4815 accuracy: 0.96875, loss: 0.09097965806722641      \n",
      "train step #4816 accuracy: 0.96875, loss: 0.12658028304576874      \n",
      "train step #4817 accuracy: 0.96875, loss: 0.10558939725160599      \n",
      "train step #4818 accuracy: 0.984375, loss: 0.11135298758745193      \n",
      "train step #4819 accuracy: 0.96875, loss: 0.07125713676214218      \n",
      "train step #4820 accuracy: 0.9375, loss: 0.23314854502677917      \n",
      "train step #4821 accuracy: 0.96875, loss: 0.16994933784008026      \n",
      "train step #4822 accuracy: 0.953125, loss: 0.1695663183927536       \n",
      "train step #4823 accuracy:   1.0, loss: 0.02063291147351265      \n",
      "train step #4824 accuracy: 0.984375, loss: 0.05269669368863106      \n",
      "train step #4825 accuracy: 0.953125, loss: 0.21763087809085846      \n",
      "train step #4826 accuracy: 0.921875, loss: 0.16520744562149048      \n",
      "train step #4827 accuracy: 0.984375, loss: 0.07856927812099457      \n",
      "train step #4828 accuracy: 0.96875, loss: 0.1867567002773285       \n",
      "train step #4829 accuracy: 0.921875, loss: 0.15340915322303772      \n",
      "train step #4830 accuracy: 0.984375, loss: 0.05815708637237549      \n",
      "train step #4831 accuracy:   1.0, loss: 0.03853391110897064      \n",
      "train step #4832 accuracy: 0.90625, loss: 0.3477209806442261       \n",
      "train step #4833 accuracy: 0.96875, loss: 0.10250110924243927      \n",
      "train step #4834 accuracy: 0.96875, loss: 0.1453641802072525       \n",
      "train step #4835 accuracy: 0.9375, loss: 0.19573135673999786      \n",
      "train step #4836 accuracy: 0.984375, loss: 0.10799810290336609      \n",
      "train step #4837 accuracy: 0.90625, loss: 0.24042801558971405      \n",
      "train step #4838 accuracy: 0.953125, loss: 0.1696031540632248       \n",
      "train step #4839 accuracy: 0.984375, loss: 0.10347398370504379      \n",
      "train step #4840 accuracy: 0.890625, loss: 0.21948888897895813      \n",
      "train step #4841 accuracy: 0.96875, loss: 0.16919276118278503      \n",
      "train step #4842 accuracy: 0.90625, loss: 0.30598950386047363      \n",
      "train step #4843 accuracy: 0.96875, loss: 0.1086888238787651       \n",
      "train step #4844 accuracy: 0.984375, loss: 0.10335943847894669      \n",
      "train step #4845 accuracy: 0.96875, loss: 0.15646280348300934      \n",
      "train step #4846 accuracy: 0.984375, loss: 0.08310472965240479      \n",
      "train step #4847 accuracy: 0.984375, loss: 0.07104422897100449      \n",
      "train step #4848 accuracy: 0.96875, loss: 0.1557113379240036       \n",
      "train step #4849 accuracy: 0.9375, loss: 0.17085649073123932      \n",
      "train step #4850 accuracy: 0.953125, loss: 0.12549880146980286      \n",
      "train step #4851 accuracy: 0.953125, loss: 0.23390072584152222      \n",
      "train step #4852 accuracy:   1.0, loss: 0.023956943303346634     \n",
      "train step #4853 accuracy: 0.984375, loss: 0.08444908261299133      \n",
      "train step #4854 accuracy: 0.953125, loss: 0.16195446252822876      \n",
      "train step #4855 accuracy: 0.96875, loss: 0.14700447022914886      \n",
      "train step #4856 accuracy: 0.96875, loss: 0.1550716906785965       \n",
      "train step #4857 accuracy: 0.984375, loss: 0.07154234498739243      \n",
      "train step #4858 accuracy: 0.984375, loss: 0.0726090744137764       \n",
      "dev accuracy:   1.0, loss: 0.026027292013168335     \n",
      "dev accuracy:   1.0, loss: 0.0339319109916687       \n",
      "dev accuracy:   1.0, loss: 0.06067842245101929      \n",
      "dev accuracy: 0.9375, loss: 0.17242157459259033      \n",
      "dev accuracy:   1.0, loss: 0.03869602084159851      \n",
      "dev accuracy:   1.0, loss: 0.03253120183944702      \n",
      "dev accuracy: 0.9375, loss: 0.14698076248168945      \n",
      "dev accuracy:   1.0, loss: 0.014724969863891602     \n",
      "dev accuracy:   1.0, loss: 0.0122469961643219       \n",
      "dev accuracy: 0.9375, loss: 0.30593204498291016      \n",
      "dev accuracy:   1.0, loss: 0.013705521821975708     \n",
      "dev accuracy:   1.0, loss: 0.005002349615097046     \n",
      "dev accuracy:   1.0, loss: 0.010406523942947388     \n",
      "dev accuracy: 0.9375, loss: 0.11247202754020691      \n",
      "dev accuracy: 0.9375, loss: 0.36971205472946167      \n",
      "dev accuracy:   1.0, loss: 0.0010735392570495605    \n",
      "dev accuracy:   1.0, loss: 0.032671600580215454     \n",
      "dev accuracy: 0.9375, loss: 0.16895055770874023      \n",
      "dev accuracy: 0.875, loss: 0.22999027371406555      \n",
      "dev accuracy: 0.9375, loss: 0.4205172061920166       \n",
      "dev accuracy: 0.8125, loss: 0.5698195099830627       \n",
      "dev accuracy: 0.9375, loss: 0.12327848374843597      \n",
      "dev accuracy:   1.0, loss: 0.02937859296798706      \n",
      "dev accuracy:   1.0, loss: 0.0016322731971740723    \n",
      "dev accuracy: 0.875, loss: 0.28154200315475464      \n",
      "dev accuracy:   1.0, loss: 0.0066953301429748535    \n",
      "dev accuracy: 0.9375, loss: 0.1666698455810547       \n",
      "dev accuracy:   1.0, loss: 0.013856709003448486     \n",
      "dev accuracy: 0.9375, loss: 0.3648220896720886       \n",
      "dev accuracy:   1.0, loss: 0.015599042177200317     \n",
      "dev accuracy: 0.9375, loss: 0.14235946536064148      \n",
      "dev accuracy:   1.0, loss: 0.040524423122406006     \n",
      "dev accuracy: 0.9375, loss: 0.2174397110939026       \n",
      "dev accuracy: 0.875, loss: 0.6171493530273438       \n",
      "dev accuracy: 0.9375, loss: 0.12060524523258209      \n",
      "dev accuracy:   1.0, loss: 0.032710909843444824     \n",
      "dev accuracy:   1.0, loss: 0.025064736604690552     \n",
      "dev accuracy: 0.9375, loss: 0.1498008668422699       \n",
      "dev accuracy:  0.75, loss: 0.6447368860244751       \n",
      "dev accuracy: 0.9375, loss: 0.17479732632637024      \n",
      "dev accuracy: 0.9375, loss: 0.24684396386146545      \n",
      "dev accuracy:   1.0, loss: 0.024632394313812256     \n",
      "dev accuracy:   1.0, loss: 0.003630906343460083     \n",
      "dev accuracy: 0.875, loss: 0.37140151858329773      \n",
      "dev accuracy: 0.875, loss: 0.5822402834892273       \n",
      "dev accuracy: 0.9375, loss: 0.44870725274086         \n",
      "dev accuracy:   1.0, loss: 0.008122891187667847     \n",
      "dev accuracy: 0.875, loss: 0.3666301667690277       \n",
      "dev accuracy: 0.9375, loss: 0.22565066814422607      \n",
      "dev accuracy:   1.0, loss: 0.004288733005523682     \n",
      "dev accuracy:   1.0, loss: 0.08372518420219421      \n",
      "dev accuracy: 0.9375, loss: 0.16754020750522614      \n",
      "dev accuracy: 0.9375, loss: 0.07891342043876648      \n",
      "dev accuracy: 0.875, loss: 0.22172090411186218      \n",
      "dev accuracy: 0.9375, loss: 0.29494985938072205      \n",
      "dev accuracy:   1.0, loss: 0.028390735387802124     \n",
      "dev accuracy: 0.875, loss: 0.4994601905345917       \n",
      "dev accuracy:   1.0, loss: 0.09424437582492828      \n",
      "dev accuracy:   1.0, loss: 0.0016894936561584473    \n",
      "dev accuracy:   1.0, loss: 0.046275705099105835     \n",
      "dev accuracy: 0.875, loss: 0.2413819432258606       \n",
      "dev accuracy:   1.0, loss: 0.01578560471534729      \n",
      "dev accuracy:   1.0, loss: 0.003289937973022461     \n",
      "dev accuracy:   1.0, loss: 0.008758962154388428     \n",
      "dev accuracy: 0.9375, loss: 0.10809791088104248      \n",
      "dev accuracy: 0.9375, loss: 0.12274366617202759      \n",
      "dev accuracy:   1.0, loss: 0.07948276400566101      \n",
      "dev accuracy: 0.875, loss: 0.2560668885707855       \n",
      "dev accuracy:   1.0, loss: 0.003954172134399414     \n",
      "dev accuracy:   1.0, loss: 0.004219412803649902     \n",
      "dev accuracy:   1.0, loss: 0.11395178735256195      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy:   1.0, loss: 0.03830835223197937      \n",
      "dev accuracy:   1.0, loss: 0.048653244972229004     \n",
      "dev accuracy: 0.9375, loss: 0.22789211571216583      \n",
      "dev accuracy:   1.0, loss: 0.04924607276916504      \n",
      "dev accuracy:   1.0, loss: 0.041128456592559814     \n",
      "dev accuracy: 0.9375, loss: 0.12117272615432739      \n",
      "dev accuracy:   1.0, loss: 0.012014150619506836     \n",
      "dev accuracy: 0.9375, loss: 0.1530616730451584       \n",
      "dev accuracy: 0.9375, loss: 0.38479799032211304      \n",
      "dev accuracy: 0.875, loss: 0.29625123739242554      \n",
      "dev accuracy:   1.0, loss: 0.0061910152435302734    \n",
      "dev accuracy:   1.0, loss: 0.004793226718902588     \n",
      "dev accuracy: 0.875, loss: 0.3442337214946747       \n",
      "dev accuracy:   1.0, loss: 0.003226727247238159     \n",
      "dev accuracy: 0.875, loss: 0.16640815138816833      \n",
      "dev accuracy:   1.0, loss: 0.011220663785934448     \n",
      "dev accuracy: 0.8125, loss: 0.7238321900367737       \n",
      "dev accuracy: 0.9375, loss: 0.13856077194213867      \n",
      "dev accuracy: 0.875, loss: 0.2828293442726135       \n",
      "dev accuracy: 0.875, loss: 0.7179090976715088       \n",
      "dev accuracy: 0.8125, loss: 0.43830469250679016      \n",
      "dev accuracy: 0.875, loss: 0.7731015086174011       \n",
      "dev accuracy:   1.0, loss: 0.002859354019165039     \n",
      "dev accuracy:   1.0, loss: 0.043333351612091064     \n",
      "dev accuracy: 0.9375, loss: 0.19152577221393585      \n",
      "dev accuracy:   1.0, loss: 0.03325444459915161      \n",
      "dev accuracy:   1.0, loss: 0.047102078795433044     \n",
      "dev accuracy: 0.9375, loss: 0.38330078125            \n",
      "dev accuracy: 0.9375, loss: 0.15024566650390625      \n",
      "dev accuracy:   1.0, loss: 0.01379483938217163      \n",
      "dev accuracy:   1.0, loss: 0.016367048025131226     \n",
      "dev accuracy:   1.0, loss: 0.008101105690002441     \n",
      "dev accuracy:   1.0, loss: 0.013713657855987549     \n",
      "dev accuracy: 0.8125, loss: 0.43268150091171265      \n",
      "dev accuracy:   1.0, loss: 0.015287905931472778     \n",
      "dev accuracy: 0.9375, loss: 0.2665385603904724       \n",
      "dev accuracy:   1.0, loss: 0.008130073547363281     \n",
      "dev accuracy: 0.875, loss: 0.32870936393737793      \n",
      "dev accuracy: 0.875, loss: 0.18840114772319794      \n",
      "dev accuracy:   1.0, loss: 0.1551337093114853       \n",
      "dev accuracy: 0.9375, loss: 0.14026743173599243      \n",
      "dev accuracy:   1.0, loss: 0.01776030659675598      \n",
      "dev accuracy:   1.0, loss: 0.0015614330768585205    \n",
      "dev accuracy:   1.0, loss: 0.027064859867095947     \n",
      "dev accuracy:   1.0, loss: 0.020000189542770386     \n",
      "dev accuracy:   1.0, loss: 0.07876354455947876      \n",
      "dev accuracy:   1.0, loss: 0.04399985074996948      \n",
      "dev accuracy: 0.9375, loss: 0.1729765236377716       \n",
      "dev accuracy: 0.8125, loss: 0.7172804474830627       \n",
      "dev accuracy: 0.9375, loss: 0.19597268104553223      \n",
      "dev accuracy:   1.0, loss: 0.061270713806152344     \n",
      "dev accuracy:   1.0, loss: 0.06342998147010803      \n",
      "dev accuracy:   1.0, loss: 0.006964892148971558     \n",
      "dev accuracy: 0.9375, loss: 0.21102699637413025      \n",
      "dev accuracy: 0.875, loss: 0.28925764560699463      \n",
      "dev accuracy: 0.8125, loss: 0.677513599395752        \n",
      "dev accuracy:   1.0, loss: 0.04264557361602783      \n",
      "dev accuracy:   1.0, loss: 0.0022257864475250244    \n",
      "dev accuracy:   1.0, loss: 0.000780642032623291     \n",
      "dev accuracy:   1.0, loss: 0.031099334359169006     \n",
      "dev accuracy: 0.8125, loss: 0.7211297750473022       \n",
      "dev accuracy:  0.75, loss: 0.6886361837387085       \n",
      "dev accuracy:   1.0, loss: 0.02212393283843994      \n",
      "dev accuracy:   1.0, loss: 0.0488685667514801       \n",
      "dev accuracy:   1.0, loss: 0.018606722354888916     \n",
      "dev accuracy: 0.875, loss: 0.33314916491508484      \n",
      "dev accuracy:   1.0, loss: 0.05772349238395691      \n",
      "dev accuracy: 0.9375, loss: 0.12520620226860046      \n",
      "dev accuracy: 0.875, loss: 0.38782796263694763      \n",
      "dev accuracy:   1.0, loss: 0.0008652806282043457    \n",
      "dev accuracy:   1.0, loss: 0.007774293422698975     \n",
      "dev accuracy: 0.9375, loss: 0.2695487141609192       \n",
      "dev accuracy:   1.0, loss: 0.021482467651367188     \n",
      "dev accuracy:   1.0, loss: 0.03225407004356384      \n",
      "dev accuracy:   1.0, loss: 0.053014904260635376     \n",
      "dev accuracy: 0.9375, loss: 0.15782994031906128      \n",
      "dev accuracy: 0.8125, loss: 0.5212717056274414       \n",
      "dev accuracy:   1.0, loss: 0.016287624835968018     \n",
      "dev accuracy:   1.0, loss: 0.002871215343475342     \n",
      "dev accuracy:   1.0, loss: 0.020264625549316406     \n",
      "dev accuracy: 0.9375, loss: 0.07911801338195801      \n",
      "dev accuracy:   1.0, loss: 0.0467204749584198       \n",
      "dev accuracy: 0.9375, loss: 0.077688068151474        \n",
      "dev accuracy: 0.9375, loss: 0.29125162959098816      \n",
      "dev accuracy:   1.0, loss: 0.0037021636962890625    \n",
      "dev accuracy: 0.875, loss: 0.436197429895401        \n",
      "dev accuracy:   1.0, loss: 0.03438326716423035      \n",
      "dev accuracy:   1.0, loss: 0.0021286606788635254    \n",
      "dev accuracy:   1.0, loss: 0.0020276308059692383    \n",
      "dev accuracy:   1.0, loss: 0.001983165740966797     \n",
      "dev accuracy:   1.0, loss: 0.005782604217529297     \n",
      "dev accuracy:   1.0, loss: 0.05139842629432678      \n",
      "dev accuracy:   1.0, loss: 0.056044936180114746     \n",
      "dev accuracy:   1.0, loss: 0.012581557035446167     \n",
      "dev accuracy:   1.0, loss: 0.009048879146575928     \n",
      "dev accuracy: 0.9375, loss: 0.5019164085388184       \n",
      "dev accuracy: 0.875, loss: 0.3522028923034668       \n",
      "dev accuracy: 0.9375, loss: 0.21922366321086884      \n",
      "dev accuracy:   1.0, loss: 0.005960941314697266     \n",
      "dev accuracy: 0.875, loss: 0.248064786195755        \n",
      "dev accuracy:   1.0, loss: 0.042449742555618286     \n",
      "dev accuracy: 0.9375, loss: 0.3572210669517517       \n",
      "dev accuracy: 0.9375, loss: 0.7482328414916992       \n",
      "dev accuracy: 0.9375, loss: 0.09731946885585785      \n",
      "dev accuracy:   1.0, loss: 0.04929383099079132      \n",
      "dev accuracy:   1.0, loss: 0.023438990116119385     \n",
      "dev accuracy: 0.8125, loss: 0.5134313702583313       \n",
      "dev accuracy: 0.875, loss: 0.43052610754966736      \n",
      "dev accuracy: 0.875, loss: 0.539749026298523        \n",
      "dev accuracy:   1.0, loss: 0.010542571544647217     \n",
      "dev accuracy: 0.9375, loss: 0.31754428148269653      \n",
      "dev accuracy: 0.9375, loss: 0.1339091658592224       \n",
      "dev accuracy: 0.9375, loss: 0.11502689123153687      \n",
      "dev accuracy: 0.875, loss: 0.4266493618488312       \n",
      "dev accuracy:   1.0, loss: 0.004208385944366455     \n",
      "dev accuracy: 0.9375, loss: 0.13006897270679474      \n",
      "dev accuracy: 0.875, loss: 0.2323419600725174       \n",
      "dev accuracy: 0.9375, loss: 0.09002178907394409      \n",
      "dev accuracy: 0.9375, loss: 0.34449058771133423      \n",
      "dev accuracy:   1.0, loss: 0.014728009700775146     \n",
      "dev accuracy: 0.9375, loss: 0.19966912269592285      \n",
      "dev accuracy:   1.0, loss: 0.0601840615272522       \n",
      "dev accuracy:   1.0, loss: 0.011097590439021587     \n",
      "final dev accuracy: 0.9532860824742269\n",
      "saving best model...\n",
      "train step #4859 accuracy: 0.9375, loss: 0.2318050116300583       \n",
      "train step #4860 accuracy: 0.984375, loss: 0.04455591365695         \n",
      "train step #4861 accuracy: 0.96875, loss: 0.1562836468219757       \n",
      "train step #4862 accuracy: 0.984375, loss: 0.07736989855766296      \n",
      "train step #4863 accuracy: 0.921875, loss: 0.32664796710014343      \n",
      "train step #4864 accuracy: 0.96875, loss: 0.06606216728687286      \n",
      "train step #4865 accuracy:   1.0, loss: 0.03133385628461838      \n",
      "train step #4866 accuracy:   1.0, loss: 0.027203232049942017     \n",
      "train step #4867 accuracy: 0.953125, loss: 0.22976525127887726      \n",
      "train step #4868 accuracy: 0.9375, loss: 0.16276732087135315      \n",
      "train step #4869 accuracy: 0.984375, loss: 0.12374749034643173      \n",
      "train step #4870 accuracy: 0.984375, loss: 0.04815443605184555      \n",
      "train step #4871 accuracy: 0.9375, loss: 0.25903376936912537      \n",
      "train step #4872 accuracy: 0.890625, loss: 0.34884005784988403      \n",
      "train step #4873 accuracy: 0.9375, loss: 0.22518526017665863      \n",
      "train step #4874 accuracy: 0.953125, loss: 0.19596154987812042      \n",
      "train step #4875 accuracy: 0.984375, loss: 0.10155873000621796      \n",
      "train step #4876 accuracy: 0.953125, loss: 0.1317829042673111       \n",
      "train step #4877 accuracy: 0.96875, loss: 0.13477391004562378      \n",
      "train step #4878 accuracy: 0.96875, loss: 0.09587004780769348      \n",
      "train step #4879 accuracy: 0.953125, loss: 0.14899928867816925      \n",
      "train step #4880 accuracy: 0.953125, loss: 0.09372781962156296      \n",
      "train step #4881 accuracy: 0.953125, loss: 0.19293849170207977      \n",
      "train step #4882 accuracy: 0.953125, loss: 0.20033422112464905      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #4883 accuracy: 0.96875, loss: 0.12377788126468658      \n",
      "train step #4884 accuracy: 0.953125, loss: 0.20185969769954681      \n",
      "train step #4885 accuracy: 0.96875, loss: 0.1778212934732437       \n",
      "train step #4886 accuracy: 0.96875, loss: 0.13668867945671082      \n",
      "train step #4887 accuracy: 0.96875, loss: 0.2138916403055191       \n",
      "train step #4888 accuracy: 0.96875, loss: 0.12117060273885727      \n",
      "train step #4889 accuracy:   1.0, loss: 0.03776610642671585      \n",
      "train step #4890 accuracy: 0.9375, loss: 0.17093728482723236      \n",
      "train step #4891 accuracy: 0.9375, loss: 0.2386469542980194       \n",
      "train step #4892 accuracy: 0.96875, loss: 0.11843361705541611      \n",
      "train step #4893 accuracy: 0.96875, loss: 0.09457066655158997      \n",
      "train step #4894 accuracy: 0.96875, loss: 0.09889949858188629      \n",
      "train step #4895 accuracy: 0.96875, loss: 0.10378357023000717      \n",
      "train step #4896 accuracy: 0.953125, loss: 0.140694260597229        \n",
      "train step #4897 accuracy:   1.0, loss: 0.04864243045449257      \n",
      "train step #4898 accuracy: 0.984375, loss: 0.07792435586452484      \n",
      "train step #4899 accuracy: 0.953125, loss: 0.16969195008277893      \n",
      "train step #4900 accuracy: 0.96875, loss: 0.11274028569459915      \n",
      "train step #4901 accuracy: 0.953125, loss: 0.16571199893951416      \n",
      "train step #4902 accuracy: 0.96875, loss: 0.0904683992266655       \n",
      "train step #4903 accuracy: 0.984375, loss: 0.09019999206066132      \n",
      "train step #4904 accuracy: 0.984375, loss: 0.0854557678103447       \n",
      "train step #4905 accuracy: 0.984375, loss: 0.07597942650318146      \n",
      "train step #4906 accuracy: 0.9375, loss: 0.14577245712280273      \n",
      "train step #4907 accuracy: 0.953125, loss: 0.1375310868024826       \n",
      "train step #4908 accuracy: 0.984375, loss: 0.08315863460302353      \n",
      "train step #4909 accuracy: 0.953125, loss: 0.2169492542743683       \n",
      "train step #4910 accuracy: 0.953125, loss: 0.16389915347099304      \n",
      "train step #4911 accuracy: 0.953125, loss: 0.20871375501155853      \n",
      "train step #4912 accuracy: 0.96875, loss: 0.09446722269058228      \n",
      "train step #4913 accuracy: 0.984375, loss: 0.10030714422464371      \n",
      "train step #4914 accuracy: 0.984375, loss: 0.03712897747755051      \n",
      "train step #4915 accuracy: 0.953125, loss: 0.17307762801647186      \n",
      "train step #4916 accuracy: 0.984375, loss: 0.07671945542097092      \n",
      "train step #4917 accuracy:   1.0, loss: 0.02501843497157097      \n",
      "train step #4918 accuracy: 0.921875, loss: 0.23334327340126038      \n",
      "train step #4919 accuracy: 0.96875, loss: 0.12437449395656586      \n",
      "train step #4920 accuracy: 0.953125, loss: 0.17603744566440582      \n",
      "train step #4921 accuracy: 0.921875, loss: 0.2974763512611389       \n",
      "train step #4922 accuracy: 0.9375, loss: 0.18513062596321106      \n",
      "train step #4923 accuracy: 0.984375, loss: 0.11032774299383163      \n",
      "train step #4924 accuracy: 0.96875, loss: 0.15282417833805084      \n",
      "train step #4925 accuracy: 0.984375, loss: 0.05771269276738167      \n",
      "train step #4926 accuracy: 0.953125, loss: 0.15955449640750885      \n",
      "train step #4927 accuracy: 0.984375, loss: 0.07510748505592346      \n",
      "train step #4928 accuracy: 0.984375, loss: 0.10289651900529861      \n",
      "train step #4929 accuracy: 0.984375, loss: 0.06983379274606705      \n",
      "train step #4930 accuracy: 0.953125, loss: 0.10263524949550629      \n",
      "train step #4931 accuracy: 0.984375, loss: 0.08429093658924103      \n",
      "train step #4932 accuracy: 0.953125, loss: 0.15758761763572693      \n",
      "train step #4933 accuracy: 0.96875, loss: 0.12374304980039597      \n",
      "train step #4934 accuracy: 0.9375, loss: 0.19375908374786377      \n",
      "train step #4935 accuracy: 0.984375, loss: 0.0933188647031784       \n",
      "train step #4936 accuracy:   1.0, loss: 0.08662335574626923      \n",
      "train step #4937 accuracy: 0.96875, loss: 0.10675343871116638      \n",
      "train step #4938 accuracy: 0.984375, loss: 0.060084473341703415     \n",
      "train step #4939 accuracy: 0.96875, loss: 0.10468357056379318      \n",
      "train step #4940 accuracy: 0.96875, loss: 0.07982977479696274      \n",
      "train step #4941 accuracy: 0.96875, loss: 0.12973305583000183      \n",
      "train step #4942 accuracy: 0.984375, loss: 0.07643212378025055      \n",
      "train step #4943 accuracy: 0.96875, loss: 0.05536472797393799      \n",
      "train step #4944 accuracy: 0.96875, loss: 0.1515485793352127       \n",
      "train step #4945 accuracy: 0.984375, loss: 0.07733215391635895      \n",
      "train step #4946 accuracy: 0.921875, loss: 0.25821512937545776      \n",
      "train step #4947 accuracy: 0.984375, loss: 0.14719700813293457      \n",
      "train step #4948 accuracy: 0.953125, loss: 0.1629103422164917       \n",
      "train step #4949 accuracy: 0.9375, loss: 0.2924998998641968       \n",
      "train step #4950 accuracy: 0.953125, loss: 0.1449059098958969       \n",
      "train step #4951 accuracy: 0.953125, loss: 0.19458745419979095      \n",
      "train step #4952 accuracy: 0.96875, loss: 0.08001585304737091      \n",
      "train step #4953 accuracy: 0.953125, loss: 0.124465212225914        \n",
      "train step #4954 accuracy: 0.96875, loss: 0.11723366379737854      \n",
      "train step #4955 accuracy: 0.96875, loss: 0.1435193568468094       \n",
      "train step #4956 accuracy: 0.984375, loss: 0.06374430656433105      \n",
      "train step #4957 accuracy: 0.953125, loss: 0.23640385270118713      \n",
      "train step #4958 accuracy: 0.921875, loss: 0.25448060035705566      \n",
      "train step #4959 accuracy: 0.9375, loss: 0.27411505579948425      \n",
      "train step #4960 accuracy: 0.984375, loss: 0.05382555350661278      \n",
      "train step #4961 accuracy: 0.96875, loss: 0.10280220210552216      \n",
      "train step #4962 accuracy: 0.9375, loss: 0.1954391598701477       \n",
      "train step #4963 accuracy: 0.953125, loss: 0.1858331859111786       \n",
      "train step #4964 accuracy: 0.921875, loss: 0.3521263003349304       \n",
      "train step #4965 accuracy: 0.953125, loss: 0.13170242309570312      \n",
      "train step #4966 accuracy: 0.9375, loss: 0.19220459461212158      \n",
      "train step #4967 accuracy: 0.96875, loss: 0.10450142621994019      \n",
      "train step #4968 accuracy: 0.984375, loss: 0.06190134212374687      \n",
      "train step #4969 accuracy: 0.984375, loss: 0.07588547468185425      \n",
      "train step #4970 accuracy: 0.96875, loss: 0.11697076261043549      \n",
      "train step #4971 accuracy: 0.984375, loss: 0.07702124863862991      \n",
      "train step #4972 accuracy: 0.96875, loss: 0.151153102517128        \n",
      "train step #4973 accuracy:   1.0, loss: 0.029527679085731506     \n",
      "train step #4974 accuracy: 0.953125, loss: 0.13533897697925568      \n",
      "train step #4975 accuracy: 0.9375, loss: 0.2263379842042923       \n",
      "train step #4976 accuracy:   1.0, loss: 0.01862284168601036      \n",
      "train step #4977 accuracy: 0.953125, loss: 0.17707356810569763      \n",
      "train step #4978 accuracy: 0.90625, loss: 0.20737794041633606      \n",
      "train step #4979 accuracy: 0.921875, loss: 0.32570576667785645      \n",
      "train step #4980 accuracy: 0.984375, loss: 0.10660309344530106      \n",
      "train step #4981 accuracy:   1.0, loss: 0.04075207561254501      \n",
      "train step #4982 accuracy: 0.984375, loss: 0.08190415799617767      \n",
      "train step #4983 accuracy: 0.953125, loss: 0.1678490936756134       \n",
      "train step #4984 accuracy: 0.96875, loss: 0.14545413851737976      \n",
      "train step #4985 accuracy: 0.953125, loss: 0.23276162147521973      \n",
      "train step #4986 accuracy: 0.984375, loss: 0.15028630197048187      \n",
      "train step #4987 accuracy: 0.984375, loss: 0.06149758771061897      \n",
      "train step #4988 accuracy: 0.921875, loss: 0.20454269647598267      \n",
      "train step #4989 accuracy: 0.96875, loss: 0.09736998379230499      \n",
      "train step #4990 accuracy: 0.921875, loss: 0.3066510260105133       \n",
      "train step #4991 accuracy:   1.0, loss: 0.030122671276330948     \n",
      "train step #4992 accuracy: 0.96875, loss: 0.09722607582807541      \n",
      "train step #4993 accuracy: 0.984375, loss: 0.07286706566810608      \n",
      "train step #4994 accuracy: 0.984375, loss: 0.11322945356369019      \n",
      "train step #4995 accuracy: 0.90625, loss: 0.2891552150249481       \n",
      "train step #4996 accuracy: 0.96875, loss: 0.12855291366577148      \n",
      "train step #4997 accuracy:   1.0, loss: 0.03049156814813614      \n",
      "train step #4998 accuracy: 0.953125, loss: 0.15927886962890625      \n",
      "train step #4999 accuracy: 0.9375, loss: 0.21871709823608398      \n",
      "train step #5000 accuracy: 0.96875, loss: 0.18605472147464752      \n",
      "train step #5001 accuracy: 0.9375, loss: 0.14314395189285278      \n",
      "train step #5002 accuracy: 0.984375, loss: 0.07520359754562378      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #5003 accuracy: 0.953125, loss: 0.09963131695985794      \n",
      "train step #5004 accuracy: 0.9375, loss: 0.14836150407791138      \n",
      "train step #5005 accuracy: 0.96875, loss: 0.17721664905548096      \n",
      "train step #5006 accuracy: 0.96875, loss: 0.11254820972681046      \n",
      "train step #5007 accuracy: 0.953125, loss: 0.18470820784568787      \n",
      "train step #5008 accuracy: 0.96875, loss: 0.1697302907705307       \n",
      "train step #5009 accuracy: 0.96875, loss: 0.17338815331459045      \n",
      "train step #5010 accuracy: 0.984375, loss: 0.07731717824935913      \n",
      "train step #5011 accuracy:   1.0, loss: 0.04576132446527481      \n",
      "train step #5012 accuracy: 0.984375, loss: 0.047980379313230515     \n",
      "train step #5013 accuracy: 0.96875, loss: 0.08840036392211914      \n",
      "train step #5014 accuracy: 0.984375, loss: 0.07353799790143967      \n",
      "train step #5015 accuracy: 0.953125, loss: 0.2989013195037842       \n",
      "train step #5016 accuracy: 0.984375, loss: 0.10911531746387482      \n",
      "train step #5017 accuracy: 0.984375, loss: 0.05899138003587723      \n",
      "train step #5018 accuracy: 0.953125, loss: 0.11112994700670242      \n",
      "train step #5019 accuracy: 0.984375, loss: 0.06360743939876556      \n",
      "train step #5020 accuracy: 0.984375, loss: 0.1224445253610611       \n",
      "train step #5021 accuracy:   1.0, loss: 0.018217317759990692     \n",
      "train step #5022 accuracy: 0.96875, loss: 0.18095466494560242      \n",
      "train step #5023 accuracy: 0.953125, loss: 0.2128521353006363       \n",
      "train step #5024 accuracy: 0.9375, loss: 0.2241239696741104       \n",
      "train step #5025 accuracy:   1.0, loss: 0.024761773645877838     \n",
      "train step #5026 accuracy: 0.953125, loss: 0.1421285718679428       \n",
      "train step #5027 accuracy: 0.9375, loss: 0.13285239040851593      \n",
      "train step #5028 accuracy: 0.9375, loss: 0.22485505044460297      \n",
      "train step #5029 accuracy: 0.9375, loss: 0.18438422679901123      \n",
      "train step #5030 accuracy: 0.984375, loss: 0.07269896566867828      \n",
      "train step #5031 accuracy: 0.96875, loss: 0.04647441953420639      \n",
      "train step #5032 accuracy: 0.96875, loss: 0.0883694440126419       \n",
      "train step #5033 accuracy: 0.9375, loss: 0.18974336981773376      \n",
      "train step #5034 accuracy: 0.953125, loss: 0.16477389633655548      \n",
      "train step #5035 accuracy: 0.953125, loss: 0.22992360591888428      \n",
      "train step #5036 accuracy: 0.953125, loss: 0.12581130862236023      \n",
      "train step #5037 accuracy: 0.96875, loss: 0.17028464376926422      \n",
      "train step #5038 accuracy: 0.96875, loss: 0.09201490134000778      \n",
      "train step #5039 accuracy: 0.96875, loss: 0.15127265453338623      \n",
      "train step #5040 accuracy: 0.96875, loss: 0.17632800340652466      \n",
      "train step #5041 accuracy: 0.984375, loss: 0.0912381112575531       \n",
      "train step #5042 accuracy: 0.96875, loss: 0.0734570324420929       \n",
      "train step #5043 accuracy: 0.96875, loss: 0.19498635828495026      \n",
      "train step #5044 accuracy: 0.953125, loss: 0.18576186895370483      \n",
      "train step #5045 accuracy: 0.953125, loss: 0.10941226780414581      \n",
      "train step #5046 accuracy:   1.0, loss: 0.009038165211677551     \n",
      "train step #5047 accuracy: 0.953125, loss: 0.14760538935661316      \n",
      "train step #5048 accuracy: 0.953125, loss: 0.16919063031673431      \n",
      "train step #5049 accuracy: 0.953125, loss: 0.14887696504592896      \n",
      "train step #5050 accuracy: 0.96875, loss: 0.206217423081398        \n",
      "train step #5051 accuracy: 0.953125, loss: 0.12174010276794434      \n",
      "train step #5052 accuracy: 0.96875, loss: 0.1027621179819107       \n",
      "train step #5053 accuracy: 0.96875, loss: 0.06232567876577377      \n",
      "train step #5054 accuracy: 0.9375, loss: 0.27923494577407837      \n",
      "train step #5055 accuracy: 0.96875, loss: 0.17275339365005493      \n",
      "train step #5056 accuracy: 0.953125, loss: 0.20890690386295319      \n",
      "train step #5057 accuracy:   1.0, loss: 0.04559048265218735      \n",
      "train step #5058 accuracy:   1.0, loss: 0.03227455914020538      \n",
      "train step #5059 accuracy:   1.0, loss: 0.028951242566108704     \n",
      "train step #5060 accuracy:   1.0, loss: 0.02534104883670807      \n",
      "train step #5061 accuracy: 0.953125, loss: 0.10290494561195374      \n",
      "train step #5062 accuracy: 0.953125, loss: 0.17874857783317566      \n",
      "train step #5063 accuracy: 0.953125, loss: 0.16620700061321259      \n",
      "train step #5064 accuracy: 0.921875, loss: 0.22653532028198242      \n",
      "train step #5065 accuracy: 0.9375, loss: 0.1694512963294983       \n",
      "train step #5066 accuracy: 0.984375, loss: 0.06957422941923141      \n",
      "train step #5067 accuracy: 0.984375, loss: 0.03413105010986328      \n",
      "train step #5068 accuracy:   1.0, loss: 0.04701464623212814      \n",
      "train step #5069 accuracy: 0.984375, loss: 0.06878727674484253      \n",
      "train step #5070 accuracy: 0.984375, loss: 0.11378127336502075      \n",
      "train step #5071 accuracy: 0.984375, loss: 0.09301100671291351      \n",
      "train step #5072 accuracy: 0.953125, loss: 0.16059236228466034      \n",
      "train step #5073 accuracy: 0.984375, loss: 0.04205170273780823      \n",
      "train step #5074 accuracy: 0.984375, loss: 0.10243971645832062      \n",
      "train step #5075 accuracy: 0.984375, loss: 0.06622439622879028      \n",
      "train step #5076 accuracy:   1.0, loss: 0.03184682875871658      \n",
      "train step #5077 accuracy: 0.953125, loss: 0.18581056594848633      \n",
      "train step #5078 accuracy: 0.953125, loss: 0.23406285047531128      \n",
      "train step #5079 accuracy: 0.9375, loss: 0.24235187470912933      \n",
      "train step #5080 accuracy: 0.96875, loss: 0.13164077699184418      \n",
      "train step #5081 accuracy: 0.90625, loss: 0.23672574758529663      \n",
      "train step #5082 accuracy: 0.9375, loss: 0.22562359273433685      \n",
      "train step #5083 accuracy: 0.9375, loss: 0.1363057941198349       \n",
      "train step #5084 accuracy: 0.984375, loss: 0.07552693784236908      \n",
      "train step #5085 accuracy: 0.984375, loss: 0.08416411280632019      \n",
      "train step #5086 accuracy: 0.953125, loss: 0.11550899595022202      \n",
      "train step #5087 accuracy: 0.953125, loss: 0.07678300887346268      \n",
      "train step #5088 accuracy: 0.984375, loss: 0.0590251199901104       \n",
      "train step #5089 accuracy: 0.96875, loss: 0.11370611190795898      \n",
      "train step #5090 accuracy: 0.984375, loss: 0.09444516897201538      \n",
      "train step #5091 accuracy: 0.953125, loss: 0.18018698692321777      \n",
      "train step #5092 accuracy: 0.96875, loss: 0.14258359372615814      \n",
      "train step #5093 accuracy: 0.96875, loss: 0.10700047761201859      \n",
      "train step #5094 accuracy: 0.984375, loss: 0.07733795046806335      \n",
      "train step #5095 accuracy: 0.96875, loss: 0.10311117023229599      \n",
      "train step #5096 accuracy: 0.9375, loss: 0.25934624671936035      \n",
      "train step #5097 accuracy: 0.921875, loss: 0.26361072063446045      \n",
      "train step #5098 accuracy: 0.96875, loss: 0.27975893020629883      \n",
      "train step #5099 accuracy: 0.96875, loss: 0.10439147055149078      \n",
      "train step #5100 accuracy: 0.96875, loss: 0.05861347168684006      \n",
      "train step #5101 accuracy: 0.953125, loss: 0.18128512799739838      \n",
      "train step #5102 accuracy: 0.921875, loss: 0.23933365941047668      \n",
      "train step #5103 accuracy: 0.984375, loss: 0.06331440806388855      \n",
      "train step #5104 accuracy: 0.96875, loss: 0.16555748879909515      \n",
      "train step #5105 accuracy: 0.953125, loss: 0.2272425889968872       \n",
      "train step #5106 accuracy: 0.953125, loss: 0.15529558062553406      \n",
      "train step #5107 accuracy: 0.984375, loss: 0.062324345111846924     \n",
      "train step #5108 accuracy: 0.96875, loss: 0.13073550164699554      \n",
      "train step #5109 accuracy: 0.90625, loss: 0.29326486587524414      \n",
      "train step #5110 accuracy: 0.953125, loss: 0.12586136162281036      \n",
      "train step #5111 accuracy: 0.96875, loss: 0.15393465757369995      \n",
      "train step #5112 accuracy: 0.96875, loss: 0.1584123969078064       \n",
      "train step #5113 accuracy: 0.984375, loss: 0.05276292562484741      \n",
      "train step #5114 accuracy: 0.921875, loss: 0.36824238300323486      \n",
      "train step #5115 accuracy: 0.984375, loss: 0.09031940251588821      \n",
      "train step #5116 accuracy: 0.96875, loss: 0.13476130366325378      \n",
      "train step #5117 accuracy: 0.9375, loss: 0.12681442499160767      \n",
      "train step #5118 accuracy: 0.984375, loss: 0.05019707977771759      \n",
      "train step #5119 accuracy: 0.90625, loss: 0.3170469403266907       \n",
      "train step #5120 accuracy: 0.96875, loss: 0.1701403707265854       \n",
      "train step #5121 accuracy:   1.0, loss: 0.040871512144804        \n",
      "train step #5122 accuracy: 0.9375, loss: 0.2148434817790985       \n",
      "train step #5123 accuracy: 0.96875, loss: 0.13370472192764282      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #5124 accuracy: 0.96875, loss: 0.09036459773778915      \n",
      "train step #5125 accuracy: 0.953125, loss: 0.19660677015781403      \n",
      "train step #5126 accuracy: 0.96875, loss: 0.13431183993816376      \n",
      "train step #5127 accuracy: 0.984375, loss: 0.13915768265724182      \n",
      "train step #5128 accuracy:   1.0, loss: 0.026291411370038986     \n",
      "train step #5129 accuracy: 0.9375, loss: 0.14962482452392578      \n",
      "train step #5130 accuracy: 0.953125, loss: 0.17430861294269562      \n",
      "train step #5131 accuracy: 0.984375, loss: 0.06634679436683655      \n",
      "train step #5132 accuracy:   1.0, loss: 0.04925929382443428      \n",
      "train step #5133 accuracy: 0.984375, loss: 0.06909380853176117      \n",
      "train step #5134 accuracy: 0.953125, loss: 0.12394096702337265      \n",
      "train step #5135 accuracy: 0.984375, loss: 0.041738688945770264     \n",
      "train step #5136 accuracy: 0.9375, loss: 0.21106301248073578      \n",
      "train step #5137 accuracy: 0.921875, loss: 0.23751144111156464      \n",
      "train step #5138 accuracy: 0.9375, loss: 0.14206567406654358      \n",
      "train step #5139 accuracy: 0.984375, loss: 0.04630158096551895      \n",
      "train step #5140 accuracy: 0.984375, loss: 0.05191776528954506      \n",
      "train step #5141 accuracy: 0.953125, loss: 0.11250821501016617      \n",
      "train step #5142 accuracy: 0.96875, loss: 0.11764733493328094      \n",
      "train step #5143 accuracy: 0.96875, loss: 0.08835253864526749      \n",
      "train step #5144 accuracy: 0.984375, loss: 0.0729963481426239       \n",
      "train step #5145 accuracy: 0.96875, loss: 0.18052726984024048      \n",
      "train step #5146 accuracy: 0.953125, loss: 0.14761115610599518      \n",
      "train step #5147 accuracy: 0.953125, loss: 0.12796808779239655      \n",
      "train step #5148 accuracy: 0.921875, loss: 0.24574214220046997      \n",
      "train step #5149 accuracy: 0.96875, loss: 0.1268273890018463       \n",
      "train step #5150 accuracy: 0.96875, loss: 0.1067010760307312       \n",
      "train step #5151 accuracy: 0.96875, loss: 0.1431373655796051       \n",
      "train step #5152 accuracy: 0.96875, loss: 0.16350197792053223      \n",
      "train step #5153 accuracy: 0.96875, loss: 0.14508220553398132      \n",
      "train step #5154 accuracy: 0.96875, loss: 0.09568218886852264      \n",
      "train step #5155 accuracy: 0.953125, loss: 0.21407505869865417      \n",
      "train step #5156 accuracy: 0.953125, loss: 0.1019844263792038       \n",
      "train step #5157 accuracy: 0.96875, loss: 0.1785302311182022       \n",
      "train step #5158 accuracy: 0.984375, loss: 0.13110293447971344      \n",
      "train step #5159 accuracy: 0.9375, loss: 0.25990116596221924      \n",
      "train step #5160 accuracy: 0.953125, loss: 0.14187191426753998      \n",
      "train step #5161 accuracy: 0.984375, loss: 0.062017157673835754     \n",
      "train step #5162 accuracy: 0.953125, loss: 0.1316283941268921       \n",
      "train step #5163 accuracy: 0.96875, loss: 0.11105954647064209      \n",
      "train step #5164 accuracy: 0.9375, loss: 0.24046069383621216      \n",
      "train step #5165 accuracy: 0.9375, loss: 0.2776551842689514       \n",
      "train step #5166 accuracy: 0.875, loss: 0.41229477524757385      \n",
      "train step #5167 accuracy: 0.984375, loss: 0.04423864185810089      \n",
      "train step #5168 accuracy: 0.984375, loss: 0.08320610225200653      \n",
      "train step #5169 accuracy: 0.890625, loss: 0.2282848209142685       \n",
      "train step #5170 accuracy: 0.96875, loss: 0.11971765011548996      \n",
      "train step #5171 accuracy: 0.96875, loss: 0.14560167491436005      \n",
      "train step #5172 accuracy: 0.9375, loss: 0.16419973969459534      \n",
      "train step #5173 accuracy: 0.9375, loss: 0.18153977394104004      \n",
      "train step #5174 accuracy: 0.9375, loss: 0.18418018519878387      \n",
      "train step #5175 accuracy: 0.96875, loss: 0.1056145504117012       \n",
      "train step #5176 accuracy: 0.953125, loss: 0.09426674991846085      \n",
      "train step #5177 accuracy: 0.9375, loss: 0.18060597777366638      \n",
      "train step #5178 accuracy: 0.984375, loss: 0.06168755143880844      \n",
      "train step #5179 accuracy: 0.921875, loss: 0.3480452597141266       \n",
      "train step #5180 accuracy: 0.96875, loss: 0.08911686390638351      \n",
      "train step #5181 accuracy: 0.984375, loss: 0.08927808701992035      \n",
      "train step #5182 accuracy: 0.953125, loss: 0.1597573161125183       \n",
      "train step #5183 accuracy: 0.984375, loss: 0.06020139902830124      \n",
      "train step #5184 accuracy: 0.953125, loss: 0.20427806675434113      \n",
      "train step #5185 accuracy: 0.921875, loss: 0.24045038223266602      \n",
      "train step #5186 accuracy: 0.96875, loss: 0.07941510528326035      \n",
      "train step #5187 accuracy: 0.921875, loss: 0.2493707835674286       \n",
      "train step #5188 accuracy: 0.984375, loss: 0.13914188742637634      \n",
      "train step #5189 accuracy: 0.96875, loss: 0.13207262754440308      \n",
      "train step #5190 accuracy: 0.96875, loss: 0.0951249822974205       \n",
      "train step #5191 accuracy: 0.953125, loss: 0.12339889258146286      \n",
      "train step #5192 accuracy: 0.984375, loss: 0.05947232246398926      \n",
      "train step #5193 accuracy: 0.96875, loss: 0.10613969713449478      \n",
      "train step #5194 accuracy: 0.984375, loss: 0.07831702381372452      \n",
      "train step #5195 accuracy: 0.96875, loss: 0.10830273479223251      \n",
      "train step #5196 accuracy: 0.984375, loss: 0.06817762553691864      \n",
      "train step #5197 accuracy: 0.953125, loss: 0.20633149147033691      \n",
      "train step #5198 accuracy: 0.890625, loss: 0.3450945019721985       \n",
      "train step #5199 accuracy: 0.984375, loss: 0.11318246275186539      \n",
      "train step #5200 accuracy: 0.921875, loss: 0.19283363223075867      \n",
      "train step #5201 accuracy: 0.953125, loss: 0.25264549255371094      \n",
      "train step #5202 accuracy: 0.953125, loss: 0.1734125167131424       \n",
      "train step #5203 accuracy: 0.96875, loss: 0.15569642186164856      \n",
      "train step #5204 accuracy: 0.9375, loss: 0.20062588155269623      \n",
      "train step #5205 accuracy: 0.953125, loss: 0.17380838096141815      \n",
      "dev accuracy: 0.875, loss: 0.5483449101448059       \n",
      "dev accuracy: 0.9375, loss: 0.20083832740783691      \n",
      "dev accuracy: 0.875, loss: 0.41216641664505005      \n",
      "dev accuracy: 0.875, loss: 0.2900441884994507       \n",
      "dev accuracy: 0.9375, loss: 0.27558931708335876      \n",
      "dev accuracy: 0.875, loss: 0.5447357296943665       \n",
      "dev accuracy:   1.0, loss: 0.029314666986465454     \n",
      "dev accuracy:   1.0, loss: 0.04631775617599487      \n",
      "dev accuracy: 0.9375, loss: 0.12578138709068298      \n",
      "dev accuracy: 0.875, loss: 0.5467165112495422       \n",
      "dev accuracy: 0.8125, loss: 0.609244167804718        \n",
      "dev accuracy: 0.9375, loss: 0.23315668106079102      \n",
      "dev accuracy:   1.0, loss: 0.0486811101436615       \n",
      "dev accuracy:   1.0, loss: 0.009453266859054565     \n",
      "dev accuracy: 0.9375, loss: 0.14772039651870728      \n",
      "dev accuracy: 0.9375, loss: 0.16556447744369507      \n",
      "dev accuracy:   1.0, loss: 0.008860379457473755     \n",
      "dev accuracy:   1.0, loss: 0.10196498036384583      \n",
      "dev accuracy:   1.0, loss: 0.002347588539123535     \n",
      "dev accuracy: 0.9375, loss: 0.23956817388534546      \n",
      "dev accuracy: 0.875, loss: 0.4046858549118042       \n",
      "dev accuracy: 0.9375, loss: 0.18060114979743958      \n",
      "dev accuracy:   1.0, loss: 0.014322817325592041     \n",
      "dev accuracy: 0.9375, loss: 0.1297626495361328       \n",
      "dev accuracy:   1.0, loss: 0.011878430843353271     \n",
      "dev accuracy: 0.875, loss: 0.17326140403747559      \n",
      "dev accuracy:  0.75, loss: 1.0799570083618164       \n",
      "dev accuracy:   1.0, loss: 0.04157400131225586      \n",
      "dev accuracy:   1.0, loss: 0.01387709379196167      \n",
      "dev accuracy:   1.0, loss: 0.03378680348396301      \n",
      "dev accuracy: 0.875, loss: 0.1991548240184784       \n",
      "dev accuracy:   1.0, loss: 0.00572437047958374      \n",
      "dev accuracy: 0.9375, loss: 0.09809359908103943      \n",
      "dev accuracy: 0.9375, loss: 0.22084081172943115      \n",
      "dev accuracy:   1.0, loss: 0.05671998858451843      \n",
      "dev accuracy: 0.9375, loss: 0.46701329946517944      \n",
      "dev accuracy: 0.9375, loss: 0.15930376946926117      \n",
      "dev accuracy: 0.9375, loss: 0.45932841300964355      \n",
      "dev accuracy:   1.0, loss: 0.03890526294708252      \n",
      "dev accuracy:   1.0, loss: 0.01247626543045044      \n",
      "dev accuracy: 0.9375, loss: 0.1293526440858841       \n",
      "dev accuracy:   1.0, loss: 0.02964615821838379      \n",
      "dev accuracy:   1.0, loss: 0.02216702699661255      \n",
      "dev accuracy: 0.9375, loss: 0.07136967778205872      \n",
      "dev accuracy: 0.875, loss: 0.4083602726459503       \n",
      "dev accuracy:   1.0, loss: 0.000639796257019043     \n",
      "dev accuracy: 0.9375, loss: 0.18099412322044373      \n",
      "dev accuracy:   1.0, loss: 0.05014003813266754      \n",
      "dev accuracy:   1.0, loss: 0.03163701295852661      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy: 0.875, loss: 0.28015613555908203      \n",
      "dev accuracy: 0.875, loss: 0.2977180480957031       \n",
      "dev accuracy: 0.9375, loss: 0.14497771859169006      \n",
      "dev accuracy:   1.0, loss: 0.007581353187561035     \n",
      "dev accuracy: 0.9375, loss: 0.13477560877799988      \n",
      "dev accuracy:   1.0, loss: 0.004276752471923828     \n",
      "dev accuracy:   1.0, loss: 0.05232959985733032      \n",
      "dev accuracy: 0.9375, loss: 0.051752716302871704     \n",
      "dev accuracy: 0.875, loss: 0.21665021777153015      \n",
      "dev accuracy:   1.0, loss: 0.01994583010673523      \n",
      "dev accuracy: 0.875, loss: 0.4927634000778198       \n",
      "dev accuracy:   1.0, loss: 0.012760430574417114     \n",
      "dev accuracy: 0.9375, loss: 0.13471314311027527      \n",
      "dev accuracy: 0.9375, loss: 0.1931338906288147       \n",
      "dev accuracy:   1.0, loss: 0.002848803997039795     \n",
      "dev accuracy: 0.875, loss: 0.321913480758667        \n",
      "dev accuracy: 0.9375, loss: 0.21730878949165344      \n",
      "dev accuracy:   1.0, loss: 0.046158552169799805     \n",
      "dev accuracy:   1.0, loss: 0.018370211124420166     \n",
      "dev accuracy:   1.0, loss: 0.005195200443267822     \n",
      "dev accuracy:   1.0, loss: 0.04900243878364563      \n",
      "dev accuracy:   1.0, loss: 0.006512254476547241     \n",
      "dev accuracy: 0.9375, loss: 0.21058285236358643      \n",
      "dev accuracy: 0.9375, loss: 0.44797632098197937      \n",
      "dev accuracy:   1.0, loss: 0.025488287210464478     \n",
      "dev accuracy: 0.875, loss: 0.41032618284225464      \n",
      "dev accuracy: 0.9375, loss: 0.10704299807548523      \n",
      "dev accuracy: 0.9375, loss: 0.20380759239196777      \n",
      "dev accuracy:   1.0, loss: 0.04159468412399292      \n",
      "dev accuracy:   1.0, loss: 0.006810307502746582     \n",
      "dev accuracy: 0.9375, loss: 0.10369686782360077      \n",
      "dev accuracy:   1.0, loss: 0.09908042848110199      \n",
      "dev accuracy: 0.9375, loss: 0.2479953169822693       \n",
      "dev accuracy: 0.9375, loss: 0.21248917281627655      \n",
      "dev accuracy: 0.875, loss: 0.5295536518096924       \n",
      "dev accuracy: 0.9375, loss: 0.13703477382659912      \n",
      "dev accuracy:   1.0, loss: 0.03330636024475098      \n",
      "dev accuracy:   1.0, loss: 0.025850236415863037     \n",
      "dev accuracy: 0.9375, loss: 0.11047124117612839      \n",
      "dev accuracy: 0.875, loss: 0.38801854848861694      \n",
      "dev accuracy:   1.0, loss: 0.009103447198867798     \n",
      "dev accuracy: 0.9375, loss: 0.11411559581756592      \n",
      "dev accuracy:   1.0, loss: 0.005074799060821533     \n",
      "dev accuracy: 0.875, loss: 0.4489515721797943       \n",
      "dev accuracy:   1.0, loss: 0.004838675260543823     \n",
      "dev accuracy:   1.0, loss: 0.033721864223480225     \n",
      "dev accuracy: 0.875, loss: 0.4350326955318451       \n",
      "dev accuracy: 0.9375, loss: 0.13348619639873505      \n",
      "dev accuracy:   1.0, loss: 0.03212037682533264      \n",
      "dev accuracy: 0.875, loss: 0.3180256485939026       \n",
      "dev accuracy: 0.875, loss: 0.3237297832965851       \n",
      "dev accuracy:   1.0, loss: 0.024797916412353516     \n",
      "dev accuracy:   1.0, loss: 0.0028066635131835938    \n",
      "dev accuracy: 0.9375, loss: 0.1289876401424408       \n",
      "dev accuracy:   1.0, loss: 0.03381645679473877      \n",
      "dev accuracy: 0.9375, loss: 0.13132455945014954      \n",
      "dev accuracy:   1.0, loss: 0.0038066506385803223    \n",
      "dev accuracy:   1.0, loss: 0.026083707809448242     \n",
      "dev accuracy: 0.9375, loss: 0.18211311101913452      \n",
      "dev accuracy: 0.9375, loss: 0.24667426943778992      \n",
      "dev accuracy:   1.0, loss: 0.05696588754653931      \n",
      "dev accuracy: 0.9375, loss: 0.2307470738887787       \n",
      "dev accuracy: 0.9375, loss: 0.08780887722969055      \n",
      "dev accuracy: 0.9375, loss: 0.13596096634864807      \n",
      "dev accuracy: 0.9375, loss: 0.11150237917900085      \n",
      "dev accuracy: 0.9375, loss: 0.2662566304206848       \n",
      "dev accuracy: 0.9375, loss: 0.09896272420883179      \n",
      "dev accuracy: 0.9375, loss: 0.5059458613395691       \n",
      "dev accuracy: 0.9375, loss: 0.2953033149242401       \n",
      "dev accuracy:   1.0, loss: 0.05131146311759949      \n",
      "dev accuracy:   1.0, loss: 0.0032744407653808594    \n",
      "dev accuracy:   1.0, loss: 0.02540743350982666      \n",
      "dev accuracy:   1.0, loss: 0.08962470293045044      \n",
      "dev accuracy:   1.0, loss: 0.013086318969726562     \n",
      "dev accuracy:   1.0, loss: 0.1098892092704773       \n",
      "dev accuracy: 0.875, loss: 0.7504311800003052       \n",
      "dev accuracy: 0.9375, loss: 0.08535832166671753      \n",
      "dev accuracy: 0.9375, loss: 0.13266590237617493      \n",
      "dev accuracy:   1.0, loss: 0.012344509363174438     \n",
      "dev accuracy: 0.9375, loss: 0.22318419814109802      \n",
      "dev accuracy:   1.0, loss: 0.002944350242614746     \n",
      "dev accuracy: 0.9375, loss: 0.11048182845115662      \n",
      "dev accuracy: 0.9375, loss: 0.4311861991882324       \n",
      "dev accuracy:   1.0, loss: 0.008579343557357788     \n",
      "dev accuracy:   1.0, loss: 0.053155720233917236     \n",
      "dev accuracy: 0.9375, loss: 0.38201823830604553      \n",
      "dev accuracy: 0.9375, loss: 0.11104492843151093      \n",
      "dev accuracy: 0.9375, loss: 0.2510281801223755       \n",
      "dev accuracy:   1.0, loss: 0.005343198776245117     \n",
      "dev accuracy: 0.9375, loss: 0.10069811344146729      \n",
      "dev accuracy: 0.9375, loss: 0.19746911525726318      \n",
      "dev accuracy: 0.9375, loss: 0.08846969902515411      \n",
      "dev accuracy: 0.6875, loss: 1.06239914894104         \n",
      "dev accuracy:   1.0, loss: 0.07252117991447449      \n",
      "dev accuracy: 0.9375, loss: 0.10905563831329346      \n",
      "dev accuracy: 0.9375, loss: 0.1594509333372116       \n",
      "dev accuracy:   1.0, loss: 0.058261483907699585     \n",
      "dev accuracy:   1.0, loss: 0.03352147340774536      \n",
      "dev accuracy: 0.875, loss: 0.419208824634552        \n",
      "dev accuracy:   1.0, loss: 0.07789173722267151      \n",
      "dev accuracy:   1.0, loss: 0.0012732148170471191    \n",
      "dev accuracy: 0.9375, loss: 0.10496069490909576      \n",
      "dev accuracy: 0.875, loss: 0.5363407135009766       \n",
      "dev accuracy: 0.9375, loss: 0.25319597125053406      \n",
      "dev accuracy: 0.9375, loss: 0.2193307876586914       \n",
      "dev accuracy:   1.0, loss: 0.029573380947113037     \n",
      "dev accuracy: 0.875, loss: 0.6386651396751404       \n",
      "dev accuracy: 0.9375, loss: 0.12039409577846527      \n",
      "dev accuracy:   1.0, loss: 0.00475311279296875      \n",
      "dev accuracy:   1.0, loss: 0.006850183010101318     \n",
      "dev accuracy: 0.9375, loss: 0.14511792361736298      \n",
      "dev accuracy: 0.9375, loss: 0.3199400305747986       \n",
      "dev accuracy:   1.0, loss: 0.044251829385757446     \n",
      "dev accuracy:   1.0, loss: 0.0035065412521362305    \n",
      "dev accuracy: 0.875, loss: 0.2289375215768814       \n",
      "dev accuracy: 0.875, loss: 0.37558794021606445      \n",
      "dev accuracy: 0.9375, loss: 0.1745634526014328       \n",
      "dev accuracy:   1.0, loss: 0.0019317269325256348    \n",
      "dev accuracy:   1.0, loss: 0.031554460525512695     \n",
      "dev accuracy: 0.9375, loss: 0.15060535073280334      \n",
      "dev accuracy:   1.0, loss: 0.0028048157691955566    \n",
      "dev accuracy: 0.9375, loss: 0.19211965799331665      \n",
      "dev accuracy: 0.9375, loss: 0.09429556131362915      \n",
      "dev accuracy:   1.0, loss: 0.01807427406311035      \n",
      "dev accuracy: 0.9375, loss: 0.29323744773864746      \n",
      "dev accuracy: 0.9375, loss: 0.2216506004333496       \n",
      "dev accuracy: 0.9375, loss: 0.17608769237995148      \n",
      "dev accuracy:   1.0, loss: 0.018348515033721924     \n",
      "dev accuracy: 0.9375, loss: 0.2041843980550766       \n",
      "dev accuracy: 0.9375, loss: 0.4565596282482147       \n",
      "dev accuracy: 0.9375, loss: 0.2424883246421814       \n",
      "dev accuracy: 0.9375, loss: 0.31474068760871887      \n",
      "dev accuracy: 0.9375, loss: 0.1533370018005371       \n",
      "dev accuracy:   1.0, loss: 0.0030791759490966797    \n",
      "dev accuracy: 0.9375, loss: 0.13183334469795227      \n",
      "dev accuracy: 0.9375, loss: 0.15449750423431396      \n",
      "dev accuracy:   1.0, loss: 0.009769588708877563     \n",
      "dev accuracy:   1.0, loss: 0.006208568811416626     \n",
      "dev accuracy:   1.0, loss: 0.006147414445877075     \n",
      "dev accuracy: 0.9375, loss: 0.16155099868774414      \n",
      "dev accuracy: 0.9375, loss: 0.2453324794769287       \n",
      "dev accuracy: 0.9375, loss: 0.10076145827770233      \n",
      "dev accuracy: 0.9375, loss: 0.3021088242530823       \n",
      "dev accuracy:   1.0, loss: 0.0009413361549377441    \n",
      "dev accuracy: 0.6666666666666666, loss: 0.7454280853271484       \n",
      "final dev accuracy: 0.9502792096219932\n",
      "train step #5206 accuracy: 0.9375, loss: 0.14799077808856964      \n",
      "train step #5207 accuracy: 0.984375, loss: 0.05651521310210228      \n",
      "train step #5208 accuracy: 0.96875, loss: 0.08166574686765671      \n",
      "train step #5209 accuracy: 0.984375, loss: 0.09504520893096924      \n",
      "train step #5210 accuracy:   1.0, loss: 0.06572621315717697      \n",
      "train step #5211 accuracy:   1.0, loss: 0.0187605619430542       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #5212 accuracy: 0.96875, loss: 0.11471433937549591      \n",
      "train step #5213 accuracy: 0.90625, loss: 0.22877031564712524      \n",
      "train step #5214 accuracy: 0.9375, loss: 0.2189374417066574       \n",
      "train step #5215 accuracy: 0.921875, loss: 0.23160859942436218      \n",
      "train step #5216 accuracy:   1.0, loss: 0.04235924407839775      \n",
      "train step #5217 accuracy: 0.9375, loss: 0.18681472539901733      \n",
      "train step #5218 accuracy: 0.953125, loss: 0.14859679341316223      \n",
      "train step #5219 accuracy: 0.9375, loss: 0.2092306911945343       \n",
      "train step #5220 accuracy: 0.984375, loss: 0.0413106344640255       \n",
      "train step #5221 accuracy: 0.953125, loss: 0.20264551043510437      \n",
      "train step #5222 accuracy: 0.953125, loss: 0.17222054302692413      \n",
      "train step #5223 accuracy: 0.953125, loss: 0.11801742017269135      \n",
      "train step #5224 accuracy:   1.0, loss: 0.027958832681179047     \n",
      "train step #5225 accuracy: 0.953125, loss: 0.18798434734344482      \n",
      "train step #5226 accuracy: 0.96875, loss: 0.0976165160536766       \n",
      "train step #5227 accuracy: 0.96875, loss: 0.1583407074213028       \n",
      "train step #5228 accuracy: 0.96875, loss: 0.10539403557777405      \n",
      "train step #5229 accuracy:   1.0, loss: 0.01724332571029663      \n",
      "train step #5230 accuracy: 0.984375, loss: 0.08045113831758499      \n",
      "train step #5231 accuracy: 0.953125, loss: 0.15994644165039062      \n",
      "train step #5232 accuracy: 0.96875, loss: 0.12784826755523682      \n",
      "train step #5233 accuracy: 0.96875, loss: 0.08217266201972961      \n",
      "train step #5234 accuracy: 0.96875, loss: 0.12414075434207916      \n",
      "train step #5235 accuracy: 0.96875, loss: 0.14381122589111328      \n",
      "train step #5236 accuracy: 0.984375, loss: 0.06147601827979088      \n",
      "train step #5237 accuracy: 0.96875, loss: 0.08739542961120605      \n",
      "train step #5238 accuracy: 0.953125, loss: 0.14680108428001404      \n",
      "train step #5239 accuracy: 0.953125, loss: 0.1676248461008072       \n",
      "train step #5240 accuracy: 0.96875, loss: 0.1525961011648178       \n",
      "train step #5241 accuracy: 0.921875, loss: 0.2169005125761032       \n",
      "train step #5242 accuracy: 0.96875, loss: 0.10357191413640976      \n",
      "train step #5243 accuracy: 0.984375, loss: 0.05997299775481224      \n",
      "train step #5244 accuracy: 0.921875, loss: 0.20567326247692108      \n",
      "train step #5245 accuracy: 0.921875, loss: 0.24753189086914062      \n",
      "train step #5246 accuracy: 0.96875, loss: 0.07586127519607544      \n",
      "train step #5247 accuracy: 0.984375, loss: 0.02327205240726471      \n",
      "train step #5248 accuracy: 0.984375, loss: 0.09419207274913788      \n",
      "train step #5249 accuracy: 0.9375, loss: 0.24559378623962402      \n",
      "train step #5250 accuracy: 0.9375, loss: 0.23545214533805847      \n",
      "train step #5251 accuracy: 0.984375, loss: 0.10320519655942917      \n",
      "train step #5252 accuracy: 0.984375, loss: 0.11192893236875534      \n",
      "train step #5253 accuracy: 0.90625, loss: 0.3478308916091919       \n",
      "train step #5254 accuracy: 0.921875, loss: 0.14868250489234924      \n",
      "train step #5255 accuracy: 0.953125, loss: 0.14853781461715698      \n",
      "train step #5256 accuracy:   1.0, loss: 0.05556441843509674      \n",
      "train step #5257 accuracy: 0.953125, loss: 0.15153880417346954      \n",
      "train step #5258 accuracy: 0.96875, loss: 0.0957823321223259       \n",
      "train step #5259 accuracy: 0.984375, loss: 0.06875710189342499      \n",
      "train step #5260 accuracy: 0.921875, loss: 0.23110036551952362      \n",
      "train step #5261 accuracy: 0.96875, loss: 0.14728978276252747      \n",
      "train step #5262 accuracy: 0.984375, loss: 0.07595691084861755      \n",
      "train step #5263 accuracy: 0.96875, loss: 0.13124549388885498      \n",
      "train step #5264 accuracy: 0.984375, loss: 0.04713977500796318      \n",
      "train step #5265 accuracy: 0.921875, loss: 0.2111741304397583       \n",
      "train step #5266 accuracy: 0.921875, loss: 0.19456277787685394      \n",
      "train step #5267 accuracy:   1.0, loss: 0.036488041281700134     \n",
      "train step #5268 accuracy: 0.96875, loss: 0.12006622552871704      \n",
      "train step #5269 accuracy: 0.953125, loss: 0.13953399658203125      \n",
      "train step #5270 accuracy: 0.953125, loss: 0.25986918807029724      \n",
      "train step #5271 accuracy: 0.953125, loss: 0.12021811306476593      \n",
      "train step #5272 accuracy: 0.96875, loss: 0.11052506417036057      \n",
      "train step #5273 accuracy: 0.9375, loss: 0.16410622000694275      \n",
      "train step #5274 accuracy: 0.953125, loss: 0.15750816464424133      \n",
      "train step #5275 accuracy: 0.984375, loss: 0.06072167679667473      \n",
      "train step #5276 accuracy: 0.9375, loss: 0.215803861618042        \n",
      "train step #5277 accuracy: 0.96875, loss: 0.15729783475399017      \n",
      "train step #5278 accuracy: 0.96875, loss: 0.11101185530424118      \n",
      "train step #5279 accuracy: 0.953125, loss: 0.08338537812232971      \n",
      "train step #5280 accuracy: 0.90625, loss: 0.338993102312088        \n",
      "train step #5281 accuracy: 0.953125, loss: 0.12412600219249725      \n",
      "train step #5282 accuracy: 0.96875, loss: 0.11113192141056061      \n",
      "train step #5283 accuracy: 0.953125, loss: 0.15057797729969025      \n",
      "train step #5284 accuracy: 0.96875, loss: 0.08347824215888977      \n",
      "train step #5285 accuracy: 0.984375, loss: 0.051452524960041046     \n",
      "train step #5286 accuracy: 0.96875, loss: 0.09484314918518066      \n",
      "train step #5287 accuracy: 0.984375, loss: 0.06821156293153763      \n",
      "train step #5288 accuracy: 0.984375, loss: 0.08846518397331238      \n",
      "train step #5289 accuracy: 0.953125, loss: 0.20049753785133362      \n",
      "train step #5290 accuracy: 0.96875, loss: 0.09355238080024719      \n",
      "train step #5291 accuracy: 0.953125, loss: 0.1640114188194275       \n",
      "train step #5292 accuracy:   1.0, loss: 0.020472809672355652     \n",
      "train step #5293 accuracy: 0.984375, loss: 0.040245503187179565     \n",
      "train step #5294 accuracy: 0.984375, loss: 0.08976557105779648      \n",
      "train step #5295 accuracy: 0.953125, loss: 0.17006918787956238      \n",
      "train step #5296 accuracy: 0.9375, loss: 0.17500810325145721      \n",
      "train step #5297 accuracy: 0.96875, loss: 0.15936769545078278      \n",
      "train step #5298 accuracy: 0.875, loss: 0.4321329891681671       \n",
      "train step #5299 accuracy: 0.984375, loss: 0.05028350278735161      \n",
      "train step #5300 accuracy: 0.984375, loss: 0.10516989976167679      \n",
      "train step #5301 accuracy: 0.96875, loss: 0.10752308368682861      \n",
      "train step #5302 accuracy: 0.96875, loss: 0.11372905969619751      \n",
      "train step #5303 accuracy: 0.984375, loss: 0.0768955796957016       \n",
      "train step #5304 accuracy: 0.96875, loss: 0.22886553406715393      \n",
      "train step #5305 accuracy: 0.921875, loss: 0.32924026250839233      \n",
      "train step #5306 accuracy: 0.921875, loss: 0.27934688329696655      \n",
      "train step #5307 accuracy: 0.9375, loss: 0.16151484847068787      \n",
      "train step #5308 accuracy: 0.921875, loss: 0.1681940257549286       \n",
      "train step #5309 accuracy: 0.953125, loss: 0.1790177822113037       \n",
      "train step #5310 accuracy: 0.953125, loss: 0.13146735727787018      \n",
      "train step #5311 accuracy: 0.96875, loss: 0.08671063184738159      \n",
      "train step #5312 accuracy: 0.953125, loss: 0.1496228724718094       \n",
      "train step #5313 accuracy: 0.9375, loss: 0.2170104831457138       \n",
      "train step #5314 accuracy: 0.9375, loss: 0.23033756017684937      \n",
      "train step #5315 accuracy: 0.953125, loss: 0.2756859064102173       \n",
      "train step #5316 accuracy: 0.96875, loss: 0.13105857372283936      \n",
      "train step #5317 accuracy: 0.984375, loss: 0.11092201620340347      \n",
      "train step #5318 accuracy: 0.90625, loss: 0.3086228668689728       \n",
      "train step #5319 accuracy: 0.96875, loss: 0.13697217404842377      \n",
      "train step #5320 accuracy: 0.984375, loss: 0.058391083031892776     \n",
      "train step #5321 accuracy: 0.921875, loss: 0.2007536143064499       \n",
      "train step #5322 accuracy:   1.0, loss: 0.01512022316455841      \n",
      "train step #5323 accuracy: 0.96875, loss: 0.16018129885196686      \n",
      "train step #5324 accuracy: 0.984375, loss: 0.0692276656627655       \n",
      "train step #5325 accuracy: 0.859375, loss: 0.43489933013916016      \n",
      "train step #5326 accuracy: 0.984375, loss: 0.04619660973548889      \n",
      "train step #5327 accuracy: 0.953125, loss: 0.1208161860704422       \n",
      "train step #5328 accuracy: 0.9375, loss: 0.2544591426849365       \n",
      "train step #5329 accuracy: 0.890625, loss: 0.36545997858047485      \n",
      "train step #5330 accuracy: 0.96875, loss: 0.1278172880411148       \n",
      "train step #5331 accuracy: 0.984375, loss: 0.2637330889701843       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #5332 accuracy: 0.953125, loss: 0.16336661577224731      \n",
      "train step #5333 accuracy: 0.953125, loss: 0.13188232481479645      \n",
      "train step #5334 accuracy: 0.9375, loss: 0.24321550130844116      \n",
      "train step #5335 accuracy:   1.0, loss: 0.09022980183362961      \n",
      "train step #5336 accuracy: 0.9375, loss: 0.1258690357208252       \n",
      "train step #5337 accuracy: 0.9375, loss: 0.20279407501220703      \n",
      "train step #5338 accuracy: 0.953125, loss: 0.35095077753067017      \n",
      "train step #5339 accuracy: 0.953125, loss: 0.19798791408538818      \n",
      "train step #5340 accuracy: 0.96875, loss: 0.09318052977323532      \n",
      "train step #5341 accuracy:   1.0, loss: 0.029455646872520447     \n",
      "train step #5342 accuracy: 0.9375, loss: 0.2587393820285797       \n",
      "train step #5343 accuracy: 0.953125, loss: 0.14546769857406616      \n",
      "train step #5344 accuracy:   1.0, loss: 0.026381880044937134     \n",
      "train step #5345 accuracy: 0.984375, loss: 0.051442138850688934     \n",
      "train step #5346 accuracy:   1.0, loss: 0.046048011630773544     \n",
      "train step #5347 accuracy: 0.96875, loss: 0.11577562987804413      \n",
      "train step #5348 accuracy: 0.96875, loss: 0.15357890725135803      \n",
      "train step #5349 accuracy: 0.984375, loss: 0.04747743159532547      \n",
      "train step #5350 accuracy: 0.953125, loss: 0.1150897741317749       \n",
      "train step #5351 accuracy: 0.9375, loss: 0.10737413167953491      \n",
      "train step #5352 accuracy: 0.984375, loss: 0.04347768425941467      \n",
      "train step #5353 accuracy: 0.953125, loss: 0.1018201932311058       \n",
      "train step #5354 accuracy: 0.984375, loss: 0.05042184144258499      \n",
      "train step #5355 accuracy: 0.90625, loss: 0.2511568069458008       \n",
      "train step #5356 accuracy: 0.984375, loss: 0.11217280477285385      \n",
      "train step #5357 accuracy: 0.984375, loss: 0.10040005296468735      \n",
      "train step #5358 accuracy: 0.96875, loss: 0.07526929676532745      \n",
      "train step #5359 accuracy: 0.953125, loss: 0.11202846467494965      \n",
      "train step #5360 accuracy: 0.96875, loss: 0.16083969175815582      \n",
      "train step #5361 accuracy:   1.0, loss: 0.01834973692893982      \n",
      "train step #5362 accuracy: 0.9375, loss: 0.21220090985298157      \n",
      "train step #5363 accuracy: 0.96875, loss: 0.11147379875183105      \n",
      "train step #5364 accuracy: 0.984375, loss: 0.07766939699649811      \n",
      "train step #5365 accuracy: 0.96875, loss: 0.09296145290136337      \n",
      "train step #5366 accuracy: 0.96875, loss: 0.10344745963811874      \n",
      "train step #5367 accuracy: 0.96875, loss: 0.11700250208377838      \n",
      "train step #5368 accuracy: 0.96875, loss: 0.13174977898597717      \n",
      "train step #5369 accuracy: 0.96875, loss: 0.06086673587560654      \n",
      "train step #5370 accuracy: 0.9375, loss: 0.1987609714269638       \n",
      "train step #5371 accuracy: 0.984375, loss: 0.03692622482776642      \n",
      "train step #5372 accuracy: 0.984375, loss: 0.07283025234937668      \n",
      "train step #5373 accuracy: 0.984375, loss: 0.07840599119663239      \n",
      "train step #5374 accuracy: 0.984375, loss: 0.0784585177898407       \n",
      "train step #5375 accuracy: 0.984375, loss: 0.09793268889188766      \n",
      "train step #5376 accuracy: 0.921875, loss: 0.28641483187675476      \n",
      "train step #5377 accuracy: 0.984375, loss: 0.05188428983092308      \n",
      "train step #5378 accuracy: 0.96875, loss: 0.19750268757343292      \n",
      "train step #5379 accuracy: 0.96875, loss: 0.07178419083356857      \n",
      "train step #5380 accuracy: 0.984375, loss: 0.07661840319633484      \n",
      "train step #5381 accuracy: 0.9375, loss: 0.2504958510398865       \n",
      "train step #5382 accuracy: 0.96875, loss: 0.12419553846120834      \n",
      "train step #5383 accuracy: 0.984375, loss: 0.1109013482928276       \n",
      "train step #5384 accuracy: 0.953125, loss: 0.1399310976266861       \n",
      "train step #5385 accuracy: 0.984375, loss: 0.06554961204528809      \n",
      "train step #5386 accuracy: 0.953125, loss: 0.14569774270057678      \n",
      "train step #5387 accuracy: 0.984375, loss: 0.052465178072452545     \n",
      "train step #5388 accuracy: 0.953125, loss: 0.15072792768478394      \n",
      "train step #5389 accuracy: 0.953125, loss: 0.1914372593164444       \n",
      "train step #5390 accuracy: 0.96875, loss: 0.13947546482086182      \n",
      "train step #5391 accuracy: 0.9375, loss: 0.14191335439682007      \n",
      "train step #5392 accuracy: 0.96875, loss: 0.11780210584402084      \n",
      "train step #5393 accuracy: 0.9375, loss: 0.19688691198825836      \n",
      "train step #5394 accuracy: 0.9375, loss: 0.20393091440200806      \n",
      "train step #5395 accuracy:   1.0, loss: 0.024245768785476685     \n",
      "train step #5396 accuracy: 0.984375, loss: 0.11465324461460114      \n",
      "train step #5397 accuracy: 0.984375, loss: 0.0687863752245903       \n",
      "train step #5398 accuracy: 0.9375, loss: 0.2217758595943451       \n",
      "train step #5399 accuracy: 0.96875, loss: 0.15218202769756317      \n",
      "train step #5400 accuracy: 0.9375, loss: 0.26421189308166504      \n",
      "train step #5401 accuracy: 0.921875, loss: 0.2529244124889374       \n",
      "train step #5402 accuracy: 0.96875, loss: 0.10387326031923294      \n",
      "train step #5403 accuracy: 0.984375, loss: 0.06133921071887016      \n",
      "train step #5404 accuracy: 0.984375, loss: 0.10431228578090668      \n",
      "train step #5405 accuracy: 0.953125, loss: 0.1688477247953415       \n",
      "train step #5406 accuracy: 0.96875, loss: 0.12533272802829742      \n",
      "train step #5407 accuracy: 0.96875, loss: 0.1296321302652359       \n",
      "train step #5408 accuracy:   1.0, loss: 0.06415966153144836      \n",
      "train step #5409 accuracy: 0.96875, loss: 0.11677837371826172      \n",
      "train step #5410 accuracy: 0.953125, loss: 0.15627604722976685      \n",
      "train step #5411 accuracy:   1.0, loss: 0.03955580294132233      \n",
      "train step #5412 accuracy: 0.953125, loss: 0.1380537450313568       \n",
      "train step #5413 accuracy: 0.96875, loss: 0.20070572197437286      \n",
      "train step #5414 accuracy: 0.921875, loss: 0.32179442048072815      \n",
      "train step #5415 accuracy: 0.984375, loss: 0.10928734391927719      \n",
      "train step #5416 accuracy: 0.953125, loss: 0.08258521556854248      \n",
      "train step #5417 accuracy:   1.0, loss: 0.06056830286979675      \n",
      "train step #5418 accuracy:   1.0, loss: 0.025375917553901672     \n",
      "train step #5419 accuracy: 0.96875, loss: 0.14192919433116913      \n",
      "train step #5420 accuracy: 0.984375, loss: 0.19134736061096191      \n",
      "train step #5421 accuracy: 0.984375, loss: 0.06457583606243134      \n",
      "train step #5422 accuracy: 0.953125, loss: 0.16893406212329865      \n",
      "train step #5423 accuracy: 0.984375, loss: 0.08345372974872589      \n",
      "train step #5424 accuracy: 0.96875, loss: 0.13648799061775208      \n",
      "train step #5425 accuracy: 0.953125, loss: 0.1474802941083908       \n",
      "train step #5426 accuracy: 0.921875, loss: 0.253336638212204        \n",
      "train step #5427 accuracy: 0.921875, loss: 0.17760342359542847      \n",
      "train step #5428 accuracy: 0.9375, loss: 0.23743762075901031      \n",
      "train step #5429 accuracy: 0.96875, loss: 0.08672358840703964      \n",
      "train step #5430 accuracy: 0.96875, loss: 0.10678073018789291      \n",
      "train step #5431 accuracy: 0.984375, loss: 0.08011898398399353      \n",
      "train step #5432 accuracy: 0.953125, loss: 0.12943638861179352      \n",
      "train step #5433 accuracy: 0.96875, loss: 0.08922289311885834      \n",
      "train step #5434 accuracy: 0.984375, loss: 0.10909800231456757      \n",
      "train step #5435 accuracy: 0.953125, loss: 0.12427930533885956      \n",
      "train step #5436 accuracy: 0.953125, loss: 0.21178434789180756      \n",
      "train step #5437 accuracy: 0.953125, loss: 0.21966791152954102      \n",
      "train step #5438 accuracy: 0.984375, loss: 0.050001949071884155     \n",
      "train step #5439 accuracy: 0.9375, loss: 0.18705104291439056      \n",
      "train step #5440 accuracy:   1.0, loss: 0.02558724582195282      \n",
      "train step #5441 accuracy: 0.953125, loss: 0.19370386004447937      \n",
      "train step #5442 accuracy: 0.96875, loss: 0.11591850221157074      \n",
      "train step #5443 accuracy: 0.96875, loss: 0.14440244436264038      \n",
      "train step #5444 accuracy: 0.9375, loss: 0.21945710480213165      \n",
      "train step #5445 accuracy: 0.953125, loss: 0.13926872611045837      \n",
      "train step #5446 accuracy: 0.96875, loss: 0.14726629853248596      \n",
      "train step #5447 accuracy: 0.96875, loss: 0.17201952636241913      \n",
      "train step #5448 accuracy: 0.953125, loss: 0.18971571326255798      \n",
      "train step #5449 accuracy: 0.96875, loss: 0.12390990555286407      \n",
      "train step #5450 accuracy: 0.984375, loss: 0.05939626321196556      \n",
      "train step #5451 accuracy: 0.96875, loss: 0.13219448924064636      \n",
      "train step #5452 accuracy: 0.953125, loss: 0.1445874273777008       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #5453 accuracy: 0.96875, loss: 0.16853326559066772      \n",
      "train step #5454 accuracy: 0.953125, loss: 0.18540948629379272      \n",
      "train step #5455 accuracy: 0.984375, loss: 0.06751817464828491      \n",
      "train step #5456 accuracy: 0.96875, loss: 0.09102292358875275      \n",
      "train step #5457 accuracy: 0.96875, loss: 0.0881003588438034       \n",
      "train step #5458 accuracy: 0.953125, loss: 0.10960527509450912      \n",
      "train step #5459 accuracy: 0.96875, loss: 0.16270852088928223      \n",
      "train step #5460 accuracy: 0.953125, loss: 0.1646304726600647       \n",
      "train step #5461 accuracy: 0.96875, loss: 0.1478610783815384       \n",
      "train step #5462 accuracy: 0.953125, loss: 0.12201903015375137      \n",
      "train step #5463 accuracy: 0.96875, loss: 0.12625117599964142      \n",
      "train step #5464 accuracy: 0.96875, loss: 0.22903941571712494      \n",
      "train step #5465 accuracy: 0.96875, loss: 0.14298617839813232      \n",
      "train step #5466 accuracy: 0.96875, loss: 0.16065990924835205      \n",
      "train step #5467 accuracy: 0.90625, loss: 0.19451536238193512      \n",
      "train step #5468 accuracy: 0.96875, loss: 0.06473205983638763      \n",
      "train step #5469 accuracy: 0.90625, loss: 0.30330291390419006      \n",
      "train step #5470 accuracy: 0.953125, loss: 0.12857937812805176      \n",
      "train step #5471 accuracy: 0.96875, loss: 0.0863010436296463       \n",
      "train step #5472 accuracy: 0.96875, loss: 0.10139241069555283      \n",
      "train step #5473 accuracy: 0.953125, loss: 0.17231059074401855      \n",
      "train step #5474 accuracy: 0.9375, loss: 0.273346871137619        \n",
      "train step #5475 accuracy: 0.984375, loss: 0.08070959895849228      \n",
      "train step #5476 accuracy: 0.953125, loss: 0.18227717280387878      \n",
      "train step #5477 accuracy:   1.0, loss: 0.03092021495103836      \n",
      "train step #5478 accuracy: 0.953125, loss: 0.3055349290370941       \n",
      "train step #5479 accuracy: 0.984375, loss: 0.0640052780508995       \n",
      "train step #5480 accuracy: 0.921875, loss: 0.2008265107870102       \n",
      "train step #5481 accuracy: 0.921875, loss: 0.23436832427978516      \n",
      "train step #5482 accuracy: 0.9375, loss: 0.13225647807121277      \n",
      "train step #5483 accuracy:   1.0, loss: 0.03627551719546318      \n",
      "train step #5484 accuracy: 0.921875, loss: 0.33775514364242554      \n",
      "train step #5485 accuracy: 0.96875, loss: 0.13443252444267273      \n",
      "train step #5486 accuracy: 0.984375, loss: 0.15024113655090332      \n",
      "train step #5487 accuracy: 0.984375, loss: 0.04912085458636284      \n",
      "train step #5488 accuracy: 0.9375, loss: 0.16859537363052368      \n",
      "train step #5489 accuracy:   1.0, loss: 0.0337485745549202       \n",
      "train step #5490 accuracy: 0.96875, loss: 0.0673854723572731       \n",
      "train step #5491 accuracy: 0.921875, loss: 0.1789315640926361       \n",
      "train step #5492 accuracy: 0.953125, loss: 0.14215536415576935      \n",
      "train step #5493 accuracy: 0.953125, loss: 0.16474559903144836      \n",
      "train step #5494 accuracy: 0.9375, loss: 0.1668955534696579       \n",
      "train step #5495 accuracy: 0.90625, loss: 0.2893505096435547       \n",
      "train step #5496 accuracy: 0.984375, loss: 0.07216868549585342      \n",
      "train step #5497 accuracy: 0.984375, loss: 0.05760351940989494      \n",
      "train step #5498 accuracy: 0.96875, loss: 0.12744340300559998      \n",
      "train step #5499 accuracy: 0.984375, loss: 0.025401301681995392     \n",
      "train step #5500 accuracy: 0.96875, loss: 0.09788429737091064      \n",
      "train step #5501 accuracy: 0.921875, loss: 0.1911323517560959       \n",
      "train step #5502 accuracy: 0.953125, loss: 0.16798120737075806      \n",
      "train step #5503 accuracy: 0.984375, loss: 0.09487146139144897      \n",
      "train step #5504 accuracy: 0.96875, loss: 0.07826808094978333      \n",
      "train step #5505 accuracy: 0.953125, loss: 0.1586490422487259       \n",
      "train step #5506 accuracy: 0.96875, loss: 0.1302744299173355       \n",
      "train step #5507 accuracy: 0.921875, loss: 0.3070855140686035       \n",
      "train step #5508 accuracy: 0.9375, loss: 0.23784738779067993      \n",
      "train step #5509 accuracy: 0.96875, loss: 0.12927094101905823      \n",
      "train step #5510 accuracy: 0.984375, loss: 0.04286137595772743      \n",
      "train step #5511 accuracy: 0.96875, loss: 0.19471971690654755      \n",
      "train step #5512 accuracy: 0.96875, loss: 0.13043822348117828      \n",
      "train step #5513 accuracy: 0.96875, loss: 0.08247435837984085      \n",
      "train step #5514 accuracy: 0.984375, loss: 0.10780312865972519      \n",
      "train step #5515 accuracy: 0.953125, loss: 0.12356354296207428      \n",
      "train step #5516 accuracy:   1.0, loss: 0.02809760719537735      \n",
      "train step #5517 accuracy: 0.953125, loss: 0.13392136991024017      \n",
      "train step #5518 accuracy: 0.984375, loss: 0.11487720161676407      \n",
      "train step #5519 accuracy: 0.984375, loss: 0.0655001848936081       \n",
      "train step #5520 accuracy: 0.96875, loss: 0.10391495376825333      \n",
      "train step #5521 accuracy: 0.984375, loss: 0.060099419206380844     \n",
      "train step #5522 accuracy: 0.96875, loss: 0.19033604860305786      \n",
      "train step #5523 accuracy: 0.90625, loss: 0.25641995668411255      \n",
      "train step #5524 accuracy: 0.921875, loss: 0.19025608897209167      \n",
      "train step #5525 accuracy: 0.9375, loss: 0.2921215891838074       \n",
      "train step #5526 accuracy: 0.96875, loss: 0.14927111566066742      \n",
      "train step #5527 accuracy: 0.9375, loss: 0.193834125995636        \n",
      "train step #5528 accuracy: 0.921875, loss: 0.22569172084331512      \n",
      "train step #5529 accuracy: 0.921875, loss: 0.29399290680885315      \n",
      "train step #5530 accuracy: 0.90625, loss: 0.41527706384658813      \n",
      "train step #5531 accuracy: 0.96875, loss: 0.14173047244548798      \n",
      "train step #5532 accuracy: 0.984375, loss: 0.08031254261732101      \n",
      "train step #5533 accuracy: 0.984375, loss: 0.05424709618091583      \n",
      "train step #5534 accuracy: 0.984375, loss: 0.1210712417960167       \n",
      "train step #5535 accuracy: 0.96875, loss: 0.14177052676677704      \n",
      "train step #5536 accuracy: 0.9375, loss: 0.21538950502872467      \n",
      "train step #5537 accuracy: 0.921875, loss: 0.2186010479927063       \n",
      "train step #5538 accuracy: 0.96875, loss: 0.14185118675231934      \n",
      "train step #5539 accuracy: 0.984375, loss: 0.07975340634584427      \n",
      "train step #5540 accuracy: 0.953125, loss: 0.14630478620529175      \n",
      "train step #5541 accuracy: 0.9375, loss: 0.18369770050048828      \n",
      "train step #5542 accuracy: 0.90625, loss: 0.31595540046691895      \n",
      "train step #5543 accuracy: 0.9375, loss: 0.21448460221290588      \n",
      "train step #5544 accuracy: 0.984375, loss: 0.06219753250479698      \n",
      "train step #5545 accuracy: 0.984375, loss: 0.08469287306070328      \n",
      "train step #5546 accuracy: 0.953125, loss: 0.112144835293293        \n",
      "train step #5547 accuracy: 0.984375, loss: 0.1327795535326004       \n",
      "train step #5548 accuracy: 0.96875, loss: 0.1052333191037178       \n",
      "train step #5549 accuracy: 0.96875, loss: 0.06407869607210159      \n",
      "train step #5550 accuracy: 0.9375, loss: 0.23114480078220367      \n",
      "train step #5551 accuracy:   1.0, loss: 0.026018206030130386     \n",
      "train step #5552 accuracy: 0.90625, loss: 0.3099533021450043       \n",
      "dev accuracy: 0.875, loss: 0.31163471937179565      \n",
      "dev accuracy:   1.0, loss: 0.046809375286102295     \n",
      "dev accuracy:   1.0, loss: 0.04974550008773804      \n",
      "dev accuracy: 0.8125, loss: 0.33557865023612976      \n",
      "dev accuracy: 0.9375, loss: 0.16782565414905548      \n",
      "dev accuracy:   1.0, loss: 0.05185762047767639      \n",
      "dev accuracy: 0.875, loss: 0.12617561221122742      \n",
      "dev accuracy:   1.0, loss: 0.08307074010372162      \n",
      "dev accuracy: 0.875, loss: 0.21464954316616058      \n",
      "dev accuracy: 0.9375, loss: 0.2812945246696472       \n",
      "dev accuracy: 0.9375, loss: 0.14554771780967712      \n",
      "dev accuracy:   1.0, loss: 0.0062219202518463135    \n",
      "dev accuracy: 0.9375, loss: 0.34420832991600037      \n",
      "dev accuracy: 0.875, loss: 0.2589116394519806       \n",
      "dev accuracy:   1.0, loss: 0.04924619197845459      \n",
      "dev accuracy: 0.875, loss: 0.25462788343429565      \n",
      "dev accuracy:   1.0, loss: 0.0014671087265014648    \n",
      "dev accuracy:   1.0, loss: 0.03841879963874817      \n",
      "dev accuracy: 0.875, loss: 0.4292861223220825       \n",
      "dev accuracy:   1.0, loss: 0.01583164930343628      \n",
      "dev accuracy: 0.9375, loss: 0.1690962314605713       \n",
      "dev accuracy:   1.0, loss: 0.015469163656234741     \n",
      "dev accuracy:   1.0, loss: 0.012201786041259766     \n",
      "dev accuracy:   1.0, loss: 0.015405416488647461     \n",
      "dev accuracy: 0.9375, loss: 0.10887323319911957      \n",
      "dev accuracy:   1.0, loss: 0.033062756061553955     \n",
      "dev accuracy: 0.9375, loss: 0.22833392024040222      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy:   1.0, loss: 0.00666472315788269      \n",
      "dev accuracy:   1.0, loss: 0.013289839029312134     \n",
      "dev accuracy:   1.0, loss: 0.0064723193645477295    \n",
      "dev accuracy: 0.9375, loss: 0.10335728526115417      \n",
      "dev accuracy: 0.9375, loss: 0.17077291011810303      \n",
      "dev accuracy: 0.9375, loss: 0.1951839029788971       \n",
      "dev accuracy: 0.9375, loss: 0.2760511040687561       \n",
      "dev accuracy: 0.875, loss: 0.7465400695800781       \n",
      "dev accuracy: 0.875, loss: 0.36847782135009766      \n",
      "dev accuracy: 0.9375, loss: 0.13076052069664001      \n",
      "dev accuracy:   1.0, loss: 0.00464966893196106      \n",
      "dev accuracy:   1.0, loss: 0.011913150548934937     \n",
      "dev accuracy: 0.9375, loss: 0.5311250686645508       \n",
      "dev accuracy:   1.0, loss: 0.0036867260932922363    \n",
      "dev accuracy: 0.9375, loss: 0.16135790944099426      \n",
      "dev accuracy: 0.8125, loss: 0.7712477445602417       \n",
      "dev accuracy:   1.0, loss: 0.04744940996170044      \n",
      "dev accuracy:   1.0, loss: 0.08154013752937317      \n",
      "dev accuracy: 0.9375, loss: 0.23186886310577393      \n",
      "dev accuracy: 0.9375, loss: 0.2853628993034363       \n",
      "dev accuracy:   1.0, loss: 0.012443602085113525     \n",
      "dev accuracy: 0.9375, loss: 0.3251436948776245       \n",
      "dev accuracy: 0.9375, loss: 0.270378440618515        \n",
      "dev accuracy: 0.9375, loss: 0.10452389717102051      \n",
      "dev accuracy: 0.9375, loss: 0.2065146267414093       \n",
      "dev accuracy:   1.0, loss: 0.025002479553222656     \n",
      "dev accuracy: 0.9375, loss: 0.09399276971817017      \n",
      "dev accuracy: 0.875, loss: 0.3855721652507782       \n",
      "dev accuracy: 0.9375, loss: 0.07280750572681427      \n",
      "dev accuracy: 0.9375, loss: 0.3653872311115265       \n",
      "dev accuracy: 0.9375, loss: 0.5249683856964111       \n",
      "dev accuracy: 0.9375, loss: 0.11344209313392639      \n",
      "dev accuracy:   1.0, loss: 0.08051583170890808      \n",
      "dev accuracy: 0.9375, loss: 0.22073984146118164      \n",
      "dev accuracy:   1.0, loss: 0.035132020711898804     \n",
      "dev accuracy:   1.0, loss: 0.030335992574691772     \n",
      "dev accuracy: 0.9375, loss: 0.11840534210205078      \n",
      "dev accuracy:   1.0, loss: 0.010789543390274048     \n",
      "dev accuracy:   1.0, loss: 0.040565282106399536     \n",
      "dev accuracy: 0.8125, loss: 0.8460612893104553       \n",
      "dev accuracy:   1.0, loss: 0.03799596428871155      \n",
      "dev accuracy:   1.0, loss: 0.0016560554504394531    \n",
      "dev accuracy:   1.0, loss: 0.06263655424118042      \n",
      "dev accuracy: 0.875, loss: 0.5255303382873535       \n",
      "dev accuracy: 0.9375, loss: 0.1946355402469635       \n",
      "dev accuracy: 0.875, loss: 0.24814793467521667      \n",
      "dev accuracy:   1.0, loss: 0.0036171674728393555    \n",
      "dev accuracy:   1.0, loss: 0.03331434726715088      \n",
      "dev accuracy:   1.0, loss: 0.05225363373756409      \n",
      "dev accuracy: 0.9375, loss: 0.17424160242080688      \n",
      "dev accuracy: 0.875, loss: 0.1589900255203247       \n",
      "dev accuracy:   1.0, loss: 0.13306811451911926      \n",
      "dev accuracy: 0.9375, loss: 0.21377328038215637      \n",
      "dev accuracy:   1.0, loss: 0.11958855390548706      \n",
      "dev accuracy: 0.875, loss: 0.4265349507331848       \n",
      "dev accuracy: 0.875, loss: 0.31502190232276917      \n",
      "dev accuracy:   1.0, loss: 0.013107001781463623     \n",
      "dev accuracy: 0.875, loss: 0.3765736222267151       \n",
      "dev accuracy: 0.9375, loss: 0.2211015373468399       \n",
      "dev accuracy:   1.0, loss: 0.002587646245956421     \n",
      "dev accuracy: 0.9375, loss: 0.2043924331665039       \n",
      "dev accuracy: 0.9375, loss: 0.10271856188774109      \n",
      "dev accuracy:  0.75, loss: 0.5532336831092834       \n",
      "dev accuracy: 0.9375, loss: 0.15226639807224274      \n",
      "dev accuracy: 0.9375, loss: 0.07276871800422668      \n",
      "dev accuracy: 0.9375, loss: 0.08443152904510498      \n",
      "dev accuracy:   1.0, loss: 0.015148758888244629     \n",
      "dev accuracy:   1.0, loss: 0.03631344437599182      \n",
      "dev accuracy: 0.9375, loss: 0.17471839487552643      \n",
      "dev accuracy: 0.9375, loss: 0.05470186471939087      \n",
      "dev accuracy: 0.9375, loss: 0.15282094478607178      \n",
      "dev accuracy: 0.9375, loss: 0.40897345542907715      \n",
      "dev accuracy: 0.9375, loss: 0.3530433177947998       \n",
      "dev accuracy:   1.0, loss: 0.04650372266769409      \n",
      "dev accuracy: 0.875, loss: 0.4920913279056549       \n",
      "dev accuracy: 0.9375, loss: 0.15154847502708435      \n",
      "dev accuracy:   1.0, loss: 0.022713571786880493     \n",
      "dev accuracy: 0.9375, loss: 0.06992140412330627      \n",
      "dev accuracy: 0.9375, loss: 0.05769091844558716      \n",
      "dev accuracy: 0.9375, loss: 0.07797285914421082      \n",
      "dev accuracy: 0.875, loss: 0.17342442274093628      \n",
      "dev accuracy: 0.9375, loss: 0.07985776662826538      \n",
      "dev accuracy: 0.9375, loss: 0.34199059009552         \n",
      "dev accuracy: 0.9375, loss: 0.2115584909915924       \n",
      "dev accuracy: 0.875, loss: 0.5247381329536438       \n",
      "dev accuracy:   1.0, loss: 0.0036000609397888184    \n",
      "dev accuracy:   1.0, loss: 0.033678144216537476     \n",
      "dev accuracy: 0.9375, loss: 0.05440118908882141      \n",
      "dev accuracy:   1.0, loss: 0.11526569724082947      \n",
      "dev accuracy:   1.0, loss: 0.0011789798736572266    \n",
      "dev accuracy:   1.0, loss: 0.016720175743103027     \n",
      "dev accuracy: 0.875, loss: 0.7788612842559814       \n",
      "dev accuracy:   1.0, loss: 0.011448383331298828     \n",
      "dev accuracy: 0.9375, loss: 0.13744771480560303      \n",
      "dev accuracy:   1.0, loss: 0.0028740763664245605    \n",
      "dev accuracy: 0.875, loss: 0.1713014394044876       \n",
      "dev accuracy:   1.0, loss: 0.014803856611251831     \n",
      "dev accuracy: 0.9375, loss: 0.09337946772575378      \n",
      "dev accuracy: 0.875, loss: 0.4153645932674408       \n",
      "dev accuracy:   1.0, loss: 0.004133433103561401     \n",
      "dev accuracy: 0.9375, loss: 0.060787737369537354     \n",
      "dev accuracy:   1.0, loss: 0.04632629454135895      \n",
      "dev accuracy: 0.9375, loss: 0.06064052879810333      \n",
      "dev accuracy: 0.9375, loss: 0.1402629166841507       \n",
      "dev accuracy: 0.875, loss: 0.5301862955093384       \n",
      "dev accuracy:   1.0, loss: 0.0024656951427459717    \n",
      "dev accuracy:   1.0, loss: 0.11845016479492188      \n",
      "dev accuracy:   1.0, loss: 0.0013852715492248535    \n",
      "dev accuracy:   1.0, loss: 0.05939686298370361      \n",
      "dev accuracy: 0.9375, loss: 0.5200372934341431       \n",
      "dev accuracy:   1.0, loss: 0.05573713779449463      \n",
      "dev accuracy: 0.875, loss: 0.3298947215080261       \n",
      "dev accuracy:   1.0, loss: 0.040729790925979614     \n",
      "dev accuracy: 0.9375, loss: 0.19099485874176025      \n",
      "dev accuracy:   1.0, loss: 0.0597098171710968       \n",
      "dev accuracy:   1.0, loss: 0.025072306394577026     \n",
      "dev accuracy: 0.875, loss: 0.5127379894256592       \n",
      "dev accuracy:   1.0, loss: 0.07470977306365967      \n",
      "dev accuracy: 0.9375, loss: 0.09784042835235596      \n",
      "dev accuracy:   1.0, loss: 0.0026175975799560547    \n",
      "dev accuracy: 0.9375, loss: 0.12524323165416718      \n",
      "dev accuracy:   1.0, loss: 0.006273448467254639     \n",
      "dev accuracy: 0.875, loss: 0.6936855912208557       \n",
      "dev accuracy:   1.0, loss: 0.022534310817718506     \n",
      "dev accuracy:   1.0, loss: 0.0038297176361083984    \n",
      "dev accuracy: 0.875, loss: 0.41991284489631653      \n",
      "dev accuracy: 0.875, loss: 0.22571216523647308      \n",
      "dev accuracy: 0.9375, loss: 0.11404925584793091      \n",
      "dev accuracy:   1.0, loss: 0.011652112007141113     \n",
      "dev accuracy: 0.9375, loss: 0.16683918237686157      \n",
      "dev accuracy: 0.9375, loss: 0.15071848034858704      \n",
      "dev accuracy:   1.0, loss: 0.0018237829208374023    \n",
      "dev accuracy: 0.9375, loss: 0.2184140682220459       \n",
      "dev accuracy: 0.9375, loss: 0.051809877157211304     \n",
      "dev accuracy: 0.9375, loss: 0.23163513839244843      \n",
      "dev accuracy: 0.9375, loss: 0.21144884824752808      \n",
      "dev accuracy:   1.0, loss: 0.020264089107513428     \n",
      "dev accuracy:   1.0, loss: 0.01336929202079773      \n",
      "dev accuracy:   1.0, loss: 0.06394045054912567      \n",
      "dev accuracy:   1.0, loss: 0.00493350625038147      \n",
      "dev accuracy:   1.0, loss: 0.0034333467483520508    \n",
      "dev accuracy: 0.875, loss: 0.38478389382362366      \n",
      "dev accuracy: 0.875, loss: 0.31106358766555786      \n",
      "dev accuracy:   1.0, loss: 0.04066801071166992      \n",
      "dev accuracy: 0.9375, loss: 0.1528104543685913       \n",
      "dev accuracy: 0.9375, loss: 0.40053439140319824      \n",
      "dev accuracy: 0.875, loss: 0.3711300194263458       \n",
      "dev accuracy:   1.0, loss: 0.0008028149604797363    \n",
      "dev accuracy: 0.875, loss: 0.3009302616119385       \n",
      "dev accuracy:   1.0, loss: 0.003537803888320923     \n",
      "dev accuracy:   1.0, loss: 0.0010976791381835938    \n",
      "dev accuracy: 0.875, loss: 0.2668250501155853       \n",
      "dev accuracy: 0.9375, loss: 0.4544687569141388       \n",
      "dev accuracy:   1.0, loss: 0.05362710356712341      \n",
      "dev accuracy:   1.0, loss: 0.008066773414611816     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy:   1.0, loss: 0.026924967765808105     \n",
      "dev accuracy:   1.0, loss: 0.012370914220809937     \n",
      "dev accuracy:   1.0, loss: 0.12029567360877991      \n",
      "dev accuracy: 0.9375, loss: 0.0912696123123169       \n",
      "dev accuracy: 0.875, loss: 0.3876596987247467       \n",
      "dev accuracy:   1.0, loss: 0.02726636826992035      \n",
      "dev accuracy:   1.0, loss: 0.03758569061756134      \n",
      "dev accuracy:   1.0, loss: 0.013623058795928955     \n",
      "dev accuracy: 0.875, loss: 0.46620887517929077      \n",
      "dev accuracy: 0.9375, loss: 0.20789484679698944      \n",
      "dev accuracy: 0.9375, loss: 0.06753131747245789      \n",
      "dev accuracy:   1.0, loss: 0.00046253204345703125   \n",
      "final dev accuracy: 0.9510309278350515\n",
      "train step #5553 accuracy: 0.9375, loss: 0.15859197080135345      \n",
      "train step #5554 accuracy:   1.0, loss: 0.033583786338567734     \n",
      "train step #5555 accuracy: 0.9375, loss: 0.16252782940864563      \n",
      "train step #5556 accuracy: 0.984375, loss: 0.06792927533388138      \n",
      "train step #5557 accuracy: 0.984375, loss: 0.05077045410871506      \n",
      "train step #5558 accuracy: 0.984375, loss: 0.0813201367855072       \n",
      "train step #5559 accuracy: 0.96875, loss: 0.1446722447872162       \n",
      "train step #5560 accuracy: 0.96875, loss: 0.22826017439365387      \n",
      "train step #5561 accuracy:   1.0, loss: 0.04526782035827637      \n",
      "train step #5562 accuracy: 0.953125, loss: 0.11547155678272247      \n",
      "train step #5563 accuracy: 0.953125, loss: 0.13993841409683228      \n",
      "train step #5564 accuracy: 0.9375, loss: 0.19196248054504395      \n",
      "train step #5565 accuracy: 0.953125, loss: 0.19629353284835815      \n",
      "train step #5566 accuracy: 0.953125, loss: 0.1416141837835312       \n",
      "train step #5567 accuracy: 0.953125, loss: 0.1371820569038391       \n",
      "train step #5568 accuracy: 0.984375, loss: 0.10133565962314606      \n",
      "train step #5569 accuracy: 0.953125, loss: 0.19675107300281525      \n",
      "train step #5570 accuracy: 0.9375, loss: 0.29199323058128357      \n",
      "train step #5571 accuracy: 0.984375, loss: 0.07533569633960724      \n",
      "train step #5572 accuracy: 0.96875, loss: 0.1985538899898529       \n",
      "train step #5573 accuracy: 0.953125, loss: 0.19773384928703308      \n",
      "train step #5574 accuracy: 0.953125, loss: 0.12142449617385864      \n",
      "train step #5575 accuracy: 0.953125, loss: 0.08294878154993057      \n",
      "train step #5576 accuracy: 0.9375, loss: 0.2808153033256531       \n",
      "train step #5577 accuracy: 0.984375, loss: 0.043295785784721375     \n",
      "train step #5578 accuracy: 0.921875, loss: 0.25239723920822144      \n",
      "train step #5579 accuracy:   1.0, loss: 0.04434671252965927      \n",
      "train step #5580 accuracy: 0.984375, loss: 0.08654298633337021      \n",
      "train step #5581 accuracy: 0.96875, loss: 0.15585877001285553      \n",
      "train step #5582 accuracy:   1.0, loss: 0.023599989712238312     \n",
      "train step #5583 accuracy: 0.984375, loss: 0.08437570184469223      \n",
      "train step #5584 accuracy: 0.984375, loss: 0.10249572992324829      \n",
      "train step #5585 accuracy: 0.984375, loss: 0.088729128241539        \n",
      "train step #5586 accuracy: 0.953125, loss: 0.14966338872909546      \n",
      "train step #5587 accuracy: 0.921875, loss: 0.2821299731731415       \n",
      "train step #5588 accuracy: 0.96875, loss: 0.28707754611968994      \n",
      "train step #5589 accuracy: 0.96875, loss: 0.15359781682491302      \n",
      "train step #5590 accuracy: 0.96875, loss: 0.09090117365121841      \n",
      "train step #5591 accuracy: 0.953125, loss: 0.1362316608428955       \n",
      "train step #5592 accuracy: 0.953125, loss: 0.146609365940094        \n",
      "train step #5593 accuracy: 0.96875, loss: 0.12446026504039764      \n",
      "train step #5594 accuracy: 0.984375, loss: 0.08870885521173477      \n",
      "train step #5595 accuracy: 0.9375, loss: 0.24058383703231812      \n",
      "train step #5596 accuracy: 0.9375, loss: 0.15209946036338806      \n",
      "train step #5597 accuracy: 0.984375, loss: 0.029174916446208954     \n",
      "train step #5598 accuracy: 0.9375, loss: 0.228770911693573        \n",
      "train step #5599 accuracy:   1.0, loss: 0.014989197254180908     \n",
      "train step #5600 accuracy: 0.96875, loss: 0.09395443648099899      \n",
      "train step #5601 accuracy:   1.0, loss: 0.038318485021591187     \n",
      "train step #5602 accuracy: 0.984375, loss: 0.07840882986783981      \n",
      "train step #5603 accuracy: 0.984375, loss: 0.06979648023843765      \n",
      "train step #5604 accuracy: 0.9375, loss: 0.14325879514217377      \n",
      "train step #5605 accuracy: 0.96875, loss: 0.1520422101020813       \n",
      "train step #5606 accuracy: 0.984375, loss: 0.08575199544429779      \n",
      "train step #5607 accuracy: 0.984375, loss: 0.08945857733488083      \n",
      "train step #5608 accuracy: 0.984375, loss: 0.17481772601604462      \n",
      "train step #5609 accuracy: 0.96875, loss: 0.10122783482074738      \n",
      "train step #5610 accuracy: 0.9375, loss: 0.15304599702358246      \n",
      "train step #5611 accuracy: 0.96875, loss: 0.057989686727523804     \n",
      "train step #5612 accuracy: 0.96875, loss: 0.15337732434272766      \n",
      "train step #5613 accuracy: 0.96875, loss: 0.1614457666873932       \n",
      "train step #5614 accuracy: 0.96875, loss: 0.0700572282075882       \n",
      "train step #5615 accuracy: 0.984375, loss: 0.027847178280353546     \n",
      "train step #5616 accuracy: 0.984375, loss: 0.0499521903693676       \n",
      "train step #5617 accuracy: 0.953125, loss: 0.1179710403084755       \n",
      "train step #5618 accuracy: 0.984375, loss: 0.06061412766575813      \n",
      "train step #5619 accuracy: 0.9375, loss: 0.10844071209430695      \n",
      "train step #5620 accuracy: 0.9375, loss: 0.23319900035858154      \n",
      "train step #5621 accuracy: 0.953125, loss: 0.16458438336849213      \n",
      "train step #5622 accuracy: 0.953125, loss: 0.16671442985534668      \n",
      "train step #5623 accuracy: 0.921875, loss: 0.22111687064170837      \n",
      "train step #5624 accuracy: 0.984375, loss: 0.08082152158021927      \n",
      "train step #5625 accuracy: 0.984375, loss: 0.04181390255689621      \n",
      "train step #5626 accuracy: 0.984375, loss: 0.04518742486834526      \n",
      "train step #5627 accuracy: 0.953125, loss: 0.11759369820356369      \n",
      "train step #5628 accuracy: 0.921875, loss: 0.256328284740448        \n",
      "train step #5629 accuracy: 0.953125, loss: 0.19655178487300873      \n",
      "train step #5630 accuracy: 0.96875, loss: 0.1297350972890854       \n",
      "train step #5631 accuracy: 0.984375, loss: 0.06904245913028717      \n",
      "train step #5632 accuracy: 0.953125, loss: 0.15497659146785736      \n",
      "train step #5633 accuracy: 0.953125, loss: 0.13580797612667084      \n",
      "train step #5634 accuracy: 0.9375, loss: 0.27662599086761475      \n",
      "train step #5635 accuracy: 0.96875, loss: 0.22282378375530243      \n",
      "train step #5636 accuracy: 0.96875, loss: 0.0811772421002388       \n",
      "train step #5637 accuracy: 0.96875, loss: 0.16821911931037903      \n",
      "train step #5638 accuracy: 0.9375, loss: 0.3291269540786743       \n",
      "train step #5639 accuracy:   1.0, loss: 0.041543059051036835     \n",
      "train step #5640 accuracy: 0.921875, loss: 0.21460464596748352      \n",
      "train step #5641 accuracy: 0.96875, loss: 0.10717317461967468      \n",
      "train step #5642 accuracy: 0.953125, loss: 0.24518635869026184      \n",
      "train step #5643 accuracy:   1.0, loss: 0.03259653598070145      \n",
      "train step #5644 accuracy:   1.0, loss: 0.015117637813091278     \n",
      "train step #5645 accuracy:   1.0, loss: 0.06570117920637131      \n",
      "train step #5646 accuracy: 0.96875, loss: 0.1892251968383789       \n",
      "train step #5647 accuracy: 0.96875, loss: 0.10596314817667007      \n",
      "train step #5648 accuracy: 0.9375, loss: 0.14973366260528564      \n",
      "train step #5649 accuracy: 0.9375, loss: 0.22780130803585052      \n",
      "train step #5650 accuracy: 0.96875, loss: 0.09691572189331055      \n",
      "train step #5651 accuracy: 0.953125, loss: 0.13847948610782623      \n",
      "train step #5652 accuracy: 0.9375, loss: 0.2490430772304535       \n",
      "train step #5653 accuracy: 0.984375, loss: 0.11112823337316513      \n",
      "train step #5654 accuracy: 0.984375, loss: 0.08715083450078964      \n",
      "train step #5655 accuracy: 0.953125, loss: 0.1374952793121338       \n",
      "train step #5656 accuracy: 0.953125, loss: 0.09297023713588715      \n",
      "train step #5657 accuracy: 0.984375, loss: 0.08405384421348572      \n",
      "train step #5658 accuracy: 0.953125, loss: 0.10816361755132675      \n",
      "train step #5659 accuracy: 0.953125, loss: 0.13342584669589996      \n",
      "train step #5660 accuracy: 0.984375, loss: 0.08310309052467346      \n",
      "train step #5661 accuracy: 0.984375, loss: 0.06409783661365509      \n",
      "train step #5662 accuracy: 0.984375, loss: 0.0656743198633194       \n",
      "train step #5663 accuracy: 0.953125, loss: 0.10137026011943817      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #5664 accuracy: 0.96875, loss: 0.161833256483078        \n",
      "train step #5665 accuracy: 0.96875, loss: 0.1557353436946869       \n",
      "train step #5666 accuracy: 0.953125, loss: 0.16538596153259277      \n",
      "train step #5667 accuracy: 0.984375, loss: 0.0559745654463768       \n",
      "train step #5668 accuracy: 0.96875, loss: 0.10187430679798126      \n",
      "train step #5669 accuracy: 0.984375, loss: 0.04988178238272667      \n",
      "train step #5670 accuracy: 0.875, loss: 0.323489785194397        \n",
      "train step #5671 accuracy:   1.0, loss: 0.030677393078804016     \n",
      "train step #5672 accuracy: 0.921875, loss: 0.2678929567337036       \n",
      "train step #5673 accuracy: 0.953125, loss: 0.11786240339279175      \n",
      "train step #5674 accuracy: 0.96875, loss: 0.11249373853206635      \n",
      "train step #5675 accuracy: 0.953125, loss: 0.09299282729625702      \n",
      "train step #5676 accuracy: 0.9375, loss: 0.22160236537456512      \n",
      "train step #5677 accuracy: 0.984375, loss: 0.05126003921031952      \n",
      "train step #5678 accuracy: 0.96875, loss: 0.1306791603565216       \n",
      "train step #5679 accuracy: 0.984375, loss: 0.04398353397846222      \n",
      "train step #5680 accuracy: 0.96875, loss: 0.10376293957233429      \n",
      "train step #5681 accuracy: 0.984375, loss: 0.11564495414495468      \n",
      "train step #5682 accuracy: 0.96875, loss: 0.10059187561273575      \n",
      "train step #5683 accuracy: 0.953125, loss: 0.14219291508197784      \n",
      "train step #5684 accuracy: 0.984375, loss: 0.07391422986984253      \n",
      "train step #5685 accuracy: 0.96875, loss: 0.15520137548446655      \n",
      "train step #5686 accuracy: 0.984375, loss: 0.274549663066864        \n",
      "train step #5687 accuracy: 0.953125, loss: 0.15979918837547302      \n",
      "train step #5688 accuracy: 0.984375, loss: 0.06662050634622574      \n",
      "train step #5689 accuracy: 0.984375, loss: 0.04904695972800255      \n",
      "train step #5690 accuracy: 0.96875, loss: 0.1144150123000145       \n",
      "train step #5691 accuracy: 0.984375, loss: 0.06280627846717834      \n",
      "train step #5692 accuracy:   1.0, loss: 0.056394681334495544     \n",
      "train step #5693 accuracy: 0.984375, loss: 0.061136357486248016     \n",
      "train step #5694 accuracy: 0.953125, loss: 0.27833184599876404      \n",
      "train step #5695 accuracy: 0.96875, loss: 0.11716945469379425      \n",
      "train step #5696 accuracy: 0.90625, loss: 0.2814624309539795       \n",
      "train step #5697 accuracy: 0.953125, loss: 0.29943907260894775      \n",
      "train step #5698 accuracy: 0.921875, loss: 0.2826668918132782       \n",
      "train step #5699 accuracy: 0.953125, loss: 0.128803551197052        \n",
      "train step #5700 accuracy:   1.0, loss: 0.026638619601726532     \n",
      "train step #5701 accuracy: 0.96875, loss: 0.14418843388557434      \n",
      "train step #5702 accuracy: 0.953125, loss: 0.21413075923919678      \n",
      "train step #5703 accuracy: 0.9375, loss: 0.17479407787322998      \n",
      "train step #5704 accuracy:   1.0, loss: 0.013585522770881653     \n",
      "train step #5705 accuracy: 0.9375, loss: 0.1979239135980606       \n",
      "train step #5706 accuracy:   1.0, loss: 0.02326560765504837      \n",
      "train step #5707 accuracy: 0.96875, loss: 0.1735459268093109       \n",
      "train step #5708 accuracy: 0.953125, loss: 0.11716976761817932      \n",
      "train step #5709 accuracy: 0.984375, loss: 0.0738261267542839       \n",
      "train step #5710 accuracy: 0.984375, loss: 0.12731072306632996      \n",
      "train step #5711 accuracy: 0.984375, loss: 0.09555280208587646      \n",
      "train step #5712 accuracy: 0.953125, loss: 0.10330896824598312      \n",
      "train step #5713 accuracy: 0.9375, loss: 0.2643031179904938       \n",
      "train step #5714 accuracy: 0.96875, loss: 0.1465325653553009       \n",
      "train step #5715 accuracy: 0.9375, loss: 0.27600643038749695      \n",
      "train step #5716 accuracy: 0.984375, loss: 0.12750749289989471      \n",
      "train step #5717 accuracy: 0.96875, loss: 0.11597501486539841      \n",
      "train step #5718 accuracy: 0.984375, loss: 0.042648401111364365     \n",
      "train step #5719 accuracy: 0.953125, loss: 0.1692681908607483       \n",
      "train step #5720 accuracy: 0.96875, loss: 0.11087710410356522      \n",
      "train step #5721 accuracy: 0.890625, loss: 0.29711005091667175      \n",
      "train step #5722 accuracy: 0.921875, loss: 0.2328132838010788       \n",
      "train step #5723 accuracy: 0.96875, loss: 0.11784329265356064      \n",
      "train step #5724 accuracy: 0.96875, loss: 0.08319124579429626      \n",
      "train step #5725 accuracy: 0.96875, loss: 0.08412042260169983      \n",
      "train step #5726 accuracy: 0.953125, loss: 0.18597401678562164      \n",
      "train step #5727 accuracy: 0.953125, loss: 0.19240015745162964      \n",
      "train step #5728 accuracy: 0.921875, loss: 0.2748394012451172       \n",
      "train step #5729 accuracy: 0.9375, loss: 0.14548832178115845      \n",
      "train step #5730 accuracy: 0.984375, loss: 0.06346572935581207      \n",
      "train step #5731 accuracy: 0.921875, loss: 0.30012547969818115      \n",
      "train step #5732 accuracy: 0.9375, loss: 0.18174904584884644      \n",
      "train step #5733 accuracy: 0.9375, loss: 0.2241605669260025       \n",
      "train step #5734 accuracy: 0.984375, loss: 0.06336018443107605      \n",
      "train step #5735 accuracy: 0.921875, loss: 0.21577727794647217      \n",
      "train step #5736 accuracy: 0.984375, loss: 0.08577999472618103      \n",
      "train step #5737 accuracy: 0.953125, loss: 0.13339242339134216      \n",
      "train step #5738 accuracy: 0.96875, loss: 0.16414490342140198      \n",
      "train step #5739 accuracy: 0.96875, loss: 0.1113063395023346       \n",
      "train step #5740 accuracy: 0.953125, loss: 0.20682474970817566      \n",
      "train step #5741 accuracy: 0.9375, loss: 0.22096428275108337      \n",
      "train step #5742 accuracy: 0.984375, loss: 0.04882814362645149      \n",
      "train step #5743 accuracy: 0.96875, loss: 0.14110121130943298      \n",
      "train step #5744 accuracy: 0.96875, loss: 0.10659818351268768      \n",
      "train step #5745 accuracy: 0.984375, loss: 0.05934640392661095      \n",
      "train step #5746 accuracy: 0.984375, loss: 0.07092548906803131      \n",
      "train step #5747 accuracy: 0.9375, loss: 0.19229166209697723      \n",
      "train step #5748 accuracy: 0.96875, loss: 0.08449622988700867      \n",
      "train step #5749 accuracy: 0.96875, loss: 0.1473938524723053       \n",
      "train step #5750 accuracy:   1.0, loss: 0.032873328775167465     \n",
      "train step #5751 accuracy: 0.96875, loss: 0.08449168503284454      \n",
      "train step #5752 accuracy: 0.96875, loss: 0.06830067187547684      \n",
      "train step #5753 accuracy: 0.9375, loss: 0.329887330532074        \n",
      "train step #5754 accuracy:   1.0, loss: 0.031646132469177246     \n",
      "train step #5755 accuracy: 0.921875, loss: 0.21013157069683075      \n",
      "train step #5756 accuracy: 0.984375, loss: 0.045425817370414734     \n",
      "train step #5757 accuracy: 0.96875, loss: 0.11112514138221741      \n",
      "train step #5758 accuracy: 0.96875, loss: 0.0904737040400505       \n",
      "train step #5759 accuracy: 0.953125, loss: 0.11374802142381668      \n",
      "train step #5760 accuracy:   1.0, loss: 0.03222336620092392      \n",
      "train step #5761 accuracy: 0.9375, loss: 0.34361881017684937      \n",
      "train step #5762 accuracy: 0.953125, loss: 0.17267167568206787      \n",
      "train step #5763 accuracy: 0.96875, loss: 0.11128532141447067      \n",
      "train step #5764 accuracy: 0.90625, loss: 0.31893688440322876      \n",
      "train step #5765 accuracy: 0.96875, loss: 0.0908512994647026       \n",
      "train step #5766 accuracy: 0.921875, loss: 0.2427314966917038       \n",
      "train step #5767 accuracy: 0.953125, loss: 0.16593125462532043      \n",
      "train step #5768 accuracy: 0.96875, loss: 0.1191786676645279       \n",
      "train step #5769 accuracy: 0.9375, loss: 0.2084539383649826       \n",
      "train step #5770 accuracy: 0.953125, loss: 0.16278022527694702      \n",
      "train step #5771 accuracy: 0.96875, loss: 0.1535632610321045       \n",
      "train step #5772 accuracy: 0.96875, loss: 0.123029425740242        \n",
      "train step #5773 accuracy: 0.984375, loss: 0.08526873588562012      \n",
      "train step #5774 accuracy: 0.890625, loss: 0.2443266212940216       \n",
      "train step #5775 accuracy: 0.953125, loss: 0.17242781817913055      \n",
      "train step #5776 accuracy: 0.96875, loss: 0.07233459502458572      \n",
      "train step #5777 accuracy:   1.0, loss: 0.0450730174779892       \n",
      "train step #5778 accuracy: 0.953125, loss: 0.17548534274101257      \n",
      "train step #5779 accuracy: 0.953125, loss: 0.1920725405216217       \n",
      "train step #5780 accuracy:   1.0, loss: 0.03262707591056824      \n",
      "train step #5781 accuracy: 0.953125, loss: 0.201325461268425        \n",
      "train step #5782 accuracy: 0.984375, loss: 0.09241419285535812      \n",
      "train step #5783 accuracy: 0.953125, loss: 0.20849333703517914      \n",
      "train step #5784 accuracy: 0.9375, loss: 0.2777922451496124       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #5785 accuracy: 0.96875, loss: 0.10516121983528137      \n",
      "train step #5786 accuracy: 0.921875, loss: 0.2953091859817505       \n",
      "train step #5787 accuracy: 0.953125, loss: 0.1546696573495865       \n",
      "train step #5788 accuracy: 0.984375, loss: 0.10949595272541046      \n",
      "train step #5789 accuracy: 0.9375, loss: 0.15404930710792542      \n",
      "train step #5790 accuracy: 0.984375, loss: 0.12595218420028687      \n",
      "train step #5791 accuracy:   1.0, loss: 0.05310835689306259      \n",
      "train step #5792 accuracy:   1.0, loss: 0.036905501037836075     \n",
      "train step #5793 accuracy: 0.953125, loss: 0.17823953926563263      \n",
      "train step #5794 accuracy: 0.96875, loss: 0.13162349164485931      \n",
      "train step #5795 accuracy: 0.953125, loss: 0.11189203709363937      \n",
      "train step #5796 accuracy: 0.984375, loss: 0.09589673578739166      \n",
      "train step #5797 accuracy: 0.984375, loss: 0.03939260542392731      \n",
      "train step #5798 accuracy:   1.0, loss: 0.026010222733020782     \n",
      "train step #5799 accuracy: 0.953125, loss: 0.17089316248893738      \n",
      "train step #5800 accuracy: 0.9375, loss: 0.28588053584098816      \n",
      "train step #5801 accuracy: 0.90625, loss: 0.3428184688091278       \n",
      "train step #5802 accuracy:   1.0, loss: 0.05874738097190857      \n",
      "train step #5803 accuracy: 0.9375, loss: 0.24595500528812408      \n",
      "train step #5804 accuracy: 0.984375, loss: 0.06454135477542877      \n",
      "train step #5805 accuracy: 0.9375, loss: 0.14809823036193848      \n",
      "train step #5806 accuracy: 0.953125, loss: 0.1848483681678772       \n",
      "train step #5807 accuracy: 0.96875, loss: 0.1649986058473587       \n",
      "train step #5808 accuracy: 0.96875, loss: 0.15083402395248413      \n",
      "train step #5809 accuracy: 0.96875, loss: 0.11610060930252075      \n",
      "train step #5810 accuracy: 0.953125, loss: 0.1442365199327469       \n",
      "train step #5811 accuracy:   1.0, loss: 0.06686581671237946      \n",
      "train step #5812 accuracy: 0.96875, loss: 0.10232566297054291      \n",
      "train step #5813 accuracy: 0.9375, loss: 0.19526682794094086      \n",
      "train step #5814 accuracy: 0.96875, loss: 0.10148248821496964      \n",
      "train step #5815 accuracy: 0.984375, loss: 0.03332296758890152      \n",
      "train step #5816 accuracy: 0.953125, loss: 0.21734945476055145      \n",
      "train step #5817 accuracy: 0.953125, loss: 0.15737976133823395      \n",
      "train step #5818 accuracy: 0.984375, loss: 0.04666756093502045      \n",
      "train step #5819 accuracy: 0.96875, loss: 0.13642175495624542      \n",
      "train step #5820 accuracy: 0.921875, loss: 0.24983298778533936      \n",
      "train step #5821 accuracy: 0.984375, loss: 0.06910814344882965      \n",
      "train step #5822 accuracy:   1.0, loss: 0.02424778789281845      \n",
      "train step #5823 accuracy: 0.96875, loss: 0.18356609344482422      \n",
      "train step #5824 accuracy: 0.890625, loss: 0.2499624490737915       \n",
      "train step #5825 accuracy: 0.9375, loss: 0.2334396094083786       \n",
      "train step #5826 accuracy: 0.96875, loss: 0.22679701447486877      \n",
      "train step #5827 accuracy: 0.984375, loss: 0.0883939191699028       \n",
      "train step #5828 accuracy: 0.953125, loss: 0.17946361005306244      \n",
      "train step #5829 accuracy: 0.96875, loss: 0.14180533587932587      \n",
      "train step #5830 accuracy: 0.921875, loss: 0.1918179988861084       \n",
      "train step #5831 accuracy: 0.96875, loss: 0.20546972751617432      \n",
      "train step #5832 accuracy: 0.984375, loss: 0.07455594837665558      \n",
      "train step #5833 accuracy: 0.984375, loss: 0.10889304429292679      \n",
      "train step #5834 accuracy: 0.921875, loss: 0.2563735842704773       \n",
      "train step #5835 accuracy: 0.953125, loss: 0.09798308461904526      \n",
      "train step #5836 accuracy: 0.96875, loss: 0.19252373278141022      \n",
      "train step #5837 accuracy: 0.984375, loss: 0.13034659624099731      \n",
      "train step #5838 accuracy: 0.9375, loss: 0.1787266582250595       \n",
      "train step #5839 accuracy: 0.96875, loss: 0.09510442614555359      \n",
      "train step #5840 accuracy: 0.921875, loss: 0.27957695722579956      \n",
      "train step #5841 accuracy: 0.984375, loss: 0.06028643995523453      \n",
      "train step #5842 accuracy: 0.9375, loss: 0.19143341481685638      \n",
      "train step #5843 accuracy: 0.953125, loss: 0.08485078066587448      \n",
      "train step #5844 accuracy:   1.0, loss: 0.025141559541225433     \n",
      "train step #5845 accuracy: 0.96875, loss: 0.16796545684337616      \n",
      "train step #5846 accuracy: 0.9375, loss: 0.31283998489379883      \n",
      "train step #5847 accuracy: 0.96875, loss: 0.15663278102874756      \n",
      "train step #5848 accuracy: 0.953125, loss: 0.12678565084934235      \n",
      "train step #5849 accuracy:   1.0, loss: 0.010626249015331268     \n",
      "train step #5850 accuracy: 0.984375, loss: 0.03719181567430496      \n",
      "train step #5851 accuracy: 0.953125, loss: 0.17522472143173218      \n",
      "train step #5852 accuracy: 0.984375, loss: 0.08453178405761719      \n",
      "train step #5853 accuracy: 0.96875, loss: 0.11834967136383057      \n",
      "train step #5854 accuracy: 0.9375, loss: 0.18661370873451233      \n",
      "train step #5855 accuracy: 0.9375, loss: 0.18879084289073944      \n",
      "train step #5856 accuracy: 0.9375, loss: 0.2865549921989441       \n",
      "train step #5857 accuracy:   1.0, loss: 0.030214905738830566     \n",
      "train step #5858 accuracy:   1.0, loss: 0.049800679087638855     \n",
      "train step #5859 accuracy: 0.953125, loss: 0.16607613861560822      \n",
      "train step #5860 accuracy: 0.984375, loss: 0.05857948213815689      \n",
      "train step #5861 accuracy: 0.984375, loss: 0.08970421552658081      \n",
      "train step #5862 accuracy: 0.953125, loss: 0.10097628831863403      \n",
      "train step #5863 accuracy: 0.96875, loss: 0.1134055033326149       \n",
      "train step #5864 accuracy: 0.9375, loss: 0.23201791942119598      \n",
      "train step #5865 accuracy: 0.921875, loss: 0.3448411822319031       \n",
      "train step #5866 accuracy: 0.953125, loss: 0.20017284154891968      \n",
      "train step #5867 accuracy: 0.953125, loss: 0.108303964138031        \n",
      "train step #5868 accuracy: 0.96875, loss: 0.18178677558898926      \n",
      "train step #5869 accuracy: 0.9375, loss: 0.13744892179965973      \n",
      "train step #5870 accuracy: 0.984375, loss: 0.08937522768974304      \n",
      "train step #5871 accuracy: 0.953125, loss: 0.2073792815208435       \n",
      "train step #5872 accuracy: 0.953125, loss: 0.2037450671195984       \n",
      "train step #5873 accuracy: 0.9375, loss: 0.3190525472164154       \n",
      "train step #5874 accuracy: 0.9375, loss: 0.2960091233253479       \n",
      "train step #5875 accuracy: 0.921875, loss: 0.2230086624622345       \n",
      "train step #5876 accuracy:   1.0, loss: 0.038529396057128906     \n",
      "train step #5877 accuracy: 0.984375, loss: 0.10086381435394287      \n",
      "train step #5878 accuracy: 0.984375, loss: 0.09143674373626709      \n",
      "train step #5879 accuracy: 0.9375, loss: 0.22230854630470276      \n",
      "train step #5880 accuracy: 0.953125, loss: 0.10458213090896606      \n",
      "train step #5881 accuracy: 0.9375, loss: 0.20933209359645844      \n",
      "train step #5882 accuracy: 0.984375, loss: 0.05852223187685013      \n",
      "train step #5883 accuracy: 0.984375, loss: 0.07816857099533081      \n",
      "train step #5884 accuracy: 0.953125, loss: 0.3204350471496582       \n",
      "train step #5885 accuracy: 0.921875, loss: 0.18145285546779633      \n",
      "train step #5886 accuracy: 0.953125, loss: 0.17370706796646118      \n",
      "train step #5887 accuracy: 0.984375, loss: 0.07112102210521698      \n",
      "train step #5888 accuracy: 0.921875, loss: 0.23154112696647644      \n",
      "train step #5889 accuracy:   1.0, loss: 0.0480518564581871       \n",
      "train step #5890 accuracy: 0.921875, loss: 0.2726578414440155       \n",
      "train step #5891 accuracy: 0.96875, loss: 0.1010093092918396       \n",
      "train step #5892 accuracy: 0.984375, loss: 0.11011867225170135      \n",
      "train step #5893 accuracy: 0.953125, loss: 0.11867038160562515      \n",
      "train step #5894 accuracy:   1.0, loss: 0.03897561877965927      \n",
      "train step #5895 accuracy: 0.9375, loss: 0.22250515222549438      \n",
      "train step #5896 accuracy: 0.890625, loss: 0.30707091093063354      \n",
      "train step #5897 accuracy: 0.984375, loss: 0.07599596679210663      \n",
      "train step #5898 accuracy:   1.0, loss: 0.01752191036939621      \n",
      "train step #5899 accuracy: 0.96875, loss: 0.15778738260269165      \n",
      "dev accuracy: 0.9375, loss: 0.26389622688293457      \n",
      "dev accuracy: 0.9375, loss: 0.1838495135307312       \n",
      "dev accuracy: 0.9375, loss: 0.30949804186820984      \n",
      "dev accuracy:   1.0, loss: 0.013262301683425903     \n",
      "dev accuracy: 0.9375, loss: 0.17819678783416748      \n",
      "dev accuracy: 0.875, loss: 0.2712082862854004       \n",
      "dev accuracy: 0.9375, loss: 0.10877528786659241      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy: 0.8125, loss: 0.3682008385658264       \n",
      "dev accuracy:   1.0, loss: 0.0635019838809967       \n",
      "dev accuracy: 0.9375, loss: 0.18562525510787964      \n",
      "dev accuracy:   1.0, loss: 0.04396381974220276      \n",
      "dev accuracy: 0.875, loss: 0.16721628606319427      \n",
      "dev accuracy: 0.9375, loss: 0.1687123030424118       \n",
      "dev accuracy: 0.9375, loss: 0.3093530833721161       \n",
      "dev accuracy: 0.9375, loss: 0.20277021825313568      \n",
      "dev accuracy: 0.9375, loss: 0.05707278847694397      \n",
      "dev accuracy: 0.9375, loss: 0.18749459087848663      \n",
      "dev accuracy: 0.875, loss: 0.3450584411621094       \n",
      "dev accuracy:   1.0, loss: 0.022301852703094482     \n",
      "dev accuracy:   1.0, loss: 0.011204510927200317     \n",
      "dev accuracy: 0.9375, loss: 0.3591509759426117       \n",
      "dev accuracy:   1.0, loss: 0.03277894854545593      \n",
      "dev accuracy:   1.0, loss: 0.0046446919441223145    \n",
      "dev accuracy:   1.0, loss: 0.015978634357452393     \n",
      "dev accuracy:   1.0, loss: 0.0010006427764892578    \n",
      "dev accuracy:   1.0, loss: 0.0026973485946655273    \n",
      "dev accuracy:   1.0, loss: 0.03301176428794861      \n",
      "dev accuracy: 0.875, loss: 0.31654539704322815      \n",
      "dev accuracy:   1.0, loss: 0.04478543996810913      \n",
      "dev accuracy: 0.875, loss: 0.1167876124382019       \n",
      "dev accuracy:   1.0, loss: 0.005451619625091553     \n",
      "dev accuracy: 0.9375, loss: 0.1410999894142151       \n",
      "dev accuracy: 0.8125, loss: 0.38248589634895325      \n",
      "dev accuracy: 0.875, loss: 0.408723384141922        \n",
      "dev accuracy: 0.8125, loss: 0.41195744276046753      \n",
      "dev accuracy:   1.0, loss: 0.011472851037979126     \n",
      "dev accuracy: 0.8125, loss: 0.4649874269962311       \n",
      "dev accuracy: 0.875, loss: 0.6268960237503052       \n",
      "dev accuracy:   1.0, loss: 0.032058656215667725     \n",
      "dev accuracy: 0.8125, loss: 0.6123405694961548       \n",
      "dev accuracy:   1.0, loss: 0.024371862411499023     \n",
      "dev accuracy: 0.875, loss: 0.7737443447113037       \n",
      "dev accuracy:   1.0, loss: 0.014159739017486572     \n",
      "dev accuracy: 0.9375, loss: 0.09458252787590027      \n",
      "dev accuracy: 0.9375, loss: 0.12591424584388733      \n",
      "dev accuracy: 0.9375, loss: 0.20528879761695862      \n",
      "dev accuracy:   1.0, loss: 0.035727232694625854     \n",
      "dev accuracy:   1.0, loss: 0.025288522243499756     \n",
      "dev accuracy:   1.0, loss: 0.05486413836479187      \n",
      "dev accuracy:   1.0, loss: 0.0651969462633133       \n",
      "dev accuracy:   1.0, loss: 0.010948210954666138     \n",
      "dev accuracy: 0.875, loss: 0.45684391260147095      \n",
      "dev accuracy: 0.9375, loss: 0.29002606868743896      \n",
      "dev accuracy: 0.9375, loss: 0.24586984515190125      \n",
      "dev accuracy:   1.0, loss: 0.011118680238723755     \n",
      "dev accuracy: 0.875, loss: 0.4396500885486603       \n",
      "dev accuracy: 0.9375, loss: 0.27839115262031555      \n",
      "dev accuracy:   1.0, loss: 0.022770613431930542     \n",
      "dev accuracy:   1.0, loss: 0.017808467149734497     \n",
      "dev accuracy: 0.875, loss: 0.2900235652923584       \n",
      "dev accuracy: 0.9375, loss: 0.11672059446573257      \n",
      "dev accuracy: 0.9375, loss: 0.38948315382003784      \n",
      "dev accuracy: 0.9375, loss: 0.20609444379806519      \n",
      "dev accuracy:   1.0, loss: 0.016897737979888916     \n",
      "dev accuracy:   1.0, loss: 0.0470389723777771       \n",
      "dev accuracy:   1.0, loss: 0.018091797828674316     \n",
      "dev accuracy:   1.0, loss: 0.0027241408824920654    \n",
      "dev accuracy:   1.0, loss: 0.029908984899520874     \n",
      "dev accuracy: 0.9375, loss: 0.38771969079971313      \n",
      "dev accuracy: 0.9375, loss: 0.14960883557796478      \n",
      "dev accuracy: 0.9375, loss: 0.1452084481716156       \n",
      "dev accuracy:   1.0, loss: 0.0036934614181518555    \n",
      "dev accuracy: 0.875, loss: 0.2990003228187561       \n",
      "dev accuracy:   1.0, loss: 0.016321927309036255     \n",
      "dev accuracy: 0.875, loss: 0.5876312255859375       \n",
      "dev accuracy:   1.0, loss: 0.03201037645339966      \n",
      "dev accuracy: 0.9375, loss: 0.14498835802078247      \n",
      "dev accuracy: 0.9375, loss: 0.07296805083751678      \n",
      "dev accuracy:   1.0, loss: 0.0010204315185546875    \n",
      "dev accuracy: 0.875, loss: 0.3266576826572418       \n",
      "dev accuracy:   1.0, loss: 0.05001768469810486      \n",
      "dev accuracy: 0.9375, loss: 0.10199463367462158      \n",
      "dev accuracy:   1.0, loss: 0.019843757152557373     \n",
      "dev accuracy:   1.0, loss: 0.013906240463256836     \n",
      "dev accuracy:   1.0, loss: 0.050673454999923706     \n",
      "dev accuracy:   1.0, loss: 0.001292884349822998     \n",
      "dev accuracy: 0.9375, loss: 0.4418807625770569       \n",
      "dev accuracy: 0.875, loss: 0.2950229048728943       \n",
      "dev accuracy: 0.9375, loss: 0.32339200377464294      \n",
      "dev accuracy:   1.0, loss: 0.0045265257358551025    \n",
      "dev accuracy:   1.0, loss: 0.04847532510757446      \n",
      "dev accuracy:   1.0, loss: 0.08820433914661407      \n",
      "dev accuracy: 0.9375, loss: 0.07341727614402771      \n",
      "dev accuracy: 0.9375, loss: 0.29998353123664856      \n",
      "dev accuracy:   1.0, loss: 0.0038163065910339355    \n",
      "dev accuracy: 0.9375, loss: 0.3514558970928192       \n",
      "dev accuracy: 0.9375, loss: 0.1149822473526001       \n",
      "dev accuracy: 0.875, loss: 0.20460852980613708      \n",
      "dev accuracy:   1.0, loss: 0.024870872497558594     \n",
      "dev accuracy:   1.0, loss: 0.014620780944824219     \n",
      "dev accuracy:  0.75, loss: 0.45255669951438904      \n",
      "dev accuracy: 0.9375, loss: 0.505308210849762        \n",
      "dev accuracy: 0.9375, loss: 0.23284341394901276      \n",
      "dev accuracy: 0.9375, loss: 0.24246856570243835      \n",
      "dev accuracy:   1.0, loss: 0.0024752020835876465    \n",
      "dev accuracy: 0.875, loss: 0.6397743821144104       \n",
      "dev accuracy: 0.9375, loss: 0.11409780383110046      \n",
      "dev accuracy:   1.0, loss: 0.003955543041229248     \n",
      "dev accuracy: 0.9375, loss: 0.19815945625305176      \n",
      "dev accuracy: 0.9375, loss: 0.1543971300125122       \n",
      "dev accuracy: 0.9375, loss: 0.45182788372039795      \n",
      "dev accuracy: 0.9375, loss: 0.1302902102470398       \n",
      "dev accuracy:   1.0, loss: 0.058832526206970215     \n",
      "dev accuracy:   1.0, loss: 0.000767052173614502     \n",
      "dev accuracy: 0.875, loss: 0.24105900526046753      \n",
      "dev accuracy:   1.0, loss: 0.0066010355949401855    \n",
      "dev accuracy: 0.875, loss: 0.27990734577178955      \n",
      "dev accuracy: 0.9375, loss: 0.2020002156496048       \n",
      "dev accuracy: 0.875, loss: 0.4020540714263916       \n",
      "dev accuracy: 0.9375, loss: 0.23248857259750366      \n",
      "dev accuracy:   1.0, loss: 0.011265844106674194     \n",
      "dev accuracy:   1.0, loss: 0.044477880001068115     \n",
      "dev accuracy: 0.9375, loss: 0.09029281139373779      \n",
      "dev accuracy: 0.9375, loss: 0.06473168730735779      \n",
      "dev accuracy:   1.0, loss: 0.04163983464241028      \n",
      "dev accuracy:   1.0, loss: 0.002242565155029297     \n",
      "dev accuracy:   1.0, loss: 0.0876726508140564       \n",
      "dev accuracy: 0.875, loss: 0.4207424521446228       \n",
      "dev accuracy:   1.0, loss: 0.0027219653129577637    \n",
      "dev accuracy: 0.9375, loss: 0.11084325611591339      \n",
      "dev accuracy: 0.8125, loss: 0.5261450409889221       \n",
      "dev accuracy:   1.0, loss: 0.017888009548187256     \n",
      "dev accuracy:   1.0, loss: 0.03449517488479614      \n",
      "dev accuracy:   1.0, loss: 0.039092063903808594     \n",
      "dev accuracy: 0.9375, loss: 0.13873010873794556      \n",
      "dev accuracy: 0.9375, loss: 0.10048449039459229      \n",
      "dev accuracy: 0.875, loss: 0.5385323166847229       \n",
      "dev accuracy: 0.9375, loss: 0.2841495871543884       \n",
      "dev accuracy: 0.9375, loss: 0.09366995841264725      \n",
      "dev accuracy: 0.9375, loss: 0.19362151622772217      \n",
      "dev accuracy:   1.0, loss: 0.015347570180892944     \n",
      "dev accuracy:   1.0, loss: 0.003950387239456177     \n",
      "dev accuracy: 0.9375, loss: 0.10544820129871368      \n",
      "dev accuracy: 0.9375, loss: 0.05821320414543152      \n",
      "dev accuracy:   1.0, loss: 0.007698148488998413     \n",
      "dev accuracy:   1.0, loss: 0.004746973514556885     \n",
      "dev accuracy:   1.0, loss: 0.006054550409317017     \n",
      "dev accuracy:   1.0, loss: 0.09896820783615112      \n",
      "dev accuracy: 0.9375, loss: 0.13934224843978882      \n",
      "dev accuracy: 0.8125, loss: 1.0529776811599731       \n",
      "dev accuracy: 0.9375, loss: 0.09664750099182129      \n",
      "dev accuracy:   1.0, loss: 0.004807472229003906     \n",
      "dev accuracy:   1.0, loss: 0.005199521780014038     \n",
      "dev accuracy: 0.9375, loss: 0.11667987704277039      \n",
      "dev accuracy: 0.875, loss: 0.5449904203414917       \n",
      "dev accuracy:   1.0, loss: 0.0010363459587097168    \n",
      "dev accuracy: 0.875, loss: 0.19599778950214386      \n",
      "dev accuracy: 0.9375, loss: 0.09443432092666626      \n",
      "dev accuracy: 0.9375, loss: 0.24025726318359375      \n",
      "dev accuracy:   1.0, loss: 0.006112575531005859     \n",
      "dev accuracy:   1.0, loss: 0.007916152477264404     \n",
      "dev accuracy: 0.875, loss: 0.1610926389694214       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy: 0.9375, loss: 0.19277344644069672      \n",
      "dev accuracy:   1.0, loss: 0.037126749753952026     \n",
      "dev accuracy:   1.0, loss: 0.05552339553833008      \n",
      "dev accuracy:   1.0, loss: 0.010006368160247803     \n",
      "dev accuracy: 0.875, loss: 0.6096985936164856       \n",
      "dev accuracy:   1.0, loss: 0.08956032991409302      \n",
      "dev accuracy: 0.875, loss: 0.23545362055301666      \n",
      "dev accuracy: 0.9375, loss: 0.0656270682811737       \n",
      "dev accuracy:   1.0, loss: 0.006414473056793213     \n",
      "dev accuracy:   1.0, loss: 0.004535973072052002     \n",
      "dev accuracy: 0.9375, loss: 0.2138020545244217       \n",
      "dev accuracy: 0.875, loss: 0.16188926994800568      \n",
      "dev accuracy: 0.875, loss: 0.48025253415107727      \n",
      "dev accuracy:   1.0, loss: 0.006284236907958984     \n",
      "dev accuracy: 0.9375, loss: 0.478180855512619        \n",
      "dev accuracy:   1.0, loss: 0.07928770780563354      \n",
      "dev accuracy:   1.0, loss: 0.008270442485809326     \n",
      "dev accuracy: 0.9375, loss: 0.08214619755744934      \n",
      "dev accuracy: 0.875, loss: 0.5502635836601257       \n",
      "dev accuracy:   1.0, loss: 0.02292656898498535      \n",
      "dev accuracy:   1.0, loss: 0.02363559603691101      \n",
      "dev accuracy: 0.9375, loss: 0.2051256150007248       \n",
      "dev accuracy:   1.0, loss: 0.029953956604003906     \n",
      "dev accuracy: 0.9375, loss: 0.10542634129524231      \n",
      "dev accuracy: 0.9375, loss: 0.46660253405570984      \n",
      "dev accuracy: 0.9375, loss: 0.24686528742313385      \n",
      "dev accuracy:   1.0, loss: 0.01598823070526123      \n",
      "dev accuracy:   1.0, loss: 0.06408143043518066      \n",
      "dev accuracy: 0.9375, loss: 0.1291356384754181       \n",
      "dev accuracy: 0.9375, loss: 0.2692252993583679       \n",
      "dev accuracy: 0.9375, loss: 0.1603408306837082       \n",
      "dev accuracy:   1.0, loss: 0.02755228616297245      \n",
      "final dev accuracy: 0.9497422680412371\n",
      "train step #5900 accuracy: 0.96875, loss: 0.15093748271465302      \n",
      "train step #5901 accuracy: 0.96875, loss: 0.14183808863162994      \n",
      "train step #5902 accuracy: 0.96875, loss: 0.04401788115501404      \n",
      "train step #5903 accuracy: 0.96875, loss: 0.14733490347862244      \n",
      "train step #5904 accuracy: 0.9375, loss: 0.3209676742553711       \n",
      "train step #5905 accuracy: 0.96875, loss: 0.1170068085193634       \n",
      "train step #5906 accuracy: 0.96875, loss: 0.05773890018463135      \n",
      "train step #5907 accuracy: 0.921875, loss: 0.19196560978889465      \n",
      "train step #5908 accuracy:   1.0, loss: 0.03378060460090637      \n",
      "train step #5909 accuracy: 0.96875, loss: 0.2271045744419098       \n",
      "train step #5910 accuracy:   1.0, loss: 0.020861349999904633     \n",
      "train step #5911 accuracy:   1.0, loss: 0.02556641399860382      \n",
      "train step #5912 accuracy: 0.984375, loss: 0.04237833991646767      \n",
      "train step #5913 accuracy: 0.9375, loss: 0.146032452583313        \n",
      "train step #5914 accuracy: 0.953125, loss: 0.14066475629806519      \n",
      "train step #5915 accuracy: 0.96875, loss: 0.07609989494085312      \n",
      "train step #5916 accuracy: 0.953125, loss: 0.15896651148796082      \n",
      "train step #5917 accuracy: 0.984375, loss: 0.06597958505153656      \n",
      "train step #5918 accuracy: 0.953125, loss: 0.14135965704917908      \n",
      "train step #5919 accuracy: 0.953125, loss: 0.14176547527313232      \n",
      "train step #5920 accuracy: 0.96875, loss: 0.12237385660409927      \n",
      "train step #5921 accuracy: 0.953125, loss: 0.13436579704284668      \n",
      "train step #5922 accuracy: 0.953125, loss: 0.17286749184131622      \n",
      "train step #5923 accuracy: 0.984375, loss: 0.06726925075054169      \n",
      "train step #5924 accuracy: 0.953125, loss: 0.15031170845031738      \n",
      "train step #5925 accuracy: 0.984375, loss: 0.04223032295703888      \n",
      "train step #5926 accuracy: 0.96875, loss: 0.11204483360052109      \n",
      "train step #5927 accuracy: 0.9375, loss: 0.22726385295391083      \n",
      "train step #5928 accuracy: 0.9375, loss: 0.16803833842277527      \n",
      "train step #5929 accuracy: 0.9375, loss: 0.21062113344669342      \n",
      "train step #5930 accuracy: 0.953125, loss: 0.14970463514328003      \n",
      "train step #5931 accuracy:   1.0, loss: 0.0403871051967144       \n",
      "train step #5932 accuracy: 0.96875, loss: 0.15122748911380768      \n",
      "train step #5933 accuracy: 0.984375, loss: 0.061958298087120056     \n",
      "train step #5934 accuracy: 0.890625, loss: 0.29870492219924927      \n",
      "train step #5935 accuracy: 0.90625, loss: 0.22345112264156342      \n",
      "train step #5936 accuracy: 0.953125, loss: 0.13211283087730408      \n",
      "train step #5937 accuracy: 0.953125, loss: 0.24906118214130402      \n",
      "train step #5938 accuracy: 0.953125, loss: 0.12084497511386871      \n",
      "train step #5939 accuracy: 0.984375, loss: 0.08690527081489563      \n",
      "train step #5940 accuracy: 0.953125, loss: 0.1622547060251236       \n",
      "train step #5941 accuracy: 0.96875, loss: 0.10542338341474533      \n",
      "train step #5942 accuracy:   1.0, loss: 0.057668037712574005     \n",
      "train step #5943 accuracy: 0.96875, loss: 0.11252512037754059      \n",
      "train step #5944 accuracy: 0.96875, loss: 0.12195892632007599      \n",
      "train step #5945 accuracy: 0.9375, loss: 0.22970426082611084      \n",
      "train step #5946 accuracy: 0.9375, loss: 0.23227578401565552      \n",
      "train step #5947 accuracy: 0.953125, loss: 0.1352088898420334       \n",
      "train step #5948 accuracy: 0.953125, loss: 0.16975243389606476      \n",
      "train step #5949 accuracy: 0.953125, loss: 0.2082332968711853       \n",
      "train step #5950 accuracy: 0.984375, loss: 0.07322224974632263      \n",
      "train step #5951 accuracy: 0.96875, loss: 0.1268281191587448       \n",
      "train step #5952 accuracy: 0.953125, loss: 0.15326480567455292      \n",
      "train step #5953 accuracy: 0.96875, loss: 0.12896564602851868      \n",
      "train step #5954 accuracy: 0.984375, loss: 0.06774935126304626      \n",
      "train step #5955 accuracy: 0.96875, loss: 0.19529037177562714      \n",
      "train step #5956 accuracy:   1.0, loss: 0.022912494838237762     \n",
      "train step #5957 accuracy: 0.984375, loss: 0.06037428230047226      \n",
      "train step #5958 accuracy: 0.9375, loss: 0.12483463436365128      \n",
      "train step #5959 accuracy: 0.90625, loss: 0.17278292775154114      \n",
      "train step #5960 accuracy: 0.96875, loss: 0.07036091387271881      \n",
      "train step #5961 accuracy: 0.9375, loss: 0.16287417709827423      \n",
      "train step #5962 accuracy: 0.96875, loss: 0.07897505909204483      \n",
      "train step #5963 accuracy: 0.984375, loss: 0.06982700526714325      \n",
      "train step #5964 accuracy: 0.984375, loss: 0.07689382135868073      \n",
      "train step #5965 accuracy: 0.96875, loss: 0.11059904098510742      \n",
      "train step #5966 accuracy: 0.953125, loss: 0.20163248479366302      \n",
      "train step #5967 accuracy: 0.953125, loss: 0.1060997024178505       \n",
      "train step #5968 accuracy: 0.90625, loss: 0.36564603447914124      \n",
      "train step #5969 accuracy:   1.0, loss: 0.04308699816465378      \n",
      "train step #5970 accuracy: 0.984375, loss: 0.08424211293458939      \n",
      "train step #5971 accuracy: 0.984375, loss: 0.04465072602033615      \n",
      "train step #5972 accuracy: 0.984375, loss: 0.04469139128923416      \n",
      "train step #5973 accuracy: 0.96875, loss: 0.13117718696594238      \n",
      "train step #5974 accuracy: 0.984375, loss: 0.11291004717350006      \n",
      "train step #5975 accuracy: 0.953125, loss: 0.18669484555721283      \n",
      "train step #5976 accuracy:   1.0, loss: 0.012944020330905914     \n",
      "train step #5977 accuracy: 0.953125, loss: 0.22529131174087524      \n",
      "train step #5978 accuracy: 0.96875, loss: 0.14811457693576813      \n",
      "train step #5979 accuracy: 0.9375, loss: 0.3136689066886902       \n",
      "train step #5980 accuracy: 0.96875, loss: 0.10819771885871887      \n",
      "train step #5981 accuracy: 0.953125, loss: 0.1425568014383316       \n",
      "train step #5982 accuracy: 0.984375, loss: 0.07210627943277359      \n",
      "train step #5983 accuracy: 0.921875, loss: 0.16400806605815887      \n",
      "train step #5984 accuracy: 0.984375, loss: 0.077022023499012        \n",
      "train step #5985 accuracy: 0.96875, loss: 0.10976152867078781      \n",
      "train step #5986 accuracy: 0.90625, loss: 0.24589654803276062      \n",
      "train step #5987 accuracy: 0.984375, loss: 0.05973980948328972      \n",
      "train step #5988 accuracy: 0.96875, loss: 0.09851669520139694      \n",
      "train step #5989 accuracy: 0.96875, loss: 0.1383509635925293       \n",
      "train step #5990 accuracy:   1.0, loss: 0.024585925042629242     \n",
      "train step #5991 accuracy: 0.953125, loss: 0.1511901617050171       \n",
      "train step #5992 accuracy: 0.96875, loss: 0.1438378095626831       \n",
      "train step #5993 accuracy: 0.953125, loss: 0.19361847639083862      \n",
      "train step #5994 accuracy: 0.96875, loss: 0.10753767937421799      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #5995 accuracy: 0.953125, loss: 0.15958593785762787      \n",
      "train step #5996 accuracy: 0.9375, loss: 0.14382441341876984      \n",
      "train step #5997 accuracy: 0.9375, loss: 0.17872992157936096      \n",
      "train step #5998 accuracy: 0.9375, loss: 0.406980037689209        \n",
      "train step #5999 accuracy: 0.953125, loss: 0.20463746786117554      \n",
      "train step #6000 accuracy: 0.96875, loss: 0.15600769221782684      \n",
      "changing learning rate to 0.001\n",
      "train step #6001 accuracy: 0.984375, loss: 0.06783555448055267      \n",
      "train step #6002 accuracy: 0.984375, loss: 0.03793018311262131      \n",
      "train step #6003 accuracy: 0.953125, loss: 0.20075950026512146      \n",
      "train step #6004 accuracy: 0.96875, loss: 0.14176851511001587      \n",
      "train step #6005 accuracy: 0.984375, loss: 0.07213695347309113      \n",
      "train step #6006 accuracy: 0.9375, loss: 0.3469787836074829       \n",
      "train step #6007 accuracy: 0.96875, loss: 0.10817914456129074      \n",
      "train step #6008 accuracy: 0.984375, loss: 0.08231132477521896      \n",
      "train step #6009 accuracy: 0.984375, loss: 0.026926174759864807     \n",
      "train step #6010 accuracy: 0.96875, loss: 0.12843598425388336      \n",
      "train step #6011 accuracy: 0.953125, loss: 0.19432447850704193      \n",
      "train step #6012 accuracy: 0.96875, loss: 0.16031426191329956      \n",
      "train step #6013 accuracy: 0.96875, loss: 0.09962403029203415      \n",
      "train step #6014 accuracy: 0.9375, loss: 0.22819721698760986      \n",
      "train step #6015 accuracy: 0.9375, loss: 0.22856830060482025      \n",
      "train step #6016 accuracy: 0.96875, loss: 0.09930439293384552      \n",
      "train step #6017 accuracy: 0.96875, loss: 0.13555434346199036      \n",
      "train step #6018 accuracy: 0.984375, loss: 0.05817557871341705      \n",
      "train step #6019 accuracy: 0.9375, loss: 0.14313998818397522      \n",
      "train step #6020 accuracy: 0.984375, loss: 0.05117744207382202      \n",
      "train step #6021 accuracy: 0.953125, loss: 0.16883572936058044      \n",
      "train step #6022 accuracy: 0.96875, loss: 0.13087458908557892      \n",
      "train step #6023 accuracy: 0.984375, loss: 0.09029644727706909      \n",
      "train step #6024 accuracy: 0.9375, loss: 0.2521533668041229       \n",
      "train step #6025 accuracy: 0.921875, loss: 0.291037380695343        \n",
      "train step #6026 accuracy: 0.96875, loss: 0.11962398886680603      \n",
      "train step #6027 accuracy: 0.96875, loss: 0.21164536476135254      \n",
      "train step #6028 accuracy: 0.96875, loss: 0.15486541390419006      \n",
      "train step #6029 accuracy:   1.0, loss: 0.03378032520413399      \n",
      "train step #6030 accuracy: 0.96875, loss: 0.10688085108995438      \n",
      "train step #6031 accuracy: 0.984375, loss: 0.02469264715909958      \n",
      "train step #6032 accuracy: 0.953125, loss: 0.20590123534202576      \n",
      "train step #6033 accuracy: 0.96875, loss: 0.10567741841077805      \n",
      "train step #6034 accuracy: 0.953125, loss: 0.15149515867233276      \n",
      "train step #6035 accuracy: 0.96875, loss: 0.07785004377365112      \n",
      "train step #6036 accuracy: 0.984375, loss: 0.0830812081694603       \n",
      "train step #6037 accuracy: 0.984375, loss: 0.06314156949520111      \n",
      "train step #6038 accuracy: 0.984375, loss: 0.06913809478282928      \n",
      "train step #6039 accuracy: 0.96875, loss: 0.13028106093406677      \n",
      "train step #6040 accuracy: 0.96875, loss: 0.1488044112920761       \n",
      "train step #6041 accuracy: 0.96875, loss: 0.10374307632446289      \n",
      "train step #6042 accuracy: 0.984375, loss: 0.05230935662984848      \n",
      "train step #6043 accuracy: 0.96875, loss: 0.13315320014953613      \n",
      "train step #6044 accuracy: 0.96875, loss: 0.1539003551006317       \n",
      "train step #6045 accuracy: 0.953125, loss: 0.1412927508354187       \n",
      "train step #6046 accuracy: 0.9375, loss: 0.16670826077461243      \n",
      "train step #6047 accuracy:   1.0, loss: 0.031910642981529236     \n",
      "train step #6048 accuracy: 0.984375, loss: 0.07328282296657562      \n",
      "train step #6049 accuracy: 0.96875, loss: 0.11684085428714752      \n",
      "train step #6050 accuracy: 0.96875, loss: 0.14169642329216003      \n",
      "train step #6051 accuracy: 0.96875, loss: 0.12599578499794006      \n",
      "train step #6052 accuracy: 0.96875, loss: 0.09407377243041992      \n",
      "train step #6053 accuracy:   1.0, loss: 0.01773742586374283      \n",
      "train step #6054 accuracy: 0.984375, loss: 0.09674865007400513      \n",
      "train step #6055 accuracy: 0.9375, loss: 0.20293816924095154      \n",
      "train step #6056 accuracy: 0.921875, loss: 0.3253686726093292       \n",
      "train step #6057 accuracy: 0.984375, loss: 0.13665440678596497      \n",
      "train step #6058 accuracy: 0.953125, loss: 0.16695266962051392      \n",
      "train step #6059 accuracy: 0.96875, loss: 0.06883321702480316      \n",
      "train step #6060 accuracy:   1.0, loss: 0.026290342211723328     \n",
      "train step #6061 accuracy: 0.96875, loss: 0.18631614744663239      \n",
      "train step #6062 accuracy: 0.984375, loss: 0.12683548033237457      \n",
      "train step #6063 accuracy: 0.953125, loss: 0.14470314979553223      \n",
      "train step #6064 accuracy: 0.984375, loss: 0.0827668309211731       \n",
      "train step #6065 accuracy: 0.953125, loss: 0.22149129211902618      \n",
      "train step #6066 accuracy: 0.9375, loss: 0.15545469522476196      \n",
      "train step #6067 accuracy: 0.96875, loss: 0.0775483250617981       \n",
      "train step #6068 accuracy:   1.0, loss: 0.03934982419013977      \n",
      "train step #6069 accuracy: 0.90625, loss: 0.2684287130832672       \n",
      "train step #6070 accuracy: 0.96875, loss: 0.17633311450481415      \n",
      "train step #6071 accuracy: 0.984375, loss: 0.09959541261196136      \n",
      "train step #6072 accuracy: 0.96875, loss: 0.10793460160493851      \n",
      "train step #6073 accuracy: 0.953125, loss: 0.17034482955932617      \n",
      "train step #6074 accuracy: 0.953125, loss: 0.1262340247631073       \n",
      "train step #6075 accuracy: 0.984375, loss: 0.09381868690252304      \n",
      "train step #6076 accuracy: 0.96875, loss: 0.15776894986629486      \n",
      "train step #6077 accuracy: 0.953125, loss: 0.1367146074771881       \n",
      "train step #6078 accuracy: 0.953125, loss: 0.15411829948425293      \n",
      "train step #6079 accuracy: 0.953125, loss: 0.20679634809494019      \n",
      "train step #6080 accuracy: 0.96875, loss: 0.07917454838752747      \n",
      "train step #6081 accuracy: 0.953125, loss: 0.19273367524147034      \n",
      "train step #6082 accuracy:   1.0, loss: 0.023191645741462708     \n",
      "train step #6083 accuracy: 0.984375, loss: 0.07056108862161636      \n",
      "train step #6084 accuracy: 0.96875, loss: 0.06716349720954895      \n",
      "train step #6085 accuracy: 0.96875, loss: 0.16482806205749512      \n",
      "train step #6086 accuracy: 0.984375, loss: 0.09466585516929626      \n",
      "train step #6087 accuracy: 0.984375, loss: 0.08709971606731415      \n",
      "train step #6088 accuracy: 0.984375, loss: 0.10211848467588425      \n",
      "train step #6089 accuracy:   1.0, loss: 0.05276933312416077      \n",
      "train step #6090 accuracy: 0.953125, loss: 0.1682751625776291       \n",
      "train step #6091 accuracy: 0.96875, loss: 0.1560972034931183       \n",
      "train step #6092 accuracy: 0.96875, loss: 0.08363836258649826      \n",
      "train step #6093 accuracy: 0.953125, loss: 0.2636483907699585       \n",
      "train step #6094 accuracy: 0.921875, loss: 0.3089870512485504       \n",
      "train step #6095 accuracy: 0.953125, loss: 0.11705929040908813      \n",
      "train step #6096 accuracy: 0.984375, loss: 0.10324092209339142      \n",
      "train step #6097 accuracy: 0.984375, loss: 0.05815235525369644      \n",
      "train step #6098 accuracy:   1.0, loss: 0.02410838007926941      \n",
      "train step #6099 accuracy: 0.953125, loss: 0.11174675822257996      \n",
      "train step #6100 accuracy: 0.953125, loss: 0.18339580297470093      \n",
      "train step #6101 accuracy: 0.9375, loss: 0.20787273347377777      \n",
      "train step #6102 accuracy: 0.890625, loss: 0.3035717308521271       \n",
      "train step #6103 accuracy: 0.953125, loss: 0.17455901205539703      \n",
      "train step #6104 accuracy: 0.921875, loss: 0.22301135957241058      \n",
      "train step #6105 accuracy: 0.953125, loss: 0.13845592737197876      \n",
      "train step #6106 accuracy: 0.953125, loss: 0.1205013319849968       \n",
      "train step #6107 accuracy: 0.953125, loss: 0.08186068385839462      \n",
      "train step #6108 accuracy: 0.921875, loss: 0.14658065140247345      \n",
      "train step #6109 accuracy:   1.0, loss: 0.0709683746099472       \n",
      "train step #6110 accuracy: 0.984375, loss: 0.06846041977405548      \n",
      "train step #6111 accuracy: 0.984375, loss: 0.11481146514415741      \n",
      "train step #6112 accuracy: 0.96875, loss: 0.05699284374713898      \n",
      "train step #6113 accuracy: 0.953125, loss: 0.16196545958518982      \n",
      "train step #6114 accuracy: 0.96875, loss: 0.15509311854839325      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #6115 accuracy: 0.9375, loss: 0.2632633447647095       \n",
      "train step #6116 accuracy: 0.96875, loss: 0.08344903588294983      \n",
      "train step #6117 accuracy: 0.984375, loss: 0.07458707690238953      \n",
      "train step #6118 accuracy: 0.984375, loss: 0.09035255014896393      \n",
      "train step #6119 accuracy: 0.96875, loss: 0.09990941733121872      \n",
      "train step #6120 accuracy:   1.0, loss: 0.025484688580036163     \n",
      "train step #6121 accuracy: 0.984375, loss: 0.05977160856127739      \n",
      "train step #6122 accuracy: 0.90625, loss: 0.2839199900627136       \n",
      "train step #6123 accuracy:   1.0, loss: 0.05026429519057274      \n",
      "train step #6124 accuracy: 0.96875, loss: 0.07528889179229736      \n",
      "train step #6125 accuracy: 0.953125, loss: 0.19331786036491394      \n",
      "train step #6126 accuracy: 0.953125, loss: 0.20961910486221313      \n",
      "train step #6127 accuracy: 0.984375, loss: 0.08748769015073776      \n",
      "train step #6128 accuracy:   1.0, loss: 0.031339287757873535     \n",
      "train step #6129 accuracy: 0.96875, loss: 0.0676255002617836       \n",
      "train step #6130 accuracy: 0.96875, loss: 0.09981153905391693      \n",
      "train step #6131 accuracy: 0.953125, loss: 0.14488059282302856      \n",
      "train step #6132 accuracy: 0.953125, loss: 0.15445905923843384      \n",
      "train step #6133 accuracy: 0.984375, loss: 0.14299190044403076      \n",
      "train step #6134 accuracy:   1.0, loss: 0.028990961611270905     \n",
      "train step #6135 accuracy: 0.9375, loss: 0.24586980044841766      \n",
      "train step #6136 accuracy: 0.984375, loss: 0.10138271003961563      \n",
      "train step #6137 accuracy: 0.9375, loss: 0.24234408140182495      \n",
      "train step #6138 accuracy:   1.0, loss: 0.017606623470783234     \n",
      "train step #6139 accuracy: 0.984375, loss: 0.10389894992113113      \n",
      "train step #6140 accuracy: 0.953125, loss: 0.16611340641975403      \n",
      "train step #6141 accuracy: 0.953125, loss: 0.205002561211586        \n",
      "train step #6142 accuracy: 0.9375, loss: 0.28105199337005615      \n",
      "train step #6143 accuracy:   1.0, loss: 0.06211744621396065      \n",
      "train step #6144 accuracy: 0.984375, loss: 0.0626392588019371       \n",
      "train step #6145 accuracy: 0.953125, loss: 0.13593515753746033      \n",
      "train step #6146 accuracy: 0.953125, loss: 0.10459074378013611      \n",
      "train step #6147 accuracy: 0.953125, loss: 0.07776244729757309      \n",
      "train step #6148 accuracy: 0.984375, loss: 0.07838547229766846      \n",
      "train step #6149 accuracy: 0.921875, loss: 0.311554878950119        \n",
      "train step #6150 accuracy: 0.984375, loss: 0.03734694421291351      \n",
      "train step #6151 accuracy: 0.9375, loss: 0.26392772793769836      \n",
      "train step #6152 accuracy: 0.984375, loss: 0.09025710076093674      \n",
      "train step #6153 accuracy:   1.0, loss: 0.029878530651330948     \n",
      "train step #6154 accuracy: 0.96875, loss: 0.12054280191659927      \n",
      "train step #6155 accuracy: 0.953125, loss: 0.2534079849720001       \n",
      "train step #6156 accuracy: 0.9375, loss: 0.15172769129276276      \n",
      "train step #6157 accuracy: 0.921875, loss: 0.24356544017791748      \n",
      "train step #6158 accuracy: 0.921875, loss: 0.2724677622318268       \n",
      "train step #6159 accuracy: 0.984375, loss: 0.07127802819013596      \n",
      "train step #6160 accuracy: 0.953125, loss: 0.19740526378154755      \n",
      "train step #6161 accuracy:   1.0, loss: 0.03411852568387985      \n",
      "train step #6162 accuracy: 0.984375, loss: 0.04728648066520691      \n",
      "train step #6163 accuracy: 0.96875, loss: 0.07857244461774826      \n",
      "train step #6164 accuracy: 0.953125, loss: 0.18010331690311432      \n",
      "train step #6165 accuracy: 0.953125, loss: 0.13240452110767365      \n",
      "train step #6166 accuracy: 0.953125, loss: 0.1493169516324997       \n",
      "train step #6167 accuracy: 0.984375, loss: 0.11957630515098572      \n",
      "train step #6168 accuracy: 0.90625, loss: 0.3139280080795288       \n",
      "train step #6169 accuracy: 0.984375, loss: 0.07663273066282272      \n",
      "train step #6170 accuracy:   1.0, loss: 0.012575861066579819     \n",
      "train step #6171 accuracy:   1.0, loss: 0.05826512724161148      \n",
      "train step #6172 accuracy: 0.96875, loss: 0.1353146731853485       \n",
      "train step #6173 accuracy: 0.984375, loss: 0.10584443807601929      \n",
      "train step #6174 accuracy: 0.984375, loss: 0.09359385818243027      \n",
      "train step #6175 accuracy: 0.953125, loss: 0.16726776957511902      \n",
      "train step #6176 accuracy: 0.953125, loss: 0.16644050180912018      \n",
      "train step #6177 accuracy: 0.890625, loss: 0.3280375003814697       \n",
      "train step #6178 accuracy: 0.984375, loss: 0.09717246890068054      \n",
      "train step #6179 accuracy: 0.984375, loss: 0.12539587914943695      \n",
      "train step #6180 accuracy: 0.953125, loss: 0.16629493236541748      \n",
      "train step #6181 accuracy: 0.96875, loss: 0.1379263997077942       \n",
      "train step #6182 accuracy: 0.984375, loss: 0.08702032268047333      \n",
      "train step #6183 accuracy: 0.984375, loss: 0.1132887527346611       \n",
      "train step #6184 accuracy: 0.984375, loss: 0.04343105107545853      \n",
      "train step #6185 accuracy:   1.0, loss: 0.022440485656261444     \n",
      "train step #6186 accuracy: 0.921875, loss: 0.22403094172477722      \n",
      "train step #6187 accuracy: 0.96875, loss: 0.06845858693122864      \n",
      "train step #6188 accuracy: 0.984375, loss: 0.0888349860906601       \n",
      "train step #6189 accuracy: 0.90625, loss: 0.347048282623291        \n",
      "train step #6190 accuracy: 0.984375, loss: 0.06594396382570267      \n",
      "train step #6191 accuracy: 0.953125, loss: 0.19886213541030884      \n",
      "train step #6192 accuracy: 0.953125, loss: 0.158079594373703        \n",
      "train step #6193 accuracy:   1.0, loss: 0.01605387032032013      \n",
      "train step #6194 accuracy: 0.9375, loss: 0.25953590869903564      \n",
      "train step #6195 accuracy:   1.0, loss: 0.05640437453985214      \n",
      "train step #6196 accuracy: 0.921875, loss: 0.27658912539482117      \n",
      "train step #6197 accuracy: 0.984375, loss: 0.06566828489303589      \n",
      "train step #6198 accuracy: 0.9375, loss: 0.2212080955505371       \n",
      "train step #6199 accuracy: 0.921875, loss: 0.20803403854370117      \n",
      "train step #6200 accuracy: 0.984375, loss: 0.1039595901966095       \n",
      "train step #6201 accuracy: 0.9375, loss: 0.25657543540000916      \n",
      "train step #6202 accuracy: 0.96875, loss: 0.09205333143472672      \n",
      "train step #6203 accuracy:   1.0, loss: 0.029884696006774902     \n",
      "train step #6204 accuracy: 0.96875, loss: 0.1364089399576187       \n",
      "train step #6205 accuracy: 0.96875, loss: 0.15501593053340912      \n",
      "train step #6206 accuracy: 0.984375, loss: 0.04166547209024429      \n",
      "train step #6207 accuracy: 0.953125, loss: 0.13209357857704163      \n",
      "train step #6208 accuracy: 0.984375, loss: 0.05855868384242058      \n",
      "train step #6209 accuracy: 0.953125, loss: 0.15514594316482544      \n",
      "train step #6210 accuracy:   1.0, loss: 0.050660140812397        \n",
      "train step #6211 accuracy: 0.984375, loss: 0.06952846050262451      \n",
      "train step #6212 accuracy: 0.9375, loss: 0.31720709800720215      \n",
      "train step #6213 accuracy: 0.9375, loss: 0.18126900494098663      \n",
      "train step #6214 accuracy: 0.96875, loss: 0.10161544382572174      \n",
      "train step #6215 accuracy: 0.984375, loss: 0.10794878751039505      \n",
      "train step #6216 accuracy: 0.9375, loss: 0.2800534665584564       \n",
      "train step #6217 accuracy: 0.96875, loss: 0.23498570919036865      \n",
      "train step #6218 accuracy: 0.984375, loss: 0.06257414072751999      \n",
      "train step #6219 accuracy: 0.953125, loss: 0.14568620920181274      \n",
      "train step #6220 accuracy: 0.96875, loss: 0.1328010857105255       \n",
      "train step #6221 accuracy: 0.921875, loss: 0.21898207068443298      \n",
      "train step #6222 accuracy: 0.984375, loss: 0.03330259770154953      \n",
      "train step #6223 accuracy: 0.9375, loss: 0.23942799866199493      \n",
      "train step #6224 accuracy:   1.0, loss: 0.03137100487947464      \n",
      "train step #6225 accuracy: 0.96875, loss: 0.14529359340667725      \n",
      "train step #6226 accuracy: 0.984375, loss: 0.04303011670708656      \n",
      "train step #6227 accuracy: 0.953125, loss: 0.08833156526088715      \n",
      "train step #6228 accuracy: 0.9375, loss: 0.17179779708385468      \n",
      "train step #6229 accuracy: 0.984375, loss: 0.0393778532743454       \n",
      "train step #6230 accuracy: 0.96875, loss: 0.1472243368625641       \n",
      "train step #6231 accuracy: 0.953125, loss: 0.23168142139911652      \n",
      "train step #6232 accuracy: 0.953125, loss: 0.1631837636232376       \n",
      "train step #6233 accuracy: 0.96875, loss: 0.17395387589931488      \n",
      "train step #6234 accuracy:   1.0, loss: 0.05731518194079399      \n",
      "train step #6235 accuracy: 0.90625, loss: 0.257079541683197        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #6236 accuracy: 0.96875, loss: 0.1077486053109169       \n",
      "train step #6237 accuracy: 0.96875, loss: 0.09408771991729736      \n",
      "train step #6238 accuracy: 0.96875, loss: 0.15129512548446655      \n",
      "train step #6239 accuracy: 0.953125, loss: 0.29725179076194763      \n",
      "train step #6240 accuracy: 0.953125, loss: 0.18939171731472015      \n",
      "train step #6241 accuracy: 0.953125, loss: 0.25305885076522827      \n",
      "train step #6242 accuracy: 0.984375, loss: 0.059478722512722015     \n",
      "train step #6243 accuracy: 0.96875, loss: 0.16162839531898499      \n",
      "train step #6244 accuracy: 0.9375, loss: 0.1911977380514145       \n",
      "train step #6245 accuracy: 0.984375, loss: 0.10133080184459686      \n",
      "train step #6246 accuracy: 0.984375, loss: 0.052407875657081604     \n",
      "dev accuracy:   1.0, loss: 0.011846780776977539     \n",
      "dev accuracy:   1.0, loss: 0.02322348952293396      \n",
      "dev accuracy:   1.0, loss: 0.10081607103347778      \n",
      "dev accuracy:   1.0, loss: 0.002763509750366211     \n",
      "dev accuracy:   1.0, loss: 0.029685229063034058     \n",
      "dev accuracy: 0.9375, loss: 0.26480618119239807      \n",
      "dev accuracy:   1.0, loss: 0.0009947419166564941    \n",
      "dev accuracy:   1.0, loss: 0.01360708475112915      \n",
      "dev accuracy:   1.0, loss: 0.010175764560699463     \n",
      "dev accuracy: 0.9375, loss: 0.05687376856803894      \n",
      "dev accuracy:   1.0, loss: 0.00920712947845459      \n",
      "dev accuracy: 0.9375, loss: 0.07545110583305359      \n",
      "dev accuracy:   1.0, loss: 0.041707634925842285     \n",
      "dev accuracy: 0.8125, loss: 0.4672938585281372       \n",
      "dev accuracy: 0.875, loss: 0.49029305577278137      \n",
      "dev accuracy:   1.0, loss: 0.06354954838752747      \n",
      "dev accuracy: 0.9375, loss: 0.14135481417179108      \n",
      "dev accuracy:   1.0, loss: 0.01231604814529419      \n",
      "dev accuracy: 0.9375, loss: 0.11253483593463898      \n",
      "dev accuracy: 0.9375, loss: 0.26091673970222473      \n",
      "dev accuracy:   1.0, loss: 0.07626429200172424      \n",
      "dev accuracy:   1.0, loss: 0.019400715827941895     \n",
      "dev accuracy: 0.9375, loss: 0.26672637462615967      \n",
      "dev accuracy: 0.9375, loss: 0.1068234071135521       \n",
      "dev accuracy: 0.9375, loss: 0.20228447020053864      \n",
      "dev accuracy: 0.875, loss: 0.4444423019886017       \n",
      "dev accuracy: 0.9375, loss: 0.41616740822792053      \n",
      "dev accuracy: 0.9375, loss: 0.24091967940330505      \n",
      "dev accuracy: 0.9375, loss: 0.08046799898147583      \n",
      "dev accuracy: 0.875, loss: 0.11894100904464722      \n",
      "dev accuracy:   1.0, loss: 0.08783295750617981      \n",
      "dev accuracy: 0.875, loss: 0.26247042417526245      \n",
      "dev accuracy: 0.875, loss: 0.16680561006069183      \n",
      "dev accuracy:   1.0, loss: 0.0035501420497894287    \n",
      "dev accuracy: 0.9375, loss: 0.0632464587688446       \n",
      "dev accuracy:   1.0, loss: 0.020865559577941895     \n",
      "dev accuracy: 0.9375, loss: 0.24979528784751892      \n",
      "dev accuracy: 0.9375, loss: 0.2163054347038269       \n",
      "dev accuracy:   1.0, loss: 0.0007940828800201416    \n",
      "dev accuracy: 0.875, loss: 0.47700196504592896      \n",
      "dev accuracy:   1.0, loss: 0.015452772378921509     \n",
      "dev accuracy: 0.875, loss: 0.4531986117362976       \n",
      "dev accuracy: 0.8125, loss: 0.369854211807251        \n",
      "dev accuracy:   1.0, loss: 0.12343162298202515      \n",
      "dev accuracy:   1.0, loss: 0.002805262804031372     \n",
      "dev accuracy: 0.875, loss: 0.17142438888549805      \n",
      "dev accuracy: 0.875, loss: 0.2650654911994934       \n",
      "dev accuracy: 0.9375, loss: 0.07830837368965149      \n",
      "dev accuracy:   1.0, loss: 0.012280762195587158     \n",
      "dev accuracy:   1.0, loss: 0.0037207603454589844    \n",
      "dev accuracy:   1.0, loss: 0.02125874161720276      \n",
      "dev accuracy:   1.0, loss: 0.0015360116958618164    \n",
      "dev accuracy:   1.0, loss: 0.03562691807746887      \n",
      "dev accuracy: 0.8125, loss: 0.5346839427947998       \n",
      "dev accuracy: 0.9375, loss: 0.12017634510993958      \n",
      "dev accuracy:   1.0, loss: 0.0182248055934906       \n",
      "dev accuracy:   1.0, loss: 0.11575272679328918      \n",
      "dev accuracy:   1.0, loss: 0.058058977127075195     \n",
      "dev accuracy: 0.875, loss: 0.6509533524513245       \n",
      "dev accuracy: 0.9375, loss: 0.24494615197181702      \n",
      "dev accuracy:   1.0, loss: 0.011993497610092163     \n",
      "dev accuracy: 0.9375, loss: 0.08250835537910461      \n",
      "dev accuracy: 0.875, loss: 0.6475648283958435       \n",
      "dev accuracy: 0.875, loss: 0.36421287059783936      \n",
      "dev accuracy:   1.0, loss: 0.004827231168746948     \n",
      "dev accuracy: 0.9375, loss: 0.3298054039478302       \n",
      "dev accuracy: 0.875, loss: 0.3836881220340729       \n",
      "dev accuracy: 0.9375, loss: 0.11449024081230164      \n",
      "dev accuracy: 0.9375, loss: 0.18323355913162231      \n",
      "dev accuracy:   1.0, loss: 0.014081418514251709     \n",
      "dev accuracy: 0.875, loss: 0.4889971911907196       \n",
      "dev accuracy: 0.9375, loss: 0.24442251026630402      \n",
      "dev accuracy: 0.9375, loss: 0.336071252822876        \n",
      "dev accuracy:   1.0, loss: 0.002721726894378662     \n",
      "dev accuracy: 0.8125, loss: 0.30587127804756165      \n",
      "dev accuracy:   1.0, loss: 0.054443418979644775     \n",
      "dev accuracy: 0.8125, loss: 0.537939190864563        \n",
      "dev accuracy:   1.0, loss: 0.03397601842880249      \n",
      "dev accuracy: 0.8125, loss: 0.9585626721382141       \n",
      "dev accuracy: 0.9375, loss: 0.06406599283218384      \n",
      "dev accuracy:   1.0, loss: 0.02572798728942871      \n",
      "dev accuracy:  0.75, loss: 0.5594853162765503       \n",
      "dev accuracy:   1.0, loss: 0.006857931613922119     \n",
      "dev accuracy: 0.9375, loss: 0.12601177394390106      \n",
      "dev accuracy:   1.0, loss: 0.04257482290267944      \n",
      "dev accuracy:   1.0, loss: 0.1005391776561737       \n",
      "dev accuracy: 0.875, loss: 0.5794643759727478       \n",
      "dev accuracy:   1.0, loss: 0.01640874147415161      \n",
      "dev accuracy: 0.875, loss: 0.4021768867969513       \n",
      "dev accuracy: 0.9375, loss: 0.3418383002281189       \n",
      "dev accuracy: 0.9375, loss: 0.13087275624275208      \n",
      "dev accuracy: 0.875, loss: 0.33513158559799194      \n",
      "dev accuracy:   1.0, loss: 0.04491809010505676      \n",
      "dev accuracy:   1.0, loss: 0.01067093014717102      \n",
      "dev accuracy: 0.875, loss: 0.18524262309074402      \n",
      "dev accuracy:   1.0, loss: 0.009405136108398438     \n",
      "dev accuracy: 0.875, loss: 0.43630751967430115      \n",
      "dev accuracy: 0.9375, loss: 0.19027112424373627      \n",
      "dev accuracy:   1.0, loss: 0.008184581995010376     \n",
      "dev accuracy: 0.875, loss: 0.2749590575695038       \n",
      "dev accuracy:   1.0, loss: 0.09522414207458496      \n",
      "dev accuracy:   1.0, loss: 0.019788384437561035     \n",
      "dev accuracy: 0.875, loss: 0.28222018480300903      \n",
      "dev accuracy:   1.0, loss: 0.03644669055938721      \n",
      "dev accuracy:   1.0, loss: 0.0877147912979126       \n",
      "dev accuracy: 0.9375, loss: 0.14111685752868652      \n",
      "dev accuracy: 0.9375, loss: 0.147070050239563        \n",
      "dev accuracy: 0.875, loss: 0.17047014832496643      \n",
      "dev accuracy:   1.0, loss: 0.00030094385147094727   \n",
      "dev accuracy:   1.0, loss: 0.012179404497146606     \n",
      "dev accuracy:   1.0, loss: 0.06671622395515442      \n",
      "dev accuracy:   1.0, loss: 0.011319756507873535     \n",
      "dev accuracy:   1.0, loss: 0.05765253305435181      \n",
      "dev accuracy: 0.9375, loss: 0.20835429430007935      \n",
      "dev accuracy:   1.0, loss: 0.002550661563873291     \n",
      "dev accuracy:   1.0, loss: 0.044612884521484375     \n",
      "dev accuracy:   1.0, loss: 0.09296971559524536      \n",
      "dev accuracy: 0.9375, loss: 0.11684507131576538      \n",
      "dev accuracy: 0.9375, loss: 0.11999142169952393      \n",
      "dev accuracy:   1.0, loss: 0.01757901906967163      \n",
      "dev accuracy: 0.9375, loss: 0.33751702308654785      \n",
      "dev accuracy:   1.0, loss: 0.07175038754940033      \n",
      "dev accuracy: 0.9375, loss: 0.10903534293174744      \n",
      "dev accuracy:   1.0, loss: 0.054686516523361206     \n",
      "dev accuracy: 0.9375, loss: 0.060863763093948364     \n",
      "dev accuracy:   1.0, loss: 0.052469030022621155     \n",
      "dev accuracy:   1.0, loss: 0.00831305980682373      \n",
      "dev accuracy:   1.0, loss: 0.03769141435623169      \n",
      "dev accuracy: 0.875, loss: 0.6266965270042419       \n",
      "dev accuracy: 0.9375, loss: 0.05544349551200867      \n",
      "dev accuracy: 0.9375, loss: 0.2626146078109741       \n",
      "dev accuracy:   1.0, loss: 0.004278719425201416     \n",
      "dev accuracy:   1.0, loss: 0.028605490922927856     \n",
      "dev accuracy: 0.9375, loss: 0.439863920211792        \n",
      "dev accuracy: 0.9375, loss: 0.1582683026790619       \n",
      "dev accuracy: 0.9375, loss: 0.10585269331932068      \n",
      "dev accuracy:   1.0, loss: 0.007080763578414917     \n",
      "dev accuracy:   1.0, loss: 0.005981773138046265     \n",
      "dev accuracy:   1.0, loss: 0.04036593437194824      \n",
      "dev accuracy:   1.0, loss: 0.0742434412240982       \n",
      "dev accuracy:   1.0, loss: 0.01834118366241455      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy:   1.0, loss: 0.020976901054382324     \n",
      "dev accuracy:   1.0, loss: 0.0031508207321166992    \n",
      "dev accuracy: 0.875, loss: 0.36079853773117065      \n",
      "dev accuracy:   1.0, loss: 0.07528644800186157      \n",
      "dev accuracy: 0.9375, loss: 0.20121556520462036      \n",
      "dev accuracy:   1.0, loss: 0.014987021684646606     \n",
      "dev accuracy: 0.9375, loss: 0.12093770503997803      \n",
      "dev accuracy: 0.9375, loss: 0.22082066535949707      \n",
      "dev accuracy:   1.0, loss: 0.04633456468582153      \n",
      "dev accuracy: 0.9375, loss: 0.10823707282543182      \n",
      "dev accuracy: 0.9375, loss: 0.20745517313480377      \n",
      "dev accuracy:   1.0, loss: 0.04125630855560303      \n",
      "dev accuracy: 0.9375, loss: 0.4099663496017456       \n",
      "dev accuracy: 0.875, loss: 0.444250226020813        \n",
      "dev accuracy:   1.0, loss: 0.0007790327072143555    \n",
      "dev accuracy: 0.9375, loss: 0.28085747361183167      \n",
      "dev accuracy:   1.0, loss: 0.02799972891807556      \n",
      "dev accuracy: 0.9375, loss: 0.1417424976825714       \n",
      "dev accuracy: 0.9375, loss: 0.41811293363571167      \n",
      "dev accuracy: 0.9375, loss: 0.18044501543045044      \n",
      "dev accuracy:   1.0, loss: 0.008840501308441162     \n",
      "dev accuracy: 0.9375, loss: 0.1386583000421524       \n",
      "dev accuracy:   1.0, loss: 0.016522198915481567     \n",
      "dev accuracy: 0.9375, loss: 0.2475809007883072       \n",
      "dev accuracy:   1.0, loss: 0.006638169288635254     \n",
      "dev accuracy:   1.0, loss: 0.0712064802646637       \n",
      "dev accuracy: 0.875, loss: 0.21223576366901398      \n",
      "dev accuracy:   1.0, loss: 0.023735404014587402     \n",
      "dev accuracy:   1.0, loss: 0.006092965602874756     \n",
      "dev accuracy: 0.9375, loss: 0.16439299285411835      \n",
      "dev accuracy:   1.0, loss: 0.015379726886749268     \n",
      "dev accuracy: 0.9375, loss: 0.07320386171340942      \n",
      "dev accuracy: 0.9375, loss: 0.0744732916355133       \n",
      "dev accuracy: 0.9375, loss: 0.15987715125083923      \n",
      "dev accuracy: 0.9375, loss: 0.2296711504459381       \n",
      "dev accuracy: 0.875, loss: 0.7188858985900879       \n",
      "dev accuracy: 0.9375, loss: 0.11445164680480957      \n",
      "dev accuracy:  0.75, loss: 0.5986416935920715       \n",
      "dev accuracy:   1.0, loss: 0.003612518310546875     \n",
      "dev accuracy:   1.0, loss: 0.06772482395172119      \n",
      "dev accuracy:   1.0, loss: 0.0018658041954040527    \n",
      "dev accuracy: 0.875, loss: 0.25514715909957886      \n",
      "dev accuracy:   1.0, loss: 0.017177194356918335     \n",
      "dev accuracy: 0.9375, loss: 0.4275156259536743       \n",
      "dev accuracy:   1.0, loss: 0.026166826486587524     \n",
      "dev accuracy: 0.875, loss: 0.30456405878067017      \n",
      "dev accuracy: 0.875, loss: 0.22615142166614532      \n",
      "dev accuracy: 0.9375, loss: 0.22386431694030762      \n",
      "dev accuracy: 0.9375, loss: 0.25363120436668396      \n",
      "dev accuracy:   1.0, loss: 0.008610785007476807     \n",
      "dev accuracy: 0.9375, loss: 0.36185455322265625      \n",
      "dev accuracy: 0.8125, loss: 0.2804763615131378       \n",
      "dev accuracy:   1.0, loss: 0.0013844171771779656    \n",
      "final dev accuracy: 0.9507087628865979\n",
      "train step #6247 accuracy: 0.984375, loss: 0.047977007925510406     \n",
      "train step #6248 accuracy: 0.96875, loss: 0.1465407907962799       \n",
      "train step #6249 accuracy:   1.0, loss: 0.016275696456432343     \n",
      "train step #6250 accuracy: 0.96875, loss: 0.16309939324855804      \n",
      "train step #6251 accuracy: 0.921875, loss: 0.23500420153141022      \n",
      "train step #6252 accuracy: 0.96875, loss: 0.11686639487743378      \n",
      "train step #6253 accuracy:   1.0, loss: 0.028359774500131607     \n",
      "train step #6254 accuracy: 0.9375, loss: 0.2044256031513214       \n",
      "train step #6255 accuracy:   1.0, loss: 0.04311329126358032      \n",
      "train step #6256 accuracy: 0.96875, loss: 0.11706703901290894      \n",
      "train step #6257 accuracy:   1.0, loss: 0.0348842516541481       \n",
      "train step #6258 accuracy:   1.0, loss: 0.03203601390123367      \n",
      "train step #6259 accuracy: 0.953125, loss: 0.17498143017292023      \n",
      "train step #6260 accuracy: 0.96875, loss: 0.15982367098331451      \n",
      "train step #6261 accuracy: 0.9375, loss: 0.15297384560108185      \n",
      "train step #6262 accuracy: 0.96875, loss: 0.19779562950134277      \n",
      "train step #6263 accuracy: 0.921875, loss: 0.29894450306892395      \n",
      "train step #6264 accuracy: 0.953125, loss: 0.07862640917301178      \n",
      "train step #6265 accuracy:   1.0, loss: 0.0187935009598732       \n",
      "train step #6266 accuracy: 0.96875, loss: 0.10432905703783035      \n",
      "train step #6267 accuracy: 0.96875, loss: 0.09986770898103714      \n",
      "train step #6268 accuracy: 0.96875, loss: 0.12029089778661728      \n",
      "train step #6269 accuracy: 0.953125, loss: 0.15077972412109375      \n",
      "train step #6270 accuracy: 0.984375, loss: 0.06634806841611862      \n",
      "train step #6271 accuracy: 0.984375, loss: 0.08883187919855118      \n",
      "train step #6272 accuracy: 0.96875, loss: 0.10218613594770432      \n",
      "train step #6273 accuracy: 0.96875, loss: 0.14067886769771576      \n",
      "train step #6274 accuracy: 0.953125, loss: 0.12710319459438324      \n",
      "train step #6275 accuracy: 0.9375, loss: 0.15539494156837463      \n",
      "train step #6276 accuracy: 0.984375, loss: 0.10012789070606232      \n",
      "train step #6277 accuracy: 0.96875, loss: 0.18540921807289124      \n",
      "train step #6278 accuracy: 0.984375, loss: 0.05767544358968735      \n",
      "train step #6279 accuracy: 0.96875, loss: 0.06895297765731812      \n",
      "train step #6280 accuracy:   1.0, loss: 0.05696061626076698      \n",
      "train step #6281 accuracy: 0.984375, loss: 0.08566657453775406      \n",
      "train step #6282 accuracy: 0.9375, loss: 0.20796962082386017      \n",
      "train step #6283 accuracy: 0.96875, loss: 0.13532507419586182      \n",
      "train step #6284 accuracy:   1.0, loss: 0.045423734933137894     \n",
      "train step #6285 accuracy: 0.9375, loss: 0.2747909426689148       \n",
      "train step #6286 accuracy: 0.984375, loss: 0.11081339418888092      \n",
      "train step #6287 accuracy: 0.96875, loss: 0.12309051305055618      \n",
      "train step #6288 accuracy: 0.96875, loss: 0.14393478631973267      \n",
      "train step #6289 accuracy: 0.96875, loss: 0.14397628605365753      \n",
      "train step #6290 accuracy:   1.0, loss: 0.03692169487476349      \n",
      "train step #6291 accuracy: 0.953125, loss: 0.13237306475639343      \n",
      "train step #6292 accuracy: 0.96875, loss: 0.10613218694925308      \n",
      "train step #6293 accuracy: 0.984375, loss: 0.04008040577173233      \n",
      "train step #6294 accuracy:   1.0, loss: 0.05751597136259079      \n",
      "train step #6295 accuracy: 0.96875, loss: 0.1271095871925354       \n",
      "train step #6296 accuracy: 0.953125, loss: 0.1509113609790802       \n",
      "train step #6297 accuracy: 0.984375, loss: 0.09824735671281815      \n",
      "train step #6298 accuracy: 0.953125, loss: 0.15273535251617432      \n",
      "train step #6299 accuracy: 0.953125, loss: 0.15054678916931152      \n",
      "train step #6300 accuracy:   1.0, loss: 0.050070732831954956     \n",
      "train step #6301 accuracy: 0.9375, loss: 0.23437467217445374      \n",
      "train step #6302 accuracy: 0.96875, loss: 0.1267269253730774       \n",
      "train step #6303 accuracy: 0.984375, loss: 0.12242981046438217      \n",
      "train step #6304 accuracy: 0.96875, loss: 0.12329331040382385      \n",
      "train step #6305 accuracy: 0.953125, loss: 0.1542048454284668       \n",
      "train step #6306 accuracy: 0.953125, loss: 0.2629336714744568       \n",
      "train step #6307 accuracy: 0.96875, loss: 0.11257130652666092      \n",
      "train step #6308 accuracy: 0.9375, loss: 0.23072049021720886      \n",
      "train step #6309 accuracy:   1.0, loss: 0.0229637548327446       \n",
      "train step #6310 accuracy: 0.96875, loss: 0.10531909763813019      \n",
      "train step #6311 accuracy: 0.953125, loss: 0.16234061121940613      \n",
      "train step #6312 accuracy: 0.96875, loss: 0.12462173402309418      \n",
      "train step #6313 accuracy: 0.96875, loss: 0.13030007481575012      \n",
      "train step #6314 accuracy: 0.921875, loss: 0.14528104662895203      \n",
      "train step #6315 accuracy: 0.953125, loss: 0.13443797826766968      \n",
      "train step #6316 accuracy:   1.0, loss: 0.03922818973660469      \n",
      "train step #6317 accuracy: 0.96875, loss: 0.13814787566661835      \n",
      "train step #6318 accuracy: 0.9375, loss: 0.17512741684913635      \n",
      "train step #6319 accuracy: 0.96875, loss: 0.12050378322601318      \n",
      "train step #6320 accuracy: 0.953125, loss: 0.23321932554244995      \n",
      "train step #6321 accuracy: 0.96875, loss: 0.1191466748714447       \n",
      "train step #6322 accuracy: 0.984375, loss: 0.1297132819890976       \n",
      "train step #6323 accuracy: 0.953125, loss: 0.128373920917511        \n",
      "train step #6324 accuracy: 0.984375, loss: 0.10528907924890518      \n",
      "train step #6325 accuracy: 0.890625, loss: 0.2730974555015564       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #6326 accuracy: 0.96875, loss: 0.09607339650392532      \n",
      "train step #6327 accuracy: 0.984375, loss: 0.10323821008205414      \n",
      "train step #6328 accuracy:   1.0, loss: 0.09502073377370834      \n",
      "train step #6329 accuracy: 0.96875, loss: 0.16318300366401672      \n",
      "train step #6330 accuracy: 0.921875, loss: 0.44760221242904663      \n",
      "train step #6331 accuracy: 0.96875, loss: 0.1769443154335022       \n",
      "train step #6332 accuracy: 0.96875, loss: 0.15373018383979797      \n",
      "train step #6333 accuracy: 0.96875, loss: 0.16089241206645966      \n",
      "train step #6334 accuracy: 0.984375, loss: 0.07982960343360901      \n",
      "train step #6335 accuracy: 0.921875, loss: 0.1903121918439865       \n",
      "train step #6336 accuracy: 0.921875, loss: 0.37193506956100464      \n",
      "train step #6337 accuracy: 0.9375, loss: 0.1957014799118042       \n",
      "train step #6338 accuracy:   1.0, loss: 0.040623944252729416     \n",
      "train step #6339 accuracy: 0.96875, loss: 0.06767265498638153      \n",
      "train step #6340 accuracy: 0.953125, loss: 0.22446073591709137      \n",
      "train step #6341 accuracy: 0.9375, loss: 0.24003861844539642      \n",
      "train step #6342 accuracy: 0.96875, loss: 0.13123956322669983      \n",
      "train step #6343 accuracy: 0.984375, loss: 0.06416641175746918      \n",
      "train step #6344 accuracy: 0.96875, loss: 0.07867297530174255      \n",
      "train step #6345 accuracy: 0.9375, loss: 0.16698750853538513      \n",
      "train step #6346 accuracy: 0.984375, loss: 0.10029412806034088      \n",
      "train step #6347 accuracy: 0.953125, loss: 0.19031554460525513      \n",
      "train step #6348 accuracy: 0.96875, loss: 0.13623109459877014      \n",
      "train step #6349 accuracy: 0.953125, loss: 0.18991446495056152      \n",
      "train step #6350 accuracy: 0.9375, loss: 0.2285974770784378       \n",
      "train step #6351 accuracy:   1.0, loss: 0.04031562805175781      \n",
      "train step #6352 accuracy: 0.984375, loss: 0.07363227009773254      \n",
      "train step #6353 accuracy: 0.96875, loss: 0.14547039568424225      \n",
      "train step #6354 accuracy: 0.9375, loss: 0.19281968474388123      \n",
      "train step #6355 accuracy: 0.984375, loss: 0.03725744038820267      \n",
      "train step #6356 accuracy: 0.96875, loss: 0.13594891130924225      \n",
      "train step #6357 accuracy: 0.96875, loss: 0.11857430636882782      \n",
      "train step #6358 accuracy: 0.953125, loss: 0.1343979835510254       \n",
      "train step #6359 accuracy: 0.953125, loss: 0.12568503618240356      \n",
      "train step #6360 accuracy: 0.984375, loss: 0.049227502197027206     \n",
      "train step #6361 accuracy:   1.0, loss: 0.035700902342796326     \n",
      "train step #6362 accuracy: 0.984375, loss: 0.08496197313070297      \n",
      "train step #6363 accuracy: 0.96875, loss: 0.15022945404052734      \n",
      "train step #6364 accuracy: 0.984375, loss: 0.0740685909986496       \n",
      "train step #6365 accuracy:   1.0, loss: 0.029572036117315292     \n",
      "train step #6366 accuracy: 0.96875, loss: 0.19374537467956543      \n",
      "train step #6367 accuracy: 0.953125, loss: 0.17021512985229492      \n",
      "train step #6368 accuracy: 0.984375, loss: 0.07900673896074295      \n",
      "train step #6369 accuracy: 0.9375, loss: 0.25353994965553284      \n",
      "train step #6370 accuracy: 0.96875, loss: 0.09615901112556458      \n",
      "train step #6371 accuracy: 0.953125, loss: 0.1883043497800827       \n",
      "train step #6372 accuracy:   1.0, loss: 0.02065020054578781      \n",
      "train step #6373 accuracy:   1.0, loss: 0.030976291745901108     \n",
      "train step #6374 accuracy: 0.953125, loss: 0.20172734558582306      \n",
      "train step #6375 accuracy: 0.96875, loss: 0.14013749361038208      \n",
      "train step #6376 accuracy: 0.953125, loss: 0.1258426159620285       \n",
      "train step #6377 accuracy: 0.953125, loss: 0.20837056636810303      \n",
      "train step #6378 accuracy: 0.984375, loss: 0.08674254268407822      \n",
      "train step #6379 accuracy: 0.984375, loss: 0.10689592361450195      \n",
      "train step #6380 accuracy: 0.984375, loss: 0.06455574184656143      \n",
      "train step #6381 accuracy: 0.953125, loss: 0.13005615770816803      \n",
      "train step #6382 accuracy: 0.921875, loss: 0.3562844395637512       \n",
      "train step #6383 accuracy:   1.0, loss: 0.014784477651119232     \n",
      "train step #6384 accuracy: 0.953125, loss: 0.19156527519226074      \n",
      "train step #6385 accuracy: 0.90625, loss: 0.38968634605407715      \n",
      "train step #6386 accuracy: 0.953125, loss: 0.10696516931056976      \n",
      "train step #6387 accuracy: 0.953125, loss: 0.11571549624204636      \n",
      "train step #6388 accuracy: 0.9375, loss: 0.1437094807624817       \n",
      "train step #6389 accuracy:   1.0, loss: 0.03447836637496948      \n",
      "train step #6390 accuracy: 0.984375, loss: 0.07853662222623825      \n",
      "train step #6391 accuracy: 0.984375, loss: 0.08914558589458466      \n",
      "train step #6392 accuracy: 0.96875, loss: 0.14538082480430603      \n",
      "train step #6393 accuracy: 0.984375, loss: 0.08965349197387695      \n",
      "train step #6394 accuracy: 0.953125, loss: 0.13084980845451355      \n",
      "train step #6395 accuracy:   1.0, loss: 0.05589247867465019      \n",
      "train step #6396 accuracy:   1.0, loss: 0.03379744291305542      \n",
      "train step #6397 accuracy: 0.953125, loss: 0.14113111793994904      \n",
      "train step #6398 accuracy: 0.984375, loss: 0.13911616802215576      \n",
      "train step #6399 accuracy: 0.953125, loss: 0.21759194135665894      \n",
      "train step #6400 accuracy: 0.9375, loss: 0.13148687779903412      \n",
      "train step #6401 accuracy: 0.96875, loss: 0.14454664289951324      \n",
      "train step #6402 accuracy:   1.0, loss: 0.05757243186235428      \n",
      "train step #6403 accuracy: 0.953125, loss: 0.1251792311668396       \n",
      "train step #6404 accuracy: 0.953125, loss: 0.11381973326206207      \n",
      "train step #6405 accuracy:   1.0, loss: 0.04114130139350891      \n",
      "train step #6406 accuracy: 0.96875, loss: 0.12113497406244278      \n",
      "train step #6407 accuracy: 0.9375, loss: 0.2663806676864624       \n",
      "train step #6408 accuracy: 0.953125, loss: 0.14457571506500244      \n",
      "train step #6409 accuracy: 0.953125, loss: 0.33186784386634827      \n",
      "train step #6410 accuracy: 0.96875, loss: 0.10555855929851532      \n",
      "train step #6411 accuracy: 0.921875, loss: 0.3470156192779541       \n",
      "train step #6412 accuracy:   1.0, loss: 0.05465255677700043      \n",
      "train step #6413 accuracy: 0.96875, loss: 0.11751874536275864      \n",
      "train step #6414 accuracy: 0.921875, loss: 0.2258218228816986       \n",
      "train step #6415 accuracy: 0.921875, loss: 0.2140946239233017       \n",
      "train step #6416 accuracy: 0.984375, loss: 0.07609577476978302      \n",
      "train step #6417 accuracy: 0.953125, loss: 0.12412576377391815      \n",
      "train step #6418 accuracy: 0.984375, loss: 0.10952307283878326      \n",
      "train step #6419 accuracy: 0.984375, loss: 0.06514543294906616      \n",
      "train step #6420 accuracy: 0.9375, loss: 0.14710575342178345      \n",
      "train step #6421 accuracy: 0.953125, loss: 0.23589164018630981      \n",
      "train step #6422 accuracy: 0.984375, loss: 0.06860259175300598      \n",
      "train step #6423 accuracy: 0.984375, loss: 0.06280991435050964      \n",
      "train step #6424 accuracy: 0.96875, loss: 0.1531047523021698       \n",
      "train step #6425 accuracy: 0.953125, loss: 0.11736525595188141      \n",
      "train step #6426 accuracy: 0.984375, loss: 0.062190745025873184     \n",
      "train step #6427 accuracy:   1.0, loss: 0.021873459219932556     \n",
      "train step #6428 accuracy: 0.984375, loss: 0.07768236845731735      \n",
      "train step #6429 accuracy: 0.96875, loss: 0.11065027117729187      \n",
      "train step #6430 accuracy: 0.953125, loss: 0.11362595111131668      \n",
      "train step #6431 accuracy: 0.96875, loss: 0.10659132152795792      \n",
      "train step #6432 accuracy: 0.984375, loss: 0.09769707918167114      \n",
      "train step #6433 accuracy: 0.953125, loss: 0.13177558779716492      \n",
      "train step #6434 accuracy: 0.96875, loss: 0.05334906652569771      \n",
      "train step #6435 accuracy: 0.96875, loss: 0.10373397171497345      \n",
      "train step #6436 accuracy: 0.90625, loss: 0.2724849581718445       \n",
      "train step #6437 accuracy: 0.96875, loss: 0.1187497079372406       \n",
      "train step #6438 accuracy: 0.921875, loss: 0.223857119679451        \n",
      "train step #6439 accuracy:   1.0, loss: 0.06330540776252747      \n",
      "train step #6440 accuracy: 0.9375, loss: 0.15652719140052795      \n",
      "train step #6441 accuracy: 0.984375, loss: 0.07649276405572891      \n",
      "train step #6442 accuracy: 0.953125, loss: 0.1743980497121811       \n",
      "train step #6443 accuracy: 0.9375, loss: 0.2388962209224701       \n",
      "train step #6444 accuracy: 0.953125, loss: 0.15227743983268738      \n",
      "train step #6445 accuracy: 0.9375, loss: 0.1780492216348648       \n",
      "train step #6446 accuracy:   1.0, loss: 0.0222577303647995       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #6447 accuracy: 0.984375, loss: 0.09388647973537445      \n",
      "train step #6448 accuracy: 0.921875, loss: 0.29735398292541504      \n",
      "train step #6449 accuracy: 0.984375, loss: 0.05346309766173363      \n",
      "train step #6450 accuracy: 0.984375, loss: 0.09137376397848129      \n",
      "train step #6451 accuracy: 0.96875, loss: 0.07880236208438873      \n",
      "train step #6452 accuracy: 0.9375, loss: 0.16979797184467316      \n",
      "train step #6453 accuracy: 0.96875, loss: 0.18083854019641876      \n",
      "train step #6454 accuracy:   1.0, loss: 0.03757799044251442      \n",
      "train step #6455 accuracy: 0.984375, loss: 0.09258288890123367      \n",
      "train step #6456 accuracy: 0.96875, loss: 0.12940403819084167      \n",
      "train step #6457 accuracy: 0.90625, loss: 0.2719402015209198       \n",
      "train step #6458 accuracy: 0.96875, loss: 0.13919295370578766      \n",
      "train step #6459 accuracy: 0.96875, loss: 0.10837845504283905      \n",
      "train step #6460 accuracy: 0.953125, loss: 0.12520022690296173      \n",
      "train step #6461 accuracy: 0.953125, loss: 0.20663587749004364      \n",
      "train step #6462 accuracy: 0.96875, loss: 0.12016455084085464      \n",
      "train step #6463 accuracy: 0.984375, loss: 0.1898978352546692       \n",
      "train step #6464 accuracy: 0.96875, loss: 0.11832268536090851      \n",
      "train step #6465 accuracy: 0.921875, loss: 0.24655960500240326      \n",
      "train step #6466 accuracy: 0.96875, loss: 0.15340013802051544      \n",
      "train step #6467 accuracy: 0.9375, loss: 0.2379453033208847       \n",
      "train step #6468 accuracy:   1.0, loss: 0.042204730212688446     \n",
      "train step #6469 accuracy: 0.984375, loss: 0.08264458179473877      \n",
      "train step #6470 accuracy:   1.0, loss: 0.03328368812799454      \n",
      "train step #6471 accuracy: 0.96875, loss: 0.1010589599609375       \n",
      "train step #6472 accuracy: 0.9375, loss: 0.23744480311870575      \n",
      "train step #6473 accuracy: 0.953125, loss: 0.20108848810195923      \n",
      "train step #6474 accuracy: 0.96875, loss: 0.09631836414337158      \n",
      "train step #6475 accuracy: 0.96875, loss: 0.06074630469083786      \n",
      "train step #6476 accuracy: 0.984375, loss: 0.12689577043056488      \n",
      "train step #6477 accuracy: 0.890625, loss: 0.3384903073310852       \n",
      "train step #6478 accuracy: 0.984375, loss: 0.05773058533668518      \n",
      "train step #6479 accuracy: 0.984375, loss: 0.06005068123340607      \n",
      "train step #6480 accuracy: 0.953125, loss: 0.2284703403711319       \n",
      "train step #6481 accuracy: 0.9375, loss: 0.2389909327030182       \n",
      "train step #6482 accuracy: 0.9375, loss: 0.20920105278491974      \n",
      "train step #6483 accuracy:   1.0, loss: 0.02172818034887314      \n",
      "train step #6484 accuracy: 0.984375, loss: 0.10633674263954163      \n",
      "train step #6485 accuracy: 0.96875, loss: 0.1663382351398468       \n",
      "train step #6486 accuracy: 0.953125, loss: 0.1654692441225052       \n",
      "train step #6487 accuracy:   1.0, loss: 0.04517963528633118      \n",
      "train step #6488 accuracy: 0.96875, loss: 0.062340401113033295     \n",
      "train step #6489 accuracy: 0.921875, loss: 0.21249738335609436      \n",
      "train step #6490 accuracy: 0.96875, loss: 0.14617571234703064      \n",
      "train step #6491 accuracy: 0.96875, loss: 0.1372714340686798       \n",
      "train step #6492 accuracy: 0.953125, loss: 0.23513351380825043      \n",
      "train step #6493 accuracy: 0.953125, loss: 0.14424259960651398      \n",
      "train step #6494 accuracy:   1.0, loss: 0.04427138715982437      \n",
      "train step #6495 accuracy:   1.0, loss: 0.03225162625312805      \n",
      "train step #6496 accuracy: 0.96875, loss: 0.10252123326063156      \n",
      "train step #6497 accuracy: 0.96875, loss: 0.08913533389568329      \n",
      "train step #6498 accuracy: 0.953125, loss: 0.15065866708755493      \n",
      "train step #6499 accuracy: 0.9375, loss: 0.2365986853837967       \n",
      "train step #6500 accuracy: 0.953125, loss: 0.11333592981100082      \n",
      "train step #6501 accuracy: 0.96875, loss: 0.09849061816930771      \n",
      "train step #6502 accuracy: 0.921875, loss: 0.13164564967155457      \n",
      "train step #6503 accuracy: 0.984375, loss: 0.08373076468706131      \n",
      "train step #6504 accuracy: 0.953125, loss: 0.12315080314874649      \n",
      "train step #6505 accuracy: 0.984375, loss: 0.04846706986427307      \n",
      "train step #6506 accuracy: 0.984375, loss: 0.13489331305027008      \n",
      "train step #6507 accuracy: 0.984375, loss: 0.11329353600740433      \n",
      "train step #6508 accuracy: 0.921875, loss: 0.2905087172985077       \n",
      "train step #6509 accuracy: 0.90625, loss: 0.28955602645874023      \n",
      "train step #6510 accuracy:   1.0, loss: 0.013245180249214172     \n",
      "train step #6511 accuracy: 0.984375, loss: 0.11037132143974304      \n",
      "train step #6512 accuracy: 0.96875, loss: 0.09082379192113876      \n",
      "train step #6513 accuracy:   1.0, loss: 0.07367976009845734      \n",
      "train step #6514 accuracy: 0.96875, loss: 0.08083122223615646      \n",
      "train step #6515 accuracy: 0.953125, loss: 0.1256968080997467       \n",
      "train step #6516 accuracy:   1.0, loss: 0.0265851728618145       \n",
      "train step #6517 accuracy: 0.9375, loss: 0.17720988392829895      \n",
      "train step #6518 accuracy: 0.96875, loss: 0.14130748808383942      \n",
      "train step #6519 accuracy: 0.9375, loss: 0.2932736277580261       \n",
      "train step #6520 accuracy: 0.96875, loss: 0.3156314790248871       \n",
      "train step #6521 accuracy: 0.984375, loss: 0.10756886005401611      \n",
      "train step #6522 accuracy: 0.9375, loss: 0.25616711378097534      \n",
      "train step #6523 accuracy: 0.90625, loss: 0.4332003593444824       \n",
      "train step #6524 accuracy: 0.921875, loss: 0.30182933807373047      \n",
      "train step #6525 accuracy: 0.96875, loss: 0.11557856947183609      \n",
      "train step #6526 accuracy: 0.984375, loss: 0.043750278651714325     \n",
      "train step #6527 accuracy: 0.984375, loss: 0.12208155542612076      \n",
      "train step #6528 accuracy: 0.953125, loss: 0.19948121905326843      \n",
      "train step #6529 accuracy: 0.96875, loss: 0.09997226297855377      \n",
      "train step #6530 accuracy: 0.96875, loss: 0.07466626912355423      \n",
      "train step #6531 accuracy:   1.0, loss: 0.019224882125854492     \n",
      "train step #6532 accuracy: 0.96875, loss: 0.05186103284358978      \n",
      "train step #6533 accuracy: 0.953125, loss: 0.11392006278038025      \n",
      "train step #6534 accuracy:   1.0, loss: 0.018426470458507538     \n",
      "train step #6535 accuracy: 0.96875, loss: 0.08122235536575317      \n",
      "train step #6536 accuracy: 0.921875, loss: 0.2653695344924927       \n",
      "train step #6537 accuracy: 0.953125, loss: 0.17160940170288086      \n",
      "train step #6538 accuracy: 0.9375, loss: 0.1752631813287735       \n",
      "train step #6539 accuracy: 0.984375, loss: 0.0692046657204628       \n",
      "train step #6540 accuracy: 0.9375, loss: 0.18658766150474548      \n",
      "train step #6541 accuracy: 0.96875, loss: 0.08311084657907486      \n",
      "train step #6542 accuracy:   1.0, loss: 0.03378969803452492      \n",
      "train step #6543 accuracy: 0.984375, loss: 0.04325277358293533      \n",
      "train step #6544 accuracy: 0.96875, loss: 0.10572986304759979      \n",
      "train step #6545 accuracy: 0.96875, loss: 0.10183055698871613      \n",
      "train step #6546 accuracy: 0.9375, loss: 0.1400347203016281       \n",
      "train step #6547 accuracy:   1.0, loss: 0.05431106314063072      \n",
      "train step #6548 accuracy: 0.984375, loss: 0.1392500102519989       \n",
      "train step #6549 accuracy: 0.9375, loss: 0.24869689345359802      \n",
      "train step #6550 accuracy:   1.0, loss: 0.07078397274017334      \n",
      "train step #6551 accuracy: 0.953125, loss: 0.09430456906557083      \n",
      "train step #6552 accuracy: 0.9375, loss: 0.19565826654434204      \n",
      "train step #6553 accuracy: 0.96875, loss: 0.07095359265804291      \n",
      "train step #6554 accuracy:   1.0, loss: 0.014178145676851273     \n",
      "train step #6555 accuracy: 0.96875, loss: 0.08784223347902298      \n",
      "train step #6556 accuracy: 0.984375, loss: 0.15360583364963531      \n",
      "train step #6557 accuracy: 0.96875, loss: 0.09956404566764832      \n",
      "train step #6558 accuracy:   1.0, loss: 0.029969021677970886     \n",
      "train step #6559 accuracy: 0.953125, loss: 0.11819489300251007      \n",
      "train step #6560 accuracy: 0.9375, loss: 0.15764829516410828      \n",
      "train step #6561 accuracy: 0.90625, loss: 0.34311914443969727      \n",
      "train step #6562 accuracy: 0.984375, loss: 0.039879199117422104     \n",
      "train step #6563 accuracy: 0.96875, loss: 0.1013031154870987       \n",
      "train step #6564 accuracy: 0.984375, loss: 0.03695794194936752      \n",
      "train step #6565 accuracy: 0.984375, loss: 0.04878322780132294      \n",
      "train step #6566 accuracy: 0.921875, loss: 0.32857546210289         \n",
      "train step #6567 accuracy: 0.953125, loss: 0.14337876439094543      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #6568 accuracy: 0.984375, loss: 0.09457144886255264      \n",
      "train step #6569 accuracy: 0.953125, loss: 0.14373400807380676      \n",
      "train step #6570 accuracy: 0.953125, loss: 0.17070282995700836      \n",
      "train step #6571 accuracy: 0.953125, loss: 0.13005605340003967      \n",
      "train step #6572 accuracy: 0.9375, loss: 0.29367583990097046      \n",
      "train step #6573 accuracy: 0.921875, loss: 0.21920637786388397      \n",
      "train step #6574 accuracy: 0.84375, loss: 0.40079373121261597      \n",
      "train step #6575 accuracy: 0.9375, loss: 0.15143096446990967      \n",
      "train step #6576 accuracy: 0.890625, loss: 0.3660019040107727       \n",
      "train step #6577 accuracy: 0.953125, loss: 0.15351037681102753      \n",
      "train step #6578 accuracy: 0.953125, loss: 0.15197773277759552      \n",
      "train step #6579 accuracy: 0.96875, loss: 0.20164451003074646      \n",
      "train step #6580 accuracy: 0.921875, loss: 0.2429141104221344       \n",
      "train step #6581 accuracy: 0.921875, loss: 0.16050437092781067      \n",
      "train step #6582 accuracy: 0.96875, loss: 0.09085025638341904      \n",
      "train step #6583 accuracy: 0.984375, loss: 0.12486021220684052      \n",
      "train step #6584 accuracy: 0.984375, loss: 0.10034006834030151      \n",
      "train step #6585 accuracy: 0.921875, loss: 0.23922500014305115      \n",
      "train step #6586 accuracy: 0.953125, loss: 0.20757412910461426      \n",
      "train step #6587 accuracy: 0.9375, loss: 0.1533455103635788       \n",
      "train step #6588 accuracy: 0.984375, loss: 0.1947624683380127       \n",
      "train step #6589 accuracy: 0.9375, loss: 0.25518375635147095      \n",
      "train step #6590 accuracy: 0.984375, loss: 0.13870565593242645      \n",
      "train step #6591 accuracy: 0.96875, loss: 0.10232416540384293      \n",
      "train step #6592 accuracy: 0.984375, loss: 0.07705545425415039      \n",
      "train step #6593 accuracy: 0.96875, loss: 0.18131273984909058      \n",
      "dev accuracy: 0.9375, loss: 0.14674489200115204      \n",
      "dev accuracy:   1.0, loss: 0.04006841778755188      \n",
      "dev accuracy: 0.9375, loss: 0.26549994945526123      \n",
      "dev accuracy:   1.0, loss: 0.029087573289871216     \n",
      "dev accuracy: 0.875, loss: 0.15338340401649475      \n",
      "dev accuracy:   1.0, loss: 0.01007881760597229      \n",
      "dev accuracy: 0.9375, loss: 0.1656942069530487       \n",
      "dev accuracy: 0.9375, loss: 0.09246847033500671      \n",
      "dev accuracy: 0.875, loss: 0.30089157819747925      \n",
      "dev accuracy:   1.0, loss: 0.04173031449317932      \n",
      "dev accuracy:   1.0, loss: 0.008490383625030518     \n",
      "dev accuracy:   1.0, loss: 0.08617854118347168      \n",
      "dev accuracy: 0.9375, loss: 0.08098427951335907      \n",
      "dev accuracy: 0.9375, loss: 0.3003110885620117       \n",
      "dev accuracy: 0.9375, loss: 0.34546923637390137      \n",
      "dev accuracy: 0.8125, loss: 0.2746983766555786       \n",
      "dev accuracy:   1.0, loss: 0.032044440507888794     \n",
      "dev accuracy: 0.9375, loss: 0.06709226965904236      \n",
      "dev accuracy:   1.0, loss: 0.10272134095430374      \n",
      "dev accuracy: 0.9375, loss: 0.09463083744049072      \n",
      "dev accuracy: 0.9375, loss: 0.3055480122566223       \n",
      "dev accuracy:   1.0, loss: 0.017084062099456787     \n",
      "dev accuracy:   1.0, loss: 0.0008539557456970215    \n",
      "dev accuracy:   1.0, loss: 0.050662875175476074     \n",
      "dev accuracy: 0.9375, loss: 0.19098204374313354      \n",
      "dev accuracy: 0.9375, loss: 0.26308372616767883      \n",
      "dev accuracy: 0.9375, loss: 0.13318662345409393      \n",
      "dev accuracy: 0.9375, loss: 0.41057637333869934      \n",
      "dev accuracy: 0.875, loss: 0.3767412006855011       \n",
      "dev accuracy: 0.9375, loss: 0.137101948261261        \n",
      "dev accuracy:   1.0, loss: 0.034618526697158813     \n",
      "dev accuracy:   1.0, loss: 0.03548377752304077      \n",
      "dev accuracy: 0.875, loss: 0.6721587777137756       \n",
      "dev accuracy: 0.8125, loss: 0.29737403988838196      \n",
      "dev accuracy: 0.9375, loss: 0.1346590518951416       \n",
      "dev accuracy: 0.9375, loss: 0.33140596747398376      \n",
      "dev accuracy:   1.0, loss: 0.0035051703453063965    \n",
      "dev accuracy:   1.0, loss: 0.02710282802581787      \n",
      "dev accuracy: 0.875, loss: 0.17852835357189178      \n",
      "dev accuracy: 0.9375, loss: 0.22705674171447754      \n",
      "dev accuracy: 0.9375, loss: 0.16322582960128784      \n",
      "dev accuracy:   1.0, loss: 0.020786136388778687     \n",
      "dev accuracy:   1.0, loss: 0.0047263503074646       \n",
      "dev accuracy:   1.0, loss: 0.017310798168182373     \n",
      "dev accuracy: 0.9375, loss: 0.0866401195526123       \n",
      "dev accuracy: 0.875, loss: 0.15259690582752228      \n",
      "dev accuracy: 0.9375, loss: 0.3029341697692871       \n",
      "dev accuracy:   1.0, loss: 0.009942412376403809     \n",
      "dev accuracy:   1.0, loss: 0.03672042489051819      \n",
      "dev accuracy:   1.0, loss: 0.04197379946708679      \n",
      "dev accuracy: 0.9375, loss: 0.3824380934238434       \n",
      "dev accuracy: 0.9375, loss: 0.47564077377319336      \n",
      "dev accuracy: 0.9375, loss: 0.08891576528549194      \n",
      "dev accuracy:   1.0, loss: 0.001164555549621582     \n",
      "dev accuracy: 0.9375, loss: 0.20577149093151093      \n",
      "dev accuracy:   1.0, loss: 0.08857117593288422      \n",
      "dev accuracy:   1.0, loss: 0.0028567910194396973    \n",
      "dev accuracy: 0.9375, loss: 0.21963003277778625      \n",
      "dev accuracy: 0.8125, loss: 0.5796231031417847       \n",
      "dev accuracy:   1.0, loss: 0.00948864221572876      \n",
      "dev accuracy:   1.0, loss: 0.04712289571762085      \n",
      "dev accuracy: 0.9375, loss: 0.18060921132564545      \n",
      "dev accuracy: 0.9375, loss: 0.061055928468704224     \n",
      "dev accuracy: 0.9375, loss: 0.11053520441055298      \n",
      "dev accuracy:   1.0, loss: 0.04751253128051758      \n",
      "dev accuracy:   1.0, loss: 0.03917153179645538      \n",
      "dev accuracy:   1.0, loss: 0.022102683782577515     \n",
      "dev accuracy:   1.0, loss: 0.05160033702850342      \n",
      "dev accuracy: 0.9375, loss: 0.16976088285446167      \n",
      "dev accuracy: 0.9375, loss: 0.338016539812088        \n",
      "dev accuracy: 0.9375, loss: 0.23781153559684753      \n",
      "dev accuracy: 0.875, loss: 0.7080811262130737       \n",
      "dev accuracy:   1.0, loss: 0.012938201427459717     \n",
      "dev accuracy: 0.9375, loss: 0.09347575902938843      \n",
      "dev accuracy: 0.8125, loss: 0.23565581440925598      \n",
      "dev accuracy: 0.875, loss: 0.26568174362182617      \n",
      "dev accuracy:   1.0, loss: 0.002949953079223633     \n",
      "dev accuracy: 0.9375, loss: 0.14941838383674622      \n",
      "dev accuracy:   1.0, loss: 0.04777607321739197      \n",
      "dev accuracy: 0.9375, loss: 0.11358505487442017      \n",
      "dev accuracy:   1.0, loss: 0.008101940155029297     \n",
      "dev accuracy:   1.0, loss: 0.0012649297714233398    \n",
      "dev accuracy:   1.0, loss: 0.043836116790771484     \n",
      "dev accuracy: 0.9375, loss: 0.13926167786121368      \n",
      "dev accuracy:   1.0, loss: 0.022751718759536743     \n",
      "dev accuracy: 0.9375, loss: 0.2743467390537262       \n",
      "dev accuracy: 0.9375, loss: 0.09051623940467834      \n",
      "dev accuracy: 0.8125, loss: 0.9019021987915039       \n",
      "dev accuracy:   1.0, loss: 0.03989064693450928      \n",
      "dev accuracy:   1.0, loss: 0.03955179452896118      \n",
      "dev accuracy: 0.9375, loss: 0.34278327226638794      \n",
      "dev accuracy: 0.9375, loss: 0.24198170006275177      \n",
      "dev accuracy: 0.875, loss: 0.3653295636177063       \n",
      "dev accuracy:   1.0, loss: 0.04402083158493042      \n",
      "dev accuracy: 0.875, loss: 0.31833478808403015      \n",
      "dev accuracy:   1.0, loss: 0.08644816279411316      \n",
      "dev accuracy: 0.875, loss: 0.30444055795669556      \n",
      "dev accuracy:   1.0, loss: 0.0017557740211486816    \n",
      "dev accuracy:   1.0, loss: 0.1022840142250061       \n",
      "dev accuracy: 0.9375, loss: 0.06669473648071289      \n",
      "dev accuracy: 0.9375, loss: 0.055652886629104614     \n",
      "dev accuracy:   1.0, loss: 0.003716886043548584     \n",
      "dev accuracy:   1.0, loss: 0.0021623969078063965    \n",
      "dev accuracy: 0.9375, loss: 0.20241060853004456      \n",
      "dev accuracy: 0.875, loss: 0.3622736930847168       \n",
      "dev accuracy: 0.9375, loss: 0.24906902015209198      \n",
      "dev accuracy: 0.875, loss: 0.26053112745285034      \n",
      "dev accuracy: 0.9375, loss: 0.08240896463394165      \n",
      "dev accuracy: 0.875, loss: 0.5222557783126831       \n",
      "dev accuracy:   1.0, loss: 0.007864654064178467     \n",
      "dev accuracy: 0.875, loss: 0.38732096552848816      \n",
      "dev accuracy:   1.0, loss: 0.009385883808135986     \n",
      "dev accuracy: 0.9375, loss: 0.2267734855413437       \n",
      "dev accuracy: 0.875, loss: 0.35209712386131287      \n",
      "dev accuracy:   1.0, loss: 0.04026654362678528      \n",
      "dev accuracy: 0.9375, loss: 0.11417609453201294      \n",
      "dev accuracy: 0.875, loss: 0.4565398693084717       \n",
      "dev accuracy:   1.0, loss: 0.02084726095199585      \n",
      "dev accuracy:   1.0, loss: 0.01814296841621399      \n",
      "dev accuracy: 0.875, loss: 0.49032270908355713      \n",
      "dev accuracy:   1.0, loss: 0.05482977628707886      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy:   1.0, loss: 0.03763793408870697      \n",
      "dev accuracy: 0.9375, loss: 0.24896849691867828      \n",
      "dev accuracy:   1.0, loss: 0.02562454342842102      \n",
      "dev accuracy: 0.9375, loss: 0.326870322227478        \n",
      "dev accuracy: 0.9375, loss: 0.267590194940567        \n",
      "dev accuracy:   1.0, loss: 0.0008026361465454102    \n",
      "dev accuracy: 0.9375, loss: 0.16791054606437683      \n",
      "dev accuracy:   1.0, loss: 0.011387228965759277     \n",
      "dev accuracy: 0.9375, loss: 0.22585025429725647      \n",
      "dev accuracy:   1.0, loss: 0.07914823293685913      \n",
      "dev accuracy: 0.9375, loss: 0.1901056170463562       \n",
      "dev accuracy:   1.0, loss: 0.06975582242012024      \n",
      "dev accuracy: 0.9375, loss: 0.09505512565374374      \n",
      "dev accuracy: 0.875, loss: 0.5274302959442139       \n",
      "dev accuracy: 0.9375, loss: 0.31090304255485535      \n",
      "dev accuracy: 0.9375, loss: 0.11438348889350891      \n",
      "dev accuracy:   1.0, loss: 0.0019497871398925781    \n",
      "dev accuracy:   1.0, loss: 0.04524838924407959      \n",
      "dev accuracy:   1.0, loss: 0.003674328327178955     \n",
      "dev accuracy:   1.0, loss: 0.043054282665252686     \n",
      "dev accuracy:   1.0, loss: 0.011194497346878052     \n",
      "dev accuracy:   1.0, loss: 0.026189595460891724     \n",
      "dev accuracy: 0.875, loss: 0.33701205253601074      \n",
      "dev accuracy:   1.0, loss: 0.09068366885185242      \n",
      "dev accuracy:   1.0, loss: 0.0013635754585266113    \n",
      "dev accuracy: 0.875, loss: 0.2675482928752899       \n",
      "dev accuracy: 0.875, loss: 0.183748260140419        \n",
      "dev accuracy:   1.0, loss: 0.08800965547561646      \n",
      "dev accuracy: 0.9375, loss: 0.08203402161598206      \n",
      "dev accuracy: 0.875, loss: 0.4786163568496704       \n",
      "dev accuracy:   1.0, loss: 0.09174352139234543      \n",
      "dev accuracy: 0.9375, loss: 0.2525367736816406       \n",
      "dev accuracy: 0.8125, loss: 0.3650898337364197       \n",
      "dev accuracy:   1.0, loss: 0.030602455139160156     \n",
      "dev accuracy: 0.9375, loss: 0.14041222631931305      \n",
      "dev accuracy: 0.9375, loss: 0.11968633532524109      \n",
      "dev accuracy:   1.0, loss: 0.10864719748497009      \n",
      "dev accuracy:   1.0, loss: 0.04182547330856323      \n",
      "dev accuracy: 0.9375, loss: 0.14490488171577454      \n",
      "dev accuracy: 0.9375, loss: 0.12965652346611023      \n",
      "dev accuracy:   1.0, loss: 0.0047414302825927734    \n",
      "dev accuracy: 0.9375, loss: 0.13699333369731903      \n",
      "dev accuracy:   1.0, loss: 0.002500593662261963     \n",
      "dev accuracy:   1.0, loss: 0.0037391185760498047    \n",
      "dev accuracy: 0.9375, loss: 0.23423653841018677      \n",
      "dev accuracy:   1.0, loss: 0.07668386399745941      \n",
      "dev accuracy: 0.9375, loss: 0.17512837052345276      \n",
      "dev accuracy:   1.0, loss: 0.009627848863601685     \n",
      "dev accuracy: 0.9375, loss: 0.1948157548904419       \n",
      "dev accuracy: 0.9375, loss: 0.059455305337905884     \n",
      "dev accuracy:   1.0, loss: 0.0011430978775024414    \n",
      "dev accuracy: 0.9375, loss: 0.10031181573867798      \n",
      "dev accuracy:   1.0, loss: 0.011385470628738403     \n",
      "dev accuracy:   1.0, loss: 0.01014012098312378      \n",
      "dev accuracy: 0.9375, loss: 0.4351157248020172       \n",
      "dev accuracy:   1.0, loss: 0.03921124339103699      \n",
      "dev accuracy: 0.9375, loss: 0.18554416298866272      \n",
      "dev accuracy: 0.9375, loss: 0.12011466920375824      \n",
      "dev accuracy:   1.0, loss: 0.0008718967437744141    \n",
      "dev accuracy: 0.9375, loss: 0.2377653568983078       \n",
      "dev accuracy: 0.9375, loss: 0.13231675326824188      \n",
      "dev accuracy:   1.0, loss: 0.023727059364318848     \n",
      "dev accuracy:   1.0, loss: 0.05903828144073486      \n",
      "dev accuracy:   1.0, loss: 0.031224489212036133     \n",
      "dev accuracy: 0.9375, loss: 0.2917255163192749       \n",
      "dev accuracy: 0.8125, loss: 0.8918397426605225       \n",
      "dev accuracy:   1.0, loss: 0.03984212875366211      \n",
      "dev accuracy:   1.0, loss: 0.0005440711975097656    \n",
      "dev accuracy: 0.875, loss: 0.5362393260002136       \n",
      "dev accuracy: 0.8125, loss: 0.33752238750457764      \n",
      "dev accuracy: 0.875, loss: 0.49584949016571045      \n",
      "dev accuracy: 0.9375, loss: 0.55351722240448         \n",
      "dev accuracy:   1.0, loss: 0.0013551712036132812    \n",
      "final dev accuracy: 0.9519974226804123\n",
      "train step #6594 accuracy: 0.953125, loss: 0.17407682538032532      \n",
      "train step #6595 accuracy: 0.9375, loss: 0.21018987894058228      \n",
      "train step #6596 accuracy: 0.921875, loss: 0.3187235891819          \n",
      "train step #6597 accuracy: 0.953125, loss: 0.22160682082176208      \n",
      "train step #6598 accuracy: 0.96875, loss: 0.11841665208339691      \n",
      "train step #6599 accuracy: 0.953125, loss: 0.1513306051492691       \n",
      "train step #6600 accuracy: 0.984375, loss: 0.04662889242172241      \n",
      "train step #6601 accuracy:   1.0, loss: 0.04523654282093048      \n",
      "train step #6602 accuracy: 0.984375, loss: 0.06587778031826019      \n",
      "train step #6603 accuracy: 0.96875, loss: 0.14290183782577515      \n",
      "train step #6604 accuracy: 0.96875, loss: 0.16381719708442688      \n",
      "train step #6605 accuracy: 0.984375, loss: 0.13458678126335144      \n",
      "train step #6606 accuracy: 0.96875, loss: 0.16255466639995575      \n",
      "train step #6607 accuracy: 0.953125, loss: 0.14577865600585938      \n",
      "train step #6608 accuracy: 0.984375, loss: 0.1300705075263977       \n",
      "train step #6609 accuracy: 0.96875, loss: 0.14032422006130219      \n",
      "train step #6610 accuracy: 0.9375, loss: 0.22509248554706573      \n",
      "train step #6611 accuracy: 0.984375, loss: 0.07188556343317032      \n",
      "train step #6612 accuracy:   1.0, loss: 0.023362301290035248     \n",
      "train step #6613 accuracy: 0.96875, loss: 0.15890826284885406      \n",
      "train step #6614 accuracy: 0.96875, loss: 0.2687118351459503       \n",
      "train step #6615 accuracy: 0.96875, loss: 0.16058902442455292      \n",
      "train step #6616 accuracy: 0.96875, loss: 0.0699152946472168       \n",
      "train step #6617 accuracy:   1.0, loss: 0.028161033987998962     \n",
      "train step #6618 accuracy: 0.984375, loss: 0.07154818624258041      \n",
      "train step #6619 accuracy: 0.96875, loss: 0.08737526088953018      \n",
      "train step #6620 accuracy: 0.96875, loss: 0.11038568615913391      \n",
      "train step #6621 accuracy: 0.96875, loss: 0.101497583091259        \n",
      "train step #6622 accuracy: 0.96875, loss: 0.07412122935056686      \n",
      "train step #6623 accuracy: 0.921875, loss: 0.23006466031074524      \n",
      "train step #6624 accuracy: 0.96875, loss: 0.16643746197223663      \n",
      "train step #6625 accuracy: 0.921875, loss: 0.26215454936027527      \n",
      "train step #6626 accuracy:   1.0, loss: 0.02927371859550476      \n",
      "train step #6627 accuracy: 0.953125, loss: 0.18821242451667786      \n",
      "train step #6628 accuracy: 0.953125, loss: 0.17696434259414673      \n",
      "train step #6629 accuracy: 0.96875, loss: 0.10947366803884506      \n",
      "train step #6630 accuracy: 0.984375, loss: 0.08160676807165146      \n",
      "train step #6631 accuracy: 0.96875, loss: 0.11391360312700272      \n",
      "train step #6632 accuracy: 0.9375, loss: 0.21407921612262726      \n",
      "train step #6633 accuracy: 0.984375, loss: 0.0900200605392456       \n",
      "train step #6634 accuracy: 0.96875, loss: 0.13156284391880035      \n",
      "train step #6635 accuracy: 0.984375, loss: 0.07744594663381577      \n",
      "train step #6636 accuracy: 0.96875, loss: 0.16053177416324615      \n",
      "train step #6637 accuracy: 0.984375, loss: 0.1222580224275589       \n",
      "train step #6638 accuracy: 0.953125, loss: 0.20272648334503174      \n",
      "train step #6639 accuracy: 0.953125, loss: 0.11331993341445923      \n",
      "train step #6640 accuracy: 0.96875, loss: 0.11977744102478027      \n",
      "train step #6641 accuracy: 0.953125, loss: 0.1251276135444641       \n",
      "train step #6642 accuracy: 0.953125, loss: 0.14651978015899658      \n",
      "train step #6643 accuracy: 0.96875, loss: 0.18793562054634094      \n",
      "train step #6644 accuracy: 0.984375, loss: 0.022292472422122955     \n",
      "train step #6645 accuracy: 0.9375, loss: 0.11787919700145721      \n",
      "train step #6646 accuracy: 0.96875, loss: 0.1551237404346466       \n",
      "train step #6647 accuracy:   1.0, loss: 0.031115518882870674     \n",
      "train step #6648 accuracy: 0.984375, loss: 0.051123447716236115     \n",
      "train step #6649 accuracy: 0.984375, loss: 0.12105919420719147      \n",
      "train step #6650 accuracy: 0.96875, loss: 0.08467997610569         \n",
      "train step #6651 accuracy:   1.0, loss: 0.06198142096400261      \n",
      "train step #6652 accuracy: 0.984375, loss: 0.14342781901359558      \n",
      "train step #6653 accuracy: 0.953125, loss: 0.24437490105628967      \n",
      "train step #6654 accuracy: 0.953125, loss: 0.14135290682315826      \n",
      "train step #6655 accuracy: 0.96875, loss: 0.05919816344976425      \n",
      "train step #6656 accuracy: 0.984375, loss: 0.07093972712755203      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #6657 accuracy: 0.921875, loss: 0.23973879218101501      \n",
      "train step #6658 accuracy: 0.953125, loss: 0.13934370875358582      \n",
      "train step #6659 accuracy:   1.0, loss: 0.04211851954460144      \n",
      "train step #6660 accuracy: 0.953125, loss: 0.12026058882474899      \n",
      "train step #6661 accuracy: 0.984375, loss: 0.08143698424100876      \n",
      "train step #6662 accuracy: 0.953125, loss: 0.18824708461761475      \n",
      "train step #6663 accuracy: 0.90625, loss: 0.25512897968292236      \n",
      "train step #6664 accuracy: 0.984375, loss: 0.07231242954730988      \n",
      "train step #6665 accuracy: 0.984375, loss: 0.06441941857337952      \n",
      "train step #6666 accuracy: 0.96875, loss: 0.19332215189933777      \n",
      "train step #6667 accuracy: 0.96875, loss: 0.08152563124895096      \n",
      "train step #6668 accuracy: 0.984375, loss: 0.07841363549232483      \n",
      "train step #6669 accuracy: 0.96875, loss: 0.18120722472667694      \n",
      "train step #6670 accuracy: 0.96875, loss: 0.07806355506181717      \n",
      "train step #6671 accuracy: 0.953125, loss: 0.16673937439918518      \n",
      "train step #6672 accuracy: 0.953125, loss: 0.14658379554748535      \n",
      "train step #6673 accuracy: 0.890625, loss: 0.3155083656311035       \n",
      "train step #6674 accuracy: 0.9375, loss: 0.10097279399633408      \n",
      "train step #6675 accuracy: 0.984375, loss: 0.08446556329727173      \n",
      "train step #6676 accuracy: 0.9375, loss: 0.2105676531791687       \n",
      "train step #6677 accuracy: 0.96875, loss: 0.13004978001117706      \n",
      "train step #6678 accuracy: 0.984375, loss: 0.0516972579061985       \n",
      "train step #6679 accuracy: 0.953125, loss: 0.16804412007331848      \n",
      "train step #6680 accuracy: 0.953125, loss: 0.1747574806213379       \n",
      "train step #6681 accuracy: 0.9375, loss: 0.16662314534187317      \n",
      "train step #6682 accuracy: 0.953125, loss: 0.12525887787342072      \n",
      "train step #6683 accuracy: 0.9375, loss: 0.13851597905158997      \n",
      "train step #6684 accuracy: 0.984375, loss: 0.07188749313354492      \n",
      "train step #6685 accuracy:   1.0, loss: 0.040947869420051575     \n",
      "train step #6686 accuracy: 0.953125, loss: 0.08441942185163498      \n",
      "train step #6687 accuracy: 0.953125, loss: 0.13766486942768097      \n",
      "train step #6688 accuracy: 0.921875, loss: 0.22975337505340576      \n",
      "train step #6689 accuracy: 0.953125, loss: 0.18967680633068085      \n",
      "train step #6690 accuracy: 0.984375, loss: 0.09093284606933594      \n",
      "train step #6691 accuracy: 0.96875, loss: 0.10058054327964783      \n",
      "train step #6692 accuracy: 0.984375, loss: 0.07120184600353241      \n",
      "train step #6693 accuracy: 0.9375, loss: 0.18265734612941742      \n",
      "train step #6694 accuracy: 0.984375, loss: 0.08962854743003845      \n",
      "train step #6695 accuracy: 0.96875, loss: 0.1965581774711609       \n",
      "train step #6696 accuracy: 0.96875, loss: 0.08725021779537201      \n",
      "train step #6697 accuracy: 0.984375, loss: 0.049017708748579025     \n",
      "train step #6698 accuracy: 0.984375, loss: 0.11339753866195679      \n",
      "train step #6699 accuracy:   1.0, loss: 0.023877598345279694     \n",
      "train step #6700 accuracy: 0.96875, loss: 0.1563820093870163       \n",
      "train step #6701 accuracy: 0.953125, loss: 0.12002483755350113      \n",
      "train step #6702 accuracy: 0.96875, loss: 0.13298501074314117      \n",
      "train step #6703 accuracy: 0.921875, loss: 0.18232344090938568      \n",
      "train step #6704 accuracy: 0.984375, loss: 0.06427227705717087      \n",
      "train step #6705 accuracy: 0.984375, loss: 0.04441675916314125      \n",
      "train step #6706 accuracy: 0.953125, loss: 0.23389983177185059      \n",
      "train step #6707 accuracy: 0.984375, loss: 0.09471647441387177      \n",
      "train step #6708 accuracy: 0.96875, loss: 0.11425868421792984      \n",
      "train step #6709 accuracy: 0.953125, loss: 0.21933023631572723      \n",
      "train step #6710 accuracy: 0.953125, loss: 0.1493578404188156       \n",
      "train step #6711 accuracy: 0.921875, loss: 0.27354031801223755      \n",
      "train step #6712 accuracy: 0.96875, loss: 0.07905247807502747      \n",
      "train step #6713 accuracy: 0.984375, loss: 0.07969965785741806      \n",
      "train step #6714 accuracy: 0.984375, loss: 0.05032035708427429      \n",
      "train step #6715 accuracy: 0.953125, loss: 0.19937928020954132      \n",
      "train step #6716 accuracy: 0.953125, loss: 0.09527310729026794      \n",
      "train step #6717 accuracy: 0.96875, loss: 0.09942798316478729      \n",
      "train step #6718 accuracy: 0.96875, loss: 0.18342682719230652      \n",
      "train step #6719 accuracy: 0.953125, loss: 0.11265575885772705      \n",
      "train step #6720 accuracy: 0.96875, loss: 0.10570570826530457      \n",
      "train step #6721 accuracy: 0.953125, loss: 0.14357221126556396      \n",
      "train step #6722 accuracy:   1.0, loss: 0.0398143008351326       \n",
      "train step #6723 accuracy: 0.96875, loss: 0.1447068750858307       \n",
      "train step #6724 accuracy: 0.96875, loss: 0.11226275563240051      \n",
      "train step #6725 accuracy: 0.953125, loss: 0.18169701099395752      \n",
      "train step #6726 accuracy: 0.984375, loss: 0.08097516000270844      \n",
      "train step #6727 accuracy: 0.96875, loss: 0.12996798753738403      \n",
      "train step #6728 accuracy: 0.96875, loss: 0.1134180873632431       \n",
      "train step #6729 accuracy: 0.9375, loss: 0.24045485258102417      \n",
      "train step #6730 accuracy: 0.90625, loss: 0.20836447179317474      \n",
      "train step #6731 accuracy: 0.984375, loss: 0.08011355996131897      \n",
      "train step #6732 accuracy:   1.0, loss: 0.035459864884614944     \n",
      "train step #6733 accuracy: 0.953125, loss: 0.1574067622423172       \n",
      "train step #6734 accuracy: 0.984375, loss: 0.04820114001631737      \n",
      "train step #6735 accuracy: 0.96875, loss: 0.173643559217453        \n",
      "train step #6736 accuracy: 0.984375, loss: 0.08433669805526733      \n",
      "train step #6737 accuracy: 0.96875, loss: 0.08406758308410645      \n",
      "train step #6738 accuracy: 0.984375, loss: 0.07739880681037903      \n",
      "train step #6739 accuracy: 0.96875, loss: 0.09402556717395782      \n",
      "train step #6740 accuracy:   1.0, loss: 0.03454697132110596      \n",
      "train step #6741 accuracy: 0.984375, loss: 0.059715840965509415     \n",
      "train step #6742 accuracy: 0.890625, loss: 0.31526726484298706      \n",
      "train step #6743 accuracy: 0.90625, loss: 0.40625929832458496      \n",
      "train step #6744 accuracy: 0.96875, loss: 0.20184996724128723      \n",
      "train step #6745 accuracy: 0.984375, loss: 0.09687000513076782      \n",
      "train step #6746 accuracy: 0.953125, loss: 0.1503417193889618       \n",
      "train step #6747 accuracy: 0.96875, loss: 0.13246843218803406      \n",
      "train step #6748 accuracy:   1.0, loss: 0.023512698709964752     \n",
      "train step #6749 accuracy: 0.96875, loss: 0.11498472839593887      \n",
      "train step #6750 accuracy: 0.96875, loss: 0.09219614416360855      \n",
      "train step #6751 accuracy: 0.953125, loss: 0.14648091793060303      \n",
      "train step #6752 accuracy: 0.953125, loss: 0.16067852079868317      \n",
      "train step #6753 accuracy: 0.953125, loss: 0.10873342305421829      \n",
      "train step #6754 accuracy: 0.984375, loss: 0.06438957899808884      \n",
      "train step #6755 accuracy: 0.953125, loss: 0.10757681727409363      \n",
      "train step #6756 accuracy: 0.953125, loss: 0.1581040322780609       \n",
      "train step #6757 accuracy: 0.953125, loss: 0.22070693969726562      \n",
      "train step #6758 accuracy: 0.953125, loss: 0.11404665559530258      \n",
      "train step #6759 accuracy: 0.96875, loss: 0.12082921713590622      \n",
      "train step #6760 accuracy: 0.953125, loss: 0.13173452019691467      \n",
      "train step #6761 accuracy: 0.984375, loss: 0.07293836772441864      \n",
      "train step #6762 accuracy: 0.953125, loss: 0.15489622950553894      \n",
      "train step #6763 accuracy: 0.96875, loss: 0.17687469720840454      \n",
      "train step #6764 accuracy: 0.984375, loss: 0.05310240760445595      \n",
      "train step #6765 accuracy: 0.984375, loss: 0.12393195182085037      \n",
      "train step #6766 accuracy: 0.9375, loss: 0.22271424531936646      \n",
      "train step #6767 accuracy: 0.96875, loss: 0.11587812006473541      \n",
      "train step #6768 accuracy: 0.9375, loss: 0.17228133976459503      \n",
      "train step #6769 accuracy: 0.96875, loss: 0.16231343150138855      \n",
      "train step #6770 accuracy:   1.0, loss: 0.05442073941230774      \n",
      "train step #6771 accuracy: 0.953125, loss: 0.18900340795516968      \n",
      "train step #6772 accuracy: 0.953125, loss: 0.20622871816158295      \n",
      "train step #6773 accuracy: 0.921875, loss: 0.28458547592163086      \n",
      "train step #6774 accuracy: 0.921875, loss: 0.1698329746723175       \n",
      "train step #6775 accuracy:   1.0, loss: 0.041093312203884125     \n",
      "train step #6776 accuracy: 0.90625, loss: 0.23115535080432892      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #6777 accuracy: 0.890625, loss: 0.34427666664123535      \n",
      "train step #6778 accuracy: 0.984375, loss: 0.04061714559793472      \n",
      "train step #6779 accuracy:   1.0, loss: 0.0486442968249321       \n",
      "train step #6780 accuracy: 0.96875, loss: 0.12449666857719421      \n",
      "train step #6781 accuracy: 0.96875, loss: 0.06807629764080048      \n",
      "train step #6782 accuracy: 0.953125, loss: 0.11819697916507721      \n",
      "train step #6783 accuracy: 0.984375, loss: 0.0877562090754509       \n",
      "train step #6784 accuracy: 0.984375, loss: 0.06018584221601486      \n",
      "train step #6785 accuracy: 0.9375, loss: 0.183604434132576        \n",
      "train step #6786 accuracy: 0.984375, loss: 0.0891999751329422       \n",
      "train step #6787 accuracy: 0.984375, loss: 0.09598958492279053      \n",
      "train step #6788 accuracy: 0.953125, loss: 0.21969416737556458      \n",
      "train step #6789 accuracy:   1.0, loss: 0.04807471111416817      \n",
      "train step #6790 accuracy: 0.96875, loss: 0.08471186459064484      \n",
      "train step #6791 accuracy: 0.953125, loss: 0.15502890944480896      \n",
      "train step #6792 accuracy: 0.96875, loss: 0.12053588777780533      \n",
      "train step #6793 accuracy: 0.953125, loss: 0.08490461111068726      \n",
      "train step #6794 accuracy: 0.953125, loss: 0.1785069853067398       \n",
      "train step #6795 accuracy: 0.953125, loss: 0.16717904806137085      \n",
      "train step #6796 accuracy: 0.90625, loss: 0.2518649101257324       \n",
      "train step #6797 accuracy: 0.9375, loss: 0.2665381133556366       \n",
      "train step #6798 accuracy: 0.953125, loss: 0.16548581421375275      \n",
      "train step #6799 accuracy:   1.0, loss: 0.046138327568769455     \n",
      "train step #6800 accuracy: 0.953125, loss: 0.16664274036884308      \n",
      "train step #6801 accuracy: 0.96875, loss: 0.11124730855226517      \n",
      "train step #6802 accuracy: 0.96875, loss: 0.08391813933849335      \n",
      "train step #6803 accuracy: 0.96875, loss: 0.14006151258945465      \n",
      "train step #6804 accuracy: 0.9375, loss: 0.29941412806510925      \n",
      "train step #6805 accuracy: 0.9375, loss: 0.12817829847335815      \n",
      "train step #6806 accuracy: 0.921875, loss: 0.2617240250110626       \n",
      "train step #6807 accuracy: 0.890625, loss: 0.33413347601890564      \n",
      "train step #6808 accuracy: 0.96875, loss: 0.09119245409965515      \n",
      "train step #6809 accuracy: 0.96875, loss: 0.13791817426681519      \n",
      "train step #6810 accuracy: 0.984375, loss: 0.21432387828826904      \n",
      "train step #6811 accuracy: 0.96875, loss: 0.10988640785217285      \n",
      "train step #6812 accuracy: 0.953125, loss: 0.120541051030159        \n",
      "train step #6813 accuracy: 0.96875, loss: 0.07262906432151794      \n",
      "train step #6814 accuracy: 0.96875, loss: 0.1483791172504425       \n",
      "train step #6815 accuracy: 0.953125, loss: 0.12415142357349396      \n",
      "train step #6816 accuracy: 0.984375, loss: 0.058834951370954514     \n",
      "train step #6817 accuracy: 0.9375, loss: 0.15667122602462769      \n",
      "train step #6818 accuracy:   1.0, loss: 0.058264169842004776     \n",
      "train step #6819 accuracy: 0.9375, loss: 0.2259311079978943       \n",
      "train step #6820 accuracy: 0.96875, loss: 0.0846332237124443       \n",
      "train step #6821 accuracy: 0.9375, loss: 0.2561325430870056       \n",
      "train step #6822 accuracy: 0.984375, loss: 0.05991966277360916      \n",
      "train step #6823 accuracy: 0.953125, loss: 0.15564532577991486      \n",
      "train step #6824 accuracy: 0.984375, loss: 0.13285259902477264      \n",
      "train step #6825 accuracy:   1.0, loss: 0.02209486812353134      \n",
      "train step #6826 accuracy: 0.953125, loss: 0.1476501226425171       \n",
      "train step #6827 accuracy: 0.96875, loss: 0.1564258635044098       \n",
      "train step #6828 accuracy: 0.984375, loss: 0.10468629002571106      \n",
      "train step #6829 accuracy: 0.9375, loss: 0.21847862005233765      \n",
      "train step #6830 accuracy: 0.96875, loss: 0.15663446485996246      \n",
      "train step #6831 accuracy: 0.96875, loss: 0.06406668573617935      \n",
      "train step #6832 accuracy: 0.96875, loss: 0.102482870221138        \n",
      "train step #6833 accuracy: 0.953125, loss: 0.22110551595687866      \n",
      "train step #6834 accuracy: 0.96875, loss: 0.0968041867017746       \n",
      "train step #6835 accuracy: 0.9375, loss: 0.27608373761177063      \n",
      "train step #6836 accuracy: 0.9375, loss: 0.10541364550590515      \n",
      "train step #6837 accuracy: 0.953125, loss: 0.24863409996032715      \n",
      "train step #6838 accuracy: 0.984375, loss: 0.13562753796577454      \n",
      "train step #6839 accuracy: 0.96875, loss: 0.08742140978574753      \n",
      "train step #6840 accuracy: 0.921875, loss: 0.20644670724868774      \n",
      "train step #6841 accuracy: 0.96875, loss: 0.11537130177021027      \n",
      "train step #6842 accuracy: 0.984375, loss: 0.07242032140493393      \n",
      "train step #6843 accuracy:   1.0, loss: 0.06817575544118881      \n",
      "train step #6844 accuracy: 0.90625, loss: 0.22755169868469238      \n",
      "train step #6845 accuracy: 0.984375, loss: 0.09902691841125488      \n",
      "train step #6846 accuracy: 0.9375, loss: 0.20091035962104797      \n",
      "train step #6847 accuracy: 0.96875, loss: 0.14191997051239014      \n",
      "train step #6848 accuracy:   1.0, loss: 0.03476501256227493      \n",
      "train step #6849 accuracy: 0.9375, loss: 0.1655881553888321       \n",
      "train step #6850 accuracy: 0.984375, loss: 0.06750250607728958      \n",
      "train step #6851 accuracy: 0.9375, loss: 0.10405933111906052      \n",
      "train step #6852 accuracy: 0.984375, loss: 0.06460921466350555      \n",
      "train step #6853 accuracy: 0.984375, loss: 0.06581722944974899      \n",
      "train step #6854 accuracy: 0.9375, loss: 0.2002381682395935       \n",
      "train step #6855 accuracy: 0.953125, loss: 0.18759478628635406      \n",
      "train step #6856 accuracy: 0.984375, loss: 0.08990106731653214      \n",
      "train step #6857 accuracy: 0.9375, loss: 0.16643893718719482      \n",
      "train step #6858 accuracy: 0.953125, loss: 0.19824403524398804      \n",
      "train step #6859 accuracy: 0.984375, loss: 0.09829844534397125      \n",
      "train step #6860 accuracy: 0.921875, loss: 0.22414128482341766      \n",
      "train step #6861 accuracy:   1.0, loss: 0.02731497585773468      \n",
      "train step #6862 accuracy: 0.953125, loss: 0.14798866212368011      \n",
      "train step #6863 accuracy: 0.96875, loss: 0.173428475856781        \n",
      "train step #6864 accuracy: 0.96875, loss: 0.11932259052991867      \n",
      "train step #6865 accuracy: 0.984375, loss: 0.11386570334434509      \n",
      "train step #6866 accuracy: 0.984375, loss: 0.08094001561403275      \n",
      "train step #6867 accuracy: 0.953125, loss: 0.13096189498901367      \n",
      "train step #6868 accuracy:   1.0, loss: 0.03418538346886635      \n",
      "train step #6869 accuracy: 0.953125, loss: 0.21450671553611755      \n",
      "train step #6870 accuracy: 0.96875, loss: 0.08817598968744278      \n",
      "train step #6871 accuracy: 0.953125, loss: 0.20886804163455963      \n",
      "train step #6872 accuracy:   1.0, loss: 0.024874776601791382     \n",
      "train step #6873 accuracy: 0.96875, loss: 0.10666920989751816      \n",
      "train step #6874 accuracy: 0.96875, loss: 0.1673094481229782       \n",
      "train step #6875 accuracy: 0.96875, loss: 0.21189551055431366      \n",
      "train step #6876 accuracy: 0.984375, loss: 0.0763503685593605       \n",
      "train step #6877 accuracy: 0.953125, loss: 0.18294468522071838      \n",
      "train step #6878 accuracy: 0.953125, loss: 0.21030738949775696      \n",
      "train step #6879 accuracy: 0.9375, loss: 0.23704670369625092      \n",
      "train step #6880 accuracy: 0.953125, loss: 0.17453286051750183      \n",
      "train step #6881 accuracy: 0.921875, loss: 0.2602023482322693       \n",
      "train step #6882 accuracy: 0.984375, loss: 0.09201084077358246      \n",
      "train step #6883 accuracy: 0.984375, loss: 0.04947107285261154      \n",
      "train step #6884 accuracy: 0.953125, loss: 0.2046932578086853       \n",
      "train step #6885 accuracy: 0.9375, loss: 0.21699565649032593      \n",
      "train step #6886 accuracy: 0.984375, loss: 0.10632660239934921      \n",
      "train step #6887 accuracy: 0.953125, loss: 0.2445121556520462       \n",
      "train step #6888 accuracy: 0.921875, loss: 0.18741801381111145      \n",
      "train step #6889 accuracy:   1.0, loss: 0.042297668755054474     \n",
      "train step #6890 accuracy: 0.9375, loss: 0.20359542965888977      \n",
      "train step #6891 accuracy: 0.953125, loss: 0.14574547111988068      \n",
      "train step #6892 accuracy: 0.953125, loss: 0.06772088259458542      \n",
      "train step #6893 accuracy: 0.984375, loss: 0.1015862375497818       \n",
      "train step #6894 accuracy:   1.0, loss: 0.02698451280593872      \n",
      "train step #6895 accuracy: 0.953125, loss: 0.21991461515426636      \n",
      "train step #6896 accuracy: 0.984375, loss: 0.12489213049411774      \n",
      "train step #6897 accuracy: 0.984375, loss: 0.0560661144554615       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #6898 accuracy: 0.984375, loss: 0.08051954209804535      \n",
      "train step #6899 accuracy: 0.953125, loss: 0.24383467435836792      \n",
      "train step #6900 accuracy: 0.953125, loss: 0.17925770580768585      \n",
      "train step #6901 accuracy:   1.0, loss: 0.02008882164955139      \n",
      "train step #6902 accuracy: 0.984375, loss: 0.056461308151483536     \n",
      "train step #6903 accuracy: 0.9375, loss: 0.1440097838640213       \n",
      "train step #6904 accuracy: 0.984375, loss: 0.0877528041601181       \n",
      "train step #6905 accuracy: 0.984375, loss: 0.13986489176750183      \n",
      "train step #6906 accuracy: 0.96875, loss: 0.15457861125469208      \n",
      "train step #6907 accuracy: 0.953125, loss: 0.12869565188884735      \n",
      "train step #6908 accuracy: 0.921875, loss: 0.34781739115715027      \n",
      "train step #6909 accuracy: 0.953125, loss: 0.16820783913135529      \n",
      "train step #6910 accuracy: 0.984375, loss: 0.10524725168943405      \n",
      "train step #6911 accuracy: 0.96875, loss: 0.1134318858385086       \n",
      "train step #6912 accuracy: 0.921875, loss: 0.2430540919303894       \n",
      "train step #6913 accuracy: 0.953125, loss: 0.1294834017753601       \n",
      "train step #6914 accuracy: 0.96875, loss: 0.1375788450241089       \n",
      "train step #6915 accuracy: 0.984375, loss: 0.08210770040750504      \n",
      "train step #6916 accuracy: 0.984375, loss: 0.1120365560054779       \n",
      "train step #6917 accuracy: 0.96875, loss: 0.13008524477481842      \n",
      "train step #6918 accuracy:   1.0, loss: 0.04524261876940727      \n",
      "train step #6919 accuracy: 0.984375, loss: 0.050297003239393234     \n",
      "train step #6920 accuracy:   1.0, loss: 0.02502240240573883      \n",
      "train step #6921 accuracy: 0.921875, loss: 0.26652029156684875      \n",
      "train step #6922 accuracy: 0.984375, loss: 0.08286332339048386      \n",
      "train step #6923 accuracy: 0.921875, loss: 0.24195201694965363      \n",
      "train step #6924 accuracy: 0.921875, loss: 0.17526623606681824      \n",
      "train step #6925 accuracy: 0.953125, loss: 0.1863877922296524       \n",
      "train step #6926 accuracy: 0.953125, loss: 0.1414812207221985       \n",
      "train step #6927 accuracy: 0.90625, loss: 0.257951021194458        \n",
      "train step #6928 accuracy: 0.984375, loss: 0.10705111920833588      \n",
      "train step #6929 accuracy: 0.96875, loss: 0.15780451893806458      \n",
      "train step #6930 accuracy: 0.984375, loss: 0.13452067971229553      \n",
      "train step #6931 accuracy: 0.984375, loss: 0.11403344571590424      \n",
      "train step #6932 accuracy: 0.953125, loss: 0.1907561868429184       \n",
      "train step #6933 accuracy: 0.9375, loss: 0.1380886286497116       \n",
      "train step #6934 accuracy: 0.984375, loss: 0.058214232325553894     \n",
      "train step #6935 accuracy: 0.96875, loss: 0.0885966569185257       \n",
      "train step #6936 accuracy: 0.96875, loss: 0.14903341233730316      \n",
      "train step #6937 accuracy: 0.96875, loss: 0.1822267323732376       \n",
      "train step #6938 accuracy: 0.9375, loss: 0.18286831676959991      \n",
      "train step #6939 accuracy: 0.9375, loss: 0.19522437453269958      \n",
      "train step #6940 accuracy: 0.984375, loss: 0.08461134135723114      \n",
      "dev accuracy:   1.0, loss: 0.06400954723358154      \n",
      "dev accuracy: 0.9375, loss: 0.16327181458473206      \n",
      "dev accuracy: 0.9375, loss: 0.25621598958969116      \n",
      "dev accuracy:   1.0, loss: 0.07025685906410217      \n",
      "dev accuracy:   1.0, loss: 0.030873149633407593     \n",
      "dev accuracy:   1.0, loss: 0.09221874922513962      \n",
      "dev accuracy:   1.0, loss: 0.014415174722671509     \n",
      "dev accuracy:   1.0, loss: 0.022303789854049683     \n",
      "dev accuracy:   1.0, loss: 0.040181100368499756     \n",
      "dev accuracy:   1.0, loss: 0.0019123554229736328    \n",
      "dev accuracy: 0.8125, loss: 0.5445606708526611       \n",
      "dev accuracy: 0.9375, loss: 0.10176622867584229      \n",
      "dev accuracy: 0.875, loss: 0.619458794593811        \n",
      "dev accuracy: 0.875, loss: 0.37838947772979736      \n",
      "dev accuracy:   1.0, loss: 0.09106618165969849      \n",
      "dev accuracy:   1.0, loss: 0.016592174768447876     \n",
      "dev accuracy:   1.0, loss: 0.02985250949859619      \n",
      "dev accuracy: 0.9375, loss: 0.14414702355861664      \n",
      "dev accuracy:   1.0, loss: 0.05517283082008362      \n",
      "dev accuracy:   1.0, loss: 0.010361790657043457     \n",
      "dev accuracy: 0.9375, loss: 0.154704749584198        \n",
      "dev accuracy: 0.9375, loss: 0.23798134922981262      \n",
      "dev accuracy: 0.9375, loss: 0.18200048804283142      \n",
      "dev accuracy: 0.875, loss: 0.2703550159931183       \n",
      "dev accuracy:   1.0, loss: 0.01813867688179016      \n",
      "dev accuracy:   1.0, loss: 0.04147911071777344      \n",
      "dev accuracy:   1.0, loss: 0.0059760212898254395    \n",
      "dev accuracy:   1.0, loss: 0.0546717643737793       \n",
      "dev accuracy:   1.0, loss: 0.018278181552886963     \n",
      "dev accuracy:   1.0, loss: 0.03502810001373291      \n",
      "dev accuracy:   1.0, loss: 0.03154882788658142      \n",
      "dev accuracy: 0.9375, loss: 0.22658759355545044      \n",
      "dev accuracy: 0.9375, loss: 0.10302439332008362      \n",
      "dev accuracy:   1.0, loss: 0.006364166736602783     \n",
      "dev accuracy:   1.0, loss: 0.041421324014663696     \n",
      "dev accuracy:   1.0, loss: 0.03302186727523804      \n",
      "dev accuracy:   1.0, loss: 0.02757886052131653      \n",
      "dev accuracy: 0.9375, loss: 0.07942792773246765      \n",
      "dev accuracy: 0.9375, loss: 0.29153838753700256      \n",
      "dev accuracy: 0.875, loss: 0.5477080345153809       \n",
      "dev accuracy: 0.9375, loss: 0.06410902738571167      \n",
      "dev accuracy: 0.8125, loss: 0.3292977809906006       \n",
      "dev accuracy: 0.9375, loss: 0.13917329907417297      \n",
      "dev accuracy: 0.8125, loss: 0.7361130714416504       \n",
      "dev accuracy:   1.0, loss: 0.023893117904663086     \n",
      "dev accuracy:   1.0, loss: 0.015277326107025146     \n",
      "dev accuracy: 0.8125, loss: 0.4893360137939453       \n",
      "dev accuracy: 0.9375, loss: 0.20099303126335144      \n",
      "dev accuracy: 0.9375, loss: 0.1269931197166443       \n",
      "dev accuracy: 0.9375, loss: 0.2528923451900482       \n",
      "dev accuracy:   1.0, loss: 0.030492275953292847     \n",
      "dev accuracy: 0.9375, loss: 0.12411756813526154      \n",
      "dev accuracy: 0.875, loss: 0.37323614954948425      \n",
      "dev accuracy:   1.0, loss: 0.02467060089111328      \n",
      "dev accuracy: 0.9375, loss: 0.16413992643356323      \n",
      "dev accuracy: 0.9375, loss: 0.32414665818214417      \n",
      "dev accuracy:   1.0, loss: 0.09694033861160278      \n",
      "dev accuracy: 0.875, loss: 0.659469485282898        \n",
      "dev accuracy: 0.9375, loss: 0.0751693993806839       \n",
      "dev accuracy: 0.9375, loss: 0.15396101772785187      \n",
      "dev accuracy: 0.9375, loss: 0.19229967892169952      \n",
      "dev accuracy:   1.0, loss: 0.032639771699905396     \n",
      "dev accuracy:   1.0, loss: 0.03187766671180725      \n",
      "dev accuracy: 0.9375, loss: 0.09900665283203125      \n",
      "dev accuracy: 0.875, loss: 0.4797635078430176       \n",
      "dev accuracy: 0.875, loss: 0.6205317974090576       \n",
      "dev accuracy: 0.9375, loss: 0.38774561882019043      \n",
      "dev accuracy: 0.9375, loss: 0.3036797046661377       \n",
      "dev accuracy: 0.9375, loss: 0.12229983508586884      \n",
      "dev accuracy:   1.0, loss: 0.022467225790023804     \n",
      "dev accuracy: 0.9375, loss: 0.22767478227615356      \n",
      "dev accuracy: 0.9375, loss: 0.12629982829093933      \n",
      "dev accuracy: 0.9375, loss: 0.23368938267230988      \n",
      "dev accuracy: 0.9375, loss: 0.1625690460205078       \n",
      "dev accuracy:   1.0, loss: 0.01742565631866455      \n",
      "dev accuracy: 0.9375, loss: 0.43510013818740845      \n",
      "dev accuracy:   1.0, loss: 0.01612153649330139      \n",
      "dev accuracy:   1.0, loss: 0.010157585144042969     \n",
      "dev accuracy: 0.9375, loss: 0.1576683521270752       \n",
      "dev accuracy:   1.0, loss: 0.005748867988586426     \n",
      "dev accuracy:   1.0, loss: 0.008772104978561401     \n",
      "dev accuracy:   1.0, loss: 0.040874361991882324     \n",
      "dev accuracy: 0.9375, loss: 0.18670403957366943      \n",
      "dev accuracy:   1.0, loss: 0.02592220902442932      \n",
      "dev accuracy:   1.0, loss: 0.0032161176204681396    \n",
      "dev accuracy:   1.0, loss: 0.002458333969116211     \n",
      "dev accuracy: 0.9375, loss: 0.06522044539451599      \n",
      "dev accuracy: 0.875, loss: 0.5101056694984436       \n",
      "dev accuracy: 0.9375, loss: 0.18339312076568604      \n",
      "dev accuracy: 0.9375, loss: 0.07475915551185608      \n",
      "dev accuracy: 0.9375, loss: 0.2048114538192749       \n",
      "dev accuracy: 0.9375, loss: 0.09505343437194824      \n",
      "dev accuracy:   1.0, loss: 0.05407688021659851      \n",
      "dev accuracy: 0.875, loss: 0.48445063829421997      \n",
      "dev accuracy: 0.9375, loss: 0.05725109577178955      \n",
      "dev accuracy: 0.9375, loss: 0.18056896328926086      \n",
      "dev accuracy: 0.875, loss: 0.3852970600128174       \n",
      "dev accuracy: 0.9375, loss: 0.15316399931907654      \n",
      "dev accuracy:   1.0, loss: 0.01891779899597168      \n",
      "dev accuracy: 0.9375, loss: 0.17900769412517548      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy:   1.0, loss: 0.010660916566848755     \n",
      "dev accuracy: 0.9375, loss: 0.2809474766254425       \n",
      "dev accuracy:   1.0, loss: 0.00963371992111206      \n",
      "dev accuracy: 0.9375, loss: 0.2648515999317169       \n",
      "dev accuracy: 0.9375, loss: 0.20173980295658112      \n",
      "dev accuracy: 0.875, loss: 0.670669674873352        \n",
      "dev accuracy: 0.875, loss: 0.20135363936424255      \n",
      "dev accuracy: 0.9375, loss: 0.09085169434547424      \n",
      "dev accuracy:   1.0, loss: 0.10309787094593048      \n",
      "dev accuracy: 0.9375, loss: 0.22090312838554382      \n",
      "dev accuracy: 0.9375, loss: 0.08434462547302246      \n",
      "dev accuracy: 0.9375, loss: 0.07388970255851746      \n",
      "dev accuracy:  0.75, loss: 0.5026309490203857       \n",
      "dev accuracy:   1.0, loss: 0.0034048259258270264    \n",
      "dev accuracy: 0.875, loss: 0.3307146728038788       \n",
      "dev accuracy:   1.0, loss: 0.0054558515548706055    \n",
      "dev accuracy:   1.0, loss: 0.051929861307144165     \n",
      "dev accuracy:   1.0, loss: 0.02108672261238098      \n",
      "dev accuracy:   1.0, loss: 0.021380126476287842     \n",
      "dev accuracy: 0.8125, loss: 0.38746973872184753      \n",
      "dev accuracy:   1.0, loss: 0.002352207899093628     \n",
      "dev accuracy: 0.9375, loss: 0.21505683660507202      \n",
      "dev accuracy: 0.9375, loss: 0.47207823395729065      \n",
      "dev accuracy: 0.875, loss: 0.6314737796783447       \n",
      "dev accuracy: 0.875, loss: 0.5118879079818726       \n",
      "dev accuracy:   1.0, loss: 0.003556668758392334     \n",
      "dev accuracy: 0.9375, loss: 0.15259574353694916      \n",
      "dev accuracy: 0.8125, loss: 0.29803603887557983      \n",
      "dev accuracy:   1.0, loss: 0.004734814167022705     \n",
      "dev accuracy:   1.0, loss: 0.02449294924736023      \n",
      "dev accuracy: 0.875, loss: 0.2011677324771881       \n",
      "dev accuracy: 0.875, loss: 0.42411091923713684      \n",
      "dev accuracy: 0.875, loss: 0.22096259891986847      \n",
      "dev accuracy: 0.9375, loss: 0.3126201927661896       \n",
      "dev accuracy: 0.9375, loss: 0.0628492534160614       \n",
      "dev accuracy:   1.0, loss: 0.06918400526046753      \n",
      "dev accuracy:   1.0, loss: 0.017511695623397827     \n",
      "dev accuracy:   1.0, loss: 0.027254223823547363     \n",
      "dev accuracy:   1.0, loss: 0.002117455005645752     \n",
      "dev accuracy:   1.0, loss: 0.0012404918670654297    \n",
      "dev accuracy: 0.875, loss: 0.23248761892318726      \n",
      "dev accuracy:   1.0, loss: 0.01417049765586853      \n",
      "dev accuracy:   1.0, loss: 0.0025006532669067383    \n",
      "dev accuracy: 0.9375, loss: 0.10037872195243835      \n",
      "dev accuracy:   1.0, loss: 0.00393909215927124      \n",
      "dev accuracy: 0.9375, loss: 0.1262572705745697       \n",
      "dev accuracy: 0.9375, loss: 0.1415984034538269       \n",
      "dev accuracy:   1.0, loss: 0.0024666786193847656    \n",
      "dev accuracy:   1.0, loss: 0.06438416242599487      \n",
      "dev accuracy: 0.875, loss: 0.7576118111610413       \n",
      "dev accuracy: 0.9375, loss: 0.4664953947067261       \n",
      "dev accuracy: 0.9375, loss: 0.20364485681056976      \n",
      "dev accuracy:   1.0, loss: 0.03918686509132385      \n",
      "dev accuracy:   1.0, loss: 0.001397550106048584     \n",
      "dev accuracy:   1.0, loss: 0.017757058143615723     \n",
      "dev accuracy: 0.875, loss: 0.44471558928489685      \n",
      "dev accuracy: 0.9375, loss: 0.19868287444114685      \n",
      "dev accuracy:   1.0, loss: 0.026503831148147583     \n",
      "dev accuracy:   1.0, loss: 0.0059073567390441895    \n",
      "dev accuracy: 0.875, loss: 0.2733014225959778       \n",
      "dev accuracy: 0.9375, loss: 0.0713290274143219       \n",
      "dev accuracy: 0.9375, loss: 0.1694457232952118       \n",
      "dev accuracy:   1.0, loss: 0.026200532913208008     \n",
      "dev accuracy: 0.9375, loss: 0.31343600153923035      \n",
      "dev accuracy:   1.0, loss: 0.0370001494884491       \n",
      "dev accuracy:   1.0, loss: 0.03186711668968201      \n",
      "dev accuracy:   1.0, loss: 0.0011215806007385254    \n",
      "dev accuracy: 0.9375, loss: 0.19737078249454498      \n",
      "dev accuracy: 0.875, loss: 0.2749429941177368       \n",
      "dev accuracy:   1.0, loss: 0.01664799451828003      \n",
      "dev accuracy: 0.9375, loss: 0.33071625232696533      \n",
      "dev accuracy: 0.9375, loss: 0.1408585011959076       \n",
      "dev accuracy:   1.0, loss: 0.05481724441051483      \n",
      "dev accuracy: 0.875, loss: 0.1759943962097168       \n",
      "dev accuracy: 0.9375, loss: 0.1849091500043869       \n",
      "dev accuracy: 0.875, loss: 0.24465125799179077      \n",
      "dev accuracy:   1.0, loss: 0.020406365394592285     \n",
      "dev accuracy:   1.0, loss: 0.003670990467071533     \n",
      "dev accuracy: 0.9375, loss: 0.06594431400299072      \n",
      "dev accuracy:   1.0, loss: 0.10233588516712189      \n",
      "dev accuracy: 0.9375, loss: 0.10390913486480713      \n",
      "dev accuracy: 0.875, loss: 0.20508410036563873      \n",
      "dev accuracy:   1.0, loss: 0.0028130412101745605    \n",
      "dev accuracy:   1.0, loss: 0.019098490476608276     \n",
      "dev accuracy:   1.0, loss: 0.0030546188354492188    \n",
      "dev accuracy: 0.9375, loss: 0.1389867663383484       \n",
      "dev accuracy: 0.875, loss: 0.38106536865234375      \n",
      "dev accuracy:   1.0, loss: 0.026659369468688965     \n",
      "dev accuracy:   1.0, loss: 0.003987789154052734     \n",
      "dev accuracy:   1.0, loss: 0.02070331573486328      \n",
      "dev accuracy: 0.9375, loss: 0.344881147146225        \n",
      "dev accuracy: 0.9375, loss: 0.10300734639167786      \n",
      "dev accuracy: 0.9375, loss: 0.24087250232696533      \n",
      "dev accuracy:   1.0, loss: 0.002231597900390625     \n",
      "final dev accuracy: 0.9513530927835051\n",
      "train step #6941 accuracy: 0.9375, loss: 0.16299335658550262      \n",
      "train step #6942 accuracy: 0.96875, loss: 0.11686398833990097      \n",
      "train step #6943 accuracy: 0.96875, loss: 0.18221640586853027      \n",
      "train step #6944 accuracy: 0.921875, loss: 0.21974223852157593      \n",
      "train step #6945 accuracy: 0.96875, loss: 0.15180209279060364      \n",
      "train step #6946 accuracy: 0.90625, loss: 0.24855965375900269      \n",
      "train step #6947 accuracy: 0.96875, loss: 0.14595797657966614      \n",
      "train step #6948 accuracy: 0.875, loss: 0.4222903251647949       \n",
      "train step #6949 accuracy: 0.9375, loss: 0.18277475237846375      \n",
      "train step #6950 accuracy: 0.96875, loss: 0.14710670709609985      \n",
      "train step #6951 accuracy: 0.96875, loss: 0.16725260019302368      \n",
      "train step #6952 accuracy: 0.953125, loss: 0.16598480939865112      \n",
      "train step #6953 accuracy: 0.984375, loss: 0.05301421880722046      \n",
      "train step #6954 accuracy: 0.984375, loss: 0.12069781869649887      \n",
      "train step #6955 accuracy: 0.953125, loss: 0.2299102544784546       \n",
      "train step #6956 accuracy: 0.9375, loss: 0.1959790140390396       \n",
      "train step #6957 accuracy: 0.9375, loss: 0.20579391717910767      \n",
      "train step #6958 accuracy: 0.9375, loss: 0.2268274873495102       \n",
      "train step #6959 accuracy: 0.984375, loss: 0.08426540344953537      \n",
      "train step #6960 accuracy: 0.9375, loss: 0.22027349472045898      \n",
      "train step #6961 accuracy: 0.96875, loss: 0.060548678040504456     \n",
      "train step #6962 accuracy: 0.984375, loss: 0.06335732340812683      \n",
      "train step #6963 accuracy: 0.96875, loss: 0.06590930372476578      \n",
      "train step #6964 accuracy: 0.984375, loss: 0.04426727443933487      \n",
      "train step #6965 accuracy: 0.96875, loss: 0.11626768857240677      \n",
      "train step #6966 accuracy: 0.9375, loss: 0.3000004291534424       \n",
      "train step #6967 accuracy: 0.921875, loss: 0.20705646276474         \n",
      "train step #6968 accuracy: 0.984375, loss: 0.1203903779387474       \n",
      "train step #6969 accuracy: 0.9375, loss: 0.23788753151893616      \n",
      "train step #6970 accuracy: 0.9375, loss: 0.17186647653579712      \n",
      "train step #6971 accuracy: 0.90625, loss: 0.195985808968544        \n",
      "train step #6972 accuracy: 0.984375, loss: 0.03725339472293854      \n",
      "train step #6973 accuracy: 0.96875, loss: 0.1336730420589447       \n",
      "train step #6974 accuracy: 0.953125, loss: 0.17066706717014313      \n",
      "train step #6975 accuracy:   1.0, loss: 0.0318121612071991       \n",
      "train step #6976 accuracy: 0.921875, loss: 0.21935975551605225      \n",
      "train step #6977 accuracy: 0.96875, loss: 0.11481849104166031      \n",
      "train step #6978 accuracy: 0.984375, loss: 0.0329907163977623       \n",
      "train step #6979 accuracy: 0.984375, loss: 0.1277400106191635       \n",
      "train step #6980 accuracy: 0.9375, loss: 0.19960084557533264      \n",
      "train step #6981 accuracy:   1.0, loss: 0.036715179681777954     \n",
      "train step #6982 accuracy: 0.96875, loss: 0.17033933103084564      \n",
      "train step #6983 accuracy: 0.921875, loss: 0.2639394700527191       \n",
      "train step #6984 accuracy: 0.921875, loss: 0.30224722623825073      \n",
      "train step #6985 accuracy: 0.953125, loss: 0.19236548244953156      \n",
      "train step #6986 accuracy: 0.96875, loss: 0.10348879545927048      \n",
      "train step #6987 accuracy: 0.96875, loss: 0.05536375939846039      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #6988 accuracy: 0.96875, loss: 0.15578816831111908      \n",
      "train step #6989 accuracy: 0.96875, loss: 0.11319506168365479      \n",
      "train step #6990 accuracy: 0.984375, loss: 0.041628748178482056     \n",
      "train step #6991 accuracy: 0.9375, loss: 0.24947942793369293      \n",
      "train step #6992 accuracy: 0.96875, loss: 0.17526468634605408      \n",
      "train step #6993 accuracy: 0.984375, loss: 0.15023601055145264      \n",
      "train step #6994 accuracy: 0.984375, loss: 0.09663040935993195      \n",
      "train step #6995 accuracy: 0.921875, loss: 0.22652767598628998      \n",
      "train step #6996 accuracy:   1.0, loss: 0.009741045534610748     \n",
      "train step #6997 accuracy: 0.96875, loss: 0.1306990534067154       \n",
      "train step #6998 accuracy: 0.96875, loss: 0.14134153723716736      \n",
      "train step #6999 accuracy: 0.9375, loss: 0.24144954979419708      \n",
      "train step #7000 accuracy: 0.9375, loss: 0.19062936305999756      \n",
      "train step #7001 accuracy: 0.953125, loss: 0.168755903840065        \n",
      "train step #7002 accuracy: 0.953125, loss: 0.25516432523727417      \n",
      "train step #7003 accuracy: 0.953125, loss: 0.17493019998073578      \n",
      "train step #7004 accuracy: 0.9375, loss: 0.22187189757823944      \n",
      "train step #7005 accuracy: 0.984375, loss: 0.08069294691085815      \n",
      "train step #7006 accuracy: 0.96875, loss: 0.07338861376047134      \n",
      "train step #7007 accuracy: 0.96875, loss: 0.22581134736537933      \n",
      "train step #7008 accuracy: 0.984375, loss: 0.07382423430681229      \n",
      "train step #7009 accuracy: 0.984375, loss: 0.05146683007478714      \n",
      "train step #7010 accuracy: 0.984375, loss: 0.06998541206121445      \n",
      "train step #7011 accuracy:   1.0, loss: 0.03213842958211899      \n",
      "train step #7012 accuracy: 0.96875, loss: 0.1356680691242218       \n",
      "train step #7013 accuracy: 0.984375, loss: 0.05771172419190407      \n",
      "train step #7014 accuracy: 0.9375, loss: 0.1469956785440445       \n",
      "train step #7015 accuracy: 0.90625, loss: 0.2598169445991516       \n",
      "train step #7016 accuracy: 0.921875, loss: 0.25388604402542114      \n",
      "train step #7017 accuracy: 0.953125, loss: 0.14881208539009094      \n",
      "train step #7018 accuracy: 0.953125, loss: 0.14948414266109467      \n",
      "train step #7019 accuracy: 0.9375, loss: 0.2541709542274475       \n",
      "train step #7020 accuracy: 0.921875, loss: 0.3610880970954895       \n",
      "train step #7021 accuracy: 0.96875, loss: 0.12008004635572433      \n",
      "train step #7022 accuracy: 0.96875, loss: 0.13032864034175873      \n",
      "train step #7023 accuracy: 0.96875, loss: 0.16416817903518677      \n",
      "train step #7024 accuracy: 0.96875, loss: 0.12588196992874146      \n",
      "train step #7025 accuracy: 0.984375, loss: 0.0773201584815979       \n",
      "train step #7026 accuracy: 0.96875, loss: 0.20148701965808868      \n",
      "train step #7027 accuracy:   1.0, loss: 0.041847337037324905     \n",
      "train step #7028 accuracy:   1.0, loss: 0.06574498116970062      \n",
      "train step #7029 accuracy: 0.953125, loss: 0.1745954304933548       \n",
      "train step #7030 accuracy: 0.9375, loss: 0.11724834144115448      \n",
      "train step #7031 accuracy: 0.984375, loss: 0.08060117810964584      \n",
      "train step #7032 accuracy: 0.953125, loss: 0.16078445315361023      \n",
      "train step #7033 accuracy: 0.984375, loss: 0.06118062883615494      \n",
      "train step #7034 accuracy: 0.96875, loss: 0.12547782063484192      \n",
      "train step #7035 accuracy: 0.96875, loss: 0.15194541215896606      \n",
      "train step #7036 accuracy: 0.953125, loss: 0.09153102338314056      \n",
      "train step #7037 accuracy: 0.921875, loss: 0.2125290334224701       \n",
      "train step #7038 accuracy: 0.984375, loss: 0.08986485004425049      \n",
      "train step #7039 accuracy: 0.96875, loss: 0.1038355752825737       \n",
      "train step #7040 accuracy: 0.96875, loss: 0.07645819336175919      \n",
      "train step #7041 accuracy: 0.984375, loss: 0.03499745577573776      \n",
      "train step #7042 accuracy: 0.90625, loss: 0.24294285476207733      \n",
      "train step #7043 accuracy:   1.0, loss: 0.01615729182958603      \n",
      "train step #7044 accuracy: 0.96875, loss: 0.14458079636096954      \n",
      "train step #7045 accuracy: 0.984375, loss: 0.10442914813756943      \n",
      "train step #7046 accuracy: 0.984375, loss: 0.041452694684267044     \n",
      "train step #7047 accuracy: 0.90625, loss: 0.2957899868488312       \n",
      "train step #7048 accuracy:   1.0, loss: 0.015876412391662598     \n",
      "train step #7049 accuracy: 0.9375, loss: 0.20647798478603363      \n",
      "train step #7050 accuracy: 0.96875, loss: 0.07255703210830688      \n",
      "train step #7051 accuracy: 0.953125, loss: 0.11996114999055862      \n",
      "train step #7052 accuracy:   1.0, loss: 0.02454027533531189      \n",
      "train step #7053 accuracy: 0.953125, loss: 0.11484061181545258      \n",
      "train step #7054 accuracy: 0.96875, loss: 0.18817022442817688      \n",
      "train step #7055 accuracy: 0.96875, loss: 0.05625925958156586      \n",
      "train step #7056 accuracy: 0.96875, loss: 0.15359745919704437      \n",
      "train step #7057 accuracy: 0.984375, loss: 0.0806429535150528       \n",
      "train step #7058 accuracy: 0.953125, loss: 0.1723870486021042       \n",
      "train step #7059 accuracy: 0.984375, loss: 0.06005595251917839      \n",
      "train step #7060 accuracy: 0.984375, loss: 0.06323778629302979      \n",
      "train step #7061 accuracy: 0.96875, loss: 0.16296283900737762      \n",
      "train step #7062 accuracy: 0.96875, loss: 0.08866190165281296      \n",
      "train step #7063 accuracy: 0.984375, loss: 0.08223653584718704      \n",
      "train step #7064 accuracy: 0.953125, loss: 0.13427329063415527      \n",
      "train step #7065 accuracy:   1.0, loss: 0.04413628950715065      \n",
      "train step #7066 accuracy: 0.9375, loss: 0.19841012358665466      \n",
      "train step #7067 accuracy: 0.984375, loss: 0.09803953766822815      \n",
      "train step #7068 accuracy: 0.953125, loss: 0.1237870454788208       \n",
      "train step #7069 accuracy: 0.96875, loss: 0.16201364994049072      \n",
      "train step #7070 accuracy:   1.0, loss: 0.0342155359685421       \n",
      "train step #7071 accuracy:   1.0, loss: 0.01644747704267502      \n",
      "train step #7072 accuracy: 0.96875, loss: 0.10899422317743301      \n",
      "train step #7073 accuracy: 0.890625, loss: 0.31929343938827515      \n",
      "train step #7074 accuracy: 0.921875, loss: 0.22030426561832428      \n",
      "train step #7075 accuracy: 0.984375, loss: 0.06975714862346649      \n",
      "train step #7076 accuracy: 0.984375, loss: 0.05496348813176155      \n",
      "train step #7077 accuracy: 0.953125, loss: 0.1562444418668747       \n",
      "train step #7078 accuracy: 0.96875, loss: 0.13578841090202332      \n",
      "train step #7079 accuracy: 0.984375, loss: 0.025776676833629608     \n",
      "train step #7080 accuracy: 0.96875, loss: 0.11909347027540207      \n",
      "train step #7081 accuracy: 0.96875, loss: 0.18553033471107483      \n",
      "train step #7082 accuracy: 0.96875, loss: 0.08637316524982452      \n",
      "train step #7083 accuracy: 0.9375, loss: 0.18007558584213257      \n",
      "train step #7084 accuracy: 0.96875, loss: 0.09697680175304413      \n",
      "train step #7085 accuracy: 0.96875, loss: 0.07893868535757065      \n",
      "train step #7086 accuracy: 0.96875, loss: 0.14397619664669037      \n",
      "train step #7087 accuracy: 0.9375, loss: 0.20398300886154175      \n",
      "train step #7088 accuracy: 0.953125, loss: 0.136559396982193        \n",
      "train step #7089 accuracy:   1.0, loss: 0.01769036054611206      \n",
      "train step #7090 accuracy: 0.9375, loss: 0.16836996376514435      \n",
      "train step #7091 accuracy:   1.0, loss: 0.05931489169597626      \n",
      "train step #7092 accuracy: 0.9375, loss: 0.16744230687618256      \n",
      "train step #7093 accuracy: 0.96875, loss: 0.09445004910230637      \n",
      "train step #7094 accuracy: 0.921875, loss: 0.29135000705718994      \n",
      "train step #7095 accuracy: 0.984375, loss: 0.08858399093151093      \n",
      "train step #7096 accuracy: 0.96875, loss: 0.11774939298629761      \n",
      "train step #7097 accuracy:   1.0, loss: 0.10159231722354889      \n",
      "train step #7098 accuracy: 0.984375, loss: 0.04720906540751457      \n",
      "train step #7099 accuracy: 0.984375, loss: 0.09464266896247864      \n",
      "train step #7100 accuracy: 0.953125, loss: 0.18875941634178162      \n",
      "train step #7101 accuracy:   1.0, loss: 0.052018508315086365     \n",
      "train step #7102 accuracy: 0.953125, loss: 0.17090600728988647      \n",
      "train step #7103 accuracy: 0.921875, loss: 0.28561487793922424      \n",
      "train step #7104 accuracy: 0.96875, loss: 0.09163066744804382      \n",
      "train step #7105 accuracy: 0.953125, loss: 0.07641150057315826      \n",
      "train step #7106 accuracy: 0.96875, loss: 0.11069373041391373      \n",
      "train step #7107 accuracy: 0.921875, loss: 0.27807337045669556      \n",
      "train step #7108 accuracy: 0.96875, loss: 0.12795084714889526      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #7109 accuracy: 0.96875, loss: 0.14882586896419525      \n",
      "train step #7110 accuracy: 0.96875, loss: 0.11358008533716202      \n",
      "train step #7111 accuracy: 0.96875, loss: 0.15081371366977692      \n",
      "train step #7112 accuracy:   1.0, loss: 0.02622693032026291      \n",
      "train step #7113 accuracy: 0.96875, loss: 0.13481901586055756      \n",
      "train step #7114 accuracy: 0.9375, loss: 0.16383515298366547      \n",
      "train step #7115 accuracy: 0.96875, loss: 0.09131362289190292      \n",
      "train step #7116 accuracy: 0.984375, loss: 0.059363290667533875     \n",
      "train step #7117 accuracy: 0.984375, loss: 0.059499964118003845     \n",
      "train step #7118 accuracy: 0.9375, loss: 0.28998279571533203      \n",
      "train step #7119 accuracy: 0.9375, loss: 0.24834956228733063      \n",
      "train step #7120 accuracy: 0.984375, loss: 0.08453995734453201      \n",
      "train step #7121 accuracy: 0.90625, loss: 0.33665284514427185      \n",
      "train step #7122 accuracy: 0.96875, loss: 0.11928164213895798      \n",
      "train step #7123 accuracy: 0.96875, loss: 0.058557458221912384     \n",
      "train step #7124 accuracy: 0.9375, loss: 0.1536133736371994       \n",
      "train step #7125 accuracy: 0.953125, loss: 0.26349276304244995      \n",
      "train step #7126 accuracy:   1.0, loss: 0.03414300084114075      \n",
      "train step #7127 accuracy: 0.9375, loss: 0.1446944773197174       \n",
      "train step #7128 accuracy: 0.96875, loss: 0.1442231982946396       \n",
      "train step #7129 accuracy: 0.984375, loss: 0.09100218117237091      \n",
      "train step #7130 accuracy: 0.984375, loss: 0.0899394303560257       \n",
      "train step #7131 accuracy: 0.96875, loss: 0.08856318891048431      \n",
      "train step #7132 accuracy: 0.96875, loss: 0.0696745365858078       \n",
      "train step #7133 accuracy: 0.984375, loss: 0.06686558574438095      \n",
      "train step #7134 accuracy: 0.984375, loss: 0.16448891162872314      \n",
      "train step #7135 accuracy: 0.984375, loss: 0.07473766058683395      \n",
      "train step #7136 accuracy: 0.96875, loss: 0.19155049324035645      \n",
      "train step #7137 accuracy: 0.9375, loss: 0.17575672268867493      \n",
      "train step #7138 accuracy: 0.984375, loss: 0.08342491835355759      \n",
      "train step #7139 accuracy: 0.953125, loss: 0.2083488404750824       \n",
      "train step #7140 accuracy:   1.0, loss: 0.03497646003961563      \n",
      "train step #7141 accuracy: 0.953125, loss: 0.0993618592619896       \n",
      "train step #7142 accuracy: 0.984375, loss: 0.06861194223165512      \n",
      "train step #7143 accuracy: 0.984375, loss: 0.10449764132499695      \n",
      "train step #7144 accuracy:   1.0, loss: 0.027249999344348907     \n",
      "train step #7145 accuracy: 0.984375, loss: 0.07309020310640335      \n",
      "train step #7146 accuracy: 0.96875, loss: 0.17629501223564148      \n",
      "train step #7147 accuracy: 0.953125, loss: 0.15341147780418396      \n",
      "train step #7148 accuracy: 0.984375, loss: 0.051570817828178406     \n",
      "train step #7149 accuracy: 0.984375, loss: 0.06583236157894135      \n",
      "train step #7150 accuracy: 0.984375, loss: 0.05328298732638359      \n",
      "train step #7151 accuracy: 0.96875, loss: 0.1695387363433838       \n",
      "train step #7152 accuracy: 0.953125, loss: 0.19486594200134277      \n",
      "train step #7153 accuracy:   1.0, loss: 0.04067095369100571      \n",
      "train step #7154 accuracy: 0.953125, loss: 0.134394571185112        \n",
      "train step #7155 accuracy: 0.96875, loss: 0.151589035987854        \n",
      "train step #7156 accuracy: 0.984375, loss: 0.0798792690038681       \n",
      "train step #7157 accuracy: 0.953125, loss: 0.11802988499403         \n",
      "train step #7158 accuracy: 0.96875, loss: 0.11386435478925705      \n",
      "train step #7159 accuracy: 0.953125, loss: 0.1854756474494934       \n",
      "train step #7160 accuracy: 0.953125, loss: 0.1946791410446167       \n",
      "train step #7161 accuracy: 0.984375, loss: 0.06493446230888367      \n",
      "train step #7162 accuracy: 0.984375, loss: 0.09758257865905762      \n",
      "train step #7163 accuracy: 0.984375, loss: 0.04072926193475723      \n",
      "train step #7164 accuracy: 0.984375, loss: 0.055347785353660583     \n",
      "train step #7165 accuracy:   1.0, loss: 0.03121105581521988      \n",
      "train step #7166 accuracy: 0.984375, loss: 0.12583574652671814      \n",
      "train step #7167 accuracy: 0.984375, loss: 0.12681972980499268      \n",
      "train step #7168 accuracy:   1.0, loss: 0.020176321268081665     \n",
      "train step #7169 accuracy: 0.953125, loss: 0.15729573369026184      \n",
      "train step #7170 accuracy: 0.96875, loss: 0.13839787244796753      \n",
      "train step #7171 accuracy: 0.96875, loss: 0.1091935783624649       \n",
      "train step #7172 accuracy: 0.96875, loss: 0.1520717740058899       \n",
      "train step #7173 accuracy: 0.96875, loss: 0.1846308559179306       \n",
      "train step #7174 accuracy: 0.9375, loss: 0.2702281177043915       \n",
      "train step #7175 accuracy: 0.984375, loss: 0.03997591510415077      \n",
      "train step #7176 accuracy: 0.953125, loss: 0.33618032932281494      \n",
      "train step #7177 accuracy: 0.90625, loss: 0.26684242486953735      \n",
      "train step #7178 accuracy: 0.984375, loss: 0.07703681290149689      \n",
      "train step #7179 accuracy: 0.984375, loss: 0.05270533636212349      \n",
      "train step #7180 accuracy: 0.96875, loss: 0.10432446748018265      \n",
      "train step #7181 accuracy: 0.9375, loss: 0.24708455801010132      \n",
      "train step #7182 accuracy: 0.9375, loss: 0.1413753181695938       \n",
      "train step #7183 accuracy: 0.984375, loss: 0.0832652598619461       \n",
      "train step #7184 accuracy: 0.9375, loss: 0.217304065823555        \n",
      "train step #7185 accuracy: 0.9375, loss: 0.284649521112442        \n",
      "train step #7186 accuracy: 0.96875, loss: 0.17506377398967743      \n",
      "train step #7187 accuracy: 0.984375, loss: 0.10189957916736603      \n",
      "train step #7188 accuracy:   1.0, loss: 0.06461498886346817      \n",
      "train step #7189 accuracy: 0.984375, loss: 0.04741782695055008      \n",
      "train step #7190 accuracy: 0.96875, loss: 0.1551397740840912       \n",
      "train step #7191 accuracy: 0.953125, loss: 0.120639368891716        \n",
      "train step #7192 accuracy: 0.953125, loss: 0.12148632109165192      \n",
      "train step #7193 accuracy: 0.9375, loss: 0.2259041666984558       \n",
      "train step #7194 accuracy: 0.953125, loss: 0.18975937366485596      \n",
      "train step #7195 accuracy: 0.984375, loss: 0.06708980351686478      \n",
      "train step #7196 accuracy: 0.921875, loss: 0.18443487584590912      \n",
      "train step #7197 accuracy:   1.0, loss: 0.028072595596313477     \n",
      "train step #7198 accuracy: 0.9375, loss: 0.22045071423053741      \n",
      "train step #7199 accuracy: 0.953125, loss: 0.2021597921848297       \n",
      "train step #7200 accuracy: 0.953125, loss: 0.09499504417181015      \n",
      "train step #7201 accuracy: 0.96875, loss: 0.11013016849756241      \n",
      "train step #7202 accuracy: 0.984375, loss: 0.06151420995593071      \n",
      "train step #7203 accuracy: 0.96875, loss: 0.05863030254840851      \n",
      "train step #7204 accuracy: 0.984375, loss: 0.07001850754022598      \n",
      "train step #7205 accuracy: 0.953125, loss: 0.15257129073143005      \n",
      "train step #7206 accuracy: 0.96875, loss: 0.12337841838598251      \n",
      "train step #7207 accuracy: 0.921875, loss: 0.2534841299057007       \n",
      "train step #7208 accuracy:   1.0, loss: 0.02797914296388626      \n",
      "train step #7209 accuracy: 0.953125, loss: 0.14645713567733765      \n",
      "train step #7210 accuracy: 0.9375, loss: 0.16222254931926727      \n",
      "train step #7211 accuracy: 0.96875, loss: 0.16392409801483154      \n",
      "train step #7212 accuracy: 0.984375, loss: 0.053355589509010315     \n",
      "train step #7213 accuracy:   1.0, loss: 0.02358916401863098      \n",
      "train step #7214 accuracy: 0.984375, loss: 0.05199085548520088      \n",
      "train step #7215 accuracy: 0.953125, loss: 0.11332471668720245      \n",
      "train step #7216 accuracy:   1.0, loss: 0.035052381455898285     \n",
      "train step #7217 accuracy: 0.953125, loss: 0.09828150272369385      \n",
      "train step #7218 accuracy: 0.96875, loss: 0.17879191040992737      \n",
      "train step #7219 accuracy: 0.984375, loss: 0.14264388382434845      \n",
      "train step #7220 accuracy:   1.0, loss: 0.058172669261693954     \n",
      "train step #7221 accuracy:   1.0, loss: 0.039356641471385956     \n",
      "train step #7222 accuracy: 0.96875, loss: 0.1699671745300293       \n",
      "train step #7223 accuracy: 0.953125, loss: 0.3198877274990082       \n",
      "train step #7224 accuracy: 0.96875, loss: 0.07693130522966385      \n",
      "train step #7225 accuracy: 0.984375, loss: 0.07145093381404877      \n",
      "train step #7226 accuracy: 0.9375, loss: 0.21259842813014984      \n",
      "train step #7227 accuracy: 0.9375, loss: 0.15785817801952362      \n",
      "train step #7228 accuracy: 0.953125, loss: 0.08694951236248016      \n",
      "train step #7229 accuracy: 0.984375, loss: 0.062896728515625        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #7230 accuracy: 0.875, loss: 0.3470655679702759       \n",
      "train step #7231 accuracy: 0.953125, loss: 0.17444546520709991      \n",
      "train step #7232 accuracy: 0.953125, loss: 0.3073539435863495       \n",
      "train step #7233 accuracy: 0.96875, loss: 0.10739441215991974      \n",
      "train step #7234 accuracy: 0.984375, loss: 0.04014206677675247      \n",
      "train step #7235 accuracy: 0.953125, loss: 0.18842217326164246      \n",
      "train step #7236 accuracy: 0.921875, loss: 0.2678539752960205       \n",
      "train step #7237 accuracy: 0.984375, loss: 0.10863620042800903      \n",
      "train step #7238 accuracy: 0.953125, loss: 0.17638736963272095      \n",
      "train step #7239 accuracy: 0.953125, loss: 0.21369525790214539      \n",
      "train step #7240 accuracy: 0.96875, loss: 0.16247335076332092      \n",
      "train step #7241 accuracy: 0.984375, loss: 0.07395559549331665      \n",
      "train step #7242 accuracy: 0.96875, loss: 0.16233083605766296      \n",
      "train step #7243 accuracy: 0.96875, loss: 0.09047819674015045      \n",
      "train step #7244 accuracy: 0.953125, loss: 0.1728081852197647       \n",
      "train step #7245 accuracy: 0.96875, loss: 0.1251174807548523       \n",
      "train step #7246 accuracy: 0.9375, loss: 0.1646028459072113       \n",
      "train step #7247 accuracy: 0.96875, loss: 0.14198771119117737      \n",
      "train step #7248 accuracy: 0.921875, loss: 0.31540992856025696      \n",
      "train step #7249 accuracy: 0.96875, loss: 0.08951982110738754      \n",
      "train step #7250 accuracy: 0.984375, loss: 0.06706907600164413      \n",
      "train step #7251 accuracy: 0.984375, loss: 0.056236382573843        \n",
      "train step #7252 accuracy: 0.96875, loss: 0.14376813173294067      \n",
      "train step #7253 accuracy: 0.96875, loss: 0.11674981564283371      \n",
      "train step #7254 accuracy: 0.9375, loss: 0.20098772644996643      \n",
      "train step #7255 accuracy: 0.953125, loss: 0.1601153314113617       \n",
      "train step #7256 accuracy: 0.984375, loss: 0.03550563007593155      \n",
      "train step #7257 accuracy: 0.921875, loss: 0.2826387286186218       \n",
      "train step #7258 accuracy: 0.953125, loss: 0.21295586228370667      \n",
      "train step #7259 accuracy: 0.9375, loss: 0.14980335533618927      \n",
      "train step #7260 accuracy: 0.921875, loss: 0.3047650456428528       \n",
      "train step #7261 accuracy: 0.953125, loss: 0.13951082527637482      \n",
      "train step #7262 accuracy: 0.984375, loss: 0.04635026305913925      \n",
      "train step #7263 accuracy: 0.984375, loss: 0.05319966375827789      \n",
      "train step #7264 accuracy: 0.921875, loss: 0.2524286210536957       \n",
      "train step #7265 accuracy: 0.9375, loss: 0.13406500220298767      \n",
      "train step #7266 accuracy: 0.984375, loss: 0.10613037645816803      \n",
      "train step #7267 accuracy: 0.9375, loss: 0.22126299142837524      \n",
      "train step #7268 accuracy: 0.984375, loss: 0.06296516954898834      \n",
      "train step #7269 accuracy: 0.953125, loss: 0.3173522651195526       \n",
      "train step #7270 accuracy: 0.96875, loss: 0.05434650182723999      \n",
      "train step #7271 accuracy: 0.96875, loss: 0.11740358918905258      \n",
      "train step #7272 accuracy: 0.984375, loss: 0.16628684103488922      \n",
      "train step #7273 accuracy: 0.96875, loss: 0.12920106947422028      \n",
      "train step #7274 accuracy: 0.96875, loss: 0.11989422887563705      \n",
      "train step #7275 accuracy:   1.0, loss: 0.022590212523937225     \n",
      "train step #7276 accuracy: 0.953125, loss: 0.2501894235610962       \n",
      "train step #7277 accuracy: 0.984375, loss: 0.06606249511241913      \n",
      "train step #7278 accuracy: 0.96875, loss: 0.136636883020401        \n",
      "train step #7279 accuracy: 0.96875, loss: 0.15318867564201355      \n",
      "train step #7280 accuracy: 0.984375, loss: 0.1556982845067978       \n",
      "train step #7281 accuracy: 0.90625, loss: 0.26596570014953613      \n",
      "train step #7282 accuracy: 0.9375, loss: 0.19982773065567017      \n",
      "train step #7283 accuracy: 0.984375, loss: 0.0706138089299202       \n",
      "train step #7284 accuracy: 0.96875, loss: 0.10231401026248932      \n",
      "train step #7285 accuracy: 0.984375, loss: 0.08637765794992447      \n",
      "train step #7286 accuracy: 0.984375, loss: 0.05935065448284149      \n",
      "train step #7287 accuracy: 0.96875, loss: 0.11523132026195526      \n",
      "dev accuracy: 0.875, loss: 0.4046621024608612       \n",
      "dev accuracy:   1.0, loss: 0.0016949772834777832    \n",
      "dev accuracy: 0.8125, loss: 0.6547847390174866       \n",
      "dev accuracy: 0.9375, loss: 0.3989889919757843       \n",
      "dev accuracy:   1.0, loss: 0.13060981035232544      \n",
      "dev accuracy: 0.8125, loss: 0.49329644441604614      \n",
      "dev accuracy: 0.8125, loss: 0.5151137113571167       \n",
      "dev accuracy:   1.0, loss: 0.009786933660507202     \n",
      "dev accuracy: 0.9375, loss: 0.09483195841312408      \n",
      "dev accuracy:   1.0, loss: 0.025259196758270264     \n",
      "dev accuracy: 0.9375, loss: 0.0727754533290863       \n",
      "dev accuracy: 0.9375, loss: 0.14586447179317474      \n",
      "dev accuracy:   1.0, loss: 0.0014390349388122559    \n",
      "dev accuracy:   1.0, loss: 0.07959993183612823      \n",
      "dev accuracy: 0.875, loss: 0.6233066320419312       \n",
      "dev accuracy:   1.0, loss: 0.02732864022254944      \n",
      "dev accuracy:   1.0, loss: 0.03761249780654907      \n",
      "dev accuracy: 0.875, loss: 0.22498354315757751      \n",
      "dev accuracy:   1.0, loss: 0.004806637763977051     \n",
      "dev accuracy:   1.0, loss: 0.009516000747680664     \n",
      "dev accuracy: 0.875, loss: 0.3498023748397827       \n",
      "dev accuracy: 0.9375, loss: 0.11790309101343155      \n",
      "dev accuracy:   1.0, loss: 0.002301931381225586     \n",
      "dev accuracy: 0.9375, loss: 0.34399038553237915      \n",
      "dev accuracy: 0.8125, loss: 0.6955220699310303       \n",
      "dev accuracy:   1.0, loss: 0.09988425672054291      \n",
      "dev accuracy:   1.0, loss: 0.03070610761642456      \n",
      "dev accuracy: 0.875, loss: 0.3093615472316742       \n",
      "dev accuracy: 0.9375, loss: 0.10790517926216125      \n",
      "dev accuracy: 0.9375, loss: 0.19037257134914398      \n",
      "dev accuracy:   1.0, loss: 0.021301627159118652     \n",
      "dev accuracy:   1.0, loss: 0.0033828020095825195    \n",
      "dev accuracy: 0.9375, loss: 0.2632424533367157       \n",
      "dev accuracy:   1.0, loss: 0.0038303732872009277    \n",
      "dev accuracy: 0.875, loss: 0.685090959072113        \n",
      "dev accuracy:   1.0, loss: 0.01602029800415039      \n",
      "dev accuracy:   1.0, loss: 0.03475102782249451      \n",
      "dev accuracy: 0.875, loss: 0.35457420349121094      \n",
      "dev accuracy: 0.9375, loss: 0.11226703226566315      \n",
      "dev accuracy: 0.9375, loss: 0.09003260731697083      \n",
      "dev accuracy:   1.0, loss: 0.04472142457962036      \n",
      "dev accuracy:   1.0, loss: 0.004672616720199585     \n",
      "dev accuracy: 0.9375, loss: 0.17302358150482178      \n",
      "dev accuracy:   1.0, loss: 0.002793043851852417     \n",
      "dev accuracy: 0.9375, loss: 0.11268037557601929      \n",
      "dev accuracy: 0.9375, loss: 0.1863369643688202       \n",
      "dev accuracy: 0.9375, loss: 0.2531643211841583       \n",
      "dev accuracy:   1.0, loss: 0.007504582405090332     \n",
      "dev accuracy: 0.9375, loss: 0.21907733380794525      \n",
      "dev accuracy: 0.8125, loss: 0.33580446243286133      \n",
      "dev accuracy:   1.0, loss: 0.018588542938232422     \n",
      "dev accuracy: 0.9375, loss: 0.18941202759742737      \n",
      "dev accuracy: 0.9375, loss: 0.17095154523849487      \n",
      "dev accuracy:   1.0, loss: 0.0011134147644042969    \n",
      "dev accuracy:   1.0, loss: 0.0019940733909606934    \n",
      "dev accuracy: 0.9375, loss: 0.11906157433986664      \n",
      "dev accuracy:   1.0, loss: 0.022635728120803833     \n",
      "dev accuracy: 0.9375, loss: 0.4750806391239166       \n",
      "dev accuracy: 0.9375, loss: 0.1307612806558609       \n",
      "dev accuracy:   1.0, loss: 0.004827141761779785     \n",
      "dev accuracy: 0.8125, loss: 0.6453981995582581       \n",
      "dev accuracy:   1.0, loss: 0.0966411605477333       \n",
      "dev accuracy: 0.875, loss: 0.3263382613658905       \n",
      "dev accuracy:   1.0, loss: 0.03403232991695404      \n",
      "dev accuracy:   1.0, loss: 0.08777005970478058      \n",
      "dev accuracy: 0.8125, loss: 0.6932012438774109       \n",
      "dev accuracy: 0.9375, loss: 0.1359361708164215       \n",
      "dev accuracy:   1.0, loss: 0.012327760457992554     \n",
      "dev accuracy:   1.0, loss: 0.008316457271575928     \n",
      "dev accuracy: 0.875, loss: 0.36220940947532654      \n",
      "dev accuracy:   1.0, loss: 0.044873982667922974     \n",
      "dev accuracy: 0.9375, loss: 0.23665598034858704      \n",
      "dev accuracy: 0.875, loss: 0.32335126399993896      \n",
      "dev accuracy: 0.9375, loss: 0.37517285346984863      \n",
      "dev accuracy:   1.0, loss: 0.009414374828338623     \n",
      "dev accuracy:   1.0, loss: 0.06214049458503723      \n",
      "dev accuracy:   1.0, loss: 0.009834706783294678     \n",
      "dev accuracy:   1.0, loss: 0.002394258975982666     \n",
      "dev accuracy:   1.0, loss: 0.021944135427474976     \n",
      "dev accuracy: 0.9375, loss: 0.15576595067977905      \n",
      "dev accuracy: 0.8125, loss: 0.4521556496620178       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy: 0.8125, loss: 1.118895411491394        \n",
      "dev accuracy: 0.9375, loss: 0.14863727986812592      \n",
      "dev accuracy:   1.0, loss: 0.0013254284858703613    \n",
      "dev accuracy: 0.9375, loss: 0.1383323222398758       \n",
      "dev accuracy: 0.9375, loss: 0.3475629985332489       \n",
      "dev accuracy: 0.9375, loss: 0.38446253538131714      \n",
      "dev accuracy: 0.9375, loss: 0.22925594449043274      \n",
      "dev accuracy: 0.9375, loss: 0.348439484834671        \n",
      "dev accuracy: 0.875, loss: 0.15677809715270996      \n",
      "dev accuracy:   1.0, loss: 0.031107664108276367     \n",
      "dev accuracy:   1.0, loss: 0.003433316946029663     \n",
      "dev accuracy: 0.9375, loss: 0.4097076654434204       \n",
      "dev accuracy: 0.9375, loss: 0.16836468875408173      \n",
      "dev accuracy:   1.0, loss: 0.007263898849487305     \n",
      "dev accuracy: 0.8125, loss: 0.999207615852356        \n",
      "dev accuracy:   1.0, loss: 0.007795363664627075     \n",
      "dev accuracy:   1.0, loss: 0.04957154393196106      \n",
      "dev accuracy: 0.9375, loss: 0.11924052238464355      \n",
      "dev accuracy: 0.875, loss: 0.23545123636722565      \n",
      "dev accuracy:   1.0, loss: 0.011981189250946045     \n",
      "dev accuracy:   1.0, loss: 0.0023151040077209473    \n",
      "dev accuracy: 0.9375, loss: 0.1340261995792389       \n",
      "dev accuracy:   1.0, loss: 0.011237651109695435     \n",
      "dev accuracy: 0.9375, loss: 0.17315195500850677      \n",
      "dev accuracy:   1.0, loss: 0.0011235475540161133    \n",
      "dev accuracy: 0.9375, loss: 0.060535550117492676     \n",
      "dev accuracy: 0.875, loss: 0.28618037700653076      \n",
      "dev accuracy: 0.9375, loss: 0.06084722280502319      \n",
      "dev accuracy:   1.0, loss: 0.010073304176330566     \n",
      "dev accuracy:   1.0, loss: 0.023261189460754395     \n",
      "dev accuracy: 0.9375, loss: 0.15388277173042297      \n",
      "dev accuracy: 0.875, loss: 0.3498769998550415       \n",
      "dev accuracy:   1.0, loss: 0.017325550317764282     \n",
      "dev accuracy: 0.875, loss: 0.34417834877967834      \n",
      "dev accuracy:   1.0, loss: 0.049585163593292236     \n",
      "dev accuracy: 0.9375, loss: 0.30837151408195496      \n",
      "dev accuracy: 0.9375, loss: 0.4556175768375397       \n",
      "dev accuracy:   1.0, loss: 0.008532851934432983     \n",
      "dev accuracy: 0.9375, loss: 0.2347482293844223       \n",
      "dev accuracy: 0.875, loss: 0.20831632614135742      \n",
      "dev accuracy: 0.8125, loss: 0.4875583052635193       \n",
      "dev accuracy:   1.0, loss: 0.051037997007369995     \n",
      "dev accuracy:   1.0, loss: 0.0031870603561401367    \n",
      "dev accuracy: 0.9375, loss: 0.0763196349143982       \n",
      "dev accuracy: 0.9375, loss: 0.33991509675979614      \n",
      "dev accuracy: 0.8125, loss: 0.3550262153148651       \n",
      "dev accuracy: 0.875, loss: 0.3816448450088501       \n",
      "dev accuracy: 0.9375, loss: 0.10284954309463501      \n",
      "dev accuracy: 0.9375, loss: 0.14051419496536255      \n",
      "dev accuracy: 0.875, loss: 0.32429447770118713      \n",
      "dev accuracy:   1.0, loss: 0.0028007030487060547    \n",
      "dev accuracy:   1.0, loss: 0.013733267784118652     \n",
      "dev accuracy:   1.0, loss: 0.015530556440353394     \n",
      "dev accuracy:   1.0, loss: 0.05009981989860535      \n",
      "dev accuracy:   1.0, loss: 0.05020551383495331      \n",
      "dev accuracy: 0.875, loss: 0.17305079102516174      \n",
      "dev accuracy: 0.9375, loss: 0.12682420015335083      \n",
      "dev accuracy:   1.0, loss: 0.0027077794075012207    \n",
      "dev accuracy:   1.0, loss: 0.012541353702545166     \n",
      "dev accuracy:   1.0, loss: 0.006392985582351685     \n",
      "dev accuracy: 0.9375, loss: 0.15678170323371887      \n",
      "dev accuracy:   1.0, loss: 0.007073551416397095     \n",
      "dev accuracy:   1.0, loss: 0.040763020515441895     \n",
      "dev accuracy: 0.9375, loss: 0.3126470744609833       \n",
      "dev accuracy:   1.0, loss: 0.027980566024780273     \n",
      "dev accuracy: 0.9375, loss: 0.12783408164978027      \n",
      "dev accuracy: 0.9375, loss: 0.0903213769197464       \n",
      "dev accuracy:   1.0, loss: 0.0018125176429748535    \n",
      "dev accuracy: 0.9375, loss: 0.29689061641693115      \n",
      "dev accuracy: 0.9375, loss: 0.10344481468200684      \n",
      "dev accuracy:   1.0, loss: 0.0012233257293701172    \n",
      "dev accuracy: 0.9375, loss: 0.14908932149410248      \n",
      "dev accuracy:   1.0, loss: 0.09712913632392883      \n",
      "dev accuracy:   1.0, loss: 0.07844679057598114      \n",
      "dev accuracy: 0.9375, loss: 0.1542641520500183       \n",
      "dev accuracy:   1.0, loss: 0.006947308778762817     \n",
      "dev accuracy:   1.0, loss: 0.023289501667022705     \n",
      "dev accuracy: 0.9375, loss: 0.06242993474006653      \n",
      "dev accuracy:   1.0, loss: 0.0012205243110656738    \n",
      "dev accuracy:   1.0, loss: 0.02067047357559204      \n",
      "dev accuracy: 0.9375, loss: 0.436535120010376        \n",
      "dev accuracy: 0.875, loss: 0.29567232728004456      \n",
      "dev accuracy: 0.9375, loss: 0.16707652807235718      \n",
      "dev accuracy:   1.0, loss: 0.0646233856678009       \n",
      "dev accuracy:   1.0, loss: 0.03426218032836914      \n",
      "dev accuracy:   1.0, loss: 0.023602783679962158     \n",
      "dev accuracy:   1.0, loss: 0.01713019609451294      \n",
      "dev accuracy: 0.9375, loss: 0.16020217537879944      \n",
      "dev accuracy:   1.0, loss: 0.025647342205047607     \n",
      "dev accuracy:   1.0, loss: 0.11167362332344055      \n",
      "dev accuracy:   1.0, loss: 0.11159741878509521      \n",
      "dev accuracy:   1.0, loss: 0.01947075128555298      \n",
      "dev accuracy:   1.0, loss: 0.13243824243545532      \n",
      "dev accuracy: 0.9375, loss: 0.14322073757648468      \n",
      "dev accuracy: 0.9375, loss: 0.1442674845457077       \n",
      "dev accuracy: 0.875, loss: 0.5631622672080994       \n",
      "dev accuracy:   1.0, loss: 0.01754063367843628      \n",
      "dev accuracy:   1.0, loss: 0.001844942569732666     \n",
      "dev accuracy: 0.9375, loss: 0.06540268659591675      \n",
      "dev accuracy:   1.0, loss: 0.020551562309265137     \n",
      "dev accuracy:   1.0, loss: 0.018470078706741333     \n",
      "dev accuracy: 0.9375, loss: 0.20480701327323914      \n",
      "dev accuracy: 0.9375, loss: 0.057782500982284546     \n",
      "dev accuracy:   1.0, loss: 0.007971376180648804     \n",
      "dev accuracy: 0.8125, loss: 0.3137820363044739       \n",
      "dev accuracy:   1.0, loss: 0.006958037614822388     \n",
      "dev accuracy: 0.875, loss: 0.36968469619750977      \n",
      "dev accuracy:   1.0, loss: 0.10720717906951904      \n",
      "dev accuracy:   1.0, loss: 0.05964392423629761      \n",
      "dev accuracy:   1.0, loss: 0.002180337905883789     \n",
      "dev accuracy:   1.0, loss: 0.09137722849845886      \n",
      "dev accuracy: 0.875, loss: 0.23198360204696655      \n",
      "dev accuracy:   1.0, loss: 8.138021075865254e-05    \n",
      "final dev accuracy: 0.9519974226804123\n",
      "train step #7288 accuracy: 0.96875, loss: 0.12309497594833374      \n",
      "train step #7289 accuracy: 0.984375, loss: 0.038603994995355606     \n",
      "train step #7290 accuracy: 0.96875, loss: 0.16097864508628845      \n",
      "train step #7291 accuracy: 0.984375, loss: 0.09271882474422455      \n",
      "train step #7292 accuracy: 0.921875, loss: 0.20492413640022278      \n",
      "train step #7293 accuracy: 0.984375, loss: 0.11844976991415024      \n",
      "train step #7294 accuracy: 0.953125, loss: 0.1370237022638321       \n",
      "train step #7295 accuracy: 0.9375, loss: 0.22380119562149048      \n",
      "train step #7296 accuracy: 0.96875, loss: 0.0950167253613472       \n",
      "train step #7297 accuracy: 0.953125, loss: 0.16115012764930725      \n",
      "train step #7298 accuracy: 0.9375, loss: 0.14977295696735382      \n",
      "train step #7299 accuracy: 0.9375, loss: 0.18601341545581818      \n",
      "train step #7300 accuracy: 0.9375, loss: 0.22521664202213287      \n",
      "train step #7301 accuracy: 0.96875, loss: 0.08228546380996704      \n",
      "train step #7302 accuracy: 0.984375, loss: 0.05575227737426758      \n",
      "train step #7303 accuracy: 0.96875, loss: 0.18588338792324066      \n",
      "train step #7304 accuracy: 0.9375, loss: 0.1839040070772171       \n",
      "train step #7305 accuracy: 0.953125, loss: 0.15163321793079376      \n",
      "train step #7306 accuracy: 0.953125, loss: 0.15343166887760162      \n",
      "train step #7307 accuracy: 0.984375, loss: 0.022594936192035675     \n",
      "train step #7308 accuracy: 0.96875, loss: 0.13726672530174255      \n",
      "train step #7309 accuracy: 0.953125, loss: 0.15069477260112762      \n",
      "train step #7310 accuracy: 0.9375, loss: 0.19450892508029938      \n",
      "train step #7311 accuracy: 0.96875, loss: 0.11262261122465134      \n",
      "train step #7312 accuracy: 0.984375, loss: 0.11855246126651764      \n",
      "train step #7313 accuracy: 0.953125, loss: 0.17393642663955688      \n",
      "train step #7314 accuracy: 0.96875, loss: 0.1327044665813446       \n",
      "train step #7315 accuracy: 0.984375, loss: 0.08113279938697815      \n",
      "train step #7316 accuracy: 0.953125, loss: 0.10241779685020447      \n",
      "train step #7317 accuracy: 0.96875, loss: 0.07271204888820648      \n",
      "train step #7318 accuracy: 0.984375, loss: 0.06584888696670532      \n",
      "train step #7319 accuracy:   1.0, loss: 0.010839886963367462     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #7320 accuracy: 0.953125, loss: 0.09906415641307831      \n",
      "train step #7321 accuracy: 0.96875, loss: 0.07272082567214966      \n",
      "train step #7322 accuracy: 0.96875, loss: 0.10061116516590118      \n",
      "train step #7323 accuracy: 0.9375, loss: 0.087965227663517        \n",
      "train step #7324 accuracy: 0.96875, loss: 0.08385388553142548      \n",
      "train step #7325 accuracy: 0.953125, loss: 0.1367209255695343       \n",
      "train step #7326 accuracy:   1.0, loss: 0.05427667871117592      \n",
      "train step #7327 accuracy: 0.984375, loss: 0.10377312451601028      \n",
      "train step #7328 accuracy: 0.953125, loss: 0.13600406050682068      \n",
      "train step #7329 accuracy: 0.9375, loss: 0.24096517264842987      \n",
      "train step #7330 accuracy: 0.96875, loss: 0.13042034208774567      \n",
      "train step #7331 accuracy: 0.984375, loss: 0.06066380441188812      \n",
      "train step #7332 accuracy: 0.96875, loss: 0.13336707651615143      \n",
      "train step #7333 accuracy: 0.953125, loss: 0.16055689752101898      \n",
      "train step #7334 accuracy: 0.984375, loss: 0.0549536757171154       \n",
      "train step #7335 accuracy: 0.953125, loss: 0.21699045598506927      \n",
      "train step #7336 accuracy: 0.96875, loss: 0.26113975048065186      \n",
      "train step #7337 accuracy: 0.953125, loss: 0.06612920016050339      \n",
      "train step #7338 accuracy: 0.984375, loss: 0.04814038798213005      \n",
      "train step #7339 accuracy: 0.953125, loss: 0.21145762503147125      \n",
      "train step #7340 accuracy: 0.96875, loss: 0.12451019883155823      \n",
      "train step #7341 accuracy: 0.921875, loss: 0.25814786553382874      \n",
      "train step #7342 accuracy: 0.921875, loss: 0.5028890371322632       \n",
      "train step #7343 accuracy: 0.953125, loss: 0.16349253058433533      \n",
      "train step #7344 accuracy:   1.0, loss: 0.06448467075824738      \n",
      "train step #7345 accuracy: 0.953125, loss: 0.11276459693908691      \n",
      "train step #7346 accuracy: 0.96875, loss: 0.16416913270950317      \n",
      "train step #7347 accuracy: 0.921875, loss: 0.26841676235198975      \n",
      "train step #7348 accuracy:   1.0, loss: 0.037651412189006805     \n",
      "train step #7349 accuracy:   1.0, loss: 0.07146274298429489      \n",
      "train step #7350 accuracy: 0.921875, loss: 0.2912406325340271       \n",
      "train step #7351 accuracy: 0.953125, loss: 0.08909260481595993      \n",
      "train step #7352 accuracy: 0.9375, loss: 0.2695291340351105       \n",
      "train step #7353 accuracy: 0.953125, loss: 0.12376008182764053      \n",
      "train step #7354 accuracy: 0.96875, loss: 0.09666389971971512      \n",
      "train step #7355 accuracy: 0.984375, loss: 0.0481685996055603       \n",
      "train step #7356 accuracy: 0.9375, loss: 0.2666946053504944       \n",
      "train step #7357 accuracy: 0.984375, loss: 0.04565594345331192      \n",
      "train step #7358 accuracy:   1.0, loss: 0.051801666617393494     \n",
      "train step #7359 accuracy: 0.9375, loss: 0.2286677211523056       \n",
      "train step #7360 accuracy: 0.96875, loss: 0.1450471431016922       \n",
      "train step #7361 accuracy: 0.96875, loss: 0.0767994374036789       \n",
      "train step #7362 accuracy: 0.890625, loss: 0.345416784286499        \n",
      "train step #7363 accuracy: 0.96875, loss: 0.13956919312477112      \n",
      "train step #7364 accuracy: 0.984375, loss: 0.048643141984939575     \n",
      "train step #7365 accuracy: 0.984375, loss: 0.0978749617934227       \n",
      "train step #7366 accuracy: 0.96875, loss: 0.12756897509098053      \n",
      "train step #7367 accuracy:   1.0, loss: 0.037365395575761795     \n",
      "train step #7368 accuracy: 0.984375, loss: 0.09703236818313599      \n",
      "train step #7369 accuracy: 0.953125, loss: 0.15322023630142212      \n",
      "train step #7370 accuracy: 0.984375, loss: 0.0758502185344696       \n",
      "train step #7371 accuracy: 0.984375, loss: 0.07317405939102173      \n",
      "train step #7372 accuracy: 0.96875, loss: 0.13547027111053467      \n",
      "train step #7373 accuracy:   1.0, loss: 0.017320901155471802     \n",
      "train step #7374 accuracy: 0.9375, loss: 0.25090867280960083      \n",
      "train step #7375 accuracy: 0.96875, loss: 0.14655694365501404      \n",
      "train step #7376 accuracy: 0.921875, loss: 0.19310502707958221      \n",
      "train step #7377 accuracy: 0.921875, loss: 0.381378710269928        \n",
      "train step #7378 accuracy: 0.96875, loss: 0.12284445017576218      \n",
      "train step #7379 accuracy: 0.953125, loss: 0.12054497003555298      \n",
      "train step #7380 accuracy: 0.9375, loss: 0.21262024343013763      \n",
      "train step #7381 accuracy: 0.9375, loss: 0.27282366156578064      \n",
      "train step #7382 accuracy:   1.0, loss: 0.039310600608587265     \n",
      "train step #7383 accuracy: 0.96875, loss: 0.1196274533867836       \n",
      "train step #7384 accuracy: 0.96875, loss: 0.08270031213760376      \n",
      "train step #7385 accuracy: 0.984375, loss: 0.08507274091243744      \n",
      "train step #7386 accuracy: 0.96875, loss: 0.14690150320529938      \n",
      "train step #7387 accuracy: 0.984375, loss: 0.047402456402778625     \n",
      "train step #7388 accuracy: 0.9375, loss: 0.20006340742111206      \n",
      "train step #7389 accuracy: 0.984375, loss: 0.06888502836227417      \n",
      "train step #7390 accuracy: 0.96875, loss: 0.12332934141159058      \n",
      "train step #7391 accuracy: 0.984375, loss: 0.0447886660695076       \n",
      "train step #7392 accuracy: 0.96875, loss: 0.10757125169038773      \n",
      "train step #7393 accuracy: 0.9375, loss: 0.15038318932056427      \n",
      "train step #7394 accuracy: 0.953125, loss: 0.17028160393238068      \n",
      "train step #7395 accuracy: 0.953125, loss: 0.18872958421707153      \n",
      "train step #7396 accuracy: 0.96875, loss: 0.08702525496482849      \n",
      "train step #7397 accuracy: 0.96875, loss: 0.12545959651470184      \n",
      "train step #7398 accuracy: 0.96875, loss: 0.11064966022968292      \n",
      "train step #7399 accuracy: 0.953125, loss: 0.21927326917648315      \n",
      "train step #7400 accuracy: 0.96875, loss: 0.08507190644741058      \n",
      "train step #7401 accuracy: 0.984375, loss: 0.07468143105506897      \n",
      "train step #7402 accuracy: 0.9375, loss: 0.21105201542377472      \n",
      "train step #7403 accuracy: 0.96875, loss: 0.1433572918176651       \n",
      "train step #7404 accuracy: 0.953125, loss: 0.19826741516590118      \n",
      "train step #7405 accuracy: 0.96875, loss: 0.09321634471416473      \n",
      "train step #7406 accuracy: 0.96875, loss: 0.13261201977729797      \n",
      "train step #7407 accuracy: 0.921875, loss: 0.24866893887519836      \n",
      "train step #7408 accuracy: 0.953125, loss: 0.21321237087249756      \n",
      "train step #7409 accuracy: 0.96875, loss: 0.18299537897109985      \n",
      "train step #7410 accuracy: 0.96875, loss: 0.14331842958927155      \n",
      "train step #7411 accuracy: 0.953125, loss: 0.17892175912857056      \n",
      "train step #7412 accuracy: 0.96875, loss: 0.09571769088506699      \n",
      "train step #7413 accuracy: 0.921875, loss: 0.1865750402212143       \n",
      "train step #7414 accuracy: 0.984375, loss: 0.05916837230324745      \n",
      "train step #7415 accuracy: 0.953125, loss: 0.17089274525642395      \n",
      "train step #7416 accuracy: 0.96875, loss: 0.1286908984184265       \n",
      "train step #7417 accuracy: 0.9375, loss: 0.20529882609844208      \n",
      "train step #7418 accuracy: 0.953125, loss: 0.11333896219730377      \n",
      "train step #7419 accuracy: 0.921875, loss: 0.3973267674446106       \n",
      "train step #7420 accuracy: 0.953125, loss: 0.1921434998512268       \n",
      "train step #7421 accuracy: 0.96875, loss: 0.06595408171415329      \n",
      "train step #7422 accuracy: 0.96875, loss: 0.14565113186836243      \n",
      "train step #7423 accuracy: 0.984375, loss: 0.0518476776778698       \n",
      "train step #7424 accuracy: 0.953125, loss: 0.1439288705587387       \n",
      "train step #7425 accuracy: 0.984375, loss: 0.04919685795903206      \n",
      "train step #7426 accuracy: 0.984375, loss: 0.04771631956100464      \n",
      "train step #7427 accuracy: 0.9375, loss: 0.1562889814376831       \n",
      "train step #7428 accuracy: 0.96875, loss: 0.20008361339569092      \n",
      "train step #7429 accuracy:   1.0, loss: 0.045540038496255875     \n",
      "train step #7430 accuracy: 0.9375, loss: 0.19616028666496277      \n",
      "train step #7431 accuracy: 0.96875, loss: 0.19410376250743866      \n",
      "train step #7432 accuracy: 0.984375, loss: 0.1076735258102417       \n",
      "train step #7433 accuracy: 0.953125, loss: 0.21784332394599915      \n",
      "train step #7434 accuracy:   1.0, loss: 0.02533404529094696      \n",
      "train step #7435 accuracy: 0.9375, loss: 0.267520546913147        \n",
      "train step #7436 accuracy: 0.921875, loss: 0.32956016063690186      \n",
      "train step #7437 accuracy: 0.953125, loss: 0.18894556164741516      \n",
      "train step #7438 accuracy: 0.984375, loss: 0.07933752983808517      \n",
      "train step #7439 accuracy: 0.921875, loss: 0.35193994641304016      \n",
      "train step #7440 accuracy: 0.96875, loss: 0.1273656189441681       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #7441 accuracy: 0.984375, loss: 0.118315190076828        \n",
      "train step #7442 accuracy: 0.984375, loss: 0.12750576436519623      \n",
      "train step #7443 accuracy: 0.984375, loss: 0.1349499225616455       \n",
      "train step #7444 accuracy: 0.984375, loss: 0.06213555112481117      \n",
      "train step #7445 accuracy:   1.0, loss: 0.012033767998218536     \n",
      "train step #7446 accuracy: 0.96875, loss: 0.10377046465873718      \n",
      "train step #7447 accuracy: 0.984375, loss: 0.10333125293254852      \n",
      "train step #7448 accuracy: 0.953125, loss: 0.18838432431221008      \n",
      "train step #7449 accuracy: 0.984375, loss: 0.03910970687866211      \n",
      "train step #7450 accuracy: 0.9375, loss: 0.1541096568107605       \n",
      "train step #7451 accuracy: 0.953125, loss: 0.15092241764068604      \n",
      "train step #7452 accuracy: 0.96875, loss: 0.11488748341798782      \n",
      "train step #7453 accuracy: 0.953125, loss: 0.1333899199962616       \n",
      "train step #7454 accuracy: 0.953125, loss: 0.15747518837451935      \n",
      "train step #7455 accuracy:   1.0, loss: 0.028077058494091034     \n",
      "train step #7456 accuracy: 0.984375, loss: 0.12691821157932281      \n",
      "train step #7457 accuracy: 0.9375, loss: 0.23984475433826447      \n",
      "train step #7458 accuracy: 0.984375, loss: 0.06959544122219086      \n",
      "train step #7459 accuracy: 0.96875, loss: 0.15233436226844788      \n",
      "train step #7460 accuracy: 0.953125, loss: 0.11467109620571136      \n",
      "train step #7461 accuracy: 0.96875, loss: 0.12572059035301208      \n",
      "train step #7462 accuracy: 0.9375, loss: 0.21876272559165955      \n",
      "train step #7463 accuracy: 0.953125, loss: 0.12513941526412964      \n",
      "train step #7464 accuracy: 0.984375, loss: 0.08782795816659927      \n",
      "train step #7465 accuracy: 0.96875, loss: 0.10759235918521881      \n",
      "train step #7466 accuracy: 0.9375, loss: 0.2245989888906479       \n",
      "train step #7467 accuracy: 0.96875, loss: 0.15893587470054626      \n",
      "train step #7468 accuracy: 0.984375, loss: 0.04326781630516052      \n",
      "train step #7469 accuracy: 0.96875, loss: 0.11654074490070343      \n",
      "train step #7470 accuracy: 0.96875, loss: 0.07924111932516098      \n",
      "train step #7471 accuracy: 0.90625, loss: 0.2888394594192505       \n",
      "train step #7472 accuracy: 0.96875, loss: 0.14057013392448425      \n",
      "train step #7473 accuracy: 0.96875, loss: 0.12376289814710617      \n",
      "train step #7474 accuracy: 0.96875, loss: 0.11081898212432861      \n",
      "train step #7475 accuracy: 0.953125, loss: 0.2287522554397583       \n",
      "train step #7476 accuracy: 0.984375, loss: 0.03644148260354996      \n",
      "train step #7477 accuracy: 0.96875, loss: 0.18354223668575287      \n",
      "train step #7478 accuracy: 0.984375, loss: 0.10561031103134155      \n",
      "train step #7479 accuracy: 0.984375, loss: 0.10403569787740707      \n",
      "train step #7480 accuracy: 0.953125, loss: 0.17577044665813446      \n",
      "train step #7481 accuracy: 0.953125, loss: 0.13291725516319275      \n",
      "train step #7482 accuracy:   1.0, loss: 0.01791486144065857      \n",
      "train step #7483 accuracy: 0.9375, loss: 0.13876503705978394      \n",
      "train step #7484 accuracy:   1.0, loss: 0.0225435309112072       \n",
      "train step #7485 accuracy:   1.0, loss: 0.04412512481212616      \n",
      "train step #7486 accuracy: 0.953125, loss: 0.17374053597450256      \n",
      "train step #7487 accuracy: 0.96875, loss: 0.1177910715341568       \n",
      "train step #7488 accuracy: 0.953125, loss: 0.1258535385131836       \n",
      "train step #7489 accuracy: 0.96875, loss: 0.12979525327682495      \n",
      "train step #7490 accuracy:   1.0, loss: 0.05856076627969742      \n",
      "train step #7491 accuracy: 0.96875, loss: 0.1124507412314415       \n",
      "train step #7492 accuracy: 0.90625, loss: 0.4841424822807312       \n",
      "train step #7493 accuracy: 0.984375, loss: 0.042015884071588516     \n",
      "train step #7494 accuracy: 0.953125, loss: 0.14517737925052643      \n",
      "train step #7495 accuracy: 0.953125, loss: 0.14161738753318787      \n",
      "train step #7496 accuracy: 0.953125, loss: 0.17016997933387756      \n",
      "train step #7497 accuracy: 0.984375, loss: 0.08112751692533493      \n",
      "train step #7498 accuracy: 0.953125, loss: 0.22724545001983643      \n",
      "train step #7499 accuracy:   1.0, loss: 0.015229221433401108     \n",
      "train step #7500 accuracy: 0.96875, loss: 0.09505002945661545      \n",
      "train step #7501 accuracy:   1.0, loss: 0.024187050759792328     \n",
      "train step #7502 accuracy: 0.953125, loss: 0.13875430822372437      \n",
      "train step #7503 accuracy: 0.9375, loss: 0.2612231969833374       \n",
      "train step #7504 accuracy: 0.953125, loss: 0.17260822653770447      \n",
      "train step #7505 accuracy: 0.96875, loss: 0.1214715987443924       \n",
      "train step #7506 accuracy:   1.0, loss: 0.05600779503583908      \n",
      "train step #7507 accuracy: 0.90625, loss: 0.28313934803009033      \n",
      "train step #7508 accuracy: 0.953125, loss: 0.2359139621257782       \n",
      "train step #7509 accuracy: 0.984375, loss: 0.06493230164051056      \n",
      "train step #7510 accuracy: 0.953125, loss: 0.12872914969921112      \n",
      "train step #7511 accuracy: 0.984375, loss: 0.08099114894866943      \n",
      "train step #7512 accuracy: 0.921875, loss: 0.2990034818649292       \n",
      "train step #7513 accuracy:   1.0, loss: 0.026837490499019623     \n",
      "train step #7514 accuracy: 0.96875, loss: 0.21212729811668396      \n",
      "train step #7515 accuracy:   1.0, loss: 0.034081969410181046     \n",
      "train step #7516 accuracy:   1.0, loss: 0.023251250386238098     \n",
      "train step #7517 accuracy: 0.953125, loss: 0.2292427271604538       \n",
      "train step #7518 accuracy: 0.96875, loss: 0.19848601520061493      \n",
      "train step #7519 accuracy: 0.96875, loss: 0.1250137984752655       \n",
      "train step #7520 accuracy: 0.96875, loss: 0.13701507449150085      \n",
      "train step #7521 accuracy: 0.984375, loss: 0.07418158650398254      \n",
      "train step #7522 accuracy: 0.984375, loss: 0.046375878155231476     \n",
      "train step #7523 accuracy: 0.921875, loss: 0.2643429636955261       \n",
      "train step #7524 accuracy: 0.96875, loss: 0.08332177996635437      \n",
      "train step #7525 accuracy: 0.96875, loss: 0.08630716800689697      \n",
      "train step #7526 accuracy: 0.96875, loss: 0.09008202701807022      \n",
      "train step #7527 accuracy: 0.96875, loss: 0.10818610340356827      \n",
      "train step #7528 accuracy: 0.890625, loss: 0.22937098145484924      \n",
      "train step #7529 accuracy: 0.96875, loss: 0.1157054528594017       \n",
      "train step #7530 accuracy: 0.984375, loss: 0.1138589158654213       \n",
      "train step #7531 accuracy:   1.0, loss: 0.04083864018321037      \n",
      "train step #7532 accuracy: 0.96875, loss: 0.16062414646148682      \n",
      "train step #7533 accuracy: 0.96875, loss: 0.10535034537315369      \n",
      "train step #7534 accuracy: 0.953125, loss: 0.1611807644367218       \n",
      "train step #7535 accuracy: 0.96875, loss: 0.13409587740898132      \n",
      "train step #7536 accuracy: 0.984375, loss: 0.09697368741035461      \n",
      "train step #7537 accuracy: 0.9375, loss: 0.21008533239364624      \n",
      "train step #7538 accuracy: 0.984375, loss: 0.0787341445684433       \n",
      "train step #7539 accuracy: 0.96875, loss: 0.11380734294652939      \n",
      "train step #7540 accuracy: 0.96875, loss: 0.15553417801856995      \n",
      "train step #7541 accuracy:   1.0, loss: 0.042266301810741425     \n",
      "train step #7542 accuracy: 0.984375, loss: 0.08147555589675903      \n",
      "train step #7543 accuracy: 0.984375, loss: 0.07353618741035461      \n",
      "train step #7544 accuracy: 0.984375, loss: 0.15004196763038635      \n",
      "train step #7545 accuracy: 0.96875, loss: 0.13764110207557678      \n",
      "train step #7546 accuracy:   1.0, loss: 0.016861461102962494     \n",
      "train step #7547 accuracy: 0.953125, loss: 0.11919797956943512      \n",
      "train step #7548 accuracy: 0.984375, loss: 0.08520780503749847      \n",
      "train step #7549 accuracy: 0.96875, loss: 0.09005235135555267      \n",
      "train step #7550 accuracy: 0.96875, loss: 0.09061378985643387      \n",
      "train step #7551 accuracy: 0.984375, loss: 0.09094073623418808      \n",
      "train step #7552 accuracy:   1.0, loss: 0.09498082101345062      \n",
      "train step #7553 accuracy: 0.984375, loss: 0.07084264606237411      \n",
      "train step #7554 accuracy: 0.984375, loss: 0.08372978866100311      \n",
      "train step #7555 accuracy: 0.9375, loss: 0.17472051084041595      \n",
      "train step #7556 accuracy: 0.921875, loss: 0.2691112160682678       \n",
      "train step #7557 accuracy: 0.96875, loss: 0.06423631310462952      \n",
      "train step #7558 accuracy: 0.984375, loss: 0.1116810068488121       \n",
      "train step #7559 accuracy: 0.953125, loss: 0.16044896841049194      \n",
      "train step #7560 accuracy: 0.96875, loss: 0.10369172692298889      \n",
      "train step #7561 accuracy: 0.953125, loss: 0.17951235175132751      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #7562 accuracy: 0.953125, loss: 0.20286232233047485      \n",
      "train step #7563 accuracy: 0.984375, loss: 0.08957047015428543      \n",
      "train step #7564 accuracy: 0.90625, loss: 0.26873651146888733      \n",
      "train step #7565 accuracy:   1.0, loss: 0.03440907597541809      \n",
      "train step #7566 accuracy: 0.953125, loss: 0.1284884512424469       \n",
      "train step #7567 accuracy: 0.921875, loss: 0.25084418058395386      \n",
      "train step #7568 accuracy: 0.96875, loss: 0.11861266195774078      \n",
      "train step #7569 accuracy: 0.96875, loss: 0.1423175036907196       \n",
      "train step #7570 accuracy: 0.9375, loss: 0.25692519545555115      \n",
      "train step #7571 accuracy: 0.953125, loss: 0.20700973272323608      \n",
      "train step #7572 accuracy: 0.9375, loss: 0.25084707140922546      \n",
      "train step #7573 accuracy: 0.96875, loss: 0.12966673076152802      \n",
      "train step #7574 accuracy: 0.984375, loss: 0.13907185196876526      \n",
      "train step #7575 accuracy: 0.984375, loss: 0.048987582325935364     \n",
      "train step #7576 accuracy: 0.921875, loss: 0.20710818469524384      \n",
      "train step #7577 accuracy: 0.96875, loss: 0.16883584856987         \n",
      "train step #7578 accuracy: 0.90625, loss: 0.4118674397468567       \n",
      "train step #7579 accuracy: 0.984375, loss: 0.0663331151008606       \n",
      "train step #7580 accuracy: 0.953125, loss: 0.13363772630691528      \n",
      "train step #7581 accuracy: 0.90625, loss: 0.239450141787529        \n",
      "train step #7582 accuracy: 0.90625, loss: 0.29132896661758423      \n",
      "train step #7583 accuracy: 0.96875, loss: 0.04554884135723114      \n",
      "train step #7584 accuracy: 0.921875, loss: 0.21237856149673462      \n",
      "train step #7585 accuracy: 0.984375, loss: 0.11105075478553772      \n",
      "train step #7586 accuracy: 0.953125, loss: 0.15857744216918945      \n",
      "train step #7587 accuracy:   1.0, loss: 0.031645435839891434     \n",
      "train step #7588 accuracy: 0.921875, loss: 0.2688749134540558       \n",
      "train step #7589 accuracy: 0.953125, loss: 0.20659507811069489      \n",
      "train step #7590 accuracy: 0.984375, loss: 0.07701878249645233      \n",
      "train step #7591 accuracy: 0.953125, loss: 0.15640120208263397      \n",
      "train step #7592 accuracy: 0.9375, loss: 0.25220242142677307      \n",
      "train step #7593 accuracy: 0.953125, loss: 0.15233995020389557      \n",
      "train step #7594 accuracy: 0.953125, loss: 0.17387093603610992      \n",
      "train step #7595 accuracy: 0.984375, loss: 0.07507144659757614      \n",
      "train step #7596 accuracy: 0.96875, loss: 0.04835066199302673      \n",
      "train step #7597 accuracy: 0.96875, loss: 0.13879889249801636      \n",
      "train step #7598 accuracy: 0.984375, loss: 0.07503876090049744      \n",
      "train step #7599 accuracy: 0.921875, loss: 0.28859931230545044      \n",
      "train step #7600 accuracy: 0.921875, loss: 0.20388910174369812      \n",
      "train step #7601 accuracy: 0.96875, loss: 0.11774298548698425      \n",
      "train step #7602 accuracy: 0.984375, loss: 0.034004323184490204     \n",
      "train step #7603 accuracy: 0.984375, loss: 0.09437557309865952      \n",
      "train step #7604 accuracy: 0.96875, loss: 0.16354911029338837      \n",
      "train step #7605 accuracy: 0.984375, loss: 0.08168043196201324      \n",
      "train step #7606 accuracy: 0.96875, loss: 0.09526967257261276      \n",
      "train step #7607 accuracy: 0.96875, loss: 0.12361623346805573      \n",
      "train step #7608 accuracy: 0.984375, loss: 0.050428587943315506     \n",
      "train step #7609 accuracy:   1.0, loss: 0.03613464906811714      \n",
      "train step #7610 accuracy: 0.984375, loss: 0.1037399172782898       \n",
      "train step #7611 accuracy:   1.0, loss: 0.05021011084318161      \n",
      "train step #7612 accuracy: 0.953125, loss: 0.1050223708152771       \n",
      "train step #7613 accuracy: 0.984375, loss: 0.11791515350341797      \n",
      "train step #7614 accuracy: 0.9375, loss: 0.28346192836761475      \n",
      "train step #7615 accuracy: 0.96875, loss: 0.07342100143432617      \n",
      "train step #7616 accuracy: 0.984375, loss: 0.08688059449195862      \n",
      "train step #7617 accuracy: 0.953125, loss: 0.21115413308143616      \n",
      "train step #7618 accuracy: 0.921875, loss: 0.23252776265144348      \n",
      "train step #7619 accuracy: 0.9375, loss: 0.2477559596300125       \n",
      "train step #7620 accuracy: 0.96875, loss: 0.14179560542106628      \n",
      "train step #7621 accuracy: 0.90625, loss: 0.23920048773288727      \n",
      "train step #7622 accuracy: 0.921875, loss: 0.26670750975608826      \n",
      "train step #7623 accuracy: 0.953125, loss: 0.1725061535835266       \n",
      "train step #7624 accuracy: 0.9375, loss: 0.16609862446784973      \n",
      "train step #7625 accuracy: 0.96875, loss: 0.13969077169895172      \n",
      "train step #7626 accuracy: 0.96875, loss: 0.10805359482765198      \n",
      "train step #7627 accuracy: 0.9375, loss: 0.14232052862644196      \n",
      "train step #7628 accuracy: 0.984375, loss: 0.07467719912528992      \n",
      "train step #7629 accuracy: 0.984375, loss: 0.09066813439130783      \n",
      "train step #7630 accuracy: 0.96875, loss: 0.13763268291950226      \n",
      "train step #7631 accuracy: 0.984375, loss: 0.06848303973674774      \n",
      "train step #7632 accuracy: 0.953125, loss: 0.13029694557189941      \n",
      "train step #7633 accuracy: 0.953125, loss: 0.1551159918308258       \n",
      "train step #7634 accuracy:   1.0, loss: 0.03241978585720062      \n",
      "dev accuracy: 0.9375, loss: 0.06899723410606384      \n",
      "dev accuracy:   1.0, loss: 0.028069406747817993     \n",
      "dev accuracy: 0.8125, loss: 0.2736116945743561       \n",
      "dev accuracy:   1.0, loss: 0.02828603982925415      \n",
      "dev accuracy: 0.9375, loss: 0.12268029153347015      \n",
      "dev accuracy:   1.0, loss: 0.004773259162902832     \n",
      "dev accuracy: 0.875, loss: 0.553773045539856        \n",
      "dev accuracy: 0.9375, loss: 0.08330714702606201      \n",
      "dev accuracy: 0.875, loss: 0.6487425565719604       \n",
      "dev accuracy: 0.875, loss: 0.5113245844841003       \n",
      "dev accuracy: 0.9375, loss: 0.3702944815158844       \n",
      "dev accuracy: 0.9375, loss: 0.19639283418655396      \n",
      "dev accuracy: 0.875, loss: 0.19095462560653687      \n",
      "dev accuracy:   1.0, loss: 0.006506294012069702     \n",
      "dev accuracy:   1.0, loss: 0.005513131618499756     \n",
      "dev accuracy:   1.0, loss: 0.0015666484832763672    \n",
      "dev accuracy:   1.0, loss: 0.09513185918331146      \n",
      "dev accuracy:   1.0, loss: 0.0010491609573364258    \n",
      "dev accuracy:   1.0, loss: 0.060849323868751526     \n",
      "dev accuracy: 0.9375, loss: 0.16979628801345825      \n",
      "dev accuracy: 0.9375, loss: 0.259610652923584        \n",
      "dev accuracy: 0.9375, loss: 0.21995791792869568      \n",
      "dev accuracy:   1.0, loss: 0.024979740381240845     \n",
      "dev accuracy:   1.0, loss: 0.07062725722789764      \n",
      "dev accuracy: 0.875, loss: 0.3815646767616272       \n",
      "dev accuracy: 0.9375, loss: 0.08579692244529724      \n",
      "dev accuracy: 0.9375, loss: 0.16265887022018433      \n",
      "dev accuracy:   1.0, loss: 0.03842461109161377      \n",
      "dev accuracy: 0.9375, loss: 0.2230195850133896       \n",
      "dev accuracy:   1.0, loss: 0.07791972160339355      \n",
      "dev accuracy: 0.9375, loss: 0.18888559937477112      \n",
      "dev accuracy:   1.0, loss: 0.11281509697437286      \n",
      "dev accuracy: 0.875, loss: 0.3483644127845764       \n",
      "dev accuracy: 0.9375, loss: 0.11188901960849762      \n",
      "dev accuracy:   1.0, loss: 0.010362118482589722     \n",
      "dev accuracy:   1.0, loss: 0.0005750060081481934    \n",
      "dev accuracy: 0.9375, loss: 0.2523983120918274       \n",
      "dev accuracy: 0.9375, loss: 0.25727546215057373      \n",
      "dev accuracy:   1.0, loss: 0.02192157506942749      \n",
      "dev accuracy: 0.9375, loss: 0.16477209329605103      \n",
      "dev accuracy:   1.0, loss: 0.036010921001434326     \n",
      "dev accuracy:   1.0, loss: 0.0022131800651550293    \n",
      "dev accuracy:   1.0, loss: 0.04734286665916443      \n",
      "dev accuracy: 0.9375, loss: 0.09543898701667786      \n",
      "dev accuracy: 0.9375, loss: 0.09289878606796265      \n",
      "dev accuracy:   1.0, loss: 0.017447203397750854     \n",
      "dev accuracy:   1.0, loss: 0.008897393941879272     \n",
      "dev accuracy: 0.8125, loss: 0.7558757662773132       \n",
      "dev accuracy: 0.9375, loss: 0.35483211278915405      \n",
      "dev accuracy:   1.0, loss: 0.022143840789794922     \n",
      "dev accuracy: 0.875, loss: 0.26175180077552795      \n",
      "dev accuracy:   1.0, loss: 0.042750656604766846     \n",
      "dev accuracy:   1.0, loss: 0.05205720663070679      \n",
      "dev accuracy: 0.875, loss: 0.33527639508247375      \n",
      "dev accuracy: 0.9375, loss: 0.1611623764038086       \n",
      "dev accuracy:   1.0, loss: 0.002256423234939575     \n",
      "dev accuracy:   1.0, loss: 0.009488880634307861     \n",
      "dev accuracy: 0.9375, loss: 0.2712748348712921       \n",
      "dev accuracy:   1.0, loss: 0.02052322030067444      \n",
      "dev accuracy:   1.0, loss: 0.020175516605377197     \n",
      "dev accuracy: 0.9375, loss: 0.29739290475845337      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy:   1.0, loss: 0.018157511949539185     \n",
      "dev accuracy:   1.0, loss: 0.02501162886619568      \n",
      "dev accuracy: 0.875, loss: 0.2925023138523102       \n",
      "dev accuracy: 0.875, loss: 0.4754074811935425       \n",
      "dev accuracy:   1.0, loss: 0.046578675508499146     \n",
      "dev accuracy:   1.0, loss: 0.018877923488616943     \n",
      "dev accuracy: 0.9375, loss: 0.1974990963935852       \n",
      "dev accuracy:   1.0, loss: 0.06078742444515228      \n",
      "dev accuracy:   1.0, loss: 0.03196236491203308      \n",
      "dev accuracy: 0.875, loss: 0.5305222868919373       \n",
      "dev accuracy: 0.8125, loss: 0.8262996673583984       \n",
      "dev accuracy: 0.9375, loss: 0.07797347009181976      \n",
      "dev accuracy:   1.0, loss: 0.00978115200996399      \n",
      "dev accuracy:   1.0, loss: 0.05959522724151611      \n",
      "dev accuracy: 0.875, loss: 0.5216858386993408       \n",
      "dev accuracy: 0.9375, loss: 0.15131089091300964      \n",
      "dev accuracy:   1.0, loss: 0.032848238945007324     \n",
      "dev accuracy: 0.875, loss: 0.4861498475074768       \n",
      "dev accuracy: 0.9375, loss: 0.1385655403137207       \n",
      "dev accuracy: 0.875, loss: 0.17933499813079834      \n",
      "dev accuracy: 0.9375, loss: 0.10750439763069153      \n",
      "dev accuracy:   1.0, loss: 0.055586546659469604     \n",
      "dev accuracy: 0.8125, loss: 0.7728968858718872       \n",
      "dev accuracy: 0.9375, loss: 0.21845528483390808      \n",
      "dev accuracy:   1.0, loss: 0.016689300537109375     \n",
      "dev accuracy:   1.0, loss: 0.04300692677497864      \n",
      "dev accuracy:   1.0, loss: 0.01933726668357849      \n",
      "dev accuracy: 0.9375, loss: 0.34881097078323364      \n",
      "dev accuracy: 0.875, loss: 0.28401172161102295      \n",
      "dev accuracy:   1.0, loss: 0.0001704096794128418    \n",
      "dev accuracy: 0.9375, loss: 0.20266413688659668      \n",
      "dev accuracy:   1.0, loss: 0.06837195158004761      \n",
      "dev accuracy: 0.9375, loss: 0.14859119057655334      \n",
      "dev accuracy: 0.9375, loss: 0.2604398727416992       \n",
      "dev accuracy:   1.0, loss: 0.041762739419937134     \n",
      "dev accuracy: 0.9375, loss: 0.16035196185112         \n",
      "dev accuracy: 0.875, loss: 0.4607836604118347       \n",
      "dev accuracy: 0.875, loss: 0.36995729804039         \n",
      "dev accuracy: 0.9375, loss: 0.1380707323551178       \n",
      "dev accuracy:   1.0, loss: 0.044986873865127563     \n",
      "dev accuracy: 0.9375, loss: 0.13914451003074646      \n",
      "dev accuracy: 0.9375, loss: 0.41141214966773987      \n",
      "dev accuracy:   1.0, loss: 0.00780642032623291      \n",
      "dev accuracy:   1.0, loss: 0.016934454441070557     \n",
      "dev accuracy: 0.9375, loss: 0.11693260073661804      \n",
      "dev accuracy: 0.9375, loss: 0.5113157033920288       \n",
      "dev accuracy:   1.0, loss: 0.017148256301879883     \n",
      "dev accuracy: 0.9375, loss: 0.14846152067184448      \n",
      "dev accuracy:   1.0, loss: 0.0016909241676330566    \n",
      "dev accuracy:   1.0, loss: 0.02211567759513855      \n",
      "dev accuracy:   1.0, loss: 0.05062238872051239      \n",
      "dev accuracy:   1.0, loss: 0.006474494934082031     \n",
      "dev accuracy: 0.9375, loss: 0.11506770551204681      \n",
      "dev accuracy:   1.0, loss: 0.0043825507164001465    \n",
      "dev accuracy:   1.0, loss: 0.006746828556060791     \n",
      "dev accuracy:   1.0, loss: 0.04663899540901184      \n",
      "dev accuracy: 0.9375, loss: 0.10114282369613647      \n",
      "dev accuracy:   1.0, loss: 0.07096533477306366      \n",
      "dev accuracy: 0.9375, loss: 0.05090296268463135      \n",
      "dev accuracy: 0.875, loss: 0.29990628361701965      \n",
      "dev accuracy: 0.875, loss: 0.5411632657051086       \n",
      "dev accuracy: 0.9375, loss: 0.5072823166847229       \n",
      "dev accuracy: 0.9375, loss: 0.12775671482086182      \n",
      "dev accuracy:   1.0, loss: 0.003992199897766113     \n",
      "dev accuracy:   1.0, loss: 0.08811083436012268      \n",
      "dev accuracy:   1.0, loss: 0.0072969794273376465    \n",
      "dev accuracy: 0.875, loss: 0.3753322958946228       \n",
      "dev accuracy:   1.0, loss: 0.02054351568222046      \n",
      "dev accuracy:   1.0, loss: 0.024105817079544067     \n",
      "dev accuracy: 0.8125, loss: 0.33552053570747375      \n",
      "dev accuracy:   1.0, loss: 0.006215840578079224     \n",
      "dev accuracy: 0.9375, loss: 0.076933354139328        \n",
      "dev accuracy: 0.875, loss: 0.3183821737766266       \n",
      "dev accuracy: 0.8125, loss: 0.3701775074005127       \n",
      "dev accuracy:   1.0, loss: 0.0003070235252380371    \n",
      "dev accuracy: 0.875, loss: 0.21327945590019226      \n",
      "dev accuracy: 0.9375, loss: 0.2213243693113327       \n",
      "dev accuracy:   1.0, loss: 0.0017224550247192383    \n",
      "dev accuracy: 0.9375, loss: 0.15070182085037231      \n",
      "dev accuracy:   1.0, loss: 0.027920812368392944     \n",
      "dev accuracy:   1.0, loss: 0.0003342628479003906    \n",
      "dev accuracy:   1.0, loss: 0.017262399196624756     \n",
      "dev accuracy: 0.9375, loss: 0.3505536615848541       \n",
      "dev accuracy: 0.875, loss: 0.33131566643714905      \n",
      "dev accuracy: 0.9375, loss: 0.4624004364013672       \n",
      "dev accuracy:   1.0, loss: 0.01688501238822937      \n",
      "dev accuracy:   1.0, loss: 0.04365414381027222      \n",
      "dev accuracy:   1.0, loss: 0.016779720783233643     \n",
      "dev accuracy: 0.9375, loss: 0.1672891229391098       \n",
      "dev accuracy: 0.875, loss: 0.19258645176887512      \n",
      "dev accuracy: 0.9375, loss: 0.19176997244358063      \n",
      "dev accuracy:   1.0, loss: 0.02731415629386902      \n",
      "dev accuracy:   1.0, loss: 0.032551705837249756     \n",
      "dev accuracy: 0.9375, loss: 0.1821054220199585       \n",
      "dev accuracy: 0.875, loss: 0.3261107802391052       \n",
      "dev accuracy: 0.875, loss: 0.26811927556991577      \n",
      "dev accuracy:   1.0, loss: 0.004920989274978638     \n",
      "dev accuracy: 0.9375, loss: 0.3080589473247528       \n",
      "dev accuracy:   1.0, loss: 0.03125837445259094      \n",
      "dev accuracy: 0.8125, loss: 0.5627788305282593       \n",
      "dev accuracy: 0.9375, loss: 0.16997016966342926      \n",
      "dev accuracy:   1.0, loss: 0.027680397033691406     \n",
      "dev accuracy:   1.0, loss: 0.009603053331375122     \n",
      "dev accuracy: 0.9375, loss: 0.06848913431167603      \n",
      "dev accuracy:   1.0, loss: 0.023898422718048096     \n",
      "dev accuracy:   1.0, loss: 0.0187053382396698       \n",
      "dev accuracy: 0.9375, loss: 0.3802955746650696       \n",
      "dev accuracy:   1.0, loss: 0.0493272989988327       \n",
      "dev accuracy:   1.0, loss: 0.058820873498916626     \n",
      "dev accuracy: 0.875, loss: 0.39118802547454834      \n",
      "dev accuracy: 0.9375, loss: 0.0931997299194336       \n",
      "dev accuracy:   1.0, loss: 0.004289865493774414     \n",
      "dev accuracy:   1.0, loss: 0.010951817035675049     \n",
      "dev accuracy:   1.0, loss: 0.0169467031955719       \n",
      "dev accuracy:   1.0, loss: 0.009439289569854736     \n",
      "dev accuracy: 0.875, loss: 0.3715150058269501       \n",
      "dev accuracy:   1.0, loss: 0.000834047794342041     \n",
      "dev accuracy: 0.9375, loss: 0.10940882563591003      \n",
      "dev accuracy:   1.0, loss: 0.0541708767414093       \n",
      "dev accuracy: 0.875, loss: 0.3127138912677765       \n",
      "dev accuracy:   1.0, loss: 0.06498667597770691      \n",
      "dev accuracy: 0.9375, loss: 0.24117502570152283      \n",
      "dev accuracy:   1.0, loss: 0.04795825481414795      \n",
      "dev accuracy: 0.9375, loss: 0.44166332483291626      \n",
      "dev accuracy: 0.9375, loss: 0.35354331135749817      \n",
      "dev accuracy: 0.9375, loss: 0.13116513192653656      \n",
      "dev accuracy: 0.875, loss: 0.2200370877981186       \n",
      "dev accuracy: 0.9375, loss: 0.12971612811088562      \n",
      "dev accuracy: 0.875, loss: 0.2551805377006531       \n",
      "dev accuracy: 0.875, loss: 0.19489432871341705      \n",
      "dev accuracy:   1.0, loss: 0.03368896245956421      \n",
      "dev accuracy:   1.0, loss: 0.008831202983856201     \n",
      "dev accuracy:   1.0, loss: 5.181630331207998e-05    \n",
      "final dev accuracy: 0.9523195876288659\n",
      "train step #7635 accuracy: 0.96875, loss: 0.09205939620733261      \n",
      "train step #7636 accuracy: 0.953125, loss: 0.17824646830558777      \n",
      "train step #7637 accuracy: 0.96875, loss: 0.1334395408630371       \n",
      "train step #7638 accuracy: 0.984375, loss: 0.097597137093544        \n",
      "train step #7639 accuracy: 0.96875, loss: 0.10032965242862701      \n",
      "train step #7640 accuracy:   1.0, loss: 0.04053392633795738      \n",
      "train step #7641 accuracy:   1.0, loss: 0.016216516494750977     \n",
      "train step #7642 accuracy: 0.9375, loss: 0.2422906458377838       \n",
      "train step #7643 accuracy: 0.9375, loss: 0.2673971652984619       \n",
      "train step #7644 accuracy: 0.984375, loss: 0.05056548863649368      \n",
      "train step #7645 accuracy: 0.90625, loss: 0.2593928575515747       \n",
      "train step #7646 accuracy: 0.9375, loss: 0.14362409710884094      \n",
      "train step #7647 accuracy: 0.96875, loss: 0.10557371377944946      \n",
      "train step #7648 accuracy: 0.96875, loss: 0.18312864005565643      \n",
      "train step #7649 accuracy: 0.953125, loss: 0.21060022711753845      \n",
      "train step #7650 accuracy: 0.984375, loss: 0.09456363320350647      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #7651 accuracy:   1.0, loss: 0.027847066521644592     \n",
      "train step #7652 accuracy:   1.0, loss: 0.14776800572872162      \n",
      "train step #7653 accuracy: 0.984375, loss: 0.0584028959274292       \n",
      "train step #7654 accuracy: 0.984375, loss: 0.08095162361860275      \n",
      "train step #7655 accuracy: 0.96875, loss: 0.10842885076999664      \n",
      "train step #7656 accuracy: 0.953125, loss: 0.08696398884057999      \n",
      "train step #7657 accuracy: 0.9375, loss: 0.20786729454994202      \n",
      "train step #7658 accuracy: 0.953125, loss: 0.18876025080680847      \n",
      "train step #7659 accuracy: 0.984375, loss: 0.08696503192186356      \n",
      "train step #7660 accuracy: 0.96875, loss: 0.09886463731527328      \n",
      "train step #7661 accuracy: 0.984375, loss: 0.06645660102367401      \n",
      "train step #7662 accuracy: 0.9375, loss: 0.1857527792453766       \n",
      "train step #7663 accuracy: 0.921875, loss: 0.2924327850341797       \n",
      "train step #7664 accuracy: 0.9375, loss: 0.18922697007656097      \n",
      "train step #7665 accuracy: 0.9375, loss: 0.29795244336128235      \n",
      "train step #7666 accuracy: 0.953125, loss: 0.12108297646045685      \n",
      "train step #7667 accuracy: 0.984375, loss: 0.1251792162656784       \n",
      "train step #7668 accuracy: 0.984375, loss: 0.03987213969230652      \n",
      "train step #7669 accuracy: 0.984375, loss: 0.057447485625743866     \n",
      "train step #7670 accuracy: 0.953125, loss: 0.200198695063591        \n",
      "train step #7671 accuracy: 0.984375, loss: 0.05619242787361145      \n",
      "train step #7672 accuracy: 0.953125, loss: 0.15863551199436188      \n",
      "train step #7673 accuracy: 0.96875, loss: 0.11298950016498566      \n",
      "train step #7674 accuracy: 0.96875, loss: 0.251270055770874        \n",
      "train step #7675 accuracy: 0.984375, loss: 0.05224829912185669      \n",
      "train step #7676 accuracy: 0.984375, loss: 0.07092440128326416      \n",
      "train step #7677 accuracy: 0.953125, loss: 0.144170880317688        \n",
      "train step #7678 accuracy: 0.9375, loss: 0.15279576182365417      \n",
      "train step #7679 accuracy: 0.921875, loss: 0.365095853805542        \n",
      "train step #7680 accuracy:   1.0, loss: 0.037297435104846954     \n",
      "train step #7681 accuracy: 0.953125, loss: 0.14568662643432617      \n",
      "train step #7682 accuracy: 0.96875, loss: 0.13442793488502502      \n",
      "train step #7683 accuracy: 0.953125, loss: 0.22895118594169617      \n",
      "train step #7684 accuracy: 0.96875, loss: 0.08071068674325943      \n",
      "train step #7685 accuracy: 0.921875, loss: 0.2921289801597595       \n",
      "train step #7686 accuracy:   1.0, loss: 0.030100982636213303     \n",
      "train step #7687 accuracy: 0.953125, loss: 0.13432589173316956      \n",
      "train step #7688 accuracy:   1.0, loss: 0.03208627924323082      \n",
      "train step #7689 accuracy: 0.90625, loss: 0.3792683482170105       \n",
      "train step #7690 accuracy: 0.96875, loss: 0.11033466458320618      \n",
      "train step #7691 accuracy: 0.953125, loss: 0.1939174234867096       \n",
      "train step #7692 accuracy:   1.0, loss: 0.048468999564647675     \n",
      "train step #7693 accuracy: 0.9375, loss: 0.1500443071126938       \n",
      "train step #7694 accuracy: 0.984375, loss: 0.06595383584499359      \n",
      "train step #7695 accuracy: 0.96875, loss: 0.12041731923818588      \n",
      "train step #7696 accuracy: 0.96875, loss: 0.07377032935619354      \n",
      "train step #7697 accuracy: 0.984375, loss: 0.08417875319719315      \n",
      "train step #7698 accuracy: 0.96875, loss: 0.12670983374118805      \n",
      "train step #7699 accuracy: 0.953125, loss: 0.18336065113544464      \n",
      "train step #7700 accuracy: 0.984375, loss: 0.06840864568948746      \n",
      "train step #7701 accuracy: 0.953125, loss: 0.17933118343353271      \n",
      "train step #7702 accuracy: 0.96875, loss: 0.10325510799884796      \n",
      "train step #7703 accuracy: 0.96875, loss: 0.11967407166957855      \n",
      "train step #7704 accuracy: 0.96875, loss: 0.15812109410762787      \n",
      "train step #7705 accuracy: 0.96875, loss: 0.0917154848575592       \n",
      "train step #7706 accuracy: 0.9375, loss: 0.2021520435810089       \n",
      "train step #7707 accuracy: 0.96875, loss: 0.1463332623243332       \n",
      "train step #7708 accuracy: 0.984375, loss: 0.06516125053167343      \n",
      "train step #7709 accuracy: 0.953125, loss: 0.12147963047027588      \n",
      "train step #7710 accuracy: 0.9375, loss: 0.255412220954895        \n",
      "train step #7711 accuracy: 0.9375, loss: 0.24981412291526794      \n",
      "train step #7712 accuracy: 0.96875, loss: 0.12223212420940399      \n",
      "train step #7713 accuracy:   1.0, loss: 0.032627616077661514     \n",
      "train step #7714 accuracy: 0.953125, loss: 0.10338154435157776      \n",
      "train step #7715 accuracy: 0.96875, loss: 0.059440359473228455     \n",
      "train step #7716 accuracy: 0.984375, loss: 0.09961860626935959      \n",
      "train step #7717 accuracy: 0.953125, loss: 0.19873185455799103      \n",
      "train step #7718 accuracy:   1.0, loss: 0.02521657943725586      \n",
      "train step #7719 accuracy: 0.96875, loss: 0.1551346778869629       \n",
      "train step #7720 accuracy: 0.9375, loss: 0.23235709965229034      \n",
      "train step #7721 accuracy: 0.953125, loss: 0.14827388525009155      \n",
      "train step #7722 accuracy:   1.0, loss: 0.03655321151018143      \n",
      "train step #7723 accuracy: 0.984375, loss: 0.11025402694940567      \n",
      "train step #7724 accuracy: 0.953125, loss: 0.1345566064119339       \n",
      "train step #7725 accuracy: 0.96875, loss: 0.12332432717084885      \n",
      "train step #7726 accuracy: 0.984375, loss: 0.06966328620910645      \n",
      "train step #7727 accuracy: 0.90625, loss: 0.25536486506462097      \n",
      "train step #7728 accuracy: 0.984375, loss: 0.036656253039836884     \n",
      "train step #7729 accuracy: 0.984375, loss: 0.09053382277488708      \n",
      "train step #7730 accuracy: 0.96875, loss: 0.10738948732614517      \n",
      "train step #7731 accuracy: 0.953125, loss: 0.16843664646148682      \n",
      "train step #7732 accuracy: 0.921875, loss: 0.3020225167274475       \n",
      "train step #7733 accuracy: 0.953125, loss: 0.1719188392162323       \n",
      "train step #7734 accuracy: 0.984375, loss: 0.10576474666595459      \n",
      "train step #7735 accuracy: 0.984375, loss: 0.08139351010322571      \n",
      "train step #7736 accuracy: 0.953125, loss: 0.19586381316184998      \n",
      "train step #7737 accuracy: 0.984375, loss: 0.08304521441459656      \n",
      "train step #7738 accuracy: 0.984375, loss: 0.049397386610507965     \n",
      "train step #7739 accuracy:   1.0, loss: 0.026619669049978256     \n",
      "train step #7740 accuracy: 0.96875, loss: 0.1501731425523758       \n",
      "train step #7741 accuracy: 0.90625, loss: 0.30635157227516174      \n",
      "train step #7742 accuracy: 0.984375, loss: 0.043129052966833115     \n",
      "train step #7743 accuracy: 0.890625, loss: 0.25928357243537903      \n",
      "train step #7744 accuracy: 0.953125, loss: 0.18039943277835846      \n",
      "train step #7745 accuracy: 0.96875, loss: 0.12721587717533112      \n",
      "train step #7746 accuracy: 0.984375, loss: 0.10360324382781982      \n",
      "train step #7747 accuracy: 0.953125, loss: 0.09507428109645844      \n",
      "train step #7748 accuracy: 0.921875, loss: 0.2152441293001175       \n",
      "train step #7749 accuracy: 0.96875, loss: 0.08506850898265839      \n",
      "train step #7750 accuracy: 0.984375, loss: 0.08544933050870895      \n",
      "train step #7751 accuracy: 0.96875, loss: 0.11509954929351807      \n",
      "train step #7752 accuracy: 0.953125, loss: 0.09297887980937958      \n",
      "train step #7753 accuracy: 0.96875, loss: 0.08313056826591492      \n",
      "train step #7754 accuracy: 0.96875, loss: 0.14967866241931915      \n",
      "train step #7755 accuracy: 0.953125, loss: 0.1197928711771965       \n",
      "train step #7756 accuracy: 0.96875, loss: 0.09336534887552261      \n",
      "train step #7757 accuracy: 0.9375, loss: 0.17869186401367188      \n",
      "train step #7758 accuracy: 0.921875, loss: 0.20895697176456451      \n",
      "train step #7759 accuracy: 0.96875, loss: 0.09722720086574554      \n",
      "train step #7760 accuracy: 0.96875, loss: 0.1643037497997284       \n",
      "train step #7761 accuracy: 0.9375, loss: 0.157020702958107        \n",
      "train step #7762 accuracy: 0.9375, loss: 0.1797672063112259       \n",
      "train step #7763 accuracy: 0.953125, loss: 0.170355424284935        \n",
      "train step #7764 accuracy: 0.953125, loss: 0.23911939561367035      \n",
      "train step #7765 accuracy: 0.890625, loss: 0.32203149795532227      \n",
      "train step #7766 accuracy: 0.96875, loss: 0.10583961755037308      \n",
      "train step #7767 accuracy: 0.921875, loss: 0.2732657194137573       \n",
      "train step #7768 accuracy: 0.9375, loss: 0.22207462787628174      \n",
      "train step #7769 accuracy:   1.0, loss: 0.05242865905165672      \n",
      "train step #7770 accuracy: 0.953125, loss: 0.18478736281394958      \n",
      "train step #7771 accuracy: 0.984375, loss: 0.09856555610895157      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #7772 accuracy: 0.953125, loss: 0.21808725595474243      \n",
      "train step #7773 accuracy: 0.96875, loss: 0.089014433324337        \n",
      "train step #7774 accuracy: 0.953125, loss: 0.27078181505203247      \n",
      "train step #7775 accuracy: 0.96875, loss: 0.12492413073778152      \n",
      "train step #7776 accuracy: 0.96875, loss: 0.11242654919624329      \n",
      "train step #7777 accuracy: 0.984375, loss: 0.1106577217578888       \n",
      "train step #7778 accuracy: 0.9375, loss: 0.14621001482009888      \n",
      "train step #7779 accuracy: 0.984375, loss: 0.04855787381529808      \n",
      "train step #7780 accuracy: 0.953125, loss: 0.12336300313472748      \n",
      "train step #7781 accuracy:   1.0, loss: 0.01705615222454071      \n",
      "train step #7782 accuracy: 0.96875, loss: 0.10025908052921295      \n",
      "train step #7783 accuracy: 0.984375, loss: 0.10923793166875839      \n",
      "train step #7784 accuracy: 0.953125, loss: 0.19565103948116302      \n",
      "train step #7785 accuracy: 0.953125, loss: 0.19301171600818634      \n",
      "train step #7786 accuracy: 0.96875, loss: 0.11827907711267471      \n",
      "train step #7787 accuracy: 0.953125, loss: 0.08559151738882065      \n",
      "train step #7788 accuracy: 0.953125, loss: 0.16171987354755402      \n",
      "train step #7789 accuracy: 0.9375, loss: 0.3348228335380554       \n",
      "train step #7790 accuracy: 0.984375, loss: 0.10273509472608566      \n",
      "train step #7791 accuracy: 0.96875, loss: 0.1480652093887329       \n",
      "train step #7792 accuracy: 0.984375, loss: 0.0463959164917469       \n",
      "train step #7793 accuracy: 0.984375, loss: 0.09232249110937119      \n",
      "train step #7794 accuracy: 0.96875, loss: 0.09544701129198074      \n",
      "train step #7795 accuracy: 0.96875, loss: 0.18907245993614197      \n",
      "train step #7796 accuracy: 0.953125, loss: 0.16524724662303925      \n",
      "train step #7797 accuracy: 0.96875, loss: 0.20202243328094482      \n",
      "train step #7798 accuracy: 0.921875, loss: 0.29439735412597656      \n",
      "train step #7799 accuracy: 0.96875, loss: 0.1500558853149414       \n",
      "train step #7800 accuracy:   1.0, loss: 0.04257889464497566      \n",
      "train step #7801 accuracy: 0.96875, loss: 0.12923945486545563      \n",
      "train step #7802 accuracy: 0.96875, loss: 0.09122207760810852      \n",
      "train step #7803 accuracy: 0.9375, loss: 0.20943129062652588      \n",
      "train step #7804 accuracy: 0.984375, loss: 0.03780096024274826      \n",
      "train step #7805 accuracy: 0.953125, loss: 0.11542458087205887      \n",
      "train step #7806 accuracy: 0.953125, loss: 0.15527507662773132      \n",
      "train step #7807 accuracy: 0.953125, loss: 0.16695348918437958      \n",
      "train step #7808 accuracy: 0.9375, loss: 0.20215608179569244      \n",
      "train step #7809 accuracy: 0.96875, loss: 0.14999404549598694      \n",
      "train step #7810 accuracy: 0.96875, loss: 0.13675335049629211      \n",
      "train step #7811 accuracy: 0.984375, loss: 0.10313449800014496      \n",
      "train step #7812 accuracy: 0.96875, loss: 0.07578864693641663      \n",
      "train step #7813 accuracy: 0.984375, loss: 0.07223246991634369      \n",
      "train step #7814 accuracy: 0.96875, loss: 0.1080305352807045       \n",
      "train step #7815 accuracy: 0.984375, loss: 0.07627025246620178      \n",
      "train step #7816 accuracy: 0.9375, loss: 0.181324303150177        \n",
      "train step #7817 accuracy: 0.921875, loss: 0.27712225914001465      \n",
      "train step #7818 accuracy: 0.96875, loss: 0.11484606564044952      \n",
      "train step #7819 accuracy: 0.984375, loss: 0.19880928099155426      \n",
      "train step #7820 accuracy: 0.984375, loss: 0.12605220079421997      \n",
      "train step #7821 accuracy: 0.96875, loss: 0.10007677972316742      \n",
      "train step #7822 accuracy: 0.9375, loss: 0.2064100056886673       \n",
      "train step #7823 accuracy: 0.953125, loss: 0.1717035472393036       \n",
      "train step #7824 accuracy: 0.984375, loss: 0.11794615536928177      \n",
      "train step #7825 accuracy:   1.0, loss: 0.02732345089316368      \n",
      "train step #7826 accuracy: 0.984375, loss: 0.048386652022600174     \n",
      "train step #7827 accuracy: 0.984375, loss: 0.06754891574382782      \n",
      "train step #7828 accuracy: 0.9375, loss: 0.17168743908405304      \n",
      "train step #7829 accuracy: 0.96875, loss: 0.14261162281036377      \n",
      "train step #7830 accuracy: 0.984375, loss: 0.054472703486680984     \n",
      "train step #7831 accuracy: 0.921875, loss: 0.24710358679294586      \n",
      "train step #7832 accuracy: 0.921875, loss: 0.3016202747821808       \n",
      "train step #7833 accuracy: 0.9375, loss: 0.24895676970481873      \n",
      "train step #7834 accuracy: 0.984375, loss: 0.07072422653436661      \n",
      "train step #7835 accuracy: 0.953125, loss: 0.1975361853837967       \n",
      "train step #7836 accuracy: 0.96875, loss: 0.20595943927764893      \n",
      "train step #7837 accuracy: 0.96875, loss: 0.12109745293855667      \n",
      "train step #7838 accuracy: 0.984375, loss: 0.05425775423645973      \n",
      "train step #7839 accuracy: 0.984375, loss: 0.06801899522542953      \n",
      "train step #7840 accuracy: 0.921875, loss: 0.204644575715065        \n",
      "train step #7841 accuracy: 0.953125, loss: 0.27451539039611816      \n",
      "train step #7842 accuracy: 0.984375, loss: 0.0705069974064827       \n",
      "train step #7843 accuracy: 0.953125, loss: 0.17837801575660706      \n",
      "train step #7844 accuracy: 0.921875, loss: 0.2661358118057251       \n",
      "train step #7845 accuracy: 0.984375, loss: 0.06546587496995926      \n",
      "train step #7846 accuracy: 0.984375, loss: 0.08192382007837296      \n",
      "train step #7847 accuracy: 0.96875, loss: 0.11179935932159424      \n",
      "train step #7848 accuracy: 0.953125, loss: 0.16955305635929108      \n",
      "train step #7849 accuracy: 0.953125, loss: 0.19703522324562073      \n",
      "train step #7850 accuracy: 0.984375, loss: 0.09487121552228928      \n",
      "train step #7851 accuracy: 0.984375, loss: 0.07122983038425446      \n",
      "train step #7852 accuracy: 0.9375, loss: 0.22625471651554108      \n",
      "train step #7853 accuracy: 0.96875, loss: 0.14603787660598755      \n",
      "train step #7854 accuracy: 0.984375, loss: 0.09102386981248856      \n",
      "train step #7855 accuracy: 0.984375, loss: 0.10660646855831146      \n",
      "train step #7856 accuracy: 0.96875, loss: 0.12011183798313141      \n",
      "train step #7857 accuracy: 0.984375, loss: 0.08078600466251373      \n",
      "train step #7858 accuracy: 0.96875, loss: 0.06328341364860535      \n",
      "train step #7859 accuracy: 0.984375, loss: 0.07228388637304306      \n",
      "train step #7860 accuracy:   1.0, loss: 0.009984083473682404     \n",
      "train step #7861 accuracy: 0.984375, loss: 0.08924257010221481      \n",
      "train step #7862 accuracy: 0.984375, loss: 0.07891733199357986      \n",
      "train step #7863 accuracy: 0.984375, loss: 0.06832043826580048      \n",
      "train step #7864 accuracy: 0.953125, loss: 0.167064368724823        \n",
      "train step #7865 accuracy: 0.9375, loss: 0.2308301329612732       \n",
      "train step #7866 accuracy: 0.984375, loss: 0.06756079941987991      \n",
      "train step #7867 accuracy: 0.96875, loss: 0.1116051897406578       \n",
      "train step #7868 accuracy:   1.0, loss: 0.03373417630791664      \n",
      "train step #7869 accuracy:   1.0, loss: 0.02423645183444023      \n",
      "train step #7870 accuracy: 0.9375, loss: 0.21569165587425232      \n",
      "train step #7871 accuracy: 0.9375, loss: 0.22480309009552002      \n",
      "train step #7872 accuracy: 0.953125, loss: 0.24613110721111298      \n",
      "train step #7873 accuracy: 0.9375, loss: 0.17041313648223877      \n",
      "train step #7874 accuracy: 0.984375, loss: 0.06298200786113739      \n",
      "train step #7875 accuracy: 0.96875, loss: 0.08319487422704697      \n",
      "train step #7876 accuracy: 0.96875, loss: 0.09006638079881668      \n",
      "train step #7877 accuracy: 0.9375, loss: 0.17835727334022522      \n",
      "train step #7878 accuracy: 0.921875, loss: 0.18402963876724243      \n",
      "train step #7879 accuracy: 0.921875, loss: 0.2237316370010376       \n",
      "train step #7880 accuracy: 0.953125, loss: 0.181168794631958        \n",
      "train step #7881 accuracy: 0.96875, loss: 0.13328999280929565      \n",
      "train step #7882 accuracy: 0.90625, loss: 0.27249273657798767      \n",
      "train step #7883 accuracy: 0.96875, loss: 0.13828745484352112      \n",
      "train step #7884 accuracy: 0.96875, loss: 0.13492979109287262      \n",
      "train step #7885 accuracy: 0.953125, loss: 0.14096477627754211      \n",
      "train step #7886 accuracy: 0.984375, loss: 0.06008855625987053      \n",
      "train step #7887 accuracy: 0.921875, loss: 0.24533002078533173      \n",
      "train step #7888 accuracy: 0.96875, loss: 0.18347322940826416      \n",
      "train step #7889 accuracy: 0.984375, loss: 0.06150887534022331      \n",
      "train step #7890 accuracy: 0.96875, loss: 0.1617954820394516       \n",
      "train step #7891 accuracy: 0.96875, loss: 0.11331827193498611      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #7892 accuracy: 0.9375, loss: 0.23160070180892944      \n",
      "train step #7893 accuracy: 0.96875, loss: 0.08955350518226624      \n",
      "train step #7894 accuracy: 0.96875, loss: 0.1280711591243744       \n",
      "train step #7895 accuracy: 0.9375, loss: 0.2210352122783661       \n",
      "train step #7896 accuracy: 0.96875, loss: 0.13734132051467896      \n",
      "train step #7897 accuracy: 0.953125, loss: 0.15004557371139526      \n",
      "train step #7898 accuracy: 0.921875, loss: 0.19570116698741913      \n",
      "train step #7899 accuracy: 0.9375, loss: 0.2642933130264282       \n",
      "train step #7900 accuracy: 0.953125, loss: 0.130264014005661        \n",
      "train step #7901 accuracy:   1.0, loss: 0.029833845794200897     \n",
      "train step #7902 accuracy: 0.9375, loss: 0.20848841965198517      \n",
      "train step #7903 accuracy: 0.9375, loss: 0.1483832448720932       \n",
      "train step #7904 accuracy:   1.0, loss: 0.023183681070804596     \n",
      "train step #7905 accuracy: 0.921875, loss: 0.3146612048149109       \n",
      "train step #7906 accuracy: 0.9375, loss: 0.16752736270427704      \n",
      "train step #7907 accuracy: 0.96875, loss: 0.07315756380558014      \n",
      "train step #7908 accuracy: 0.96875, loss: 0.10182489454746246      \n",
      "train step #7909 accuracy: 0.96875, loss: 0.1491248458623886       \n",
      "train step #7910 accuracy: 0.9375, loss: 0.1748650223016739       \n",
      "train step #7911 accuracy: 0.984375, loss: 0.11291516572237015      \n",
      "train step #7912 accuracy:   1.0, loss: 0.04417376592755318      \n",
      "train step #7913 accuracy: 0.9375, loss: 0.16624756157398224      \n",
      "train step #7914 accuracy:   1.0, loss: 0.009837709367275238     \n",
      "train step #7915 accuracy: 0.96875, loss: 0.11570203304290771      \n",
      "train step #7916 accuracy: 0.953125, loss: 0.20237162709236145      \n",
      "train step #7917 accuracy: 0.984375, loss: 0.06539089977741241      \n",
      "train step #7918 accuracy: 0.96875, loss: 0.1683463603258133       \n",
      "train step #7919 accuracy: 0.984375, loss: 0.07988551259040833      \n",
      "train step #7920 accuracy: 0.9375, loss: 0.19600333273410797      \n",
      "train step #7921 accuracy: 0.984375, loss: 0.10783028602600098      \n",
      "train step #7922 accuracy: 0.984375, loss: 0.08391696214675903      \n",
      "train step #7923 accuracy: 0.9375, loss: 0.211604505777359        \n",
      "train step #7924 accuracy: 0.984375, loss: 0.07754666358232498      \n",
      "train step #7925 accuracy: 0.96875, loss: 0.14337357878684998      \n",
      "train step #7926 accuracy: 0.953125, loss: 0.15988628566265106      \n",
      "train step #7927 accuracy: 0.953125, loss: 0.24982935190200806      \n",
      "train step #7928 accuracy:   1.0, loss: 0.04527093842625618      \n",
      "train step #7929 accuracy: 0.9375, loss: 0.22857719659805298      \n",
      "train step #7930 accuracy: 0.96875, loss: 0.0897805467247963       \n",
      "train step #7931 accuracy: 0.953125, loss: 0.11789380013942719      \n",
      "train step #7932 accuracy: 0.9375, loss: 0.24026578664779663      \n",
      "train step #7933 accuracy: 0.984375, loss: 0.0699380561709404       \n",
      "train step #7934 accuracy: 0.9375, loss: 0.19950388371944427      \n",
      "train step #7935 accuracy: 0.984375, loss: 0.06968390941619873      \n",
      "train step #7936 accuracy: 0.984375, loss: 0.03418489173054695      \n",
      "train step #7937 accuracy: 0.96875, loss: 0.1944212168455124       \n",
      "train step #7938 accuracy: 0.96875, loss: 0.10868328809738159      \n",
      "train step #7939 accuracy: 0.953125, loss: 0.11128657311201096      \n",
      "train step #7940 accuracy: 0.984375, loss: 0.0698857232928276       \n",
      "train step #7941 accuracy: 0.953125, loss: 0.18479850888252258      \n",
      "train step #7942 accuracy: 0.984375, loss: 0.11179567873477936      \n",
      "train step #7943 accuracy: 0.9375, loss: 0.23928280174732208      \n",
      "train step #7944 accuracy: 0.875, loss: 0.4044775068759918       \n",
      "train step #7945 accuracy: 0.890625, loss: 0.3305940628051758       \n",
      "train step #7946 accuracy: 0.984375, loss: 0.07612545043230057      \n",
      "train step #7947 accuracy: 0.984375, loss: 0.0940987691283226       \n",
      "train step #7948 accuracy:   1.0, loss: 0.02543818950653076      \n",
      "train step #7949 accuracy: 0.984375, loss: 0.1041349247097969       \n",
      "train step #7950 accuracy: 0.96875, loss: 0.152764230966568        \n",
      "train step #7951 accuracy: 0.9375, loss: 0.20303034782409668      \n",
      "train step #7952 accuracy: 0.953125, loss: 0.143673375248909        \n",
      "train step #7953 accuracy: 0.984375, loss: 0.07934829592704773      \n",
      "train step #7954 accuracy:   1.0, loss: 0.055611610412597656     \n",
      "train step #7955 accuracy: 0.96875, loss: 0.1008879616856575       \n",
      "train step #7956 accuracy: 0.96875, loss: 0.08023962378501892      \n",
      "train step #7957 accuracy: 0.96875, loss: 0.08766362071037292      \n",
      "train step #7958 accuracy: 0.96875, loss: 0.055807746946811676     \n",
      "train step #7959 accuracy: 0.9375, loss: 0.24906912446022034      \n",
      "train step #7960 accuracy: 0.96875, loss: 0.10652206838130951      \n",
      "train step #7961 accuracy: 0.96875, loss: 0.13434095680713654      \n",
      "train step #7962 accuracy: 0.953125, loss: 0.13873513042926788      \n",
      "train step #7963 accuracy:   1.0, loss: 0.041468262672424316     \n",
      "train step #7964 accuracy: 0.96875, loss: 0.11301813274621964      \n",
      "train step #7965 accuracy: 0.9375, loss: 0.18256017565727234      \n",
      "train step #7966 accuracy: 0.9375, loss: 0.2200392186641693       \n",
      "train step #7967 accuracy:   1.0, loss: 0.02866804227232933      \n",
      "train step #7968 accuracy: 0.9375, loss: 0.16894325613975525      \n",
      "train step #7969 accuracy:   1.0, loss: 0.02522953972220421      \n",
      "train step #7970 accuracy: 0.96875, loss: 0.15924234688282013      \n",
      "train step #7971 accuracy: 0.96875, loss: 0.09716552495956421      \n",
      "train step #7972 accuracy: 0.96875, loss: 0.13752834498882294      \n",
      "train step #7973 accuracy: 0.953125, loss: 0.2934529185295105       \n",
      "train step #7974 accuracy: 0.953125, loss: 0.1926303207874298       \n",
      "train step #7975 accuracy:   1.0, loss: 0.019742436707019806     \n",
      "train step #7976 accuracy: 0.9375, loss: 0.17971214652061462      \n",
      "train step #7977 accuracy: 0.9375, loss: 0.28453072905540466      \n",
      "train step #7978 accuracy: 0.953125, loss: 0.23904044926166534      \n",
      "train step #7979 accuracy: 0.953125, loss: 0.22588440775871277      \n",
      "train step #7980 accuracy: 0.984375, loss: 0.10915140807628632      \n",
      "train step #7981 accuracy: 0.984375, loss: 0.09410590678453445      \n",
      "dev accuracy: 0.9375, loss: 0.07527387142181396      \n",
      "dev accuracy: 0.9375, loss: 0.06814204156398773      \n",
      "dev accuracy:   1.0, loss: 0.011726468801498413     \n",
      "dev accuracy: 0.9375, loss: 0.23984433710575104      \n",
      "dev accuracy: 0.875, loss: 0.38074713945388794      \n",
      "dev accuracy: 0.875, loss: 0.258844256401062        \n",
      "dev accuracy: 0.875, loss: 0.3281061053276062       \n",
      "dev accuracy: 0.9375, loss: 0.3142023980617523       \n",
      "dev accuracy:   1.0, loss: 0.009408712387084961     \n",
      "dev accuracy:   1.0, loss: 0.04434598982334137      \n",
      "dev accuracy:   1.0, loss: 0.12020385265350342      \n",
      "dev accuracy: 0.875, loss: 0.14093439280986786      \n",
      "dev accuracy: 0.9375, loss: 0.19018308818340302      \n",
      "dev accuracy: 0.9375, loss: 0.09210614860057831      \n",
      "dev accuracy: 0.9375, loss: 0.21698136627674103      \n",
      "dev accuracy: 0.875, loss: 0.3382398188114166       \n",
      "dev accuracy:   1.0, loss: 0.0024367868900299072    \n",
      "dev accuracy:   1.0, loss: 0.004297018051147461     \n",
      "dev accuracy: 0.9375, loss: 0.16009443998336792      \n",
      "dev accuracy: 0.9375, loss: 0.38613662123680115      \n",
      "dev accuracy: 0.875, loss: 0.20125004649162292      \n",
      "dev accuracy: 0.875, loss: 0.6263867616653442       \n",
      "dev accuracy: 0.875, loss: 0.1821146458387375       \n",
      "dev accuracy: 0.9375, loss: 0.15800169110298157      \n",
      "dev accuracy: 0.875, loss: 0.5793061256408691       \n",
      "dev accuracy:   1.0, loss: 0.005079507827758789     \n",
      "dev accuracy:   1.0, loss: 0.004239320755004883     \n",
      "dev accuracy: 0.9375, loss: 0.08069056272506714      \n",
      "dev accuracy:   1.0, loss: 0.0063914954662323       \n",
      "dev accuracy: 0.875, loss: 0.19570305943489075      \n",
      "dev accuracy: 0.875, loss: 0.2959774136543274       \n",
      "dev accuracy:   1.0, loss: 0.0480707585811615       \n",
      "dev accuracy:   1.0, loss: 0.033209264278411865     \n",
      "dev accuracy:   1.0, loss: 0.009601294994354248     \n",
      "dev accuracy:   1.0, loss: 0.013202428817749023     \n",
      "dev accuracy: 0.9375, loss: 0.06150704622268677      \n",
      "dev accuracy:   1.0, loss: 0.014552950859069824     \n",
      "dev accuracy:   1.0, loss: 0.017014771699905396     \n",
      "dev accuracy: 0.875, loss: 0.538261890411377        \n",
      "dev accuracy:   1.0, loss: 0.02673611044883728      \n",
      "dev accuracy: 0.875, loss: 0.22033365070819855      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy:   1.0, loss: 0.0012089014053344727    \n",
      "dev accuracy:   1.0, loss: 0.0015210211277008057    \n",
      "dev accuracy: 0.9375, loss: 0.5334696173667908       \n",
      "dev accuracy: 0.9375, loss: 0.14594441652297974      \n",
      "dev accuracy:   1.0, loss: 0.0460965633392334       \n",
      "dev accuracy:   1.0, loss: 0.02224394679069519      \n",
      "dev accuracy: 0.9375, loss: 0.22635339200496674      \n",
      "dev accuracy:   1.0, loss: 0.02660125494003296      \n",
      "dev accuracy: 0.9375, loss: 0.219464510679245        \n",
      "dev accuracy:   1.0, loss: 0.009130656719207764     \n",
      "dev accuracy:   1.0, loss: 0.019348442554473877     \n",
      "dev accuracy: 0.9375, loss: 0.1951681673526764       \n",
      "dev accuracy: 0.875, loss: 0.3421807885169983       \n",
      "dev accuracy: 0.875, loss: 0.24166706204414368      \n",
      "dev accuracy: 0.9375, loss: 0.10772073268890381      \n",
      "dev accuracy: 0.9375, loss: 0.26019129157066345      \n",
      "dev accuracy:   1.0, loss: 0.05896899104118347      \n",
      "dev accuracy:   1.0, loss: 0.04373243451118469      \n",
      "dev accuracy: 0.9375, loss: 0.19008316099643707      \n",
      "dev accuracy:   1.0, loss: 0.10965102910995483      \n",
      "dev accuracy: 0.9375, loss: 0.1933245062828064       \n",
      "dev accuracy:   1.0, loss: 0.005178928375244141     \n",
      "dev accuracy:   1.0, loss: 0.052009403705596924     \n",
      "dev accuracy:   1.0, loss: 0.013337761163711548     \n",
      "dev accuracy: 0.9375, loss: 0.15138590335845947      \n",
      "dev accuracy: 0.9375, loss: 0.29475298523902893      \n",
      "dev accuracy: 0.9375, loss: 0.24797406792640686      \n",
      "dev accuracy:   1.0, loss: 0.007089108228683472     \n",
      "dev accuracy:   1.0, loss: 0.004391789436340332     \n",
      "dev accuracy: 0.9375, loss: 0.111875981092453        \n",
      "dev accuracy:   1.0, loss: 0.041750192642211914     \n",
      "dev accuracy:   1.0, loss: 0.028597980737686157     \n",
      "dev accuracy: 0.9375, loss: 0.13783782720565796      \n",
      "dev accuracy: 0.9375, loss: 0.0763755738735199       \n",
      "dev accuracy: 0.9375, loss: 0.44469133019447327      \n",
      "dev accuracy: 0.8125, loss: 0.44904831051826477      \n",
      "dev accuracy: 0.8125, loss: 0.4887813925743103       \n",
      "dev accuracy: 0.9375, loss: 0.09822237491607666      \n",
      "dev accuracy:   1.0, loss: 0.009827077388763428     \n",
      "dev accuracy:   1.0, loss: 0.011048316955566406     \n",
      "dev accuracy:   1.0, loss: 0.05031237006187439      \n",
      "dev accuracy:  0.75, loss: 0.7537925243377686       \n",
      "dev accuracy:   1.0, loss: 0.002388894557952881     \n",
      "dev accuracy: 0.9375, loss: 0.05265837907791138      \n",
      "dev accuracy: 0.9375, loss: 0.13312608003616333      \n",
      "dev accuracy:   1.0, loss: 0.006365150213241577     \n",
      "dev accuracy: 0.9375, loss: 0.12124402821063995      \n",
      "dev accuracy: 0.9375, loss: 0.24025896191596985      \n",
      "dev accuracy:   1.0, loss: 0.00748211145401001      \n",
      "dev accuracy:   1.0, loss: 0.06232896447181702      \n",
      "dev accuracy: 0.9375, loss: 0.1393319070339203       \n",
      "dev accuracy: 0.9375, loss: 0.10883931815624237      \n",
      "dev accuracy: 0.9375, loss: 0.07731202244758606      \n",
      "dev accuracy:   1.0, loss: 0.10416269302368164      \n",
      "dev accuracy: 0.875, loss: 0.31785595417022705      \n",
      "dev accuracy: 0.9375, loss: 0.16375286877155304      \n",
      "dev accuracy:   1.0, loss: 0.008129507303237915     \n",
      "dev accuracy:   1.0, loss: 0.005478769540786743     \n",
      "dev accuracy: 0.9375, loss: 0.12047043442726135      \n",
      "dev accuracy:   1.0, loss: 0.01792868971824646      \n",
      "dev accuracy: 0.9375, loss: 0.13452164828777313      \n",
      "dev accuracy:   1.0, loss: 0.09866828471422195      \n",
      "dev accuracy: 0.875, loss: 0.3152054250240326       \n",
      "dev accuracy: 0.875, loss: 0.10781726241111755      \n",
      "dev accuracy:   1.0, loss: 0.11147356033325195      \n",
      "dev accuracy:   1.0, loss: 0.004451394081115723     \n",
      "dev accuracy:   1.0, loss: 0.008722484111785889     \n",
      "dev accuracy:   1.0, loss: 0.012595772743225098     \n",
      "dev accuracy: 0.9375, loss: 0.16501986980438232      \n",
      "dev accuracy: 0.9375, loss: 0.40358904004096985      \n",
      "dev accuracy: 0.9375, loss: 0.17742615938186646      \n",
      "dev accuracy: 0.9375, loss: 0.1311609447002411       \n",
      "dev accuracy:   1.0, loss: 0.0021385550498962402    \n",
      "dev accuracy:   1.0, loss: 0.039408162236213684     \n",
      "dev accuracy: 0.9375, loss: 0.4302036762237549       \n",
      "dev accuracy: 0.9375, loss: 0.261599600315094        \n",
      "dev accuracy: 0.9375, loss: 0.15102197229862213      \n",
      "dev accuracy:   1.0, loss: 0.044728755950927734     \n",
      "dev accuracy: 0.9375, loss: 0.3429078459739685       \n",
      "dev accuracy: 0.9375, loss: 0.0636935830116272       \n",
      "dev accuracy: 0.9375, loss: 0.16043947637081146      \n",
      "dev accuracy: 0.9375, loss: 0.13294309377670288      \n",
      "dev accuracy: 0.9375, loss: 0.21086135506629944      \n",
      "dev accuracy: 0.9375, loss: 0.17656210064888         \n",
      "dev accuracy: 0.875, loss: 0.46479567885398865      \n",
      "dev accuracy:   1.0, loss: 0.05871540307998657      \n",
      "dev accuracy:   1.0, loss: 0.004591226577758789     \n",
      "dev accuracy: 0.9375, loss: 0.09830605983734131      \n",
      "dev accuracy: 0.9375, loss: 0.13496635854244232      \n",
      "dev accuracy:   1.0, loss: 0.13466611504554749      \n",
      "dev accuracy:   1.0, loss: 0.06374186277389526      \n",
      "dev accuracy:   1.0, loss: 0.005992323160171509     \n",
      "dev accuracy: 0.9375, loss: 0.09576663374900818      \n",
      "dev accuracy:   1.0, loss: 0.013838529586791992     \n",
      "dev accuracy:   1.0, loss: 0.019822746515274048     \n",
      "dev accuracy:   1.0, loss: 0.03330317139625549      \n",
      "dev accuracy:   1.0, loss: 0.0037553906440734863    \n",
      "dev accuracy: 0.875, loss: 0.21679911017417908      \n",
      "dev accuracy: 0.875, loss: 0.4366191327571869       \n",
      "dev accuracy:   1.0, loss: 0.041876375675201416     \n",
      "dev accuracy: 0.9375, loss: 0.18576478958129883      \n",
      "dev accuracy: 0.9375, loss: 0.2762157917022705       \n",
      "dev accuracy:  0.75, loss: 0.9191511869430542       \n",
      "dev accuracy: 0.9375, loss: 0.22886516153812408      \n",
      "dev accuracy:   1.0, loss: 0.057956963777542114     \n",
      "dev accuracy:   1.0, loss: 0.01968863606452942      \n",
      "dev accuracy: 0.9375, loss: 0.26626378297805786      \n",
      "dev accuracy: 0.875, loss: 0.3706648647785187       \n",
      "dev accuracy: 0.8125, loss: 0.373339980840683        \n",
      "dev accuracy: 0.9375, loss: 0.1561804711818695       \n",
      "dev accuracy:   1.0, loss: 0.012323230504989624     \n",
      "dev accuracy:   1.0, loss: 0.003223925828933716     \n",
      "dev accuracy: 0.9375, loss: 0.07796138525009155      \n",
      "dev accuracy:   1.0, loss: 0.053183674812316895     \n",
      "dev accuracy: 0.8125, loss: 0.6825876235961914       \n",
      "dev accuracy: 0.8125, loss: 0.6425970792770386       \n",
      "dev accuracy: 0.9375, loss: 0.1672562062740326       \n",
      "dev accuracy:   1.0, loss: 0.020049870014190674     \n",
      "dev accuracy:   1.0, loss: 0.05484354496002197      \n",
      "dev accuracy: 0.875, loss: 0.6292626261711121       \n",
      "dev accuracy: 0.9375, loss: 0.0851212739944458       \n",
      "dev accuracy:   1.0, loss: 0.005456268787384033     \n",
      "dev accuracy: 0.9375, loss: 0.13036133348941803      \n",
      "dev accuracy:   1.0, loss: 0.004179120063781738     \n",
      "dev accuracy: 0.9375, loss: 0.45986539125442505      \n",
      "dev accuracy:   1.0, loss: 0.007324278354644775     \n",
      "dev accuracy: 0.875, loss: 0.2836427092552185       \n",
      "dev accuracy:   1.0, loss: 0.002359330654144287     \n",
      "dev accuracy:   1.0, loss: 0.02386501431465149      \n",
      "dev accuracy:   1.0, loss: 0.0360741913318634       \n",
      "dev accuracy: 0.9375, loss: 0.19890260696411133      \n",
      "dev accuracy:   1.0, loss: 0.0020107626914978027    \n",
      "dev accuracy:   1.0, loss: 0.03200221061706543      \n",
      "dev accuracy: 0.9375, loss: 0.17452989518642426      \n",
      "dev accuracy: 0.875, loss: 0.5045879483222961       \n",
      "dev accuracy: 0.9375, loss: 0.05389389395713806      \n",
      "dev accuracy: 0.9375, loss: 0.1411544382572174       \n",
      "dev accuracy:   1.0, loss: 0.004086405038833618     \n",
      "dev accuracy:   1.0, loss: 0.0007568597793579102    \n",
      "dev accuracy: 0.9375, loss: 0.15859101712703705      \n",
      "dev accuracy:   1.0, loss: 0.004410594701766968     \n",
      "dev accuracy: 0.9375, loss: 0.20271459221839905      \n",
      "dev accuracy:   1.0, loss: 0.03127303719520569      \n",
      "dev accuracy: 0.875, loss: 0.24971595406532288      \n",
      "dev accuracy:   1.0, loss: 0.0038818717002868652    \n",
      "dev accuracy: 0.875, loss: 0.7238694429397583       \n",
      "dev accuracy: 0.875, loss: 0.43169474601745605      \n",
      "dev accuracy:   1.0, loss: 0.0031705498695373535    \n",
      "dev accuracy: 0.9375, loss: 0.3012826442718506       \n",
      "dev accuracy:   1.0, loss: 0.0033205747604370117    \n",
      "dev accuracy: 0.9375, loss: 0.42288443446159363      \n",
      "dev accuracy: 0.875, loss: 0.2204672396183014       \n",
      "dev accuracy:   1.0, loss: 0.0054601035080850124    \n",
      "final dev accuracy: 0.9503865979381443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #7982 accuracy: 0.96875, loss: 0.13771182298660278      \n",
      "train step #7983 accuracy: 0.96875, loss: 0.11703081429004669      \n",
      "train step #7984 accuracy:   1.0, loss: 0.03965518996119499      \n",
      "train step #7985 accuracy: 0.96875, loss: 0.11498327553272247      \n",
      "train step #7986 accuracy: 0.96875, loss: 0.1321573704481125       \n",
      "train step #7987 accuracy: 0.984375, loss: 0.10871998965740204      \n",
      "train step #7988 accuracy:   1.0, loss: 0.042925313115119934     \n",
      "train step #7989 accuracy: 0.984375, loss: 0.02679295837879181      \n",
      "train step #7990 accuracy: 0.9375, loss: 0.24435342848300934      \n",
      "train step #7991 accuracy: 0.96875, loss: 0.0931449607014656       \n",
      "train step #7992 accuracy: 0.953125, loss: 0.1819518655538559       \n",
      "train step #7993 accuracy: 0.96875, loss: 0.05994509533047676      \n",
      "train step #7994 accuracy: 0.953125, loss: 0.17062737047672272      \n",
      "train step #7995 accuracy: 0.984375, loss: 0.05818503722548485      \n",
      "train step #7996 accuracy: 0.9375, loss: 0.27411559224128723      \n",
      "train step #7997 accuracy: 0.953125, loss: 0.18828321993350983      \n",
      "train step #7998 accuracy: 0.96875, loss: 0.12312491238117218      \n",
      "train step #7999 accuracy: 0.921875, loss: 0.25869080424308777      \n",
      "train step #8000 accuracy: 0.953125, loss: 0.15921062231063843      \n",
      "train step #8001 accuracy: 0.953125, loss: 0.1711149513721466       \n",
      "train step #8002 accuracy:   1.0, loss: 0.03448263928294182      \n",
      "train step #8003 accuracy: 0.953125, loss: 0.18326498568058014      \n",
      "train step #8004 accuracy: 0.96875, loss: 0.08522254973649979      \n",
      "train step #8005 accuracy: 0.96875, loss: 0.15248841047286987      \n",
      "train step #8006 accuracy: 0.984375, loss: 0.07646425068378448      \n",
      "train step #8007 accuracy: 0.96875, loss: 0.12823757529258728      \n",
      "train step #8008 accuracy: 0.96875, loss: 0.07191689312458038      \n",
      "train step #8009 accuracy: 0.953125, loss: 0.1552441418170929       \n",
      "train step #8010 accuracy:   1.0, loss: 0.06833573430776596      \n",
      "train step #8011 accuracy:   1.0, loss: 0.05481099709868431      \n",
      "train step #8012 accuracy:   1.0, loss: 0.04795879125595093      \n",
      "train step #8013 accuracy: 0.96875, loss: 0.1955960988998413       \n",
      "train step #8014 accuracy: 0.953125, loss: 0.26026469469070435      \n",
      "train step #8015 accuracy: 0.953125, loss: 0.1026211827993393       \n",
      "train step #8016 accuracy: 0.984375, loss: 0.15324577689170837      \n",
      "train step #8017 accuracy:   1.0, loss: 0.07428480684757233      \n",
      "train step #8018 accuracy:   1.0, loss: 0.04358053207397461      \n",
      "train step #8019 accuracy: 0.96875, loss: 0.1391289383172989       \n",
      "train step #8020 accuracy:   1.0, loss: 0.0358857735991478       \n",
      "train step #8021 accuracy: 0.984375, loss: 0.07383151352405548      \n",
      "train step #8022 accuracy: 0.96875, loss: 0.16364215314388275      \n",
      "train step #8023 accuracy: 0.984375, loss: 0.0907081812620163       \n",
      "train step #8024 accuracy: 0.96875, loss: 0.16136392951011658      \n",
      "train step #8025 accuracy: 0.953125, loss: 0.17438797652721405      \n",
      "train step #8026 accuracy: 0.953125, loss: 0.19124184548854828      \n",
      "train step #8027 accuracy: 0.96875, loss: 0.12554383277893066      \n",
      "train step #8028 accuracy: 0.984375, loss: 0.09132414311170578      \n",
      "train step #8029 accuracy: 0.9375, loss: 0.21462811529636383      \n",
      "train step #8030 accuracy: 0.9375, loss: 0.22689922153949738      \n",
      "train step #8031 accuracy: 0.953125, loss: 0.13091221451759338      \n",
      "train step #8032 accuracy: 0.96875, loss: 0.08630882948637009      \n",
      "train step #8033 accuracy: 0.953125, loss: 0.15731140971183777      \n",
      "train step #8034 accuracy: 0.984375, loss: 0.07204829156398773      \n",
      "train step #8035 accuracy: 0.953125, loss: 0.1062154695391655       \n",
      "train step #8036 accuracy: 0.984375, loss: 0.11637973040342331      \n",
      "train step #8037 accuracy: 0.984375, loss: 0.06807882338762283      \n",
      "train step #8038 accuracy: 0.984375, loss: 0.08101782947778702      \n",
      "train step #8039 accuracy:   1.0, loss: 0.023331783711910248     \n",
      "train step #8040 accuracy: 0.890625, loss: 0.288837730884552        \n",
      "train step #8041 accuracy: 0.9375, loss: 0.21347947418689728      \n",
      "train step #8042 accuracy: 0.953125, loss: 0.10886746644973755      \n",
      "train step #8043 accuracy: 0.953125, loss: 0.18772585690021515      \n",
      "train step #8044 accuracy: 0.96875, loss: 0.12395176291465759      \n",
      "train step #8045 accuracy: 0.984375, loss: 0.09537480026483536      \n",
      "train step #8046 accuracy: 0.9375, loss: 0.20721012353897095      \n",
      "train step #8047 accuracy: 0.9375, loss: 0.16251815855503082      \n",
      "train step #8048 accuracy: 0.953125, loss: 0.218042254447937        \n",
      "train step #8049 accuracy: 0.9375, loss: 0.16816221177577972      \n",
      "train step #8050 accuracy: 0.96875, loss: 0.09030996263027191      \n",
      "train step #8051 accuracy: 0.984375, loss: 0.08889029175043106      \n",
      "train step #8052 accuracy: 0.984375, loss: 0.07483495771884918      \n",
      "train step #8053 accuracy: 0.953125, loss: 0.13388659060001373      \n",
      "train step #8054 accuracy: 0.953125, loss: 0.17313870787620544      \n",
      "train step #8055 accuracy: 0.96875, loss: 0.14987434446811676      \n",
      "train step #8056 accuracy:   1.0, loss: 0.031064756214618683     \n",
      "train step #8057 accuracy: 0.984375, loss: 0.052016694098711014     \n",
      "train step #8058 accuracy: 0.984375, loss: 0.12266262620687485      \n",
      "train step #8059 accuracy: 0.9375, loss: 0.24739772081375122      \n",
      "train step #8060 accuracy: 0.9375, loss: 0.2251082807779312       \n",
      "train step #8061 accuracy: 0.953125, loss: 0.13789966702461243      \n",
      "train step #8062 accuracy: 0.96875, loss: 0.1911647617816925       \n",
      "train step #8063 accuracy:   1.0, loss: 0.08181430399417877      \n",
      "train step #8064 accuracy: 0.96875, loss: 0.08358486741781235      \n",
      "train step #8065 accuracy: 0.984375, loss: 0.06124984100461006      \n",
      "train step #8066 accuracy: 0.984375, loss: 0.0454288125038147       \n",
      "train step #8067 accuracy: 0.96875, loss: 0.1274546980857849       \n",
      "train step #8068 accuracy: 0.921875, loss: 0.2823774814605713       \n",
      "train step #8069 accuracy: 0.984375, loss: 0.04359528794884682      \n",
      "train step #8070 accuracy: 0.984375, loss: 0.09358908236026764      \n",
      "train step #8071 accuracy: 0.984375, loss: 0.06573483347892761      \n",
      "train step #8072 accuracy: 0.96875, loss: 0.12869614362716675      \n",
      "train step #8073 accuracy: 0.984375, loss: 0.06462101638317108      \n",
      "train step #8074 accuracy: 0.984375, loss: 0.08809982985258102      \n",
      "train step #8075 accuracy: 0.984375, loss: 0.12138377130031586      \n",
      "train step #8076 accuracy: 0.96875, loss: 0.1582033336162567       \n",
      "train step #8077 accuracy: 0.984375, loss: 0.11980282515287399      \n",
      "train step #8078 accuracy: 0.9375, loss: 0.17472219467163086      \n",
      "train step #8079 accuracy: 0.953125, loss: 0.18003854155540466      \n",
      "train step #8080 accuracy: 0.96875, loss: 0.16667215526103973      \n",
      "train step #8081 accuracy: 0.984375, loss: 0.07119051367044449      \n",
      "train step #8082 accuracy: 0.953125, loss: 0.21127080917358398      \n",
      "train step #8083 accuracy: 0.984375, loss: 0.11089015007019043      \n",
      "train step #8084 accuracy: 0.984375, loss: 0.10176912695169449      \n",
      "train step #8085 accuracy: 0.984375, loss: 0.09608638286590576      \n",
      "train step #8086 accuracy: 0.984375, loss: 0.07375844568014145      \n",
      "train step #8087 accuracy: 0.96875, loss: 0.11618491262197495      \n",
      "train step #8088 accuracy:   1.0, loss: 0.052851103246212006     \n",
      "train step #8089 accuracy: 0.953125, loss: 0.14185300469398499      \n",
      "train step #8090 accuracy: 0.984375, loss: 0.0674089789390564       \n",
      "train step #8091 accuracy: 0.9375, loss: 0.1810615211725235       \n",
      "train step #8092 accuracy: 0.984375, loss: 0.09675999730825424      \n",
      "train step #8093 accuracy:   1.0, loss: 0.05528421700000763      \n",
      "train step #8094 accuracy: 0.921875, loss: 0.30304309725761414      \n",
      "train step #8095 accuracy: 0.9375, loss: 0.2972707748413086       \n",
      "train step #8096 accuracy: 0.96875, loss: 0.09693249315023422      \n",
      "train step #8097 accuracy: 0.984375, loss: 0.07542581856250763      \n",
      "train step #8098 accuracy: 0.875, loss: 0.31777071952819824      \n",
      "train step #8099 accuracy: 0.96875, loss: 0.09166424721479416      \n",
      "train step #8100 accuracy: 0.953125, loss: 0.13086813688278198      \n",
      "train step #8101 accuracy: 0.984375, loss: 0.0874696746468544       \n",
      "train step #8102 accuracy: 0.96875, loss: 0.13302713632583618      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #8103 accuracy: 0.953125, loss: 0.14696243405342102      \n",
      "train step #8104 accuracy: 0.96875, loss: 0.18543536961078644      \n",
      "train step #8105 accuracy: 0.96875, loss: 0.1500849723815918       \n",
      "train step #8106 accuracy: 0.984375, loss: 0.06543934345245361      \n",
      "train step #8107 accuracy: 0.984375, loss: 0.03635247051715851      \n",
      "train step #8108 accuracy: 0.953125, loss: 0.19467400014400482      \n",
      "train step #8109 accuracy: 0.96875, loss: 0.10016871243715286      \n",
      "train step #8110 accuracy: 0.953125, loss: 0.1907535046339035       \n",
      "train step #8111 accuracy: 0.96875, loss: 0.12274104356765747      \n",
      "train step #8112 accuracy: 0.953125, loss: 0.16700352728366852      \n",
      "train step #8113 accuracy: 0.9375, loss: 0.16374291479587555      \n",
      "train step #8114 accuracy: 0.953125, loss: 0.14096172153949738      \n",
      "train step #8115 accuracy: 0.90625, loss: 0.33526912331581116      \n",
      "train step #8116 accuracy: 0.984375, loss: 0.08096099644899368      \n",
      "train step #8117 accuracy: 0.9375, loss: 0.2113281488418579       \n",
      "train step #8118 accuracy: 0.96875, loss: 0.14101846516132355      \n",
      "train step #8119 accuracy: 0.96875, loss: 0.09405995160341263      \n",
      "train step #8120 accuracy: 0.96875, loss: 0.1013810932636261       \n",
      "train step #8121 accuracy: 0.96875, loss: 0.1347944289445877       \n",
      "train step #8122 accuracy: 0.890625, loss: 0.3576526641845703       \n",
      "train step #8123 accuracy: 0.984375, loss: 0.07658402621746063      \n",
      "train step #8124 accuracy: 0.953125, loss: 0.21531358361244202      \n",
      "train step #8125 accuracy: 0.984375, loss: 0.09406115859746933      \n",
      "train step #8126 accuracy: 0.96875, loss: 0.11947143077850342      \n",
      "train step #8127 accuracy: 0.953125, loss: 0.25866037607192993      \n",
      "train step #8128 accuracy: 0.96875, loss: 0.14008541405200958      \n",
      "train step #8129 accuracy: 0.953125, loss: 0.17775695025920868      \n",
      "train step #8130 accuracy: 0.96875, loss: 0.09687557816505432      \n",
      "train step #8131 accuracy: 0.921875, loss: 0.32227200269699097      \n",
      "train step #8132 accuracy: 0.9375, loss: 0.1539815068244934       \n",
      "train step #8133 accuracy: 0.984375, loss: 0.1165856197476387       \n",
      "train step #8134 accuracy: 0.921875, loss: 0.2607686221599579       \n",
      "train step #8135 accuracy: 0.921875, loss: 0.26069748401641846      \n",
      "train step #8136 accuracy: 0.96875, loss: 0.09596274793148041      \n",
      "train step #8137 accuracy: 0.984375, loss: 0.05272030457854271      \n",
      "train step #8138 accuracy: 0.96875, loss: 0.16648870706558228      \n",
      "train step #8139 accuracy: 0.953125, loss: 0.1125296950340271       \n",
      "train step #8140 accuracy: 0.9375, loss: 0.21724984049797058      \n",
      "train step #8141 accuracy: 0.953125, loss: 0.1752748340368271       \n",
      "train step #8142 accuracy: 0.9375, loss: 0.1238473430275917       \n",
      "train step #8143 accuracy: 0.96875, loss: 0.11205660551786423      \n",
      "train step #8144 accuracy: 0.96875, loss: 0.13275235891342163      \n",
      "train step #8145 accuracy: 0.984375, loss: 0.04644344747066498      \n",
      "train step #8146 accuracy: 0.984375, loss: 0.06086396425962448      \n",
      "train step #8147 accuracy: 0.96875, loss: 0.09140517562627792      \n",
      "train step #8148 accuracy: 0.984375, loss: 0.0851248949766159       \n",
      "train step #8149 accuracy: 0.953125, loss: 0.15272191166877747      \n",
      "train step #8150 accuracy: 0.96875, loss: 0.0964888483285904       \n",
      "train step #8151 accuracy: 0.984375, loss: 0.05080389976501465      \n",
      "train step #8152 accuracy: 0.953125, loss: 0.16634505987167358      \n",
      "train step #8153 accuracy: 0.953125, loss: 0.24968497455120087      \n",
      "train step #8154 accuracy: 0.953125, loss: 0.21846254169940948      \n",
      "train step #8155 accuracy: 0.9375, loss: 0.18555787205696106      \n",
      "train step #8156 accuracy: 0.921875, loss: 0.2626149356365204       \n",
      "train step #8157 accuracy: 0.9375, loss: 0.39278948307037354      \n",
      "train step #8158 accuracy: 0.921875, loss: 0.2108137160539627       \n",
      "train step #8159 accuracy:   1.0, loss: 0.03114967793226242      \n",
      "train step #8160 accuracy: 0.921875, loss: 0.21016450226306915      \n",
      "train step #8161 accuracy: 0.953125, loss: 0.22126850485801697      \n",
      "train step #8162 accuracy: 0.9375, loss: 0.12760509550571442      \n",
      "train step #8163 accuracy: 0.96875, loss: 0.06073378771543503      \n",
      "train step #8164 accuracy: 0.921875, loss: 0.18044380843639374      \n",
      "train step #8165 accuracy:   1.0, loss: 0.03381752222776413      \n",
      "train step #8166 accuracy: 0.953125, loss: 0.1560155600309372       \n",
      "train step #8167 accuracy: 0.953125, loss: 0.20722100138664246      \n",
      "train step #8168 accuracy: 0.984375, loss: 0.11476718634366989      \n",
      "train step #8169 accuracy: 0.953125, loss: 0.10317832976579666      \n",
      "train step #8170 accuracy: 0.953125, loss: 0.13077445328235626      \n",
      "train step #8171 accuracy: 0.921875, loss: 0.15242227911949158      \n",
      "train step #8172 accuracy: 0.921875, loss: 0.23209461569786072      \n",
      "train step #8173 accuracy: 0.96875, loss: 0.15783165395259857      \n",
      "train step #8174 accuracy: 0.9375, loss: 0.2628938555717468       \n",
      "train step #8175 accuracy: 0.96875, loss: 0.1570766568183899       \n",
      "train step #8176 accuracy: 0.9375, loss: 0.1714608073234558       \n",
      "train step #8177 accuracy: 0.984375, loss: 0.052998654544353485     \n",
      "train step #8178 accuracy: 0.96875, loss: 0.20349298417568207      \n",
      "train step #8179 accuracy: 0.953125, loss: 0.16151414811611176      \n",
      "train step #8180 accuracy: 0.96875, loss: 0.10400257259607315      \n",
      "train step #8181 accuracy: 0.9375, loss: 0.26288503408432007      \n",
      "train step #8182 accuracy: 0.96875, loss: 0.10400348901748657      \n",
      "train step #8183 accuracy: 0.984375, loss: 0.10678611695766449      \n",
      "train step #8184 accuracy: 0.984375, loss: 0.10746484249830246      \n",
      "train step #8185 accuracy: 0.96875, loss: 0.06721651554107666      \n",
      "train step #8186 accuracy: 0.984375, loss: 0.06658381968736649      \n",
      "train step #8187 accuracy: 0.96875, loss: 0.16343028843402863      \n",
      "train step #8188 accuracy: 0.953125, loss: 0.11217161267995834      \n",
      "train step #8189 accuracy: 0.953125, loss: 0.2136726677417755       \n",
      "train step #8190 accuracy: 0.984375, loss: 0.1197456493973732       \n",
      "train step #8191 accuracy: 0.96875, loss: 0.0766449123620987       \n",
      "train step #8192 accuracy: 0.953125, loss: 0.12822769582271576      \n",
      "train step #8193 accuracy: 0.96875, loss: 0.12533725798130035      \n",
      "train step #8194 accuracy:   1.0, loss: 0.04617925360798836      \n",
      "train step #8195 accuracy: 0.953125, loss: 0.20298026502132416      \n",
      "train step #8196 accuracy: 0.96875, loss: 0.16645939648151398      \n",
      "train step #8197 accuracy: 0.984375, loss: 0.05520273745059967      \n",
      "train step #8198 accuracy: 0.953125, loss: 0.14169439673423767      \n",
      "train step #8199 accuracy: 0.9375, loss: 0.23016253113746643      \n",
      "train step #8200 accuracy: 0.984375, loss: 0.055599696934223175     \n",
      "train step #8201 accuracy: 0.96875, loss: 0.17761296033859253      \n",
      "train step #8202 accuracy: 0.953125, loss: 0.09734100103378296      \n",
      "train step #8203 accuracy: 0.96875, loss: 0.11751732975244522      \n",
      "train step #8204 accuracy: 0.984375, loss: 0.04488229379057884      \n",
      "train step #8205 accuracy: 0.9375, loss: 0.11933337897062302      \n",
      "train step #8206 accuracy: 0.984375, loss: 0.039743438363075256     \n",
      "train step #8207 accuracy: 0.96875, loss: 0.11998682469129562      \n",
      "train step #8208 accuracy: 0.96875, loss: 0.0918903574347496       \n",
      "train step #8209 accuracy: 0.9375, loss: 0.23908263444900513      \n",
      "train step #8210 accuracy: 0.984375, loss: 0.045497190207242966     \n",
      "train step #8211 accuracy:   1.0, loss: 0.027782514691352844     \n",
      "train step #8212 accuracy: 0.984375, loss: 0.053117137402296066     \n",
      "train step #8213 accuracy: 0.984375, loss: 0.06923385709524155      \n",
      "train step #8214 accuracy: 0.984375, loss: 0.06169825792312622      \n",
      "train step #8215 accuracy: 0.953125, loss: 0.15622133016586304      \n",
      "train step #8216 accuracy: 0.96875, loss: 0.16855302453041077      \n",
      "train step #8217 accuracy: 0.96875, loss: 0.09551109373569489      \n",
      "train step #8218 accuracy: 0.953125, loss: 0.13218651711940765      \n",
      "train step #8219 accuracy: 0.96875, loss: 0.1521759182214737       \n",
      "train step #8220 accuracy: 0.921875, loss: 0.17089611291885376      \n",
      "train step #8221 accuracy: 0.984375, loss: 0.0575496070086956       \n",
      "train step #8222 accuracy: 0.953125, loss: 0.13783575594425201      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #8223 accuracy: 0.953125, loss: 0.16629527509212494      \n",
      "train step #8224 accuracy: 0.96875, loss: 0.08732807636260986      \n",
      "train step #8225 accuracy: 0.96875, loss: 0.16391180455684662      \n",
      "train step #8226 accuracy: 0.96875, loss: 0.12449948489665985      \n",
      "train step #8227 accuracy: 0.9375, loss: 0.13805033266544342      \n",
      "train step #8228 accuracy: 0.984375, loss: 0.047969721257686615     \n",
      "train step #8229 accuracy:   1.0, loss: 0.021245427429676056     \n",
      "train step #8230 accuracy: 0.984375, loss: 0.0638519674539566       \n",
      "train step #8231 accuracy: 0.984375, loss: 0.09534260630607605      \n",
      "train step #8232 accuracy: 0.96875, loss: 0.2057095468044281       \n",
      "train step #8233 accuracy: 0.953125, loss: 0.10490294545888901      \n",
      "train step #8234 accuracy: 0.953125, loss: 0.13076843321323395      \n",
      "train step #8235 accuracy: 0.984375, loss: 0.08338786661624908      \n",
      "train step #8236 accuracy: 0.9375, loss: 0.21077264845371246      \n",
      "train step #8237 accuracy: 0.953125, loss: 0.22925323247909546      \n",
      "train step #8238 accuracy: 0.953125, loss: 0.16820450127124786      \n",
      "train step #8239 accuracy: 0.953125, loss: 0.2349015325307846       \n",
      "train step #8240 accuracy: 0.984375, loss: 0.05793643370270729      \n",
      "train step #8241 accuracy: 0.984375, loss: 0.09915778785943985      \n",
      "train step #8242 accuracy: 0.96875, loss: 0.10063216835260391      \n",
      "train step #8243 accuracy: 0.921875, loss: 0.17846758663654327      \n",
      "train step #8244 accuracy: 0.984375, loss: 0.059399597346782684     \n",
      "train step #8245 accuracy: 0.984375, loss: 0.06319615989923477      \n",
      "train step #8246 accuracy: 0.96875, loss: 0.19042930006980896      \n",
      "train step #8247 accuracy: 0.96875, loss: 0.12432757765054703      \n",
      "train step #8248 accuracy: 0.921875, loss: 0.24733608961105347      \n",
      "train step #8249 accuracy: 0.984375, loss: 0.06151164695620537      \n",
      "train step #8250 accuracy: 0.984375, loss: 0.04310663044452667      \n",
      "train step #8251 accuracy: 0.9375, loss: 0.2080913484096527       \n",
      "train step #8252 accuracy: 0.984375, loss: 0.06049509346485138      \n",
      "train step #8253 accuracy: 0.921875, loss: 0.15586411952972412      \n",
      "train step #8254 accuracy: 0.984375, loss: 0.08871947228908539      \n",
      "train step #8255 accuracy: 0.953125, loss: 0.16150853037834167      \n",
      "train step #8256 accuracy:   1.0, loss: 0.024249322712421417     \n",
      "train step #8257 accuracy: 0.96875, loss: 0.13338541984558105      \n",
      "train step #8258 accuracy: 0.921875, loss: 0.21870329976081848      \n",
      "train step #8259 accuracy: 0.953125, loss: 0.14723345637321472      \n",
      "train step #8260 accuracy: 0.984375, loss: 0.08246023952960968      \n",
      "train step #8261 accuracy: 0.953125, loss: 0.18793413043022156      \n",
      "train step #8262 accuracy: 0.984375, loss: 0.08431531488895416      \n",
      "train step #8263 accuracy: 0.953125, loss: 0.1929108202457428       \n",
      "train step #8264 accuracy: 0.984375, loss: 0.08655450493097305      \n",
      "train step #8265 accuracy: 0.953125, loss: 0.22586147487163544      \n",
      "train step #8266 accuracy: 0.953125, loss: 0.1831594556570053       \n",
      "train step #8267 accuracy: 0.953125, loss: 0.16324922442436218      \n",
      "train step #8268 accuracy: 0.9375, loss: 0.16425660252571106      \n",
      "train step #8269 accuracy: 0.953125, loss: 0.13465236127376556      \n",
      "train step #8270 accuracy: 0.9375, loss: 0.24259452521800995      \n",
      "train step #8271 accuracy: 0.96875, loss: 0.12233037501573563      \n",
      "train step #8272 accuracy: 0.984375, loss: 0.12410511076450348      \n",
      "train step #8273 accuracy: 0.96875, loss: 0.1578042209148407       \n",
      "train step #8274 accuracy: 0.96875, loss: 0.0709022730588913       \n",
      "train step #8275 accuracy: 0.984375, loss: 0.04547204077243805      \n",
      "train step #8276 accuracy: 0.96875, loss: 0.1110977977514267       \n",
      "train step #8277 accuracy: 0.953125, loss: 0.18024638295173645      \n",
      "train step #8278 accuracy: 0.984375, loss: 0.11353957653045654      \n",
      "train step #8279 accuracy: 0.9375, loss: 0.26229023933410645      \n",
      "train step #8280 accuracy: 0.96875, loss: 0.12326408922672272      \n",
      "train step #8281 accuracy:   1.0, loss: 0.024350017309188843     \n",
      "train step #8282 accuracy: 0.984375, loss: 0.11552178114652634      \n",
      "train step #8283 accuracy: 0.984375, loss: 0.05811287835240364      \n",
      "train step #8284 accuracy: 0.96875, loss: 0.11950981616973877      \n",
      "train step #8285 accuracy: 0.9375, loss: 0.16380992531776428      \n",
      "train step #8286 accuracy: 0.9375, loss: 0.10320864617824554      \n",
      "train step #8287 accuracy: 0.984375, loss: 0.07596482336521149      \n",
      "train step #8288 accuracy: 0.96875, loss: 0.15370774269104004      \n",
      "train step #8289 accuracy: 0.984375, loss: 0.1258307695388794       \n",
      "train step #8290 accuracy: 0.9375, loss: 0.3595224618911743       \n",
      "train step #8291 accuracy: 0.96875, loss: 0.1341593712568283       \n",
      "train step #8292 accuracy: 0.9375, loss: 0.2949739098548889       \n",
      "train step #8293 accuracy: 0.90625, loss: 0.27046075463294983      \n",
      "train step #8294 accuracy: 0.96875, loss: 0.08827558159828186      \n",
      "train step #8295 accuracy: 0.96875, loss: 0.1277843415737152       \n",
      "train step #8296 accuracy: 0.953125, loss: 0.1525692343711853       \n",
      "train step #8297 accuracy: 0.953125, loss: 0.1711064875125885       \n",
      "train step #8298 accuracy: 0.96875, loss: 0.10615447163581848      \n",
      "train step #8299 accuracy: 0.96875, loss: 0.08247436583042145      \n",
      "train step #8300 accuracy: 0.984375, loss: 0.0418560728430748       \n",
      "train step #8301 accuracy: 0.984375, loss: 0.09831222146749496      \n",
      "train step #8302 accuracy: 0.984375, loss: 0.07816796749830246      \n",
      "train step #8303 accuracy: 0.984375, loss: 0.10952972620725632      \n",
      "train step #8304 accuracy: 0.921875, loss: 0.19350038468837738      \n",
      "train step #8305 accuracy: 0.9375, loss: 0.3186822533607483       \n",
      "train step #8306 accuracy:   1.0, loss: 0.031571436673402786     \n",
      "train step #8307 accuracy: 0.96875, loss: 0.24683696031570435      \n",
      "train step #8308 accuracy: 0.984375, loss: 0.10450609028339386      \n",
      "train step #8309 accuracy: 0.984375, loss: 0.03400038182735443      \n",
      "train step #8310 accuracy: 0.96875, loss: 0.163707435131073        \n",
      "train step #8311 accuracy: 0.96875, loss: 0.13098928332328796      \n",
      "train step #8312 accuracy: 0.921875, loss: 0.17112194001674652      \n",
      "train step #8313 accuracy: 0.984375, loss: 0.0778321772813797       \n",
      "train step #8314 accuracy: 0.96875, loss: 0.10291524976491928      \n",
      "train step #8315 accuracy: 0.96875, loss: 0.061687249690294266     \n",
      "train step #8316 accuracy: 0.953125, loss: 0.13316330313682556      \n",
      "train step #8317 accuracy: 0.984375, loss: 0.04122866690158844      \n",
      "train step #8318 accuracy: 0.953125, loss: 0.20941296219825745      \n",
      "train step #8319 accuracy: 0.96875, loss: 0.10701379179954529      \n",
      "train step #8320 accuracy: 0.953125, loss: 0.2181330919265747       \n",
      "train step #8321 accuracy: 0.984375, loss: 0.1264328807592392       \n",
      "train step #8322 accuracy: 0.96875, loss: 0.1611161231994629       \n",
      "train step #8323 accuracy: 0.953125, loss: 0.2536005973815918       \n",
      "train step #8324 accuracy: 0.953125, loss: 0.15253405272960663      \n",
      "train step #8325 accuracy: 0.90625, loss: 0.24522258341312408      \n",
      "train step #8326 accuracy: 0.984375, loss: 0.06834631413221359      \n",
      "train step #8327 accuracy: 0.890625, loss: 0.34943079948425293      \n",
      "train step #8328 accuracy: 0.96875, loss: 0.1195271760225296       \n",
      "dev accuracy: 0.9375, loss: 0.1299409419298172       \n",
      "dev accuracy:   1.0, loss: 0.01100727915763855      \n",
      "dev accuracy:   1.0, loss: 0.007585883140563965     \n",
      "dev accuracy: 0.9375, loss: 0.3205361068248749       \n",
      "dev accuracy:   1.0, loss: 0.003684490919113159     \n",
      "dev accuracy: 0.9375, loss: 0.19584709405899048      \n",
      "dev accuracy: 0.9375, loss: 0.3781619966030121       \n",
      "dev accuracy:   1.0, loss: 0.01537594199180603      \n",
      "dev accuracy:   1.0, loss: 0.12422464787960052      \n",
      "dev accuracy:   1.0, loss: 0.00015777349472045898   \n",
      "dev accuracy: 0.9375, loss: 0.2856808006763458       \n",
      "dev accuracy:   1.0, loss: 0.0036196112632751465    \n",
      "dev accuracy:   1.0, loss: 0.05021992325782776      \n",
      "dev accuracy:   1.0, loss: 0.02696216106414795      \n",
      "dev accuracy:   1.0, loss: 0.03513598442077637      \n",
      "dev accuracy: 0.9375, loss: 0.11744403839111328      \n",
      "dev accuracy:   1.0, loss: 0.048120081424713135     \n",
      "dev accuracy: 0.9375, loss: 0.25972625613212585      \n",
      "dev accuracy:   1.0, loss: 0.04085572063922882      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy:   1.0, loss: 0.010563135147094727     \n",
      "dev accuracy: 0.875, loss: 0.6257886290550232       \n",
      "dev accuracy:   1.0, loss: 0.00821039080619812      \n",
      "dev accuracy:   1.0, loss: 0.010069310665130615     \n",
      "dev accuracy: 0.9375, loss: 0.08152282238006592      \n",
      "dev accuracy: 0.875, loss: 0.6887394189834595       \n",
      "dev accuracy: 0.9375, loss: 0.417586088180542        \n",
      "dev accuracy: 0.875, loss: 0.699939489364624        \n",
      "dev accuracy: 0.9375, loss: 0.11044500768184662      \n",
      "dev accuracy: 0.8125, loss: 1.2307108640670776       \n",
      "dev accuracy:   1.0, loss: 0.0005266666412353516    \n",
      "dev accuracy: 0.9375, loss: 0.3005008399486542       \n",
      "dev accuracy: 0.8125, loss: 0.631926417350769        \n",
      "dev accuracy:   1.0, loss: 0.005716979503631592     \n",
      "dev accuracy:   1.0, loss: 0.01796334981918335      \n",
      "dev accuracy: 0.9375, loss: 0.1511872261762619       \n",
      "dev accuracy:   1.0, loss: 0.0010496973991394043    \n",
      "dev accuracy: 0.9375, loss: 0.43177980184555054      \n",
      "dev accuracy: 0.875, loss: 0.48137494921684265      \n",
      "dev accuracy:   1.0, loss: 0.0322858989238739       \n",
      "dev accuracy: 0.875, loss: 0.4822690784931183       \n",
      "dev accuracy:   1.0, loss: 0.03720057010650635      \n",
      "dev accuracy:   1.0, loss: 0.04521492123603821      \n",
      "dev accuracy: 0.875, loss: 0.4470588266849518       \n",
      "dev accuracy: 0.9375, loss: 0.07951346039772034      \n",
      "dev accuracy: 0.9375, loss: 0.174247607588768        \n",
      "dev accuracy: 0.9375, loss: 0.09539321064949036      \n",
      "dev accuracy: 0.9375, loss: 0.14636772871017456      \n",
      "dev accuracy: 0.8125, loss: 0.44003957509994507      \n",
      "dev accuracy:   1.0, loss: 0.03268703818321228      \n",
      "dev accuracy: 0.875, loss: 0.3694702982902527       \n",
      "dev accuracy:   1.0, loss: 0.03233209252357483      \n",
      "dev accuracy: 0.9375, loss: 0.08940640091896057      \n",
      "dev accuracy: 0.9375, loss: 0.44487789273262024      \n",
      "dev accuracy: 0.9375, loss: 0.43290236592292786      \n",
      "dev accuracy: 0.875, loss: 0.1810358464717865       \n",
      "dev accuracy: 0.9375, loss: 0.5121845006942749       \n",
      "dev accuracy: 0.9375, loss: 0.11760833859443665      \n",
      "dev accuracy: 0.9375, loss: 0.07359018921852112      \n",
      "dev accuracy: 0.875, loss: 0.26088058948516846      \n",
      "dev accuracy:   1.0, loss: 0.008861362934112549     \n",
      "dev accuracy:   1.0, loss: 0.03771275281906128      \n",
      "dev accuracy:   1.0, loss: 0.006293654441833496     \n",
      "dev accuracy: 0.9375, loss: 0.17787906527519226      \n",
      "dev accuracy:   1.0, loss: 0.046347200870513916     \n",
      "dev accuracy: 0.9375, loss: 0.179371178150177        \n",
      "dev accuracy: 0.875, loss: 0.4513689875602722       \n",
      "dev accuracy: 0.875, loss: 0.5962265729904175       \n",
      "dev accuracy: 0.9375, loss: 0.32915812730789185      \n",
      "dev accuracy:   1.0, loss: 0.01091068983078003      \n",
      "dev accuracy:   1.0, loss: 0.10470375418663025      \n",
      "dev accuracy: 0.9375, loss: 0.09172192215919495      \n",
      "dev accuracy:   1.0, loss: 0.005740255117416382     \n",
      "dev accuracy: 0.8125, loss: 0.4410238564014435       \n",
      "dev accuracy: 0.9375, loss: 0.20442360639572144      \n",
      "dev accuracy: 0.9375, loss: 0.13834717869758606      \n",
      "dev accuracy:   1.0, loss: 0.005544900894165039     \n",
      "dev accuracy:   1.0, loss: 0.023422449827194214     \n",
      "dev accuracy:   1.0, loss: 0.04238861799240112      \n",
      "dev accuracy: 0.9375, loss: 0.13545122742652893      \n",
      "dev accuracy: 0.9375, loss: 0.16672363877296448      \n",
      "dev accuracy:   1.0, loss: 0.008199840784072876     \n",
      "dev accuracy: 0.875, loss: 0.372289776802063        \n",
      "dev accuracy: 0.9375, loss: 0.3482024073600769       \n",
      "dev accuracy: 0.9375, loss: 0.26742663979530334      \n",
      "dev accuracy: 0.875, loss: 0.17295697331428528      \n",
      "dev accuracy:   1.0, loss: 0.05580991506576538      \n",
      "dev accuracy: 0.875, loss: 0.3481043577194214       \n",
      "dev accuracy:   1.0, loss: 0.04802846908569336      \n",
      "dev accuracy: 0.875, loss: 0.27196452021598816      \n",
      "dev accuracy:   1.0, loss: 0.0029961466789245605    \n",
      "dev accuracy: 0.9375, loss: 0.4447157680988312       \n",
      "dev accuracy: 0.9375, loss: 0.09442806243896484      \n",
      "dev accuracy:   1.0, loss: 0.0013000965118408203    \n",
      "dev accuracy: 0.9375, loss: 0.2588597536087036       \n",
      "dev accuracy:   1.0, loss: 0.005167365074157715     \n",
      "dev accuracy:   1.0, loss: 0.10698113590478897      \n",
      "dev accuracy: 0.875, loss: 0.2598653733730316       \n",
      "dev accuracy:   1.0, loss: 0.13735619187355042      \n",
      "dev accuracy: 0.9375, loss: 0.11305854469537735      \n",
      "dev accuracy: 0.875, loss: 0.18349289894104004      \n",
      "dev accuracy: 0.9375, loss: 0.10662028193473816      \n",
      "dev accuracy: 0.9375, loss: 0.1614242047071457       \n",
      "dev accuracy:   1.0, loss: 0.002359449863433838     \n",
      "dev accuracy: 0.9375, loss: 0.3541807532310486       \n",
      "dev accuracy: 0.9375, loss: 0.08560764789581299      \n",
      "dev accuracy: 0.8125, loss: 0.5296850204467773       \n",
      "dev accuracy:   1.0, loss: 0.005766510963439941     \n",
      "dev accuracy:   1.0, loss: 0.03657156229019165      \n",
      "dev accuracy: 0.9375, loss: 0.11547964811325073      \n",
      "dev accuracy:   1.0, loss: 0.01748529076576233      \n",
      "dev accuracy: 0.875, loss: 0.29649507999420166      \n",
      "dev accuracy: 0.9375, loss: 0.2041875272989273       \n",
      "dev accuracy:   1.0, loss: 0.030695080757141113     \n",
      "dev accuracy:   1.0, loss: 0.006983160972595215     \n",
      "dev accuracy:   1.0, loss: 0.12943799793720245      \n",
      "dev accuracy: 0.9375, loss: 0.16477376222610474      \n",
      "dev accuracy: 0.9375, loss: 0.0945090651512146       \n",
      "dev accuracy: 0.8125, loss: 0.48563891649246216      \n",
      "dev accuracy:   1.0, loss: 0.04271635413169861      \n",
      "dev accuracy: 0.9375, loss: 0.19946545362472534      \n",
      "dev accuracy: 0.9375, loss: 0.20205138623714447      \n",
      "dev accuracy: 0.9375, loss: 0.18036213517189026      \n",
      "dev accuracy: 0.9375, loss: 0.05742001533508301      \n",
      "dev accuracy:   1.0, loss: 0.010677307844161987     \n",
      "dev accuracy: 0.9375, loss: 0.18866409361362457      \n",
      "dev accuracy:   1.0, loss: 0.021555840969085693     \n",
      "dev accuracy:   1.0, loss: 0.024220943450927734     \n",
      "dev accuracy:   1.0, loss: 0.0756605863571167       \n",
      "dev accuracy: 0.9375, loss: 0.13469554483890533      \n",
      "dev accuracy: 0.9375, loss: 0.10222865641117096      \n",
      "dev accuracy:   1.0, loss: 0.017627328634262085     \n",
      "dev accuracy: 0.9375, loss: 0.07312622666358948      \n",
      "dev accuracy: 0.9375, loss: 0.21176430583000183      \n",
      "dev accuracy:   1.0, loss: 0.0007651448249816895    \n",
      "dev accuracy: 0.875, loss: 0.30352890491485596      \n",
      "dev accuracy: 0.875, loss: 0.31142497062683105      \n",
      "dev accuracy:   1.0, loss: 0.015102595090866089     \n",
      "dev accuracy: 0.875, loss: 0.3132534623146057       \n",
      "dev accuracy: 0.9375, loss: 0.061189353466033936     \n",
      "dev accuracy:   1.0, loss: 0.04264822602272034      \n",
      "dev accuracy:   1.0, loss: 0.03930389881134033      \n",
      "dev accuracy:   1.0, loss: 0.004971683025360107     \n",
      "dev accuracy:   1.0, loss: 0.007795989513397217     \n",
      "dev accuracy: 0.9375, loss: 0.14161890745162964      \n",
      "dev accuracy:   1.0, loss: 0.03074824810028076      \n",
      "dev accuracy: 0.875, loss: 0.19635218381881714      \n",
      "dev accuracy:   1.0, loss: 0.01096951961517334      \n",
      "dev accuracy: 0.8125, loss: 0.42237216234207153      \n",
      "dev accuracy: 0.9375, loss: 0.19607850909233093      \n",
      "dev accuracy:   1.0, loss: 0.05132099986076355      \n",
      "dev accuracy:   1.0, loss: 0.04202955961227417      \n",
      "dev accuracy:   1.0, loss: 0.017461925745010376     \n",
      "dev accuracy: 0.9375, loss: 0.11126530170440674      \n",
      "dev accuracy:   1.0, loss: 0.005163997411727905     \n",
      "dev accuracy: 0.9375, loss: 0.12540851533412933      \n",
      "dev accuracy: 0.9375, loss: 0.21002113819122314      \n",
      "dev accuracy:   1.0, loss: 0.007588207721710205     \n",
      "dev accuracy:   1.0, loss: 0.006734251976013184     \n",
      "dev accuracy:   1.0, loss: 0.004108428955078125     \n",
      "dev accuracy: 0.875, loss: 0.20431430637836456      \n",
      "dev accuracy: 0.9375, loss: 0.10654407739639282      \n",
      "dev accuracy: 0.875, loss: 0.2379787117242813       \n",
      "dev accuracy: 0.9375, loss: 0.14188623428344727      \n",
      "dev accuracy:   1.0, loss: 0.08004556596279144      \n",
      "dev accuracy:   1.0, loss: 0.015698134899139404     \n",
      "dev accuracy: 0.9375, loss: 0.2515038251876831       \n",
      "dev accuracy:   1.0, loss: 0.004831880331039429     \n",
      "dev accuracy: 0.875, loss: 0.19473432004451752      \n",
      "dev accuracy:   1.0, loss: 0.02892705798149109      \n",
      "dev accuracy:   1.0, loss: 0.017210066318511963     \n",
      "dev accuracy: 0.875, loss: 0.4577152729034424       \n",
      "dev accuracy: 0.9375, loss: 0.2011110782623291       \n",
      "dev accuracy: 0.9375, loss: 0.11944654583930969      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy: 0.9375, loss: 0.11437249183654785      \n",
      "dev accuracy: 0.9375, loss: 0.09433847665786743      \n",
      "dev accuracy:   1.0, loss: 0.011026203632354736     \n",
      "dev accuracy:   1.0, loss: 0.004000604152679443     \n",
      "dev accuracy: 0.9375, loss: 0.06363540887832642      \n",
      "dev accuracy:   1.0, loss: 0.02313646674156189      \n",
      "dev accuracy: 0.9375, loss: 0.4097476899623871       \n",
      "dev accuracy:   1.0, loss: 0.04983608424663544      \n",
      "dev accuracy:   1.0, loss: 0.024756699800491333     \n",
      "dev accuracy:   1.0, loss: 0.013160526752471924     \n",
      "dev accuracy: 0.9375, loss: 0.17489305138587952      \n",
      "dev accuracy: 0.9375, loss: 0.1827937364578247       \n",
      "dev accuracy:   1.0, loss: 0.06503963470458984      \n",
      "dev accuracy: 0.9375, loss: 0.44327348470687866      \n",
      "dev accuracy: 0.9375, loss: 0.14657491445541382      \n",
      "dev accuracy: 0.9375, loss: 0.14188598096370697      \n",
      "dev accuracy:   1.0, loss: 0.007849186658859253     \n",
      "dev accuracy:   1.0, loss: 0.005594313144683838     \n",
      "dev accuracy: 0.9375, loss: 0.07701241970062256      \n",
      "dev accuracy: 0.9375, loss: 0.19078482687473297      \n",
      "dev accuracy:   1.0, loss: 0.005874315742403269     \n",
      "final dev accuracy: 0.9519974226804123\n",
      "train step #8329 accuracy: 0.953125, loss: 0.1697683036327362       \n",
      "train step #8330 accuracy: 0.96875, loss: 0.15701155364513397      \n",
      "train step #8331 accuracy: 0.984375, loss: 0.11269407719373703      \n",
      "train step #8332 accuracy: 0.984375, loss: 0.03970251977443695      \n",
      "train step #8333 accuracy: 0.96875, loss: 0.19069063663482666      \n",
      "train step #8334 accuracy: 0.953125, loss: 0.23154596984386444      \n",
      "train step #8335 accuracy: 0.9375, loss: 0.24405746161937714      \n",
      "train step #8336 accuracy: 0.9375, loss: 0.20325729250907898      \n",
      "train step #8337 accuracy: 0.953125, loss: 0.16499534249305725      \n",
      "train step #8338 accuracy: 0.953125, loss: 0.14229318499565125      \n",
      "train step #8339 accuracy: 0.953125, loss: 0.1226954534649849       \n",
      "train step #8340 accuracy: 0.9375, loss: 0.24745717644691467      \n",
      "train step #8341 accuracy: 0.984375, loss: 0.12401671707630157      \n",
      "train step #8342 accuracy: 0.984375, loss: 0.09993831068277359      \n",
      "train step #8343 accuracy: 0.96875, loss: 0.11844030022621155      \n",
      "train step #8344 accuracy: 0.953125, loss: 0.17919939756393433      \n",
      "train step #8345 accuracy:   1.0, loss: 0.02050364762544632      \n",
      "train step #8346 accuracy: 0.953125, loss: 0.18023785948753357      \n",
      "train step #8347 accuracy: 0.921875, loss: 0.20188617706298828      \n",
      "train step #8348 accuracy: 0.96875, loss: 0.17121542990207672      \n",
      "train step #8349 accuracy: 0.921875, loss: 0.2776918113231659       \n",
      "train step #8350 accuracy: 0.984375, loss: 0.06829939037561417      \n",
      "train step #8351 accuracy: 0.9375, loss: 0.1832580268383026       \n",
      "train step #8352 accuracy: 0.984375, loss: 0.12210007756948471      \n",
      "train step #8353 accuracy: 0.96875, loss: 0.13189876079559326      \n",
      "train step #8354 accuracy: 0.96875, loss: 0.09486137330532074      \n",
      "train step #8355 accuracy: 0.90625, loss: 0.2434905618429184       \n",
      "train step #8356 accuracy: 0.96875, loss: 0.09792889654636383      \n",
      "train step #8357 accuracy: 0.96875, loss: 0.12746138870716095      \n",
      "train step #8358 accuracy: 0.953125, loss: 0.14190632104873657      \n",
      "train step #8359 accuracy: 0.984375, loss: 0.04928769916296005      \n",
      "train step #8360 accuracy: 0.96875, loss: 0.05418790876865387      \n",
      "train step #8361 accuracy:   1.0, loss: 0.033281855285167694     \n",
      "train step #8362 accuracy: 0.96875, loss: 0.09025835245847702      \n",
      "train step #8363 accuracy: 0.984375, loss: 0.06073446199297905      \n",
      "train step #8364 accuracy: 0.96875, loss: 0.12951457500457764      \n",
      "train step #8365 accuracy: 0.984375, loss: 0.057523783296346664     \n",
      "train step #8366 accuracy: 0.984375, loss: 0.06272867321968079      \n",
      "train step #8367 accuracy: 0.953125, loss: 0.17686107754707336      \n",
      "train step #8368 accuracy: 0.96875, loss: 0.09978851675987244      \n",
      "train step #8369 accuracy: 0.9375, loss: 0.1920943707227707       \n",
      "train step #8370 accuracy: 0.953125, loss: 0.18768537044525146      \n",
      "train step #8371 accuracy:   1.0, loss: 0.018703505396842957     \n",
      "train step #8372 accuracy: 0.953125, loss: 0.2092914581298828       \n",
      "train step #8373 accuracy: 0.953125, loss: 0.2480984479188919       \n",
      "train step #8374 accuracy: 0.984375, loss: 0.06941182911396027      \n",
      "train step #8375 accuracy: 0.921875, loss: 0.1647004932165146       \n",
      "train step #8376 accuracy: 0.953125, loss: 0.19559453427791595      \n",
      "train step #8377 accuracy: 0.984375, loss: 0.05267840623855591      \n",
      "train step #8378 accuracy: 0.953125, loss: 0.18204917013645172      \n",
      "train step #8379 accuracy: 0.96875, loss: 0.15601539611816406      \n",
      "train step #8380 accuracy: 0.984375, loss: 0.07681621611118317      \n",
      "train step #8381 accuracy: 0.9375, loss: 0.20925335586071014      \n",
      "train step #8382 accuracy: 0.96875, loss: 0.18420210480690002      \n",
      "train step #8383 accuracy: 0.96875, loss: 0.0824805423617363       \n",
      "train step #8384 accuracy: 0.921875, loss: 0.2772824168205261       \n",
      "train step #8385 accuracy: 0.953125, loss: 0.2015032023191452       \n",
      "train step #8386 accuracy:   1.0, loss: 0.039455972611904144     \n",
      "train step #8387 accuracy: 0.953125, loss: 0.13698896765708923      \n",
      "train step #8388 accuracy:   1.0, loss: 0.025111284106969833     \n",
      "train step #8389 accuracy: 0.984375, loss: 0.08702768385410309      \n",
      "train step #8390 accuracy: 0.953125, loss: 0.16521646082401276      \n",
      "train step #8391 accuracy:   1.0, loss: 0.008586641401052475     \n",
      "train step #8392 accuracy:   1.0, loss: 0.0771382749080658       \n",
      "train step #8393 accuracy: 0.953125, loss: 0.12816572189331055      \n",
      "train step #8394 accuracy: 0.953125, loss: 0.16986176371574402      \n",
      "train step #8395 accuracy: 0.984375, loss: 0.056959062814712524     \n",
      "train step #8396 accuracy: 0.9375, loss: 0.20541329681873322      \n",
      "train step #8397 accuracy: 0.984375, loss: 0.10020427405834198      \n",
      "train step #8398 accuracy: 0.984375, loss: 0.0289035364985466       \n",
      "train step #8399 accuracy: 0.953125, loss: 0.19477462768554688      \n",
      "train step #8400 accuracy: 0.96875, loss: 0.1247558444738388       \n",
      "train step #8401 accuracy: 0.984375, loss: 0.06481678783893585      \n",
      "train step #8402 accuracy: 0.90625, loss: 0.22609901428222656      \n",
      "train step #8403 accuracy: 0.96875, loss: 0.09774452447891235      \n",
      "train step #8404 accuracy: 0.984375, loss: 0.07006043940782547      \n",
      "train step #8405 accuracy:   1.0, loss: 0.018164880573749542     \n",
      "train step #8406 accuracy: 0.9375, loss: 0.26992911100387573      \n",
      "train step #8407 accuracy: 0.921875, loss: 0.26276031136512756      \n",
      "train step #8408 accuracy: 0.984375, loss: 0.05347885936498642      \n",
      "train step #8409 accuracy:   1.0, loss: 0.03751856088638306      \n",
      "train step #8410 accuracy: 0.96875, loss: 0.17183101177215576      \n",
      "train step #8411 accuracy: 0.90625, loss: 0.3130953907966614       \n",
      "train step #8412 accuracy: 0.96875, loss: 0.07438084483146667      \n",
      "train step #8413 accuracy: 0.953125, loss: 0.17636547982692719      \n",
      "train step #8414 accuracy: 0.96875, loss: 0.12023022770881653      \n",
      "train step #8415 accuracy: 0.984375, loss: 0.07237929850816727      \n",
      "train step #8416 accuracy: 0.96875, loss: 0.132078155875206        \n",
      "train step #8417 accuracy: 0.984375, loss: 0.04566142335534096      \n",
      "train step #8418 accuracy: 0.96875, loss: 0.09928500652313232      \n",
      "train step #8419 accuracy: 0.890625, loss: 0.49242115020751953      \n",
      "train step #8420 accuracy: 0.953125, loss: 0.16762319207191467      \n",
      "train step #8421 accuracy: 0.984375, loss: 0.07767461985349655      \n",
      "train step #8422 accuracy: 0.9375, loss: 0.23398347198963165      \n",
      "train step #8423 accuracy: 0.96875, loss: 0.1009015291929245       \n",
      "train step #8424 accuracy: 0.953125, loss: 0.12589804828166962      \n",
      "train step #8425 accuracy: 0.96875, loss: 0.12450994551181793      \n",
      "train step #8426 accuracy: 0.984375, loss: 0.117047019302845        \n",
      "train step #8427 accuracy: 0.984375, loss: 0.052871689200401306     \n",
      "train step #8428 accuracy: 0.953125, loss: 0.08548413217067719      \n",
      "train step #8429 accuracy:   1.0, loss: 0.06530578434467316      \n",
      "train step #8430 accuracy: 0.9375, loss: 0.1619187593460083       \n",
      "train step #8431 accuracy: 0.953125, loss: 0.13576611876487732      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #8432 accuracy: 0.984375, loss: 0.1119348406791687       \n",
      "train step #8433 accuracy: 0.90625, loss: 0.2840613126754761       \n",
      "train step #8434 accuracy: 0.953125, loss: 0.18258437514305115      \n",
      "train step #8435 accuracy: 0.96875, loss: 0.11276838183403015      \n",
      "train step #8436 accuracy: 0.953125, loss: 0.19536356627941132      \n",
      "train step #8437 accuracy:   1.0, loss: 0.030932500958442688     \n",
      "train step #8438 accuracy: 0.921875, loss: 0.21287454664707184      \n",
      "train step #8439 accuracy: 0.953125, loss: 0.168364018201828        \n",
      "train step #8440 accuracy: 0.984375, loss: 0.10093899816274643      \n",
      "train step #8441 accuracy: 0.96875, loss: 0.09760934114456177      \n",
      "train step #8442 accuracy: 0.984375, loss: 0.04357560724020004      \n",
      "train step #8443 accuracy: 0.953125, loss: 0.22331446409225464      \n",
      "train step #8444 accuracy: 0.984375, loss: 0.08798878639936447      \n",
      "train step #8445 accuracy: 0.9375, loss: 0.21463005244731903      \n",
      "train step #8446 accuracy: 0.953125, loss: 0.09402299672365189      \n",
      "train step #8447 accuracy: 0.984375, loss: 0.0498904213309288       \n",
      "train step #8448 accuracy: 0.953125, loss: 0.12135586887598038      \n",
      "train step #8449 accuracy: 0.953125, loss: 0.18309612572193146      \n",
      "train step #8450 accuracy: 0.984375, loss: 0.11177800595760345      \n",
      "train step #8451 accuracy: 0.953125, loss: 0.18317911028862         \n",
      "train step #8452 accuracy: 0.984375, loss: 0.09422051906585693      \n",
      "train step #8453 accuracy: 0.96875, loss: 0.06491029262542725      \n",
      "train step #8454 accuracy: 0.96875, loss: 0.1295526921749115       \n",
      "train step #8455 accuracy: 0.953125, loss: 0.11549952626228333      \n",
      "train step #8456 accuracy:   1.0, loss: 0.028680436313152313     \n",
      "train step #8457 accuracy:   1.0, loss: 0.029553405940532684     \n",
      "train step #8458 accuracy: 0.96875, loss: 0.09035736322402954      \n",
      "train step #8459 accuracy: 0.953125, loss: 0.15723568201065063      \n",
      "train step #8460 accuracy: 0.96875, loss: 0.13884559273719788      \n",
      "train step #8461 accuracy: 0.984375, loss: 0.06940998136997223      \n",
      "train step #8462 accuracy: 0.953125, loss: 0.18002359569072723      \n",
      "train step #8463 accuracy:   1.0, loss: 0.02939712256193161      \n",
      "train step #8464 accuracy: 0.984375, loss: 0.06127508729696274      \n",
      "train step #8465 accuracy: 0.953125, loss: 0.081305131316185        \n",
      "train step #8466 accuracy: 0.96875, loss: 0.1520240753889084       \n",
      "train step #8467 accuracy: 0.96875, loss: 0.1519610732793808       \n",
      "train step #8468 accuracy: 0.984375, loss: 0.0743429884314537       \n",
      "train step #8469 accuracy:   1.0, loss: 0.05060151591897011      \n",
      "train step #8470 accuracy: 0.953125, loss: 0.1845588982105255       \n",
      "train step #8471 accuracy: 0.953125, loss: 0.14543402194976807      \n",
      "train step #8472 accuracy: 0.984375, loss: 0.11401765048503876      \n",
      "train step #8473 accuracy: 0.96875, loss: 0.1284174770116806       \n",
      "train step #8474 accuracy: 0.96875, loss: 0.21577946841716766      \n",
      "train step #8475 accuracy: 0.953125, loss: 0.20355811715126038      \n",
      "train step #8476 accuracy: 0.9375, loss: 0.20991991460323334      \n",
      "train step #8477 accuracy: 0.96875, loss: 0.13304778933525085      \n",
      "train step #8478 accuracy: 0.921875, loss: 0.2054942399263382       \n",
      "train step #8479 accuracy: 0.96875, loss: 0.06917092204093933      \n",
      "train step #8480 accuracy: 0.9375, loss: 0.25702348351478577      \n",
      "train step #8481 accuracy: 0.9375, loss: 0.2047976702451706       \n",
      "train step #8482 accuracy: 0.890625, loss: 0.31213903427124023      \n",
      "train step #8483 accuracy: 0.984375, loss: 0.08139317482709885      \n",
      "train step #8484 accuracy: 0.953125, loss: 0.1955760419368744       \n",
      "train step #8485 accuracy: 0.96875, loss: 0.07234705984592438      \n",
      "train step #8486 accuracy: 0.953125, loss: 0.19699662923812866      \n",
      "train step #8487 accuracy: 0.984375, loss: 0.07387687265872955      \n",
      "train step #8488 accuracy: 0.953125, loss: 0.1559356451034546       \n",
      "train step #8489 accuracy: 0.953125, loss: 0.13164344429969788      \n",
      "train step #8490 accuracy: 0.96875, loss: 0.13675782084465027      \n",
      "train step #8491 accuracy: 0.96875, loss: 0.16295553743839264      \n",
      "train step #8492 accuracy: 0.96875, loss: 0.16257937252521515      \n",
      "train step #8493 accuracy: 0.96875, loss: 0.1234300434589386       \n",
      "train step #8494 accuracy: 0.96875, loss: 0.10759885609149933      \n",
      "train step #8495 accuracy: 0.921875, loss: 0.1536465734243393       \n",
      "train step #8496 accuracy: 0.953125, loss: 0.19191111624240875      \n",
      "train step #8497 accuracy: 0.96875, loss: 0.09253394603729248      \n",
      "train step #8498 accuracy: 0.984375, loss: 0.08571988344192505      \n",
      "train step #8499 accuracy: 0.96875, loss: 0.08144210278987885      \n",
      "train step #8500 accuracy: 0.96875, loss: 0.11498202383518219      \n",
      "train step #8501 accuracy: 0.984375, loss: 0.11194786429405212      \n",
      "train step #8502 accuracy: 0.9375, loss: 0.17806324362754822      \n",
      "train step #8503 accuracy: 0.953125, loss: 0.10218419879674911      \n",
      "train step #8504 accuracy: 0.9375, loss: 0.2267541140317917       \n",
      "train step #8505 accuracy: 0.9375, loss: 0.3328704237937927       \n",
      "train step #8506 accuracy: 0.953125, loss: 0.09513481706380844      \n",
      "train step #8507 accuracy: 0.96875, loss: 0.15917634963989258      \n",
      "train step #8508 accuracy: 0.953125, loss: 0.10429508984088898      \n",
      "train step #8509 accuracy: 0.9375, loss: 0.16097261011600494      \n",
      "train step #8510 accuracy:   1.0, loss: 0.018832094967365265     \n",
      "train step #8511 accuracy: 0.984375, loss: 0.09402801841497421      \n",
      "train step #8512 accuracy: 0.921875, loss: 0.25674957036972046      \n",
      "train step #8513 accuracy: 0.96875, loss: 0.10945775359869003      \n",
      "train step #8514 accuracy: 0.953125, loss: 0.14001908898353577      \n",
      "train step #8515 accuracy: 0.984375, loss: 0.06692739576101303      \n",
      "train step #8516 accuracy: 0.984375, loss: 0.1062237098813057       \n",
      "train step #8517 accuracy: 0.953125, loss: 0.19477850198745728      \n",
      "train step #8518 accuracy: 0.96875, loss: 0.10340802371501923      \n",
      "train step #8519 accuracy: 0.984375, loss: 0.1558370590209961       \n",
      "train step #8520 accuracy: 0.96875, loss: 0.17026086151599884      \n",
      "train step #8521 accuracy: 0.96875, loss: 0.1083618775010109       \n",
      "train step #8522 accuracy: 0.96875, loss: 0.13154534995555878      \n",
      "train step #8523 accuracy:   1.0, loss: 0.027467288076877594     \n",
      "train step #8524 accuracy: 0.921875, loss: 0.24598193168640137      \n",
      "train step #8525 accuracy: 0.921875, loss: 0.29148805141448975      \n",
      "train step #8526 accuracy: 0.984375, loss: 0.09236352890729904      \n",
      "train step #8527 accuracy: 0.984375, loss: 0.053760211914777756     \n",
      "train step #8528 accuracy: 0.96875, loss: 0.12123598903417587      \n",
      "train step #8529 accuracy: 0.96875, loss: 0.08224799484014511      \n",
      "train step #8530 accuracy: 0.921875, loss: 0.23812012374401093      \n",
      "train step #8531 accuracy: 0.984375, loss: 0.10376228392124176      \n",
      "train step #8532 accuracy:   1.0, loss: 0.03287364915013313      \n",
      "train step #8533 accuracy: 0.921875, loss: 0.2377915382385254       \n",
      "train step #8534 accuracy:   1.0, loss: 0.05679604038596153      \n",
      "train step #8535 accuracy:   1.0, loss: 0.03840867429971695      \n",
      "train step #8536 accuracy: 0.96875, loss: 0.07605987042188644      \n",
      "train step #8537 accuracy: 0.96875, loss: 0.13193421065807343      \n",
      "train step #8538 accuracy: 0.984375, loss: 0.1367192566394806       \n",
      "train step #8539 accuracy: 0.90625, loss: 0.2719537317752838       \n",
      "train step #8540 accuracy: 0.96875, loss: 0.12105588614940643      \n",
      "train step #8541 accuracy:   1.0, loss: 0.0907207801938057       \n",
      "train step #8542 accuracy: 0.96875, loss: 0.1384122669696808       \n",
      "train step #8543 accuracy: 0.984375, loss: 0.049795858561992645     \n",
      "train step #8544 accuracy: 0.984375, loss: 0.027268923819065094     \n",
      "train step #8545 accuracy:   1.0, loss: 0.049469079822301865     \n",
      "train step #8546 accuracy: 0.984375, loss: 0.10575412958860397      \n",
      "train step #8547 accuracy: 0.921875, loss: 0.29084157943725586      \n",
      "train step #8548 accuracy: 0.953125, loss: 0.12546667456626892      \n",
      "train step #8549 accuracy: 0.984375, loss: 0.08033540099859238      \n",
      "train step #8550 accuracy: 0.953125, loss: 0.14538967609405518      \n",
      "train step #8551 accuracy: 0.96875, loss: 0.06194156035780907      \n",
      "train step #8552 accuracy: 0.984375, loss: 0.07930796593427658      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #8553 accuracy: 0.96875, loss: 0.11093755811452866      \n",
      "train step #8554 accuracy: 0.96875, loss: 0.07808391749858856      \n",
      "train step #8555 accuracy: 0.9375, loss: 0.17318414151668549      \n",
      "train step #8556 accuracy: 0.984375, loss: 0.06685248017311096      \n",
      "train step #8557 accuracy: 0.921875, loss: 0.20728248357772827      \n",
      "train step #8558 accuracy: 0.984375, loss: 0.054580941796302795     \n",
      "train step #8559 accuracy: 0.953125, loss: 0.18273170292377472      \n",
      "train step #8560 accuracy: 0.890625, loss: 0.40816837549209595      \n",
      "train step #8561 accuracy: 0.984375, loss: 0.04778516665101051      \n",
      "train step #8562 accuracy: 0.96875, loss: 0.0532558336853981       \n",
      "train step #8563 accuracy: 0.953125, loss: 0.15538997948169708      \n",
      "train step #8564 accuracy: 0.953125, loss: 0.32705527544021606      \n",
      "train step #8565 accuracy: 0.96875, loss: 0.14133508503437042      \n",
      "train step #8566 accuracy: 0.9375, loss: 0.19021075963974         \n",
      "train step #8567 accuracy: 0.96875, loss: 0.1573294699192047       \n",
      "train step #8568 accuracy: 0.90625, loss: 0.28156018257141113      \n",
      "train step #8569 accuracy: 0.96875, loss: 0.11783548444509506      \n",
      "train step #8570 accuracy: 0.96875, loss: 0.11204849183559418      \n",
      "train step #8571 accuracy:   1.0, loss: 0.0153370201587677       \n",
      "train step #8572 accuracy: 0.953125, loss: 0.1993963122367859       \n",
      "train step #8573 accuracy: 0.96875, loss: 0.15555739402770996      \n",
      "train step #8574 accuracy: 0.96875, loss: 0.13466256856918335      \n",
      "train step #8575 accuracy: 0.984375, loss: 0.15304699540138245      \n",
      "train step #8576 accuracy: 0.953125, loss: 0.26264527440071106      \n",
      "train step #8577 accuracy: 0.96875, loss: 0.11477701365947723      \n",
      "train step #8578 accuracy: 0.984375, loss: 0.04255057871341705      \n",
      "train step #8579 accuracy: 0.90625, loss: 0.23816898465156555      \n",
      "train step #8580 accuracy: 0.953125, loss: 0.2073729932308197       \n",
      "train step #8581 accuracy: 0.984375, loss: 0.09862568229436874      \n",
      "train step #8582 accuracy: 0.96875, loss: 0.1421854943037033       \n",
      "train step #8583 accuracy: 0.96875, loss: 0.11580576002597809      \n",
      "train step #8584 accuracy:   1.0, loss: 0.02556375414133072      \n",
      "train step #8585 accuracy: 0.9375, loss: 0.24656453728675842      \n",
      "train step #8586 accuracy: 0.984375, loss: 0.09796500205993652      \n",
      "train step #8587 accuracy: 0.953125, loss: 0.20267623662948608      \n",
      "train step #8588 accuracy:   1.0, loss: 0.06204063445329666      \n",
      "train step #8589 accuracy: 0.96875, loss: 0.0877610296010971       \n",
      "train step #8590 accuracy:   1.0, loss: 0.011374376714229584     \n",
      "train step #8591 accuracy: 0.984375, loss: 0.07334538549184799      \n",
      "train step #8592 accuracy: 0.953125, loss: 0.07943712174892426      \n",
      "train step #8593 accuracy: 0.9375, loss: 0.1833195984363556       \n",
      "train step #8594 accuracy: 0.984375, loss: 0.10900352150201797      \n",
      "train step #8595 accuracy: 0.984375, loss: 0.023924022912979126     \n",
      "train step #8596 accuracy: 0.921875, loss: 0.19960588216781616      \n",
      "train step #8597 accuracy: 0.953125, loss: 0.2142237424850464       \n",
      "train step #8598 accuracy: 0.9375, loss: 0.24734945595264435      \n",
      "train step #8599 accuracy: 0.96875, loss: 0.1617758572101593       \n",
      "train step #8600 accuracy: 0.984375, loss: 0.08407030999660492      \n",
      "train step #8601 accuracy: 0.984375, loss: 0.053539760410785675     \n",
      "train step #8602 accuracy:   1.0, loss: 0.031061924993991852     \n",
      "train step #8603 accuracy: 0.953125, loss: 0.16470710933208466      \n",
      "train step #8604 accuracy: 0.921875, loss: 0.2822839021682739       \n",
      "train step #8605 accuracy:   1.0, loss: 0.028428323566913605     \n",
      "train step #8606 accuracy: 0.984375, loss: 0.09323433041572571      \n",
      "train step #8607 accuracy: 0.90625, loss: 0.1919768750667572       \n",
      "train step #8608 accuracy: 0.984375, loss: 0.05105796456336975      \n",
      "train step #8609 accuracy: 0.953125, loss: 0.11345042288303375      \n",
      "train step #8610 accuracy: 0.96875, loss: 0.13315552473068237      \n",
      "train step #8611 accuracy: 0.984375, loss: 0.05932120233774185      \n",
      "train step #8612 accuracy: 0.9375, loss: 0.23083719611167908      \n",
      "train step #8613 accuracy: 0.984375, loss: 0.13934369385242462      \n",
      "train step #8614 accuracy: 0.984375, loss: 0.13415288925170898      \n",
      "train step #8615 accuracy: 0.96875, loss: 0.10996615141630173      \n",
      "train step #8616 accuracy: 0.96875, loss: 0.08468117564916611      \n",
      "train step #8617 accuracy: 0.984375, loss: 0.07086683809757233      \n",
      "train step #8618 accuracy: 0.984375, loss: 0.03700503706932068      \n",
      "train step #8619 accuracy: 0.953125, loss: 0.18905401229858398      \n",
      "train step #8620 accuracy: 0.96875, loss: 0.04413197934627533      \n",
      "train step #8621 accuracy: 0.953125, loss: 0.19290557503700256      \n",
      "train step #8622 accuracy: 0.96875, loss: 0.12783607840538025      \n",
      "train step #8623 accuracy:   1.0, loss: 0.04322056472301483      \n",
      "train step #8624 accuracy: 0.96875, loss: 0.08029036223888397      \n",
      "train step #8625 accuracy: 0.96875, loss: 0.1506795883178711       \n",
      "train step #8626 accuracy: 0.984375, loss: 0.15255852043628693      \n",
      "train step #8627 accuracy: 0.96875, loss: 0.122937873005867        \n",
      "train step #8628 accuracy: 0.953125, loss: 0.16307280957698822      \n",
      "train step #8629 accuracy: 0.984375, loss: 0.07938560843467712      \n",
      "train step #8630 accuracy: 0.953125, loss: 0.21929483115673065      \n",
      "train step #8631 accuracy:   1.0, loss: 0.029164381325244904     \n",
      "train step #8632 accuracy: 0.96875, loss: 0.14992953836917877      \n",
      "train step #8633 accuracy: 0.984375, loss: 0.10373713821172714      \n",
      "train step #8634 accuracy: 0.890625, loss: 0.3242533802986145       \n",
      "train step #8635 accuracy: 0.9375, loss: 0.2255813628435135       \n",
      "train step #8636 accuracy:   1.0, loss: 0.027039527893066406     \n",
      "train step #8637 accuracy: 0.953125, loss: 0.13959932327270508      \n",
      "train step #8638 accuracy: 0.953125, loss: 0.2100159227848053       \n",
      "train step #8639 accuracy: 0.984375, loss: 0.10999788343906403      \n",
      "train step #8640 accuracy: 0.984375, loss: 0.06696726381778717      \n",
      "train step #8641 accuracy: 0.953125, loss: 0.1682303249835968       \n",
      "train step #8642 accuracy:   1.0, loss: 0.01851237565279007      \n",
      "train step #8643 accuracy: 0.96875, loss: 0.09059630334377289      \n",
      "train step #8644 accuracy: 0.96875, loss: 0.06223292276263237      \n",
      "train step #8645 accuracy: 0.984375, loss: 0.0684000700712204       \n",
      "train step #8646 accuracy: 0.984375, loss: 0.06801120936870575      \n",
      "train step #8647 accuracy: 0.921875, loss: 0.34077000617980957      \n",
      "train step #8648 accuracy: 0.9375, loss: 0.18493743240833282      \n",
      "train step #8649 accuracy: 0.953125, loss: 0.09514285624027252      \n",
      "train step #8650 accuracy: 0.953125, loss: 0.17375463247299194      \n",
      "train step #8651 accuracy:   1.0, loss: 0.07775420695543289      \n",
      "train step #8652 accuracy: 0.984375, loss: 0.0703781396150589       \n",
      "train step #8653 accuracy: 0.953125, loss: 0.2158201038837433       \n",
      "train step #8654 accuracy: 0.984375, loss: 0.08969683945178986      \n",
      "train step #8655 accuracy: 0.953125, loss: 0.15529802441596985      \n",
      "train step #8656 accuracy: 0.984375, loss: 0.08320833742618561      \n",
      "train step #8657 accuracy: 0.9375, loss: 0.21930916607379913      \n",
      "train step #8658 accuracy: 0.9375, loss: 0.2064114809036255       \n",
      "train step #8659 accuracy: 0.96875, loss: 0.10364972800016403      \n",
      "train step #8660 accuracy: 0.984375, loss: 0.10097142308950424      \n",
      "train step #8661 accuracy: 0.953125, loss: 0.2194138914346695       \n",
      "train step #8662 accuracy: 0.953125, loss: 0.26307082176208496      \n",
      "train step #8663 accuracy: 0.96875, loss: 0.18241247534751892      \n",
      "train step #8664 accuracy: 0.96875, loss: 0.09853353351354599      \n",
      "train step #8665 accuracy: 0.9375, loss: 0.21205657720565796      \n",
      "train step #8666 accuracy: 0.921875, loss: 0.28149813413619995      \n",
      "train step #8667 accuracy: 0.96875, loss: 0.07634928077459335      \n",
      "train step #8668 accuracy: 0.96875, loss: 0.15199622511863708      \n",
      "train step #8669 accuracy: 0.96875, loss: 0.10330367088317871      \n",
      "train step #8670 accuracy: 0.953125, loss: 0.20919321477413177      \n",
      "train step #8671 accuracy:   1.0, loss: 0.018133357167243958     \n",
      "train step #8672 accuracy: 0.96875, loss: 0.08529605716466904      \n",
      "train step #8673 accuracy: 0.984375, loss: 0.1182885617017746       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #8674 accuracy: 0.953125, loss: 0.18213427066802979      \n",
      "train step #8675 accuracy: 0.9375, loss: 0.20949257910251617      \n",
      "dev accuracy:   1.0, loss: 0.0013043880462646484    \n",
      "dev accuracy: 0.9375, loss: 0.40115198493003845      \n",
      "dev accuracy: 0.875, loss: 0.48600444197654724      \n",
      "dev accuracy:   1.0, loss: 0.09324911236763         \n",
      "dev accuracy: 0.9375, loss: 0.08630090951919556      \n",
      "dev accuracy: 0.875, loss: 0.22274379432201385      \n",
      "dev accuracy: 0.9375, loss: 0.13760776817798615      \n",
      "dev accuracy: 0.9375, loss: 0.12736821174621582      \n",
      "dev accuracy:   1.0, loss: 0.005049020051956177     \n",
      "dev accuracy: 0.9375, loss: 0.10593780875205994      \n",
      "dev accuracy:   1.0, loss: 0.004544854164123535     \n",
      "dev accuracy: 0.9375, loss: 0.13703159987926483      \n",
      "dev accuracy: 0.875, loss: 0.5978517532348633       \n",
      "dev accuracy: 0.875, loss: 0.20229509472846985      \n",
      "dev accuracy: 0.9375, loss: 0.09938670694828033      \n",
      "dev accuracy: 0.875, loss: 0.18708056211471558      \n",
      "dev accuracy:   1.0, loss: 0.004487872123718262     \n",
      "dev accuracy:   1.0, loss: 0.016908913850784302     \n",
      "dev accuracy:   1.0, loss: 0.0005382299423217773    \n",
      "dev accuracy: 0.875, loss: 0.17481297254562378      \n",
      "dev accuracy:   1.0, loss: 0.10189247131347656      \n",
      "dev accuracy:   1.0, loss: 0.004790931940078735     \n",
      "dev accuracy: 0.9375, loss: 0.06796297430992126      \n",
      "dev accuracy:   1.0, loss: 0.0037309229373931885    \n",
      "dev accuracy:   1.0, loss: 0.01044851541519165      \n",
      "dev accuracy: 0.9375, loss: 0.16518402099609375      \n",
      "dev accuracy: 0.9375, loss: 0.18717114627361298      \n",
      "dev accuracy:   1.0, loss: 0.02068406343460083      \n",
      "dev accuracy: 0.875, loss: 0.582243025302887        \n",
      "dev accuracy:   1.0, loss: 0.00902816653251648      \n",
      "dev accuracy:   1.0, loss: 0.011114001274108887     \n",
      "dev accuracy:   1.0, loss: 0.02039426565170288      \n",
      "dev accuracy: 0.9375, loss: 0.2662578523159027       \n",
      "dev accuracy: 0.9375, loss: 0.23381510376930237      \n",
      "dev accuracy:   1.0, loss: 0.02737674117088318      \n",
      "dev accuracy:   1.0, loss: 0.04275012016296387      \n",
      "dev accuracy: 0.9375, loss: 0.140679270029068        \n",
      "dev accuracy: 0.9375, loss: 0.18203142285346985      \n",
      "dev accuracy: 0.9375, loss: 0.1536158323287964       \n",
      "dev accuracy: 0.875, loss: 0.25844162702560425      \n",
      "dev accuracy: 0.8125, loss: 0.7961652874946594       \n",
      "dev accuracy: 0.9375, loss: 0.07521072030067444      \n",
      "dev accuracy:   1.0, loss: 0.04502071440219879      \n",
      "dev accuracy: 0.9375, loss: 0.1279216855764389       \n",
      "dev accuracy:   1.0, loss: 0.02791011333465576      \n",
      "dev accuracy: 0.9375, loss: 0.5025259256362915       \n",
      "dev accuracy:   1.0, loss: 0.01208716630935669      \n",
      "dev accuracy: 0.9375, loss: 0.11871901154518127      \n",
      "dev accuracy: 0.875, loss: 0.3527463674545288       \n",
      "dev accuracy: 0.9375, loss: 0.44261911511421204      \n",
      "dev accuracy: 0.875, loss: 0.3482217788696289       \n",
      "dev accuracy:   1.0, loss: 0.015517771244049072     \n",
      "dev accuracy:   1.0, loss: 0.06065346300601959      \n",
      "dev accuracy: 0.9375, loss: 0.4946158528327942       \n",
      "dev accuracy: 0.8125, loss: 0.30823343992233276      \n",
      "dev accuracy:   1.0, loss: 0.057229623198509216     \n",
      "dev accuracy:   1.0, loss: 0.04851333796977997      \n",
      "dev accuracy:   1.0, loss: 0.04409411549568176      \n",
      "dev accuracy: 0.9375, loss: 0.16766421496868134      \n",
      "dev accuracy:   1.0, loss: 0.04450958967208862      \n",
      "dev accuracy:   1.0, loss: 0.0026748478412628174    \n",
      "dev accuracy:   1.0, loss: 0.02163669466972351      \n",
      "dev accuracy:   1.0, loss: 0.14289353787899017      \n",
      "dev accuracy: 0.875, loss: 0.32189497351646423      \n",
      "dev accuracy: 0.8125, loss: 0.3798254132270813       \n",
      "dev accuracy: 0.9375, loss: 0.26587724685668945      \n",
      "dev accuracy: 0.8125, loss: 0.45109909772872925      \n",
      "dev accuracy: 0.9375, loss: 0.21335150301456451      \n",
      "dev accuracy: 0.9375, loss: 0.3324477970600128       \n",
      "dev accuracy:   1.0, loss: 0.026641398668289185     \n",
      "dev accuracy:   1.0, loss: 0.010302871465682983     \n",
      "dev accuracy: 0.875, loss: 0.30690711736679077      \n",
      "dev accuracy: 0.9375, loss: 0.13045209646224976      \n",
      "dev accuracy: 0.875, loss: 0.14773288369178772      \n",
      "dev accuracy:   1.0, loss: 0.03498762845993042      \n",
      "dev accuracy:   1.0, loss: 0.03799441456794739      \n",
      "dev accuracy: 0.9375, loss: 0.21430450677871704      \n",
      "dev accuracy:   1.0, loss: 0.013315737247467041     \n",
      "dev accuracy: 0.9375, loss: 0.27539312839508057      \n",
      "dev accuracy:   1.0, loss: 0.022114664316177368     \n",
      "dev accuracy:   1.0, loss: 0.0010336637496948242    \n",
      "dev accuracy: 0.9375, loss: 0.27254700660705566      \n",
      "dev accuracy: 0.9375, loss: 0.26226502656936646      \n",
      "dev accuracy: 0.9375, loss: 0.09548735618591309      \n",
      "dev accuracy:   1.0, loss: 0.05183720588684082      \n",
      "dev accuracy: 0.875, loss: 0.4137035310268402       \n",
      "dev accuracy: 0.9375, loss: 0.28114864230155945      \n",
      "dev accuracy:   1.0, loss: 0.02631312608718872      \n",
      "dev accuracy:   1.0, loss: 0.029820799827575684     \n",
      "dev accuracy: 0.9375, loss: 0.1488284170627594       \n",
      "dev accuracy: 0.9375, loss: 0.1388927549123764       \n",
      "dev accuracy:   1.0, loss: 0.001339554786682129     \n",
      "dev accuracy: 0.9375, loss: 0.10911673307418823      \n",
      "dev accuracy: 0.9375, loss: 0.18242880702018738      \n",
      "dev accuracy:   1.0, loss: 0.007874250411987305     \n",
      "dev accuracy: 0.875, loss: 0.34263142943382263      \n",
      "dev accuracy: 0.9375, loss: 0.15513451397418976      \n",
      "dev accuracy:   1.0, loss: 0.004197925329208374     \n",
      "dev accuracy:   1.0, loss: 0.04171881079673767      \n",
      "dev accuracy: 0.9375, loss: 0.40956994891166687      \n",
      "dev accuracy: 0.9375, loss: 0.30595675110816956      \n",
      "dev accuracy:   1.0, loss: 0.01316899061203003      \n",
      "dev accuracy:   1.0, loss: 0.003024458885192871     \n",
      "dev accuracy:   1.0, loss: 0.020680993795394897     \n",
      "dev accuracy: 0.9375, loss: 0.22018328309059143      \n",
      "dev accuracy: 0.875, loss: 0.16433873772621155      \n",
      "dev accuracy: 0.9375, loss: 0.056719183921813965     \n",
      "dev accuracy: 0.9375, loss: 0.4797898828983307       \n",
      "dev accuracy:   1.0, loss: 0.026691824197769165     \n",
      "dev accuracy:   1.0, loss: 0.04998499155044556      \n",
      "dev accuracy:   1.0, loss: 0.011676907539367676     \n",
      "dev accuracy:   1.0, loss: 0.09497404098510742      \n",
      "dev accuracy:   1.0, loss: 0.0030391812324523926    \n",
      "dev accuracy: 0.875, loss: 0.6784769296646118       \n",
      "dev accuracy:   1.0, loss: 0.1384345144033432       \n",
      "dev accuracy:   1.0, loss: 0.02913367748260498      \n",
      "dev accuracy:   1.0, loss: 0.02970997989177704      \n",
      "dev accuracy:   1.0, loss: 0.0036790966987609863    \n",
      "dev accuracy: 0.9375, loss: 0.13441932201385498      \n",
      "dev accuracy: 0.875, loss: 0.29022297263145447      \n",
      "dev accuracy:   1.0, loss: 0.001234203577041626     \n",
      "dev accuracy:   1.0, loss: 0.007560759782791138     \n",
      "dev accuracy: 0.875, loss: 0.3109603524208069       \n",
      "dev accuracy: 0.9375, loss: 0.07326892018318176      \n",
      "dev accuracy: 0.9375, loss: 0.06900018453598022      \n",
      "dev accuracy: 0.9375, loss: 0.16957390308380127      \n",
      "dev accuracy:   1.0, loss: 0.0034223198890686035    \n",
      "dev accuracy:   1.0, loss: 0.0005763769149780273    \n",
      "dev accuracy:   1.0, loss: 0.04563680291175842      \n",
      "dev accuracy:   1.0, loss: 0.020751625299453735     \n",
      "dev accuracy:   1.0, loss: 0.034270256757736206     \n",
      "dev accuracy:   1.0, loss: 0.011738985776901245     \n",
      "dev accuracy: 0.9375, loss: 0.27560320496559143      \n",
      "dev accuracy: 0.9375, loss: 0.2634114623069763       \n",
      "dev accuracy: 0.875, loss: 0.3699232339859009       \n",
      "dev accuracy: 0.9375, loss: 0.2505943179130554       \n",
      "dev accuracy: 0.875, loss: 0.41056278347969055      \n",
      "dev accuracy:   1.0, loss: 0.03440028429031372      \n",
      "dev accuracy: 0.9375, loss: 0.1556987464427948       \n",
      "dev accuracy:   1.0, loss: 0.041845887899398804     \n",
      "dev accuracy:   1.0, loss: 0.004641354084014893     \n",
      "dev accuracy:   1.0, loss: 0.03181859850883484      \n",
      "dev accuracy: 0.9375, loss: 0.07819029688835144      \n",
      "dev accuracy:  0.75, loss: 0.7944311499595642       \n",
      "dev accuracy:   1.0, loss: 0.032692283391952515     \n",
      "dev accuracy: 0.8125, loss: 0.8192377686500549       \n",
      "dev accuracy:   1.0, loss: 0.04020330309867859      \n",
      "dev accuracy:   1.0, loss: 0.030345380306243896     \n",
      "dev accuracy: 0.875, loss: 0.1924149990081787       \n",
      "dev accuracy:   1.0, loss: 0.001044631004333496     \n",
      "dev accuracy: 0.9375, loss: 0.34598538279533386      \n",
      "dev accuracy: 0.9375, loss: 0.43431106209754944      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy: 0.9375, loss: 0.22124391794204712      \n",
      "dev accuracy: 0.875, loss: 0.28206878900527954      \n",
      "dev accuracy:   1.0, loss: 0.14533492922782898      \n",
      "dev accuracy:   1.0, loss: 0.03575374186038971      \n",
      "dev accuracy: 0.9375, loss: 0.3385275602340698       \n",
      "dev accuracy:   1.0, loss: 0.05175754427909851      \n",
      "dev accuracy: 0.9375, loss: 0.0763901025056839       \n",
      "dev accuracy:   1.0, loss: 0.017124563455581665     \n",
      "dev accuracy: 0.9375, loss: 0.09128686785697937      \n",
      "dev accuracy: 0.875, loss: 0.7584766149520874       \n",
      "dev accuracy: 0.9375, loss: 0.09876704216003418      \n",
      "dev accuracy:   1.0, loss: 0.029720723628997803     \n",
      "dev accuracy: 0.9375, loss: 0.41954824328422546      \n",
      "dev accuracy:   1.0, loss: 0.0001965165138244629    \n",
      "dev accuracy: 0.875, loss: 0.18113529682159424      \n",
      "dev accuracy:   1.0, loss: 0.0857158750295639       \n",
      "dev accuracy: 0.9375, loss: 0.2521195709705353       \n",
      "dev accuracy: 0.9375, loss: 0.06619849801063538      \n",
      "dev accuracy: 0.9375, loss: 0.14213339984416962      \n",
      "dev accuracy:   1.0, loss: 0.005340456962585449     \n",
      "dev accuracy:   1.0, loss: 0.01104825735092163      \n",
      "dev accuracy: 0.9375, loss: 0.35085949301719666      \n",
      "dev accuracy:   1.0, loss: 0.06057235598564148      \n",
      "dev accuracy: 0.9375, loss: 0.2466202974319458       \n",
      "dev accuracy:   1.0, loss: 0.03327363729476929      \n",
      "dev accuracy:   1.0, loss: 0.07205355167388916      \n",
      "dev accuracy:   1.0, loss: 0.0035222768783569336    \n",
      "dev accuracy: 0.9375, loss: 0.12916725873947144      \n",
      "dev accuracy:   1.0, loss: 0.048029422760009766     \n",
      "dev accuracy: 0.9375, loss: 0.053906023502349854     \n",
      "dev accuracy: 0.9375, loss: 0.3466053903102875       \n",
      "dev accuracy:   1.0, loss: 0.04140424728393555      \n",
      "dev accuracy: 0.9375, loss: 0.4351601004600525       \n",
      "dev accuracy: 0.875, loss: 0.27465757727622986      \n",
      "dev accuracy: 0.9375, loss: 0.13310125470161438      \n",
      "dev accuracy:   1.0, loss: 0.014056175947189331     \n",
      "dev accuracy: 0.875, loss: 0.3075021207332611       \n",
      "dev accuracy: 0.9375, loss: 0.09513580799102783      \n",
      "dev accuracy: 0.9375, loss: 0.16718102991580963      \n",
      "dev accuracy: 0.9375, loss: 0.20134848356246948      \n",
      "dev accuracy:   1.0, loss: 0.07980766892433167      \n",
      "dev accuracy:   1.0, loss: 2.3206075638881885e-05   \n",
      "final dev accuracy: 0.9532860824742269\n",
      "train step #8676 accuracy: 0.984375, loss: 0.058329373598098755     \n",
      "train step #8677 accuracy: 0.96875, loss: 0.15335100889205933      \n",
      "train step #8678 accuracy: 0.984375, loss: 0.09017165005207062      \n",
      "train step #8679 accuracy:   1.0, loss: 0.12918561697006226      \n",
      "train step #8680 accuracy: 0.9375, loss: 0.23061303794384003      \n",
      "train step #8681 accuracy: 0.921875, loss: 0.23313447833061218      \n",
      "train step #8682 accuracy: 0.953125, loss: 0.2858560085296631       \n",
      "train step #8683 accuracy: 0.90625, loss: 0.28528183698654175      \n",
      "train step #8684 accuracy:   1.0, loss: 0.11708873510360718      \n",
      "train step #8685 accuracy: 0.953125, loss: 0.13008832931518555      \n",
      "train step #8686 accuracy: 0.9375, loss: 0.27337926626205444      \n",
      "train step #8687 accuracy: 0.96875, loss: 0.13481031358242035      \n",
      "train step #8688 accuracy: 0.953125, loss: 0.26365822553634644      \n",
      "train step #8689 accuracy: 0.984375, loss: 0.05408444255590439      \n",
      "train step #8690 accuracy: 0.96875, loss: 0.12759210169315338      \n",
      "train step #8691 accuracy:   1.0, loss: 0.05035087466239929      \n",
      "train step #8692 accuracy: 0.984375, loss: 0.05733378231525421      \n",
      "train step #8693 accuracy: 0.953125, loss: 0.14647656679153442      \n",
      "train step #8694 accuracy: 0.953125, loss: 0.1260485053062439       \n",
      "train step #8695 accuracy: 0.984375, loss: 0.04825693741440773      \n",
      "train step #8696 accuracy: 0.9375, loss: 0.21910595893859863      \n",
      "train step #8697 accuracy: 0.9375, loss: 0.21220150589942932      \n",
      "train step #8698 accuracy: 0.984375, loss: 0.05582293123006821      \n",
      "train step #8699 accuracy: 0.96875, loss: 0.11562405526638031      \n",
      "train step #8700 accuracy: 0.953125, loss: 0.2303684502840042       \n",
      "train step #8701 accuracy:   1.0, loss: 0.024565424770116806     \n",
      "train step #8702 accuracy: 0.96875, loss: 0.1101299375295639       \n",
      "train step #8703 accuracy: 0.9375, loss: 0.17893686890602112      \n",
      "train step #8704 accuracy: 0.9375, loss: 0.1766301691532135       \n",
      "train step #8705 accuracy: 0.953125, loss: 0.21774575114250183      \n",
      "train step #8706 accuracy: 0.96875, loss: 0.09379920363426208      \n",
      "train step #8707 accuracy: 0.921875, loss: 0.2814718186855316       \n",
      "train step #8708 accuracy: 0.984375, loss: 0.0675818994641304       \n",
      "train step #8709 accuracy:   1.0, loss: 0.040830936282873154     \n",
      "train step #8710 accuracy: 0.9375, loss: 0.16736136376857758      \n",
      "train step #8711 accuracy:   1.0, loss: 0.014731686562299728     \n",
      "train step #8712 accuracy:   1.0, loss: 0.047716204077005386     \n",
      "train step #8713 accuracy: 0.96875, loss: 0.10708217322826385      \n",
      "train step #8714 accuracy: 0.9375, loss: 0.1692304015159607       \n",
      "train step #8715 accuracy: 0.984375, loss: 0.11538727581501007      \n",
      "train step #8716 accuracy: 0.953125, loss: 0.15485185384750366      \n",
      "train step #8717 accuracy: 0.9375, loss: 0.21417494118213654      \n",
      "train step #8718 accuracy: 0.953125, loss: 0.1569058895111084       \n",
      "train step #8719 accuracy: 0.96875, loss: 0.07586286962032318      \n",
      "train step #8720 accuracy: 0.9375, loss: 0.12540031969547272      \n",
      "train step #8721 accuracy: 0.953125, loss: 0.14208251237869263      \n",
      "train step #8722 accuracy: 0.953125, loss: 0.17646977305412292      \n",
      "train step #8723 accuracy: 0.9375, loss: 0.17882096767425537      \n",
      "train step #8724 accuracy: 0.96875, loss: 0.12992937862873077      \n",
      "train step #8725 accuracy: 0.9375, loss: 0.20166602730751038      \n",
      "train step #8726 accuracy: 0.984375, loss: 0.05364503711462021      \n",
      "train step #8727 accuracy: 0.984375, loss: 0.07495079934597015      \n",
      "train step #8728 accuracy: 0.96875, loss: 0.09022962301969528      \n",
      "train step #8729 accuracy: 0.9375, loss: 0.1772484928369522       \n",
      "train step #8730 accuracy: 0.9375, loss: 0.13592422008514404      \n",
      "train step #8731 accuracy: 0.96875, loss: 0.0817653015255928       \n",
      "train step #8732 accuracy: 0.953125, loss: 0.23771759867668152      \n",
      "train step #8733 accuracy: 0.96875, loss: 0.12092174589633942      \n",
      "train step #8734 accuracy: 0.984375, loss: 0.060989923775196075     \n",
      "train step #8735 accuracy: 0.9375, loss: 0.17876289784908295      \n",
      "train step #8736 accuracy:   1.0, loss: 0.008724451065063477     \n",
      "train step #8737 accuracy: 0.96875, loss: 0.11138290166854858      \n",
      "train step #8738 accuracy: 0.96875, loss: 0.13028644025325775      \n",
      "train step #8739 accuracy: 0.953125, loss: 0.22710193693637848      \n",
      "train step #8740 accuracy: 0.953125, loss: 0.2302781641483307       \n",
      "train step #8741 accuracy: 0.953125, loss: 0.20708543062210083      \n",
      "train step #8742 accuracy: 0.96875, loss: 0.06476738303899765      \n",
      "train step #8743 accuracy: 0.984375, loss: 0.10598403960466385      \n",
      "train step #8744 accuracy: 0.953125, loss: 0.16039900481700897      \n",
      "train step #8745 accuracy: 0.96875, loss: 0.07988207042217255      \n",
      "train step #8746 accuracy: 0.953125, loss: 0.18219256401062012      \n",
      "train step #8747 accuracy:   1.0, loss: 0.04158364236354828      \n",
      "train step #8748 accuracy: 0.953125, loss: 0.1455536186695099       \n",
      "train step #8749 accuracy: 0.953125, loss: 0.09143558889627457      \n",
      "train step #8750 accuracy: 0.953125, loss: 0.15809769928455353      \n",
      "train step #8751 accuracy: 0.96875, loss: 0.07441714406013489      \n",
      "train step #8752 accuracy: 0.953125, loss: 0.12817271053791046      \n",
      "train step #8753 accuracy: 0.9375, loss: 0.2445947229862213       \n",
      "train step #8754 accuracy: 0.96875, loss: 0.08425654470920563      \n",
      "train step #8755 accuracy: 0.96875, loss: 0.13289102911949158      \n",
      "train step #8756 accuracy: 0.953125, loss: 0.1549866944551468       \n",
      "train step #8757 accuracy: 0.984375, loss: 0.05257510766386986      \n",
      "train step #8758 accuracy: 0.953125, loss: 0.21697412431240082      \n",
      "train step #8759 accuracy: 0.96875, loss: 0.10593997687101364      \n",
      "train step #8760 accuracy: 0.96875, loss: 0.12703384459018707      \n",
      "train step #8761 accuracy: 0.984375, loss: 0.12257268279790878      \n",
      "train step #8762 accuracy: 0.96875, loss: 0.109958715736866        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #8763 accuracy: 0.9375, loss: 0.2011992186307907       \n",
      "train step #8764 accuracy: 0.96875, loss: 0.11307436972856522      \n",
      "train step #8765 accuracy: 0.984375, loss: 0.06270374357700348      \n",
      "train step #8766 accuracy: 0.984375, loss: 0.10123256593942642      \n",
      "train step #8767 accuracy: 0.984375, loss: 0.0925520807504654       \n",
      "train step #8768 accuracy: 0.953125, loss: 0.24216672778129578      \n",
      "train step #8769 accuracy: 0.953125, loss: 0.16076302528381348      \n",
      "train step #8770 accuracy: 0.921875, loss: 0.2862793803215027       \n",
      "train step #8771 accuracy: 0.96875, loss: 0.13643169403076172      \n",
      "train step #8772 accuracy: 0.96875, loss: 0.20923790335655212      \n",
      "train step #8773 accuracy: 0.984375, loss: 0.1192551851272583       \n",
      "train step #8774 accuracy: 0.984375, loss: 0.04288510978221893      \n",
      "train step #8775 accuracy:   1.0, loss: 0.06836123764514923      \n",
      "train step #8776 accuracy: 0.984375, loss: 0.07463914901018143      \n",
      "train step #8777 accuracy:   1.0, loss: 0.015644237399101257     \n",
      "train step #8778 accuracy: 0.96875, loss: 0.06377547234296799      \n",
      "train step #8779 accuracy: 0.984375, loss: 0.10602548718452454      \n",
      "train step #8780 accuracy: 0.984375, loss: 0.09067121893167496      \n",
      "train step #8781 accuracy: 0.984375, loss: 0.09929835796356201      \n",
      "train step #8782 accuracy: 0.96875, loss: 0.09798033535480499      \n",
      "train step #8783 accuracy: 0.96875, loss: 0.060951754450798035     \n",
      "train step #8784 accuracy: 0.953125, loss: 0.10795778036117554      \n",
      "train step #8785 accuracy: 0.90625, loss: 0.27179086208343506      \n",
      "train step #8786 accuracy: 0.953125, loss: 0.16916173696517944      \n",
      "train step #8787 accuracy: 0.96875, loss: 0.0878213569521904       \n",
      "train step #8788 accuracy: 0.96875, loss: 0.11278722435235977      \n",
      "train step #8789 accuracy:   1.0, loss: 0.027521789073944092     \n",
      "train step #8790 accuracy:   1.0, loss: 0.06651165336370468      \n",
      "train step #8791 accuracy: 0.984375, loss: 0.04256091266870499      \n",
      "train step #8792 accuracy:   1.0, loss: 0.05310841649770737      \n",
      "train step #8793 accuracy:   1.0, loss: 0.016239725053310394     \n",
      "train step #8794 accuracy: 0.984375, loss: 0.09341955929994583      \n",
      "train step #8795 accuracy:   1.0, loss: 0.03784656524658203      \n",
      "train step #8796 accuracy: 0.953125, loss: 0.10824185609817505      \n",
      "train step #8797 accuracy: 0.984375, loss: 0.057694341987371445     \n",
      "train step #8798 accuracy: 0.96875, loss: 0.08568357676267624      \n",
      "train step #8799 accuracy: 0.984375, loss: 0.06859567016363144      \n",
      "train step #8800 accuracy: 0.96875, loss: 0.14158880710601807      \n",
      "train step #8801 accuracy:   1.0, loss: 0.06952887028455734      \n",
      "train step #8802 accuracy: 0.96875, loss: 0.0956159234046936       \n",
      "train step #8803 accuracy: 0.984375, loss: 0.10792123526334763      \n",
      "train step #8804 accuracy: 0.9375, loss: 0.2163418084383011       \n",
      "train step #8805 accuracy: 0.953125, loss: 0.23829743266105652      \n",
      "train step #8806 accuracy: 0.953125, loss: 0.19156482815742493      \n",
      "train step #8807 accuracy: 0.953125, loss: 0.26702502369880676      \n",
      "train step #8808 accuracy: 0.96875, loss: 0.16808275878429413      \n",
      "train step #8809 accuracy: 0.984375, loss: 0.05517680197954178      \n",
      "train step #8810 accuracy:   1.0, loss: 0.011005602777004242     \n",
      "train step #8811 accuracy: 0.96875, loss: 0.14995211362838745      \n",
      "train step #8812 accuracy:   1.0, loss: 0.0208551287651062       \n",
      "train step #8813 accuracy: 0.96875, loss: 0.07316283881664276      \n",
      "train step #8814 accuracy: 0.953125, loss: 0.2534192204475403       \n",
      "train step #8815 accuracy: 0.96875, loss: 0.15033739805221558      \n",
      "train step #8816 accuracy: 0.9375, loss: 0.1525188386440277       \n",
      "train step #8817 accuracy: 0.96875, loss: 0.09771198034286499      \n",
      "train step #8818 accuracy: 0.953125, loss: 0.1724064201116562       \n",
      "train step #8819 accuracy: 0.96875, loss: 0.07873696088790894      \n",
      "train step #8820 accuracy: 0.96875, loss: 0.16310471296310425      \n",
      "train step #8821 accuracy: 0.96875, loss: 0.13168036937713623      \n",
      "train step #8822 accuracy: 0.984375, loss: 0.0628366768360138       \n",
      "train step #8823 accuracy: 0.9375, loss: 0.12341534346342087      \n",
      "train step #8824 accuracy: 0.953125, loss: 0.07940355688333511      \n",
      "train step #8825 accuracy: 0.96875, loss: 0.1930195838212967       \n",
      "train step #8826 accuracy: 0.9375, loss: 0.20676380395889282      \n",
      "train step #8827 accuracy: 0.984375, loss: 0.050785236060619354     \n",
      "train step #8828 accuracy: 0.9375, loss: 0.21055790781974792      \n",
      "train step #8829 accuracy: 0.984375, loss: 0.04473824426531792      \n",
      "train step #8830 accuracy: 0.96875, loss: 0.189748153090477        \n",
      "train step #8831 accuracy: 0.96875, loss: 0.13053061068058014      \n",
      "train step #8832 accuracy: 0.96875, loss: 0.15646317601203918      \n",
      "train step #8833 accuracy: 0.984375, loss: 0.06527212262153625      \n",
      "train step #8834 accuracy: 0.96875, loss: 0.22446587681770325      \n",
      "train step #8835 accuracy: 0.96875, loss: 0.12351406365633011      \n",
      "train step #8836 accuracy: 0.984375, loss: 0.04282326251268387      \n",
      "train step #8837 accuracy: 0.9375, loss: 0.15071341395378113      \n",
      "train step #8838 accuracy: 0.96875, loss: 0.13639511168003082      \n",
      "train step #8839 accuracy: 0.9375, loss: 0.21778909862041473      \n",
      "train step #8840 accuracy: 0.953125, loss: 0.25034379959106445      \n",
      "train step #8841 accuracy: 0.953125, loss: 0.08942786604166031      \n",
      "train step #8842 accuracy: 0.953125, loss: 0.24667641520500183      \n",
      "train step #8843 accuracy: 0.9375, loss: 0.25086480379104614      \n",
      "train step #8844 accuracy: 0.984375, loss: 0.07260669022798538      \n",
      "train step #8845 accuracy: 0.984375, loss: 0.10075780004262924      \n",
      "train step #8846 accuracy: 0.9375, loss: 0.22713078558444977      \n",
      "train step #8847 accuracy: 0.984375, loss: 0.08691917359828949      \n",
      "train step #8848 accuracy: 0.96875, loss: 0.135276198387146        \n",
      "train step #8849 accuracy: 0.96875, loss: 0.13834762573242188      \n",
      "train step #8850 accuracy: 0.953125, loss: 0.18761539459228516      \n",
      "train step #8851 accuracy: 0.953125, loss: 0.16869381070137024      \n",
      "train step #8852 accuracy: 0.96875, loss: 0.07474759966135025      \n",
      "train step #8853 accuracy: 0.953125, loss: 0.19006739556789398      \n",
      "train step #8854 accuracy: 0.921875, loss: 0.25686779618263245      \n",
      "train step #8855 accuracy:   1.0, loss: 0.04574509337544441      \n",
      "train step #8856 accuracy:   1.0, loss: 0.01340215653181076      \n",
      "train step #8857 accuracy: 0.984375, loss: 0.0669853612780571       \n",
      "train step #8858 accuracy: 0.953125, loss: 0.1204405352473259       \n",
      "train step #8859 accuracy:   1.0, loss: 0.06620852649211884      \n",
      "train step #8860 accuracy: 0.953125, loss: 0.17989882826805115      \n",
      "train step #8861 accuracy: 0.984375, loss: 0.04462898522615433      \n",
      "train step #8862 accuracy: 0.9375, loss: 0.17579789459705353      \n",
      "train step #8863 accuracy: 0.921875, loss: 0.1873566210269928       \n",
      "train step #8864 accuracy: 0.984375, loss: 0.17117474973201752      \n",
      "train step #8865 accuracy: 0.96875, loss: 0.07853522151708603      \n",
      "train step #8866 accuracy: 0.96875, loss: 0.07794700562953949      \n",
      "train step #8867 accuracy: 0.953125, loss: 0.16265174746513367      \n",
      "train step #8868 accuracy: 0.953125, loss: 0.15235452353954315      \n",
      "train step #8869 accuracy: 0.953125, loss: 0.20459626615047455      \n",
      "train step #8870 accuracy: 0.96875, loss: 0.10101345181465149      \n",
      "train step #8871 accuracy: 0.921875, loss: 0.24170757830142975      \n",
      "train step #8872 accuracy: 0.953125, loss: 0.15487653017044067      \n",
      "train step #8873 accuracy: 0.96875, loss: 0.07808111608028412      \n",
      "train step #8874 accuracy: 0.96875, loss: 0.10217060893774033      \n",
      "train step #8875 accuracy: 0.96875, loss: 0.11458790302276611      \n",
      "train step #8876 accuracy: 0.96875, loss: 0.08056880533695221      \n",
      "train step #8877 accuracy: 0.96875, loss: 0.11006602644920349      \n",
      "train step #8878 accuracy: 0.96875, loss: 0.08923595398664474      \n",
      "train step #8879 accuracy: 0.953125, loss: 0.12042687833309174      \n",
      "train step #8880 accuracy: 0.984375, loss: 0.1255236566066742       \n",
      "train step #8881 accuracy:   1.0, loss: 0.026070483028888702     \n",
      "train step #8882 accuracy: 0.9375, loss: 0.20258066058158875      \n",
      "train step #8883 accuracy: 0.953125, loss: 0.18866266310214996      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #8884 accuracy: 0.96875, loss: 0.0991571694612503       \n",
      "train step #8885 accuracy: 0.96875, loss: 0.1680261790752411       \n",
      "train step #8886 accuracy: 0.96875, loss: 0.1706988662481308       \n",
      "train step #8887 accuracy: 0.953125, loss: 0.13455641269683838      \n",
      "train step #8888 accuracy: 0.96875, loss: 0.11194086074829102      \n",
      "train step #8889 accuracy:   1.0, loss: 0.029042057693004608     \n",
      "train step #8890 accuracy: 0.984375, loss: 0.08233031630516052      \n",
      "train step #8891 accuracy: 0.953125, loss: 0.23741625249385834      \n",
      "train step #8892 accuracy: 0.984375, loss: 0.06875140964984894      \n",
      "train step #8893 accuracy: 0.96875, loss: 0.06994032114744186      \n",
      "train step #8894 accuracy: 0.96875, loss: 0.10164930671453476      \n",
      "train step #8895 accuracy: 0.921875, loss: 0.22693946957588196      \n",
      "train step #8896 accuracy: 0.953125, loss: 0.2036258578300476       \n",
      "train step #8897 accuracy: 0.96875, loss: 0.11145221441984177      \n",
      "train step #8898 accuracy:   1.0, loss: 0.027511760592460632     \n",
      "train step #8899 accuracy: 0.984375, loss: 0.03995799273252487      \n",
      "train step #8900 accuracy: 0.984375, loss: 0.05174386501312256      \n",
      "train step #8901 accuracy: 0.953125, loss: 0.19774183630943298      \n",
      "train step #8902 accuracy: 0.96875, loss: 0.09625988453626633      \n",
      "train step #8903 accuracy: 0.953125, loss: 0.13342732191085815      \n",
      "train step #8904 accuracy: 0.96875, loss: 0.15116660296916962      \n",
      "train step #8905 accuracy:   1.0, loss: 0.01685207337141037      \n",
      "train step #8906 accuracy: 0.9375, loss: 0.21690751612186432      \n",
      "train step #8907 accuracy: 0.9375, loss: 0.20961745083332062      \n",
      "train step #8908 accuracy:   1.0, loss: 0.03436814993619919      \n",
      "train step #8909 accuracy: 0.9375, loss: 0.2270442694425583       \n",
      "train step #8910 accuracy: 0.953125, loss: 0.11753931641578674      \n",
      "train step #8911 accuracy: 0.96875, loss: 0.12206939607858658      \n",
      "train step #8912 accuracy: 0.9375, loss: 0.18818847835063934      \n",
      "train step #8913 accuracy: 0.96875, loss: 0.11700756847858429      \n",
      "train step #8914 accuracy: 0.984375, loss: 0.10745356976985931      \n",
      "train step #8915 accuracy: 0.953125, loss: 0.13228148221969604      \n",
      "train step #8916 accuracy: 0.96875, loss: 0.14415152370929718      \n",
      "train step #8917 accuracy:   1.0, loss: 0.09252119809389114      \n",
      "train step #8918 accuracy: 0.921875, loss: 0.3069756031036377       \n",
      "train step #8919 accuracy: 0.96875, loss: 0.11749961972236633      \n",
      "train step #8920 accuracy: 0.9375, loss: 0.2344842255115509       \n",
      "train step #8921 accuracy: 0.96875, loss: 0.17369508743286133      \n",
      "train step #8922 accuracy:   1.0, loss: 0.020202383399009705     \n",
      "train step #8923 accuracy: 0.9375, loss: 0.17823274433612823      \n",
      "train step #8924 accuracy: 0.9375, loss: 0.24164099991321564      \n",
      "train step #8925 accuracy: 0.90625, loss: 0.2933086156845093       \n",
      "train step #8926 accuracy: 0.9375, loss: 0.1234801635146141       \n",
      "train step #8927 accuracy: 0.984375, loss: 0.08950401842594147      \n",
      "train step #8928 accuracy: 0.984375, loss: 0.08187635987997055      \n",
      "train step #8929 accuracy: 0.984375, loss: 0.09171991050243378      \n",
      "train step #8930 accuracy: 0.96875, loss: 0.09882379323244095      \n",
      "train step #8931 accuracy: 0.9375, loss: 0.3482937514781952       \n",
      "train step #8932 accuracy: 0.9375, loss: 0.19777603447437286      \n",
      "train step #8933 accuracy: 0.984375, loss: 0.10281181335449219      \n",
      "train step #8934 accuracy: 0.9375, loss: 0.1872684210538864       \n",
      "train step #8935 accuracy: 0.9375, loss: 0.2374333143234253       \n",
      "train step #8936 accuracy: 0.9375, loss: 0.23116064071655273      \n",
      "train step #8937 accuracy: 0.96875, loss: 0.14311781525611877      \n",
      "train step #8938 accuracy: 0.9375, loss: 0.22851227223873138      \n",
      "train step #8939 accuracy: 0.96875, loss: 0.17046643793582916      \n",
      "train step #8940 accuracy: 0.9375, loss: 0.16050979495048523      \n",
      "train step #8941 accuracy: 0.96875, loss: 0.2164507806301117       \n",
      "train step #8942 accuracy: 0.9375, loss: 0.24011856317520142      \n",
      "train step #8943 accuracy: 0.984375, loss: 0.042482901364564896     \n",
      "train step #8944 accuracy: 0.9375, loss: 0.13187357783317566      \n",
      "train step #8945 accuracy: 0.984375, loss: 0.045479364693164825     \n",
      "train step #8946 accuracy: 0.9375, loss: 0.30525559186935425      \n",
      "train step #8947 accuracy: 0.984375, loss: 0.09205128997564316      \n",
      "train step #8948 accuracy: 0.96875, loss: 0.11980412900447845      \n",
      "train step #8949 accuracy: 0.953125, loss: 0.13729004561901093      \n",
      "train step #8950 accuracy:   1.0, loss: 0.036708440631628036     \n",
      "train step #8951 accuracy: 0.9375, loss: 0.1123816967010498       \n",
      "train step #8952 accuracy: 0.953125, loss: 0.16557340323925018      \n",
      "train step #8953 accuracy: 0.984375, loss: 0.1693166196346283       \n",
      "train step #8954 accuracy: 0.953125, loss: 0.18291600048542023      \n",
      "train step #8955 accuracy: 0.9375, loss: 0.18134848773479462      \n",
      "train step #8956 accuracy: 0.96875, loss: 0.1065727174282074       \n",
      "train step #8957 accuracy: 0.953125, loss: 0.19033648073673248      \n",
      "train step #8958 accuracy: 0.96875, loss: 0.17534169554710388      \n",
      "train step #8959 accuracy: 0.984375, loss: 0.13635075092315674      \n",
      "train step #8960 accuracy:   1.0, loss: 0.03306204825639725      \n",
      "train step #8961 accuracy: 0.9375, loss: 0.17063120007514954      \n",
      "train step #8962 accuracy: 0.984375, loss: 0.04724973440170288      \n",
      "train step #8963 accuracy: 0.96875, loss: 0.16518612205982208      \n",
      "train step #8964 accuracy:   1.0, loss: 0.020528867840766907     \n",
      "train step #8965 accuracy:   1.0, loss: 0.03679047152400017      \n",
      "train step #8966 accuracy: 0.921875, loss: 0.2333545982837677       \n",
      "train step #8967 accuracy: 0.984375, loss: 0.08875591307878494      \n",
      "train step #8968 accuracy: 0.984375, loss: 0.0952494814991951       \n",
      "train step #8969 accuracy: 0.9375, loss: 0.17081807553768158      \n",
      "train step #8970 accuracy: 0.90625, loss: 0.28210824728012085      \n",
      "train step #8971 accuracy: 0.96875, loss: 0.1133926510810852       \n",
      "train step #8972 accuracy:   1.0, loss: 0.0653747096657753       \n",
      "train step #8973 accuracy:   1.0, loss: 0.031804926693439484     \n",
      "train step #8974 accuracy: 0.984375, loss: 0.08471420407295227      \n",
      "train step #8975 accuracy: 0.984375, loss: 0.06540820747613907      \n",
      "train step #8976 accuracy: 0.953125, loss: 0.27307403087615967      \n",
      "train step #8977 accuracy: 0.9375, loss: 0.1611257642507553       \n",
      "train step #8978 accuracy: 0.984375, loss: 0.05492237210273743      \n",
      "train step #8979 accuracy:   1.0, loss: 0.03689093142747879      \n",
      "train step #8980 accuracy:   1.0, loss: 0.030691809952259064     \n",
      "train step #8981 accuracy: 0.953125, loss: 0.11963500082492828      \n",
      "train step #8982 accuracy: 0.96875, loss: 0.12154145538806915      \n",
      "train step #8983 accuracy: 0.9375, loss: 0.22951766848564148      \n",
      "train step #8984 accuracy: 0.96875, loss: 0.10471874475479126      \n",
      "train step #8985 accuracy: 0.984375, loss: 0.08827173709869385      \n",
      "train step #8986 accuracy: 0.96875, loss: 0.10957424342632294      \n",
      "train step #8987 accuracy: 0.984375, loss: 0.07563896477222443      \n",
      "train step #8988 accuracy: 0.984375, loss: 0.10380563139915466      \n",
      "train step #8989 accuracy: 0.9375, loss: 0.15944673120975494      \n",
      "train step #8990 accuracy: 0.96875, loss: 0.15101131796836853      \n",
      "train step #8991 accuracy: 0.984375, loss: 0.06023800000548363      \n",
      "train step #8992 accuracy: 0.984375, loss: 0.11662281304597855      \n",
      "train step #8993 accuracy: 0.90625, loss: 0.25434887409210205      \n",
      "train step #8994 accuracy: 0.96875, loss: 0.13350649178028107      \n",
      "train step #8995 accuracy: 0.953125, loss: 0.1624857783317566       \n",
      "train step #8996 accuracy: 0.953125, loss: 0.1959322988986969       \n",
      "train step #8997 accuracy: 0.984375, loss: 0.04576503485441208      \n",
      "train step #8998 accuracy:   1.0, loss: 0.03753558546304703      \n",
      "train step #8999 accuracy: 0.984375, loss: 0.09985862672328949      \n",
      "train step #9000 accuracy: 0.953125, loss: 0.12193157523870468      \n",
      "train step #9001 accuracy: 0.96875, loss: 0.10379014164209366      \n",
      "train step #9002 accuracy: 0.9375, loss: 0.24022093415260315      \n",
      "train step #9003 accuracy: 0.96875, loss: 0.1666703224182129       \n",
      "train step #9004 accuracy: 0.9375, loss: 0.1665319949388504       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #9005 accuracy: 0.953125, loss: 0.22378776967525482      \n",
      "train step #9006 accuracy: 0.953125, loss: 0.1931251883506775       \n",
      "train step #9007 accuracy: 0.96875, loss: 0.19103071093559265      \n",
      "train step #9008 accuracy: 0.984375, loss: 0.03447716683149338      \n",
      "train step #9009 accuracy: 0.96875, loss: 0.1613484025001526       \n",
      "train step #9010 accuracy: 0.96875, loss: 0.11439330875873566      \n",
      "train step #9011 accuracy: 0.96875, loss: 0.10079407691955566      \n",
      "train step #9012 accuracy: 0.96875, loss: 0.08840620517730713      \n",
      "train step #9013 accuracy: 0.953125, loss: 0.12818461656570435      \n",
      "train step #9014 accuracy: 0.96875, loss: 0.05477406829595566      \n",
      "train step #9015 accuracy: 0.96875, loss: 0.12988345324993134      \n",
      "train step #9016 accuracy:   1.0, loss: 0.020442456007003784     \n",
      "train step #9017 accuracy: 0.953125, loss: 0.11765875667333603      \n",
      "train step #9018 accuracy: 0.96875, loss: 0.15828309953212738      \n",
      "train step #9019 accuracy: 0.96875, loss: 0.12822134792804718      \n",
      "train step #9020 accuracy: 0.96875, loss: 0.15030905604362488      \n",
      "train step #9021 accuracy: 0.9375, loss: 0.20918579399585724      \n",
      "train step #9022 accuracy: 0.96875, loss: 0.15410281717777252      \n",
      "dev accuracy: 0.9375, loss: 0.19991600513458252      \n",
      "dev accuracy: 0.8125, loss: 0.5979544520378113       \n",
      "dev accuracy:   1.0, loss: 0.027425020933151245     \n",
      "dev accuracy: 0.9375, loss: 0.08540219068527222      \n",
      "dev accuracy:   1.0, loss: 0.027436137199401855     \n",
      "dev accuracy:   1.0, loss: 0.005345195531845093     \n",
      "dev accuracy: 0.875, loss: 0.43760067224502563      \n",
      "dev accuracy: 0.875, loss: 0.31503045558929443      \n",
      "dev accuracy: 0.9375, loss: 0.18970251083374023      \n",
      "dev accuracy: 0.9375, loss: 0.14617130160331726      \n",
      "dev accuracy: 0.9375, loss: 0.10868173837661743      \n",
      "dev accuracy:   1.0, loss: 0.04050898551940918      \n",
      "dev accuracy: 0.9375, loss: 0.0840315967798233       \n",
      "dev accuracy: 0.9375, loss: 0.1734492927789688       \n",
      "dev accuracy: 0.9375, loss: 0.261250376701355        \n",
      "dev accuracy: 0.9375, loss: 0.08868013322353363      \n",
      "dev accuracy:   1.0, loss: 0.04262518882751465      \n",
      "dev accuracy: 0.9375, loss: 0.23467348515987396      \n",
      "dev accuracy:   1.0, loss: 0.01179957389831543      \n",
      "dev accuracy: 0.875, loss: 0.2115231156349182       \n",
      "dev accuracy:   1.0, loss: 0.047406986355781555     \n",
      "dev accuracy:   1.0, loss: 0.006940990686416626     \n",
      "dev accuracy: 0.9375, loss: 0.15637755393981934      \n",
      "dev accuracy: 0.9375, loss: 0.10067325830459595      \n",
      "dev accuracy:   1.0, loss: 0.05173289775848389      \n",
      "dev accuracy:   1.0, loss: 0.10345372557640076      \n",
      "dev accuracy: 0.9375, loss: 0.14475953578948975      \n",
      "dev accuracy:   1.0, loss: 0.11353503167629242      \n",
      "dev accuracy:   1.0, loss: 0.015183061361312866     \n",
      "dev accuracy: 0.875, loss: 0.5157464742660522       \n",
      "dev accuracy:   1.0, loss: 0.002981841564178467     \n",
      "dev accuracy:   1.0, loss: 0.10153377801179886      \n",
      "dev accuracy: 0.9375, loss: 0.06464517116546631      \n",
      "dev accuracy:   1.0, loss: 0.045324504375457764     \n",
      "dev accuracy:   1.0, loss: 0.025189071893692017     \n",
      "dev accuracy: 0.9375, loss: 0.10655146837234497      \n",
      "dev accuracy:   1.0, loss: 0.013169467449188232     \n",
      "dev accuracy:   1.0, loss: 0.013035178184509277     \n",
      "dev accuracy:   1.0, loss: 0.06584349274635315      \n",
      "dev accuracy: 0.9375, loss: 0.14783525466918945      \n",
      "dev accuracy:   1.0, loss: 0.06857350468635559      \n",
      "dev accuracy:   1.0, loss: 0.04223930835723877      \n",
      "dev accuracy: 0.875, loss: 0.2438451200723648       \n",
      "dev accuracy: 0.875, loss: 0.3986228406429291       \n",
      "dev accuracy:   1.0, loss: 0.0015917420387268066    \n",
      "dev accuracy: 0.9375, loss: 0.11430239677429199      \n",
      "dev accuracy: 0.8125, loss: 0.8575881123542786       \n",
      "dev accuracy: 0.9375, loss: 0.20018282532691956      \n",
      "dev accuracy: 0.9375, loss: 0.11019584536552429      \n",
      "dev accuracy: 0.875, loss: 0.21949699521064758      \n",
      "dev accuracy:   1.0, loss: 0.0006383657455444336    \n",
      "dev accuracy: 0.9375, loss: 0.08131182193756104      \n",
      "dev accuracy:   1.0, loss: 0.0034969449043273926    \n",
      "dev accuracy: 0.9375, loss: 0.2615801990032196       \n",
      "dev accuracy: 0.875, loss: 0.3409107029438019       \n",
      "dev accuracy:   1.0, loss: 0.0690011978149414       \n",
      "dev accuracy: 0.9375, loss: 0.1495395451784134       \n",
      "dev accuracy:   1.0, loss: 0.002475649118423462     \n",
      "dev accuracy:   1.0, loss: 0.011232614517211914     \n",
      "dev accuracy: 0.9375, loss: 0.2402551919221878       \n",
      "dev accuracy: 0.9375, loss: 0.20501521229743958      \n",
      "dev accuracy: 0.9375, loss: 0.07875415682792664      \n",
      "dev accuracy:   1.0, loss: 0.14751793444156647      \n",
      "dev accuracy: 0.875, loss: 0.41599148511886597      \n",
      "dev accuracy: 0.9375, loss: 0.2468307912349701       \n",
      "dev accuracy:   1.0, loss: 0.047623783349990845     \n",
      "dev accuracy: 0.875, loss: 0.38442033529281616      \n",
      "dev accuracy:   1.0, loss: 0.005858242511749268     \n",
      "dev accuracy:   1.0, loss: 0.0201435387134552       \n",
      "dev accuracy:   1.0, loss: 0.006090641021728516     \n",
      "dev accuracy: 0.9375, loss: 0.19497692584991455      \n",
      "dev accuracy:   1.0, loss: 0.014839887619018555     \n",
      "dev accuracy: 0.875, loss: 0.2482963502407074       \n",
      "dev accuracy: 0.9375, loss: 0.1749616265296936       \n",
      "dev accuracy: 0.875, loss: 0.37138599157333374      \n",
      "dev accuracy: 0.9375, loss: 0.1004018485546112       \n",
      "dev accuracy: 0.9375, loss: 0.09186767041683197      \n",
      "dev accuracy:   1.0, loss: 0.041821688413619995     \n",
      "dev accuracy:   1.0, loss: 0.001672983169555664     \n",
      "dev accuracy: 0.9375, loss: 0.09571021795272827      \n",
      "dev accuracy:   1.0, loss: 0.017895430326461792     \n",
      "dev accuracy: 0.9375, loss: 0.10360762476921082      \n",
      "dev accuracy: 0.8125, loss: 0.4566081166267395       \n",
      "dev accuracy: 0.9375, loss: 0.20775365829467773      \n",
      "dev accuracy:   1.0, loss: 0.007815748453140259     \n",
      "dev accuracy:   1.0, loss: 0.018890976905822754     \n",
      "dev accuracy: 0.9375, loss: 0.14789918065071106      \n",
      "dev accuracy:   1.0, loss: 0.005542933940887451     \n",
      "dev accuracy: 0.9375, loss: 0.29229864478111267      \n",
      "dev accuracy: 0.875, loss: 0.23170106112957         \n",
      "dev accuracy:   1.0, loss: 0.005934685468673706     \n",
      "dev accuracy: 0.875, loss: 0.5110332369804382       \n",
      "dev accuracy: 0.9375, loss: 0.05676853656768799      \n",
      "dev accuracy:   1.0, loss: 0.03755873441696167      \n",
      "dev accuracy:   1.0, loss: 0.026492536067962646     \n",
      "dev accuracy: 0.9375, loss: 0.23531432449817657      \n",
      "dev accuracy:   1.0, loss: 0.015452653169631958     \n",
      "dev accuracy: 0.9375, loss: 0.1812814176082611       \n",
      "dev accuracy:   1.0, loss: 0.0043762922286987305    \n",
      "dev accuracy:   1.0, loss: 0.01588362455368042      \n",
      "dev accuracy:   1.0, loss: 0.09521621465682983      \n",
      "dev accuracy:   1.0, loss: 0.053651511669158936     \n",
      "dev accuracy: 0.9375, loss: 0.24063456058502197      \n",
      "dev accuracy:   1.0, loss: 0.04514092206954956      \n",
      "dev accuracy:   1.0, loss: 0.01095089316368103      \n",
      "dev accuracy: 0.9375, loss: 0.20951825380325317      \n",
      "dev accuracy:   1.0, loss: 0.005187779664993286     \n",
      "dev accuracy:   1.0, loss: 0.047348082065582275     \n",
      "dev accuracy: 0.9375, loss: 0.4304991066455841       \n",
      "dev accuracy: 0.9375, loss: 0.07333151996135712      \n",
      "dev accuracy: 0.9375, loss: 0.3091265857219696       \n",
      "dev accuracy: 0.9375, loss: 0.23414477705955505      \n",
      "dev accuracy: 0.6875, loss: 0.9954572916030884       \n",
      "dev accuracy: 0.9375, loss: 0.09204885363578796      \n",
      "dev accuracy: 0.9375, loss: 0.22166326642036438      \n",
      "dev accuracy: 0.9375, loss: 0.12921932339668274      \n",
      "dev accuracy: 0.9375, loss: 0.26986461877822876      \n",
      "dev accuracy:   1.0, loss: 0.024599909782409668     \n",
      "dev accuracy:   1.0, loss: 0.020150452852249146     \n",
      "dev accuracy:   1.0, loss: 0.0008360743522644043    \n",
      "dev accuracy:   1.0, loss: 0.018444985151290894     \n",
      "dev accuracy:   1.0, loss: 0.0004188418388366699    \n",
      "dev accuracy:   1.0, loss: 0.05147998034954071      \n",
      "dev accuracy: 0.9375, loss: 0.08997035026550293      \n",
      "dev accuracy: 0.875, loss: 0.6615589261054993       \n",
      "dev accuracy:   1.0, loss: 0.04800450801849365      \n",
      "dev accuracy: 0.9375, loss: 0.25449448823928833      \n",
      "dev accuracy:   1.0, loss: 0.10276630520820618      \n",
      "dev accuracy: 0.9375, loss: 0.11121422052383423      \n",
      "dev accuracy:   1.0, loss: 0.06768900156021118      \n",
      "dev accuracy:   1.0, loss: 0.0138624906539917       \n",
      "dev accuracy: 0.9375, loss: 0.2653125524520874       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev accuracy: 0.9375, loss: 0.23195970058441162      \n",
      "dev accuracy: 0.9375, loss: 0.34474772214889526      \n",
      "dev accuracy:   1.0, loss: 0.04554641246795654      \n",
      "dev accuracy: 0.875, loss: 0.3456769287586212       \n",
      "dev accuracy:   1.0, loss: 0.004736065864562988     \n",
      "dev accuracy:   1.0, loss: 0.024448364973068237     \n",
      "dev accuracy: 0.9375, loss: 0.4244897663593292       \n",
      "dev accuracy: 0.9375, loss: 0.42405635118484497      \n",
      "dev accuracy: 0.875, loss: 0.19665458798408508      \n",
      "dev accuracy:   1.0, loss: 0.1442660242319107       \n",
      "dev accuracy: 0.9375, loss: 0.2419506013393402       \n",
      "dev accuracy: 0.9375, loss: 0.18000692129135132      \n",
      "dev accuracy: 0.8125, loss: 0.46109670400619507      \n",
      "dev accuracy: 0.9375, loss: 0.10697042942047119      \n",
      "dev accuracy:   1.0, loss: 0.01246267557144165      \n",
      "dev accuracy:   1.0, loss: 0.024306774139404297     \n",
      "dev accuracy: 0.9375, loss: 0.10578089952468872      \n",
      "dev accuracy: 0.875, loss: 0.335683673620224        \n",
      "dev accuracy: 0.9375, loss: 0.21083147823810577      \n",
      "dev accuracy: 0.8125, loss: 0.24554504454135895      \n",
      "dev accuracy: 0.8125, loss: 0.3020804524421692       \n",
      "dev accuracy: 0.9375, loss: 0.22353661060333252      \n",
      "dev accuracy:   1.0, loss: 0.025368094444274902     \n",
      "dev accuracy: 0.9375, loss: 0.6210038661956787       \n",
      "dev accuracy:   1.0, loss: 0.1120222806930542       \n",
      "dev accuracy:   1.0, loss: 0.0003421306610107422    \n",
      "dev accuracy: 0.9375, loss: 0.3674375116825104       \n",
      "dev accuracy:   1.0, loss: 0.08660630881786346      \n",
      "dev accuracy:   1.0, loss: 0.022654861211776733     \n",
      "dev accuracy: 0.9375, loss: 0.13632190227508545      \n",
      "dev accuracy:   1.0, loss: 0.003536313772201538     \n",
      "dev accuracy:   1.0, loss: 0.0246240496635437       \n",
      "dev accuracy: 0.9375, loss: 0.13915273547172546      \n",
      "dev accuracy: 0.9375, loss: 0.1129879280924797       \n",
      "dev accuracy:   1.0, loss: 0.031858861446380615     \n",
      "dev accuracy: 0.9375, loss: 0.1680775284767151       \n",
      "dev accuracy: 0.875, loss: 0.44167500734329224      \n",
      "dev accuracy: 0.9375, loss: 0.2589055597782135       \n",
      "dev accuracy:   1.0, loss: 0.008686065673828125     \n",
      "dev accuracy:   1.0, loss: 0.04025217890739441      \n",
      "dev accuracy: 0.9375, loss: 0.1899329572916031       \n",
      "dev accuracy:   1.0, loss: 0.04574143886566162      \n",
      "dev accuracy: 0.875, loss: 0.1864265352487564       \n",
      "dev accuracy: 0.9375, loss: 0.319513201713562        \n",
      "dev accuracy: 0.9375, loss: 0.4285632371902466       \n",
      "dev accuracy: 0.875, loss: 0.3482797145843506       \n",
      "dev accuracy:   1.0, loss: 0.00286710262298584      \n",
      "dev accuracy:   1.0, loss: 0.004392147064208984     \n",
      "dev accuracy: 0.9375, loss: 0.09107623994350433      \n",
      "dev accuracy:   1.0, loss: 0.0072882771492004395    \n",
      "dev accuracy: 0.9375, loss: 0.0966804027557373       \n",
      "dev accuracy:   1.0, loss: 0.025214791297912598     \n",
      "dev accuracy:   1.0, loss: 0.09350922703742981      \n",
      "dev accuracy: 0.9375, loss: 0.48455607891082764      \n",
      "dev accuracy: 0.9375, loss: 0.5383762717247009       \n",
      "dev accuracy:   1.0, loss: 0.03040182590484619      \n",
      "dev accuracy: 0.875, loss: 0.6493164300918579       \n",
      "dev accuracy: 0.9375, loss: 0.16256968677043915      \n",
      "dev accuracy: 0.9375, loss: 0.0967220664024353       \n",
      "dev accuracy: 0.875, loss: 0.665071427822113        \n",
      "dev accuracy:   1.0, loss: 0.04042184352874756      \n",
      "dev accuracy: 0.6666666666666666, loss: 0.2898569107055664       \n",
      "final dev accuracy: 0.9509235395189004\n",
      "test accuracy:   1.0, loss: 0.01132655143737793      \n",
      "test accuracy: 0.9375, loss: 0.21965909004211426      \n",
      "test accuracy:   1.0, loss: 0.005177557468414307     \n",
      "test accuracy: 0.9375, loss: 0.13756372034549713      \n",
      "test accuracy:   1.0, loss: 0.0437452495098114       \n",
      "test accuracy:   1.0, loss: 0.004035055637359619     \n",
      "test accuracy:   1.0, loss: 0.0014438033103942871    \n",
      "test accuracy: 0.875, loss: 0.25507426261901855      \n",
      "test accuracy: 0.9375, loss: 0.1640072762966156       \n",
      "test accuracy:   1.0, loss: 0.027900874614715576     \n",
      "test accuracy: 0.875, loss: 0.47014880180358887      \n",
      "test accuracy: 0.875, loss: 0.18972480297088623      \n",
      "test accuracy: 0.9375, loss: 0.19465792179107666      \n",
      "test accuracy:  0.75, loss: 0.6318871974945068       \n",
      "test accuracy:   1.0, loss: 0.006194502115249634     \n",
      "test accuracy:   1.0, loss: 0.039641618728637695     \n",
      "test accuracy: 0.875, loss: 0.40142515301704407      \n",
      "test accuracy:   1.0, loss: 0.053893059492111206     \n",
      "test accuracy:   1.0, loss: 0.029349714517593384     \n",
      "test accuracy: 0.9375, loss: 0.11271417886018753      \n",
      "test accuracy:   1.0, loss: 0.01666778326034546      \n",
      "test accuracy:   1.0, loss: 0.0015253424644470215    \n",
      "test accuracy:   1.0, loss: 0.00871366262435913      \n",
      "test accuracy:   1.0, loss: 0.02510678768157959      \n",
      "test accuracy:   1.0, loss: 0.008068323135375977     \n",
      "test accuracy:   1.0, loss: 0.04369246959686279      \n",
      "test accuracy: 0.9375, loss: 0.05750781297683716      \n",
      "test accuracy:   1.0, loss: 0.05600184202194214      \n",
      "test accuracy:   1.0, loss: 0.026082277297973633     \n",
      "test accuracy:   1.0, loss: 0.01561543345451355      \n",
      "test accuracy: 0.875, loss: 0.2598518133163452       \n",
      "test accuracy:   1.0, loss: 0.002878546714782715     \n",
      "test accuracy:   1.0, loss: 0.0014957785606384277    \n",
      "test accuracy:   1.0, loss: 0.013034522533416748     \n",
      "test accuracy: 0.9375, loss: 0.08341959118843079      \n",
      "test accuracy: 0.9375, loss: 0.282051146030426        \n",
      "test accuracy: 0.875, loss: 0.2698175609111786       \n",
      "test accuracy: 0.875, loss: 0.4505375027656555       \n",
      "test accuracy: 0.9375, loss: 0.07320117950439453      \n",
      "test accuracy:   1.0, loss: 0.0029471516609191895    \n",
      "test accuracy: 0.9375, loss: 0.25340649485588074      \n",
      "test accuracy:   1.0, loss: 0.03778812289237976      \n",
      "test accuracy:   1.0, loss: 0.02377977967262268      \n",
      "test accuracy: 0.8125, loss: 0.474353164434433        \n",
      "test accuracy: 0.9375, loss: 0.36398598551750183      \n",
      "test accuracy: 0.9375, loss: 0.18107178807258606      \n",
      "test accuracy: 0.875, loss: 0.33877718448638916      \n",
      "test accuracy: 0.9375, loss: 0.09832355380058289      \n",
      "test accuracy:   1.0, loss: 0.003179788589477539     \n",
      "test accuracy:   1.0, loss: 0.028371661901474        \n",
      "test accuracy: 0.9375, loss: 0.22872069478034973      \n",
      "test accuracy: 0.9375, loss: 0.062048494815826416     \n",
      "test accuracy: 0.9375, loss: 0.13590779900550842      \n",
      "test accuracy:   1.0, loss: 0.011330068111419678     \n",
      "test accuracy: 0.9375, loss: 0.1652808040380478       \n",
      "test accuracy:   1.0, loss: 0.03756561875343323      \n",
      "test accuracy: 0.9375, loss: 0.11504420638084412      \n",
      "test accuracy:   1.0, loss: 0.003555119037628174     \n",
      "test accuracy:   1.0, loss: 0.011361002922058105     \n",
      "test accuracy: 0.9375, loss: 0.06360533833503723      \n",
      "test accuracy:   1.0, loss: 0.004808545112609863     \n",
      "test accuracy: 0.9375, loss: 0.2901197373867035       \n",
      "test accuracy:   1.0, loss: 0.007604777812957764     \n",
      "test accuracy:   1.0, loss: 0.0019197463989257812    \n",
      "test accuracy: 0.9375, loss: 0.21085813641548157      \n",
      "test accuracy: 0.875, loss: 0.25265616178512573      \n",
      "test accuracy:   1.0, loss: 0.12053349614143372      \n",
      "test accuracy:   1.0, loss: 0.025982052087783813     \n",
      "test accuracy: 0.9375, loss: 0.13379058241844177      \n",
      "test accuracy:   1.0, loss: 0.02311992645263672      \n",
      "test accuracy:   1.0, loss: 0.013507544994354248     \n",
      "test accuracy:   1.0, loss: 0.0018887817859649658    \n",
      "test accuracy:   1.0, loss: 0.009148716926574707     \n",
      "test accuracy: 0.9375, loss: 0.254605233669281        \n",
      "test accuracy: 0.875, loss: 0.31569838523864746      \n",
      "test accuracy:   1.0, loss: 0.009354829788208008     \n",
      "test accuracy:   1.0, loss: 0.02734997868537903      \n",
      "test accuracy: 0.9375, loss: 0.20211036503314972      \n",
      "test accuracy:   1.0, loss: 0.05459558963775635      \n",
      "test accuracy: 0.9375, loss: 0.21630443632602692      \n",
      "test accuracy:   1.0, loss: 0.03462493419647217      \n",
      "test accuracy: 0.9375, loss: 0.2546013295650482       \n",
      "test accuracy:   1.0, loss: 0.01770240068435669      \n",
      "test accuracy:   1.0, loss: 0.01673448085784912      \n",
      "test accuracy: 0.9375, loss: 0.18732480704784393      \n",
      "test accuracy:   1.0, loss: 0.010056734085083008     \n",
      "test accuracy: 0.9375, loss: 0.13381345570087433      \n",
      "test accuracy:   1.0, loss: 0.02468763291835785      \n",
      "test accuracy: 0.9375, loss: 0.12442439794540405      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:   1.0, loss: 0.013709187507629395     \n",
      "test accuracy:   1.0, loss: 0.0327606201171875       \n",
      "test accuracy: 0.9375, loss: 0.20119708776474         \n",
      "test accuracy: 0.875, loss: 0.7215802669525146       \n",
      "test accuracy:   1.0, loss: 0.0037711262702941895    \n",
      "test accuracy:   1.0, loss: 0.017562448978424072     \n",
      "test accuracy: 0.9375, loss: 0.20317262411117554      \n",
      "test accuracy:   1.0, loss: 0.0036230087280273438    \n",
      "test accuracy:   1.0, loss: 0.006030678749084473     \n",
      "test accuracy:   1.0, loss: 0.009665250778198242     \n",
      "test accuracy:   1.0, loss: 0.026600241661071777     \n",
      "test accuracy: 0.9375, loss: 0.12577015161514282      \n",
      "test accuracy:   1.0, loss: 0.003833949565887451     \n",
      "test accuracy:   1.0, loss: 0.039680227637290955     \n",
      "test accuracy:   1.0, loss: 0.011337071657180786     \n",
      "test accuracy:   1.0, loss: 0.09160539507865906      \n",
      "test accuracy:   1.0, loss: 0.024337172508239746     \n",
      "test accuracy:   1.0, loss: 0.09897445142269135      \n",
      "test accuracy: 0.9375, loss: 0.14369289577007294      \n",
      "test accuracy:   1.0, loss: 0.036102473735809326     \n",
      "test accuracy:   1.0, loss: 0.021036744117736816     \n",
      "test accuracy:   1.0, loss: 0.0022276639938354492    \n",
      "test accuracy:   1.0, loss: 0.0076427161693573       \n",
      "test accuracy: 0.9375, loss: 0.1018284261226654       \n",
      "test accuracy: 0.9375, loss: 0.18521332740783691      \n",
      "test accuracy:   1.0, loss: 0.07240137457847595      \n",
      "test accuracy:   1.0, loss: 0.028937458992004395     \n",
      "test accuracy:   1.0, loss: 0.0069151222705841064    \n",
      "test accuracy:   1.0, loss: 0.01191982626914978      \n",
      "test accuracy: 0.9375, loss: 0.18557780981063843      \n",
      "test accuracy:   1.0, loss: 0.010963767766952515     \n",
      "test accuracy:   1.0, loss: 0.044746965169906616     \n",
      "test accuracy:   1.0, loss: 0.03202894330024719      \n",
      "test accuracy: 0.9375, loss: 0.09248518943786621      \n",
      "test accuracy:   1.0, loss: 0.0023385286331176758    \n",
      "test accuracy:   1.0, loss: 0.011255502700805664     \n",
      "test accuracy: 0.9375, loss: 0.19481855630874634      \n",
      "test accuracy:   1.0, loss: 0.003622382879257202     \n",
      "test accuracy: 0.9375, loss: 0.48299160599708557      \n",
      "test accuracy: 0.9375, loss: 0.17183740437030792      \n",
      "test accuracy: 0.9375, loss: 0.2315155416727066       \n",
      "test accuracy:   1.0, loss: 0.08475443720817566      \n",
      "test accuracy: 0.8125, loss: 0.316612184047699        \n",
      "test accuracy: 0.875, loss: 0.2713536024093628       \n",
      "test accuracy:   1.0, loss: 0.0038598179817199707    \n",
      "test accuracy: 0.8125, loss: 0.5856012105941772       \n",
      "test accuracy: 0.9375, loss: 0.3812214136123657       \n",
      "test accuracy:   1.0, loss: 0.007204383611679077     \n",
      "test accuracy: 0.875, loss: 0.45168888568878174      \n",
      "test accuracy:   1.0, loss: 0.0013907551765441895    \n",
      "test accuracy:   1.0, loss: 0.013992637395858765     \n",
      "test accuracy: 0.9375, loss: 0.14512526988983154      \n",
      "test accuracy:   1.0, loss: 0.010492920875549316     \n",
      "test accuracy: 0.9375, loss: 0.1449548900127411       \n",
      "test accuracy: 0.8125, loss: 0.4245394468307495       \n",
      "test accuracy:   1.0, loss: 0.02253049612045288      \n",
      "test accuracy: 0.9375, loss: 0.0647578239440918       \n",
      "test accuracy: 0.875, loss: 0.21765615046024323      \n",
      "test accuracy: 0.9375, loss: 0.2928452491760254       \n",
      "test accuracy: 0.9375, loss: 0.18346761167049408      \n",
      "test accuracy:   1.0, loss: 0.009157896041870117     \n",
      "test accuracy: 0.9375, loss: 0.2077997624874115       \n",
      "test accuracy:   1.0, loss: 0.004041612148284912     \n",
      "test accuracy: 0.9375, loss: 0.08705297112464905      \n",
      "test accuracy:   1.0, loss: 0.14222677052021027      \n",
      "test accuracy:   1.0, loss: 0.026233673095703125     \n",
      "test accuracy: 0.9375, loss: 0.20209625363349915      \n",
      "test accuracy: 0.9375, loss: 0.0830112099647522       \n",
      "test accuracy:   1.0, loss: 0.01721370220184326      \n",
      "test accuracy:   1.0, loss: 0.0017229318618774414    \n",
      "test accuracy:   1.0, loss: 0.04897141456604004      \n",
      "test accuracy:   1.0, loss: 0.008343100547790527     \n",
      "test accuracy:   1.0, loss: 0.00024628639221191406   \n",
      "test accuracy: 0.9375, loss: 0.2262207716703415       \n",
      "test accuracy:   1.0, loss: 0.007178515195846558     \n",
      "test accuracy:   1.0, loss: 0.0614013671875          \n",
      "test accuracy:   1.0, loss: 0.05102834105491638      \n",
      "test accuracy:   1.0, loss: 0.04165571928024292      \n",
      "test accuracy: 0.8125, loss: 0.4213918149471283       \n",
      "test accuracy:   1.0, loss: 0.010037928819656372     \n",
      "test accuracy: 0.875, loss: 0.3517763018608093       \n",
      "test accuracy: 0.9375, loss: 0.13468000292778015      \n",
      "test accuracy:   1.0, loss: 0.002615511417388916     \n",
      "test accuracy:   1.0, loss: 0.020740479230880737     \n",
      "test accuracy:   1.0, loss: 0.007386982440948486     \n",
      "test accuracy: 0.9375, loss: 0.18265901505947113      \n",
      "test accuracy: 0.9375, loss: 0.09678101539611816      \n",
      "test accuracy:   1.0, loss: 0.015883982181549072     \n",
      "test accuracy: 0.9375, loss: 0.15857110917568207      \n",
      "test accuracy: 0.9375, loss: 0.1446426659822464       \n",
      "test accuracy:   1.0, loss: 0.006160825490951538     \n",
      "test accuracy:  0.75, loss: 1.0437270402908325       \n",
      "test accuracy: 0.9375, loss: 0.07184538245201111      \n",
      "test accuracy: 0.9375, loss: 0.16729703545570374      \n",
      "test accuracy: 0.9375, loss: 0.18141667544841766      \n",
      "test accuracy:   1.0, loss: 0.010415881872177124     \n",
      "test accuracy: 0.9375, loss: 0.053738147020339966     \n",
      "test accuracy:   1.0, loss: 0.06102839112281799      \n",
      "test accuracy: 0.875, loss: 0.42222481966018677      \n",
      "test accuracy: 0.875, loss: 0.23604737222194672      \n",
      "test accuracy:   1.0, loss: 0.0019324421882629395    \n",
      "test accuracy:   1.0, loss: 0.025993913412094116     \n",
      "test accuracy:   1.0, loss: 0.02360314130783081      \n",
      "test accuracy: 0.8571428571428571, loss: 0.42244890332221985      \n",
      "final test accuracy: 0.9613510880155894\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=config[\"lr\"][0], \n",
    "    nesterov=config[\"use_nesterov\"], \n",
    "    weight_decay=config[\"weight_decay\"], \n",
    "    momentum=config[\"momentum\"]\n",
    ")\n",
    "schedule_steps = config[\"schedule\"]\n",
    "schedule_steps.append(np.inf)\n",
    "sched_idx = 0\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "max_acc = 0\n",
    "\n",
    "train_loader = data.DataLoader(train_set, batch_size=config[\"batch_size\"], shuffle=True, drop_last=True)\n",
    "dev_loader = data.DataLoader(dev_set, batch_size=min(len(dev_set), 16), shuffle=True)\n",
    "test_loader = data.DataLoader(test_set, batch_size=min(len(test_set), 16), shuffle=True)\n",
    "step_no = 0\n",
    "\n",
    "for epoch_idx in range(config[\"n_epochs\"]):\n",
    "    for batch_idx, (model_in, labels) in enumerate(train_loader):\n",
    "        model.train() # sets the model in training mode\n",
    "        optimizer.zero_grad() # Zero gradients\n",
    "        \n",
    "        model_in = model_in.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        model_in = Variable(model_in, requires_grad=False)\n",
    "        scores = model(model_in)\n",
    "        \n",
    "        labels = Variable(labels, requires_grad=False)\n",
    "        loss = criterion(scores, labels)\n",
    "        loss.backward() # perform a backward pass\n",
    "        \n",
    "        optimizer.step() # and update the weights\n",
    "        step_no += 1\n",
    "        if step_no > schedule_steps[sched_idx]:\n",
    "            sched_idx += 1\n",
    "            print(\"changing learning rate to {}\".format(config[\"lr\"][sched_idx]))\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=config[\"lr\"][sched_idx],\n",
    "                nesterov=config[\"use_nesterov\"], momentum=config[\"momentum\"], weight_decay=config[\"weight_decay\"])\n",
    "        print_eval(\"train step #{}\".format(step_no), scores, labels, loss)\n",
    "\n",
    "    if epoch_idx % config[\"dev_every\"] == config[\"dev_every\"] - 1:\n",
    "        model.eval() # sets the model in evaluation mode\n",
    "        accs = []\n",
    "        for model_in, labels in dev_loader:\n",
    "            model_in = Variable(model_in, requires_grad=False)\n",
    "            model_in = model_in.cuda()\n",
    "            labels = labels.cuda()\n",
    "            scores = model(model_in)\n",
    "            labels = Variable(labels, requires_grad=False)\n",
    "            loss = criterion(scores, labels)\n",
    "            loss_numeric = loss.cpu().data.numpy()[0]\n",
    "            accs.append(print_eval(\"dev\", scores, labels, loss))\n",
    "        avg_acc = np.mean(accs)\n",
    "        print(\"final dev accuracy: {}\".format(avg_acc))\n",
    "        if avg_acc > max_acc:\n",
    "            print(\"saving best model...\")\n",
    "            max_acc = avg_acc\n",
    "            model.save(config[\"output_file\"])\n",
    "evaluate(config, model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_in, labels in test_loader:\n",
    "    model_in = Variable(model_in, requires_grad=False).cuda()\n",
    "    labels = labels.cuda()\n",
    "    scores = model(model_in)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(labels[0])\n",
    "print(int(scores[0].max(0)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2word = {v: k.strip(\"_\") for k, v in words.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load(config[\"output_file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_folder = \"./../raw_data/test/audio/\"\n",
    "eval_wavs = {\n",
    "    os.path.join(eval_folder, file_path): os.path.join(eval_folder, file_path) # TODO: this is hack, be careful\n",
    "        for file_path in os.listdir(\"./../raw_data/test/audio/\")\n",
    "            if file_path.endswith(\".wav\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158538"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_wavs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = SpeechDataset(eval_wavs, DatasetType.TEST, test_cfg)\n",
    "eval_loader = data.DataLoader(eval_set, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'rsplit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-1427a20345b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorei\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             sub.write(\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0mwav_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\",\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlabel2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorei\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'rsplit'"
     ]
    }
   ],
   "source": [
    "with open(\"../submission.txt\", \"w\") as sub:\n",
    "    sub.write(\"fname,label\\n\")\n",
    "    for model_in, wav_paths in eval_loader:\n",
    "        scores = model(Variable(model_in, requires_grad=False).cuda())\n",
    "        for i, scorei in enumerate(scores):\n",
    "            sub.write(\n",
    "                wav_paths[i].rsplit(\"/\")[-1] + \",\" + label2word[int(scorei.max(0)[1])] + \"\\n\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"no\".strip(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "print(label2word[int(scores[4].max(0)[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,UklGRiR9AABXQVZFZm10IBAAAAABAAEAgD4AAAB9AAACABAAZGF0YQB9AABPAWH/WP7XAZb/0QHa/pMAYQGR/6gBIwD9AOb+ewBMAET/h/6u/y8Aav6QAcj+6f/X/34Bdv5bAWcB3QFH/g4BQf6F/wP/mf6f/gkBZwEp/pH/kf+NAEYAIf/L/+n/5v7fABcA3wCNAFUBD/9PAcv/3QHy/in+kAHm/t0BIwDL/1IA6f8yAXkBJgFh/yf//f6/AUH+xv/XAREARgBe/k8BKf4b/7r/RgCNAJABi//a/uD+rv+c/8UBtgCu/9kA9wBeAI0AigFGAEH+c/+kAGoAewCo/2cBXv6o/3P/vwFt//cAQADC/sIA8v6cAfL+yP6KAS/+dQBYADoAXgBkAIoBpAA4AdT+Uv6l/l4Ah/7g/pb/ogFSAHD+ywG8/iP+8QAp/ikAvP5nAdEBi/9kAEAAJgGEAXz+RP/9/gUAtP9h/ywBIAGWAcgAvP41/ikATwHa/uP/Pv9//wsAUv55/5H/Mv/a/uz+1/9w/ikAgQBz/2oAqP+F/98Aef8OASwBLAE6AFb/0QHA/3MB2QDUAKv+ywEy/0QBIf8FAM4AQABbASMAwP/CAH//ef8UAcL+5v6KAaX+vwGR/84AXgB1AOD+/QCoAeUAagDCAIoBzv7R/0AA0QFY/oL+ewDR/9H/Qf7U/lj+agBN/pH/2QAv/sIAbf8b/3sAuQG0/7MB4P5nAXMBzv73/s7+GgGQAWH/WwEUAUAAfgH3/v0A5v68/h3+Uv7CAK7/Z/9t/7MBnwAv/qj/yP5N/uMBhwAs/2T+LP/fAJz/O/5YAC/+XP/R/1b/uv8FAMb/Xv47/nUACf/s/gUA0QE4//cAA/9c/xEA4P5kAP0AUv7C/k8BIAG3/tr+ZABVASz//QB+AcIAFwDR/9T+OgD9ANEBwgCiARcAbf9n/5H/rgEh//EAWwFVAWT+qP8h/ykAdv6BACH/pACNAOb+qgCkAKX+pAA+Acb/nwDUAIoBTf5z/wn/ywFw/gn/yADU/mQASv/g/moAtgDI/vf+f/81ABEAxQEP/xv/Nf5JAR3+bwAJAYv/wgCzAcj+vADC/lIAnwCc/1D/4/+x/lb/vACT/nMBkwAsAWEBJgFt/yn+Tf41/gMBzgDZABQBTf6kAJYBh/5eAET/LwB+AYEALP+wACH/Nf5q/sD/AAAy/+MBqAH1/2cBfgGT/mr+t/68ABv/nP+o/wUAnP+QAV7+bwCZ/v3+CQGcAbAAdQC8/pkASQHfADL/n/7I/kH+9/6l/lL+n/5Q/1D/vwEsATgBsf5W/yH/8v5+AcIAi/9c/93/1P5GAJABTwHd//cApAAd/vX/tP+0/0QBgv7OAKX+O/5B/ov/t/4JAfcAagBvAHUAKQCc/6IBswFYAGoAigFhASABD/9VAWoA0QGHAMIAKQA4/64BZP6i/6X+fgFvAC8Asf5h/3P/yP79AMsB8QDrAGf/QAC0/1z/G//3/gn/LP92/vEAuQHxABj+sf4FAI0A8QCNAPEAkf/U/pYBrv8J/8sBuv9t/z7/WwF5Af3+ov+C/uP/wgA4//L+q/4h/7z+lgH3/h0An/4y/+D+NQDG/xoB2v5AAEr/igHxAJP+VQHXAX4BLwCW/1L+rv8J/2r+rv+/AZP+TwGu/zUAkf8OAWQA/f6L/2oAOP8V/1j+fP5q/h3+9f9S/pABOP/A/8gAnAHU/iwBCwBJAXz+zgC6/ywB9wBS/gAArgFbAaL/Mv+T/pYBsf5E/8b/3wCW/9f/kwDrAOMBrv/d/+4BGgFn/8b/TACoAeD+ZwHv/6QAmQAv/rAA8v7d/2H/zgAXALwAYQEUAS/+LP/lACMARgDG/0T/RAHX/wsAWwFt/0kBcwHR/1gALP9+AcD/AwFq/nP/OAGBAEYAvAApAPL+ewCH/nz+n/6N/gz+UP+HAH4BmQDO/pwBmQBh/34Bzv4OAfv/ZACF/3MB7P6BAHkBCQGR/wACi/+H/oEAqgAjAEkBOP/L/14Ajf5+AfQByAAFAEf++/+8AHUAIwDIAKQAc//9/nb+NQARAHkBi//v/9f/9P2i/4EABv4b/3D+Kf6NAFUBEv7C/iH/AAB5/7MBbf/lAFb/mQCW/xX/zgDm/pkAcP4mAbr/GgEj/pMAD/+f/gD+n/7L/5b9HQDxACkAJ/8XAMIAsAAyAaoAogG2AG8AZACCAp8ARgCNANEBGgGwAPcCNQCIAoUDfAKHANcBGAIpAiwBmQJnATL/9/7j/wUAHf47/iH/i/8Y/m8A8v4LAHj9kf/9/un/bf1q/gn9Gv1J/a7/Tf5//x0ADv3x/MX9OP3l/BL+Mv+C/g79av5YAAP/TwFnAfoBtP8gARoBWwGoAcIA4/9z//v/+gHxACYBagAh/03+Pv86/OX6FvpR+v/7cvvh+cf6v/sd/Iz6svmG+tH9vPyT/On/NQAaAW3/QAARAB0CkQMTBmsEzAVxBv4GzQnlCf0NfA2AEg0TkhR+FYEWNRiRGTsaBxwKG7caThyCGpoctBliGZwXbRdyFSISXw9vC2YKWggnBegBSf1d+DvzhPIT7ILo7udI44jfvd9k20napNnH2TfYItnn1hzZ/NnT27ffDeHP4eLlrefw7YPup/Ca9YX2rPmz/f3+bQHGBcAFGgoPDAsL8QuoDFUMYQylDfoKEQsPDLkKHAdMCS4HlwWjBXYChf/y/tf/DP40/K39Q/1m+cf6BfyS+vb4V/iG+gL5e/ox+TT64vvl/Eb8rf3l/L/9h/yK/SD9pAAn/67/TQR5Aw0IdQvCDbUSlRWxGiYgJyRuKLMrXC/GMSk33TjpOKo3TzYANwk4WDd0M8AxEjB2MHgrlSneJmciEBspFqAP0wmIAv38SvTz7rHog+Oc3mbYqdei02HRN81xzbrKl8qoxsbIy8auyHbHZcneyjnMeM8b09LVQNni3LfdqeLs6InssPHD9QT4Hf62AKkFRgk6C/sOqRAHEXEReBVaE6oUmBQFFjEVERZjFK8S4hOPEVwOag1hDPQK9gchBW0DVQGi/1L+uftm+3L5qPRN9XDzpO/E7mbufe437v7sR+oS6kfqJ+vs6G7r9u1u7Q3ux+8G8xLzz/VZ90j3Wvn/+1L+CwCUBG8JnwtCESkWAh4BJcopUy7YMyM50jw0QHtCwEW9RNVGz0bPSNJHZEQDQ4RBRkKPP7Q6jTepM90vfSezIOYagRQ4DIoBAvlD8nPphuJ23a/XNNAWzC/F0MTPvr+7j7lvurK37bdvur63b7iWu0e+HMFjw4TEcMfBzoLSuNYg2snfcOg57U313vggAT8FSQqLEOITABh5GX0cVB7OIfEfGiLlIZAiHSFVII8eNhwwHPUZ6RnOFvwUvQ9KDpgJiwWkAOb+zfrk9uzzZvA37uDqQux/6cLoIOdy5bbme+TK5UDmNOZk5kbmD+mZ6Mnq5+zz7E/wh/NB8+n2LfbH+vT7HQAnA5EFVQoNEXgVzBuHIWUnIS/rNZo7fT98RBNIhkn0TJBO1kzdTshNAE0DToxLfUowRhVFp0GoOgg2ITHwKJEkdBtFEu0IbwCy+aHuy+kw32bagdDny2HIhsEjvLC4ILl8swmyFbIdsXiwkbKoskqyRbZUtwu6cLwow7fHQssG0nrVUt1d5Grok/Ee9+X8aAUXCe8OdBJ2GE4edx4yJP4lSya1JsknViZ0Jj8m1ScSI2Qj3x/2HzMb+hezFxYSDA86CUgImQLC/lr7UPSZ86zslOrO6GzlQOTp4Kngi95N387bNd393ePexuBW4FPheuLH5MvnAOr57mnvkfR39yX7FP0pAl8GFgfLDBASpBYzG0YhbSQRLPIw0zVWPFVBtEUfSptMBk+uTp9PnFDDUWpPRk01TfNKskjXQ8VBYD/XOPAznC0KKNYgJxt6EPEJkf+n+crwHegB4b/aSdHJy9/FWcA+vdm4YLdWtG60OLISsY+uWLGisJywVrJTs4i1wro/v8rCnsXJy9fR1dZV3Frj8eYI8C/zbPuuAe0GXA72FAMZ1h63IyolyinuLZcvvTB/Ly0xSS23LggrGSmeKHkimyAEG+YYZhXbD5UKnQeF/6r8Kvc187rrU+qD4/7fQd8+3GnbFNpR1z/XydbQ2L/c0dwh4GLiVeXr5I3oB+yy7i/xf/SM+vr9DgEjAsoITwyrD8QRchPCFiEZhh/fH3El2ydqLDkzvjTuOA0/vECuReRHQkpJTJ5L3kkXTUxLP0nGRQFG5UCwQGs7fDmhNKswxCcVJIAd0BUNEawGIf/k9i7vmupW4CPbxtOYzkrIqcEDvei7d7XGtF6xta2VrLurs64vrwiw1q5hsuazSLetuSy9ksF8xxnNA9Pq1xTcXeTR5zHwYvac/doCcgrMEA8X7RyhIDYljykDLdEvbjFOMlwx4DDmLkcusy0RKuQotyMIIAIgGBpvFBsQ1gp0BS8AxftX+L/wuOzf5kbkSOF+3DLc4tog2vbZ09mk20fdBt+d4OHjiuVY5mTo5uoC7vbvbfQT+eX6NQBBBLgIIAwkEZgUkBUMGCcb6h28ISMjBCanKWQucTATMgs1YDYbOkI9bj6EQbdEfkN8RlxFfERfRgBCMUFpPi08WTvnNKwykS8cKDkmhCC9GpsT5g0NBsj+aPao8qXqnuSc3DDWIM9lyaLGJcK8vDG5tbbPs+axDq68r1qsQ65DsH6ubbBws9y397qLvR7A68Oay9bND9Xh2AzdSOMh64Dv6fTU/JQENwrGDkMVIxh9HFAkeSRXKFUrjSw2MN0v1TA1LrwsNSxpKsknLSZZJXUfshylGMcUhQ7FCkUHCQMU+9X30fQu70DvfOoe6orns+Vi4i7kw+GA4p7khuIC5cHkR+h/6eDqVOxk8ejyZ/Qo+kn93wCuA8kG2QuoDmMSvxWlGFkawxqBH1UgFyH1JCQlGyYIKYorWyvcKzsukS+vMUszbzeQOBc3QDeEOAM4GjbLNgs1fy+iLYYqFii6JgAhlBwbG8UVqRAyDFcHeQG5/WL21vAW7ZXlUOBp27HUns5TyWbEwL8vvLm5ArdHs5yyKbGtsOyxJrLmsYKzebSPuTS6QbyvwWHGSsrNzOvQidZV2tLiYecB7Nbwo/YJ/R8G4gowD5MWJxu5IHAjYiYKKEQtWCyuLTgvUzDlLL8tyCzHKOAlLyOZI1sgSBy3GIYU/BLDDxELMwcSBLr/vP40+ob4f/RG8QLw7e6p7RztuusY6qXqQuw+6aDsE+7J7B3xOvEV9P3zUPYo+tf9OAGiAV8EaAd9CM4Nzw8ZE/QVOhbjFyEbvRqbHoMeQh5+IlsiriTMJjwniSe4KacpZy2fLpMs+i3lLHUsNS4+LV0qlSnkKDwlcCMRH74eAxmqFhMR1w5qCy0FOgD5+d729/Gu6b7jXN7E2MPU582FyqTFksNYvA675bjvtKuzYbKUs7ez7bVxtZW5xLnCvNi/icLuxm7Km80F0OrXddsM32zlq+rn7E31N/mf/tUENwp2DZISQRjPGsEfnyNNJYknCyoOK8Ur5SqSKF0ocikwJ5EmtyVYIYwfNB8EHbEazhZgE5gSOw3fC80JUANwAib9tvz+95r3vPMs9NnvYfI08R/utu997IPuo+2S7YDvBvMy9MvylPXM9g77dfpW/wAABgRfBOUJ5Qk1DdEO7xCpEGkUNRZ+F4IaUxriHk8gGCO5IhUmryZ9KQUqUy6CLmQs7i2QLeIp+SnzJ4IjiyR2I30cZRrNFEUQJgrQCAcGXAVQ//D6qvr68rbxivCI6s7oO+jW48veltwn1WPONssOxjO/Qb4SvJ+8XrpSvEe+770wvsnAa8BRwevFf8r8zE3Sb9mr3YbiXubM687zHPi/AWQL2w9sFQ0cBB1sHsUgiiLHHwshLyNgIOEcDRz9FjcV9RBbDKwIvgj8Bx4E/gaaBrIG1AKgBJ/+RgC8/jv+yP7xACkAfv1z/cj8F/xa+ZL6Wvni+3791ADuARX/T/uS+qn4svd9+VX70PuTAIUDZQTBB8QIjAeSCWwI9ApNDbYLkgluB1z/vPxA/LMBIhKyJ11AcVN4YrpmHF+lWNFQl1CAVABYUV++XqVYlUoFN/QiJxDg/jz3CfQD9FrwAOrm3cnLW7sdr+ymGKgrrB2xjbpyxL3JNceBxdPDRsXVyTfPadtw6CH0eviP+df0vu5p5M/fTd/b4Y/jSON3403flNRgz9rJXsXsx47LP9Wo3mfnze+W8kb6iv2IAnsLIhRbINArgDHzNK8xLC2LJE0aYBP+EcQR6Q6kC9gFCf+v9ivwwe3161nqF/Eh9Nj2tPa69BX0s/Lf8SXwi/Zp/JMAmgTECM4LvgiAB/sFcwMtBe8DCgcyDPcLYArJBk0ENgbOApEDAQY7DaARrBFOEwQSlgy1B9f/evjc8CXutvGvBc8n3EqaafR6lH09dmRjxVmsU4NTe1jTXxRk817CTz8xmxM9+1/sLOfR5+HuXe0+6WXh/NcpxYu0PKrvqa+27sZH1Mvc7N+X4FjbCNoe1OnTPNY92r/njfFB8zHuMeV12XXOI8Uyvb2+x8E5yrHS0tUM1EvOMMmLyNnOB9aU38nsUfqYB7QOmQ04DOgKOA4KEiYXXR9PIpwkDCVEIp4diRG+CJkAf//X/23/Ff+0/5cDXgID/23/Z/0X/IL+RQWuDNYTyhM5EhAQyAu6BcD/k/wg/cD/CQE4/4r9BfpI94/wjO3S63Tt/fFZ90n9mf7u/fEAy/9t/yz/ywEQB5ISvxclHtMf7BqVFdgQVQyrBJz9ofld+Bz4yfWn+SMNcy3gT7JpWHtHfZRywWr2X71cAlecUFpKEk/CTThF3S+1Etb59elv2zPXztJS0NDNFswRzq/KCsGer2irq7Hpv77Lo9fF5c3tUvGZ8dHpo+JR2X3Wmdv25Evt5+ws5yLkf9730lzIbb0pupC7McLwztnbU+F942/kzeRV5wnnNuoe9ewEXBBfGvwfNB8nGckPXwbOApEDOQUaCpwOjBQ9FTkQ3wu6BeUAh/wYAmcMyxepHVsgoSAVG/oVngmDBo4E2wbUC/4RjB0wGmsRHwYu+gLwZers6M7mgO/2+N39ov1v+q3y1+e/5cLoGe7m84r9BQnAEFgW8g8dC7oDRwITCBUONxVsE6oUGROyEV4NJwVqAov/xwfnBvEJuwnvBb8K6gW5DL4R+R61Ma1KfWkLef9/xXi8bHJgqVRaSlg50S1kI9EXwA7sAsb0M+JpzjfE0r95vU+7wbgwvibG3M2e0AnRZs8gz0bQD9Wt3KLe0uL96NzuLu+s7t/m2dsL2TLTFtfw2SjZY9mO1jTZwdce1DDUv9F40RDXCuAK6zP2h/4/BUkM7A0PDs4LZAvnBnIKdxEaFZYXHBLhERIN8QtOCHkB1Py2+uz++QbaDUwUzRR9E0YWRBcQG90XwRQpGOsUPBxYGHsU8QmL/wf5zvMt9tDw0+8g8oTyZvtG/J326PJB6mLrBO3g83n0FPu5/a4Dqgk0CXEGh/4X/LT/vga2CS8NWwwqD9EMBg8LCysIMwVxBvkIExE/EOoSjxErE74RNQ0ICNEB0QPkBbkMRhZlGrsdfyRcL4RDd1PtXppel13nU2VImz9FMa4i6Q7OAkb8t/WH8xXr8+Pn2HPT6M88ywzJ2MEgxNjKZNJC2KHac9y12YfdFtlX2QvbiN9/4ADqv/CD7k7uIuRZ33vbe9mY1xnWMOH74HvmdOs26uHu3+aI6tXs8fHQ+VD/Nwj3DRMTyRF6EC8NogMHBjgB3f1MAOD+qwIJA6wGSgV//8v9x/gQ+Kj9jf4hA/AHxQx0EpMWYhvNHQobUxjGGagXDhWjEEcNdwaBANT8GvtO+aLyNPEL8TjyFfYw9wj7Yf3DBP4G4gqwC9UG5AeXBUsHdQn/COUJAwxjCawIjgbuAWr+RfgQ+FH6mQAsAdcBbgWFBTcIMAZfBjMF+ASwCeAPdxObE8ESIhK2CwIIBgL3/P38GvsAADgDWgjNCd8LLRC8Fr0jHjCmPZlC9UceRK466jHGJHwYUQlc/5n8XPbs9UPyLPJN6i/mltyL1ZXNTcc7xxvK3M/71V7dx+KT6B7qyex97gLuJfCu9Hf3c/0P/6X+9/xA/B732PZV8DDqDOoJ6YXp+Opx7PbvVfCh8Eny9/GF9Ebx+/Qt+KoAkQX8CU4InAzcCu4K7go5B8gCCf+K+wn9zvxX+oD6v/vo+5z9WP4d/oEAsQLkB0cNbBW3GrkgPCUnJs8nnCJjHxUb2xG6DgYN/AkXCZ0FRAFS/L75X/XR9J/z8fO99UL5c/0+AYcAcQaiARsF4wEJAzUCnwD3ABEA4wOcA5cFswHp/7r/Nf6l/o0Aq/4JAe79+/8a/VsBnP3m/m3/LwBzAyQG5AWVCK8HLAOZAAP/Efox+Yf8hQPtBvQMIRDtExIazxxvIcwkxyinK20vrTQzM/4wQytYIU8XJxBFBwn/Afdy8BztoumH6GblAuWg4Y7fUOCz3LffKt//47foB+wI8Lr0bvgN96D1XPal9SnzCfLC8U7uXOtr7G3p6Oc05pnoFOWS4s/hvuEi5C7kdeYb66zs8fHs85j4qvxY/ED8ov/pA5cFuAYZBqkHTAnwB2UEfwNtA1gCkAE/BfcCGQZ9BkgIhAoSDcINUw8NE9YTpBYdFvsZWRw2GtIbER9yHqkb7xkmFU4RxQqOBCb9BPib8LbvrOzw7WzuGvI785r3ePvT+nD+5fyo/3n/CQGIAhUDyAKZALkBywFkAFYDtgAAABH6rftk/jf73f0j/CP8//m5+7T/uf0gAaX+FAH+BI4GPwc/BekDwwSxBBwHqQUWBzkHlAadBa4DUP+H/jf7Jv31/9sEHwhXCUQMXA50EAYYRxj3IbEjxSvML2syVjG5KwEnChu6DuwC+Pcg8gTr7+ky6V7oMOoV6QzoIuSY4qzjNOQR5B3oSuvU8Ur0PPmQ/Tf5E/kK9iDywe2x6D7ns+UU5e3jPeU95QjlOuQZ43Hhx+KA5EnnrunH7zb1EfqcA1AFZgoMDxUQUw/XDkQOSQqWDC8LEQkoB30IQgYEBfQBfgHC/pkAlgGcAboDNgbbBrkKWAunCrkMIgkpCw4K4w6mD94QLhTcE8IWjBJgExkRNQtvCR0C5fyb+dr1yvB178ftcvD08Jjv4POt8lz0PPls+a37cvk3+1L+4P4vAB0A+wOuAZb/+/+c/Yf8eP3r/Ez88QB7AAkD6AEJA2cDkwIGBLQDegUxCM0HQgghBbcEDQYVA0EEKgSsBpEDmgTCAhUDoAajB18GzQcCCogP8g/kEvYUaBvHH40jgSpXKggrlStoJrkgvRrVEfgELP3h963wne0D6dfpD+nI6Gbl9uS85vrlY+Sd4p7kPud07f/ucPXW+Rz61Pwo+vD4dPbR8gjwD+sn61zpauip6zPrmO346l3tJOxl6tfpDOr47PDt4vCI9WD7Vv/ZAEIGcQaSB74GRwR9BmIDVgOQAfgE9QWuA5MCXwQ1ApEDeQOIAhsDCQEdAl0HEwjZC5gJigrdDBgPCQywC+4KagsXCWAKewuzCm8LngkTCHQHSgMOAXz+FvgY9Yry1/Ij8QzzlPUC+yn8WACIAg8D/QCi/5z9cP7O/P3+ZP5t/QAAs/3R/2T+vP65/ZP+Zvt7/DL/xv9w/s4ACQOXBdIFYAhoB70ELQWRA6IDggIwBCEFaAWmBDwG9QVICBAHxgXJBmUGAggRC3MMdBD7EEYUnxbjF9UaxBw9HqEekh9bICgfKyAZHm4bthRxD/MGHQDK+aLy5+4t7c/qP+so79/vjfHX9ITylvL68uXvEe/V7Kzu1vBV8tDwL/PG9EHzfvCD7tXqc+ku5AvkLuS44YPj3efo587ovuz87/TwY+/l8aLyuvTY9hz6Jfuo/+8DrAitCpkLgQsJDCsKxAg4A90BwgAjAPIC1wGIBMADwwTqBb0E9QW1B4AF4wOOBvAH9QXJBuUJWA2IDxsOiREVEHYNSg6KDJsKVAidBygHBwbOAgwCq/5V++H3dvWV8NbwmO9G7z3wjfOj9kb6kf+l/un/FQP6Ae79zv65/fr7wfq7+rz85fw6ALkBOAMbA2IFNgRUBrgGiwViBQIKxwm2C6kQThN1FqEV1xeyE4kTfREpDQ4Kbgc/Bx4EZQRHBLEE2gKXA5ABKf5Y/Av6DfkN9zf5PPkC+1j8afye/Hb+PgFkAMAFJgo7D9MUxB5cJr4pdSyDJxIlPBxFEM8EnvwG9XTtyOiZ6KPrMOxx7kPyce6S71DryOgU56Dh5+Fm44fone3l8dj4Ovz3/sL+tgDH+nH3bPCp6wboC+YP6S/o4OqE8ILzUPbX9DP21fUp80fz6PJK9IP3yffI/ooBUQeyCOsJ3ArOC9MJ3AjbBGcDZABc/1IAHgR2AsQGrAYlCBkIOwQnBe4B/f4DASwB4wNgCHwNoBGyE6cVsRjnEzAR2QmxAvr7p/mE8iPzOu8R8a70xvZ9+W/6jf4J/T37m/v+98b2J/Zd+GD57P6BAKUCegd3BnoFyQQSBP0A0f2Z/gL7+v28/A4BOAPkBS4HRQWpBTMFOwQgAZwDAwHj/yED7ALMA0sHSwf/CGAKxQrKCtMJiQb5BvwH0gWsBk8KZA1WEAMXyBjQHo8e0B6tHqkdwR37GWwVyQ9BDfwHgAVeAIr77fcV9O7yWPF664jq5uqH6LTpwuiE52Hnkeva6krpZepu7YPsTPFy8Mb0rfJl9YX0D/Y184v0IPI+8tnxmO+k74rwe+997J7vZu7h7nXxDvJ59Jnz/vfN+vH8gv7yAmUEQgYCCk4IeAqVCpsKSAjABZcF9AEDAasC6wARAPoBxv9KA20D/QBlBIQB1wNEA+cGaAf2CQAL2Qt5DJQPjQ25DBcLIwvABfUFOANv/PT7hvhK9jj0sfUq9/j1Dff2+ND5ePtt/bn9t/4j/lsBQQL6AcgCPgHUAJkC2QAsA20DmQJtAZYBVQHv/wMBYQEMAnMBOgAUAZED6QN2AhIExgPtBqAGdwYaCqMHJgrKCEsHPQi6Bb4G0gWmBHMD7AR0B3UJTggJDFgNgBDYEjMSjBRgFeMXZxkqHKkdEx4NHGUaBhouFEsSWAu6BYf+2PYY8xbvE+zj6bfoKuoe7BbtGe7w7c3tZu5P8BbtWexI7FTuGe4D8kPyP/a7+K/4Gvvk+LD68/eO9XLw2e8W7TDsq+ry6nfsKfGh8PHzFfQi+Nj4WvtG/BT7mf70/VMCUwSgBBkIRQdpCdMJkglRB0IIrAYBBCEDZwEjAAUAgfwn/6v+DwNBBK4DlARoBTMHBAW4Bt4H9gcXCdcMlgzCDQkORw/ZC/cNdQsNBosFDwM+/+f5w/cN9230DPV59Jz0GPWs9y34u/qN/Jz9XgA7/kr/gQARAK39zv5S/kT/YgOlAvgEgAVZBisI9QVFBy4HrAhuBSsInQXABXQHEwhjB5oGsAmjB14LcgpVDPQMeQyqC/ELXg0yDCIJMQrkB1EHmQJvAJ8AWP6/+/r7Dfkp/HX6fv38+n79Q/uk+gv6SPlG/G3/wwTTB30RkRnJHJAiMCfDJWcimB1qFsgNVgN++6LyLe0i7T/tkes073jylvQz9rfz2fEr8NLtAOpY5rPn0+YA6mvspPGO9db7qP/IAM4AYf3B+qL0L/F97NHpQ+cu5BTnD+mU7E/y5/c6+qX+y/0s/bb8Ev7F/Qv84/2R//v/lwM6CWQNUw/bET0T3hJlD64MYwmRAyf/9vrg9W30xvSX9rn7kwKpBwANGxBvFLYUuxQ3E6IOTAmOBGcBWvud+Jj4yvlI+Vj8+v3g/mH/Pv/u/fH8Gfkz+Ab1U/WT83z1g/k0+n79/QDDBJwDWQaIBFYDtwJYABQBAP5z/639AABYANEBzgLZAMMEogGgBIsDOAEDAWH/6wBE/1gAvQIrCGAKrg7VEWMUFBdeGHMZlBw5HXEcoxu7HaEe4yJBI4gjkSQ4JK0gGR4aFyoPHQt2Aof8+/ZH85Xwsu6V7srwZ/KF9NrzUvM08Zjv1eyF65bnFOVz5+vkAOgA6m7r/O+w8cb0fPWr9aXzNvV18VHvdO1660vthu247BHvYPBb8gn0wPSS+Af3uPkZ+Xf5vvdv+gv8LP1V/R0COwQzB1kGpwgdCwkOIQ4AC80JGQgTBlQG+gF5A/EAdgLv/wMDrgOaBlQILgmFDkQO0Q4nEEoQHg8GD/sOPQpPCgcGnAPLAa7/3/zi+yj6M/gn9jD3G/bL9OjwUvMM82Dw7PM29an2r/jc+ZD9eP1+AfoB1wOoAz4D3QNQA/sDxQHsAqAEQgaOBhAFbAgwBvYJ2QkcCaEICAiOBqEIhgdLB6cIUgsICsgLmQ2rDRUOShBJDJ8N2QuVCuQFRwQMAl4A0f86AE/9DP5A/IH80f01/uL79/5V/ZkAzwSJCGIOBRT9GIMeLCJcJOYjHB/mGv8TLAxYArn77vJR7WXqleWi5wnnTepf7M3tQuyk70Lufezg6rfqR+oA6EfqOetv8ST1Iviz+4cA1wHgAusAuQFt/ef5uvTY7dHpUuYd5tnkGucE6wTt3O5T9cf4KPiY+hv/RP+Z/qsCPgGfAskGtQezCp8LMg5oEg0RBBJUEcESXBCrDWoNsAmQCiQG4wNfBPcCyAAgAaj/rf3r/DT8Z/0j/GD7CPu7+rP9sPpg+db5d/mS+AT42Pjt+TH56vjJ9/z4Ivi490D6OvqY+Lv61vk3+1j+jfyiAWoAXgIBBDYGyQYICuIKEQlPCloIJQidBYMGTga0A/cCkQOQAZ8AeQEQBQoFVwlDCgULbhCAEtkUixnbGmYgaiEHJ0UoQCyBLAYuyC76KwsqiCWnHjEV9wvDBLz+P/h778nqhOd64m/k5+GM4p3ilePh48rloeVg5b/nPueI6qjpmO0/7eLw7vIS86D3Jfl99+n2ffmj9pbyI/EH7OPpVedv5PDineCq5FrlQep06xHxKvU8+QL7OgBqAHMBZQQcB04IUQfBCbMKbwvfC9kLuQqHC+4KBQvYB50HKgYVA2QCpQJh/2QA2QDgAh8IuwlvC1AOExGGFGATAhOeEugMuQr+BgwC3f17+i32lvJt8srubO597NjtGe4E7cPseu0U8LLugfHc8D70GPUR+vH8dQD0AYUFEQlEDtcMbQ7+Dx0N8g3lC/YJcQQKBSwBSv9Q/2QCiALIAskEdgSsBnEGkgcnBckESgXGA9EDeQPjAwoFegfWCEwLog5KEIQV8RaoF1wbphx3HGAe6x/WHggg5R9qIV0d0hvlFpgUgg+DCOMDvvkq94bv1eqF6WzlDuUW5OTiH+Pw5DflcuVH6GDlmeZe5uLnoudu67rpu+137inzMvRt9Ar45vVF9v73fPU48jrx3PCm7Mnq3enA6XDq0edQ6Ujs0u1D8Kj0SPkl+3MBDASABUUH+Qh+DIELogx1C64MYAqtCuUL0Ao+DKgMOAwDDlMNZwy/DMINCws+DH4KZggQB+wEyALoAc4AwgD6/RL+lv/3/An9bPv5+Vr55PbJ9eD1FPJG8WTznvFh9Kj0Nvdr94z4tvr0+7H+GAJZBsQI9gcFCcoIvwpYC8oIygpbCuQHsQQTBl8GhQPRA/0CYgOaBmUEiwUkBPsFrgPRA1wD6QO3AiMC7AKFBfYHxwl7CYIPqRDcE1gWMhnkG2MdYCDUI8wk5ycfJ+0n+SdwI6EgrhegEZIJzgJU+arxvuyT5pHgxt583Y3dfN2p4EffLeCL4Mfk2+Gj4i/m8OSx6CnoJ+lO7GzwHvXB+Hv8+vs+/Yr9vPwd/H35Cvbj8vztM+1v5v3mdeT25EPlquaK52vqgO2H88D20Pm/+w//QQSmBmYKNQ1eDcYOGRFCE3sU8RQIEwIVOhTWFfMTahY0FDMSIRDoDM4L2AexBFUBGP5S/B/5X/fM9vL1lPeX9gX6PPm5+4D68Pri+6379/7s/vr7fv17/In55/mt+4z6//uA+ij6T/3o/br/Kf7j/wAAbwCEATgDnwDGAw4BzAPyAkEE4wGOBIUDjgajBU4IMwcNCPQKHAcXCbUH2wZvCSAKQwrrC0QO0Q6JEcQTVRUyGXkZIRsLH+ggkyHsI1wkkSRJIuAj8x7EHicZmBSIDY8IwgDN+vj1/O0N7PzkneDp4OzdmdvL3B3d/dvm3ZbeBt3g327i4eNa4z7nU+px7BbvWvB886/4HPqH/Kr8Cf0x+3v6cvu1+K/2e/Fg7s3tSuva6NHny+mL6Yvp5+zZ71D05vUu+m39cwHhBs0Jcw61ENkUmBR+FwMZ5hq+Hq0eVx/xH2UchRtvFvMThAzNB/oB6/ww9ZnzyeyJ7J3rGOrt7nXvF/GF9HX6e/zo/XP9yPyW/Vv9Kfyw+sn3LvqD+cT5uf3U/LYAfAIfBu8FfQZXCW8JoAbDBLEEowW5AQ4Bc//LAbT/SQH7A/4EMQhPCtEMwA6gD50QYxLkEO0TmhHzEdcOvhG9Dc8PGA/DD6YR9hQjGNMdriLyJSIotipGKtApfSetIGUcORK2C9QAp/u3853toudL4lDeGN3X3B7fG97S4B7f8t9r39rdc9yT3bnaUdmG16PX8dv03BDiK+UA6m/x5vMt+Ez8jQDuAX4BRAGW/Y/7SPlQ9rPwRvH+7EXrvuzV6sHtB+4a8JT1xvYN+RT99wD7A0sHdAdpCWEMyQ8UFaoUlheFG8MafRwKG1AZDBiyEZcQngkzBykA8fwO+zb3h/NJ8gbzqPJE9P73HveG+oP5Zvku+uH5C/ol+zr85PiV+QX8QPw4/y8CAQQoB+cI9ArCC6IOZA3uDPcLXguqCXUJsgZRByoGfQasBh8IAAvXDkoQChJjFEMVbRdmFZgUrBNZEQoQXA7uCiIJ7wUqBroDnAEwBP0CUgCi/4X/0f+rAqID+AR6B+EGgQuzCt0M9w34D5oP4w7fC7IIowVzA8L8P/hh9B3xw+ro52/mIuQ846fj2eS14r7jCOW25Mzg5+Eh4Fbgdt/q4pThPeWk5BLoBur879fy9PKU9bj3zfox+5D9Xv70/TX+nvrc+9P6B/df92f0XPTd8vrydfGK8ofxBvM182X15Pjc++v8rv9YAlwDVwdUBn0GPQqVCFEH2AdRB+cGawYFCfAHcgqQCgkMwA4/EJoRyRGeEhUQhRA2EcYO0QzyDVwOkwu3DYQMBg9FEoASfROSFLMV9BcyF9MUhxZ4FS4UPBHNEnYP7A8pDcIN/Q1YDUYLpAvrC34MBQs6CbgGfwM+A4f+7vun++f5T/td+LL5MfmD+eH5JfvU/ND7Rvyq/KL9I/5+/f/5QPxv+oP3Gfm69Cf20vaa9Qn08vUV9gn0KvWr9Yv0pfX19mv1jvep9ub15/d/9gr4Svam92v1sveL9t722vUK9g33tPQA9e/0MvSz8nPyKfOC9Tv19fQe9cjzUPaY+N72mPih+SL45/l7+sT5WPz2+gz+Uvz7/9f/EQBzAZ8CkAF2ArQD4AI7BDYEawQSBCoE3QN2Am0D4AQkBu8FUQfcCn4K9AxcDh8R+xAtEIMR0xJWELgRhhJOE3cRXxFOE3oSbBM6FN8UnhJ0EDwRtw3yDcoKLgc8BscHwAUkBDUC4ALXAzoAhAGNADUAt/6TALAA0f+T/Kr8lv22+mD7gPrB+CD7Jfkf+Uv6j/lg+cr5Dfea9bL3evao8hv09/HL8njyOPTX9HjyTfN39wH3dPi+9xn5Zvuh++v68Ph7+oP5pvdL+FD2FfZi9jH5wfie+t749voL+mT8cP7a/pD9Z/2A+i76C/zc+Wn6Q/sI++79UP/6/Zb/RgA1As8EoARCBvkG/QJYAkcCFwBH/pP8TPx1/Pr70viG+q37QPwO/aQAZ/9cAwkDYwfABWsGuAiMCSMLzQlaCIoKhAqBCW8LoQoCCEYL1gpmCqMHdQnHCWkJVAY9CFAFAghfBr0ECgVrBJED1QQyA3MDAwMPA1AFAQTnBkoFpwh0BwcGpgZUCMcHugVCBmIF7wPIAvICGAL9AIv/gv73/Jz9hvoL+qH5svfz96f5GfmJ9wr4+Pdm+Uj50vjB+Pz60Pmn+ZX5N/ue+j37mvdo+MD2d/nq+Dz3g/ds+SX5wfjc+V362fy2/Fj8TPyc/bb8hP2Q/dD7K/ni+9b5sPpX+hb6sPxS/LD6zvwO+xT7Sf3K+/3+xfva/tT8qP8Y/o3+CwApAHwCTQQeBOcGsgb7BVcHzwQnA+8DdgQ2BC8CdgIdApYBLAGuA4ICRwI6AAkBRAFzA/UFNgbeBVYDxgXuATAE5gSABTYGuwdJDJYMeAr5CBoKcggfCHEGHAejBdMHCgdrBicFbQPjA5cD4AKzAcADGAKiA7AAy/3i+4D66/oi+Pn5mPiq/A//UgCTAOn/bQHOApMAwP+W/w//1AARACf/8Pqt+2n6P/Z29dL40vbb99/6ePuZ/KL9x/oF+r75+vuE+974lfkZ+Y38Dfko+h/5m/te/LP7Mv+8/pYBlwOIAsYDMgHFAZz/7/92/kf+Bv5G/MD/cP5P/R3+TABE/ywBnP/IAooBnwK3ArkBCwDm/m8Ahf9k/p/+4P7U/qQAkwD0AbYAlwNNAqoA7//ZANf/kQMnA1ADTwHZAK4B5gJiA2IDTQJTBB4EtwSiAx4EzgDjARX//f4+AXMBagBHAicFpgQ5BasCWQQkBBoBBgI+AcADgQBBAkAAEgIP/28A3f/7AxUFKgQxCCsIgAcNBp0F1QRKA/3+9wCi/y8Ajf5q/g//k/51/B38xf2K+7P7y/14+4T7Pv2W/ff8v/tS/OL78Ppg+1L+2fyz/TL/Bv5K/7H+Gv36/YT9IP0R/Ir7dv65/YT9XvwJ/fz6h/yc/Vr76/zo+03+fvuK/WH9NPxq/pn87P7p/0T/UP/G/3sAUgBeACEDLAFqAvQBogPIAiEDpABJAREA8gJ5A1IAfAToAVkEXAWRAxsDsAAPA7wA7//oAeACnAMyAxgCSgNiA2QCzv4J/yf/i//rACAByAIDAR0CYf9SALf+3f+T/uUAwP+lAoQBZAJtAav+wv5V/Rf8jf66//r9rgGzAWEBkAHxAF4AFwDI/pMAswHUANf/tP8+/6L/dv5v/MD/AADjAREADgF5ARoBPgEaAWEBlv9vADv+iv1N/pP8Q/28/Hz+IPtt/bf+Cf+2AOP/yACKAYQBNf4pAHP9AP4+/bb8HQDC/gYCYf8J/4cAc/+H/kQBRP+u/58AjQDrAEQDIQM1AGoAIwD9AkECJgGwACMCcAKR/7wAafyK/WH9Bv6T/rz+qP9H/vL+eP1Q/zj/Gv2N/kf+yPzC/un/bwBV/UH+t/55AY0AiAL3APsDNQKrAuYE2gIDA+wCnAHlAIv/7gEsAYIC7gEvAKL/XP+zAUECgQD6Ab0CpACrAjoAef+f/rz+c/9K/zj/4/+BAAMBfgEMAiMCagJ5/4v//f4gAfEAfP6kAIv/OgAv/sb/9/6ZACABjQCF/9397P4M/pb/ov/R/RcAD/8h/ykAvP5AACf/Ff/p//v/BQAY/or9qP04/cv9Ev4Y/nP9qP+K/df/9f+EAbAAnP+NAP0A4//IACMAi/+i/4L+uv92/n//wv63/gsA8v77/2H/kwA6ACz/WAIaAZwBHQKiAbz+BQBt/Vj+OgCR/28A0f9W/8v/rgHX/1YDLAE7AmoAhwDXAegB8QAJ/wUANf4JAeP/nP1P/bz+kP3ZANr+nP/IACMAc/8n/wAAYQF+AVz/agAFAJ/+FAFe/gkBzv44/7MB3QF8AikALwK/Ad0BfwOzAZcD4AJBAjsCwP/XAXkBuf2o/df/dfy8/Cb9QACC/hL+9/5vAJ/+Pv8aAUYAO/4pAE8B4wF5/5n+yP4mAfX/JgF5/2QAf/+u/8L+RgDX/x3+9/7R/X//9f/CAMv/dQDv/7r/n/4+AdH/7P6zAagBXv6T/lb/7v2c/wn9nP8D/xEAR/68AJn++gFwAhgC/f6iAQ4Bt/4P/4EATwELAN395QDA/3kBAAI4/8b/BgLyAkwAwgJiA/v/4ALlADUAkf97ADX+3f3rAHsALwA6ANQAAABW/5n+OgBhAcL+FwDLAcv/ogEY/m3/wgBtAbAATwFn/w4Bav7X/5MAQADs/nb+Tf6i/7YAt/7C/rwAdv6x/vL+bwAJ/8IAfgHfANQAbQEOAbYAIwD9AAMBG/8+/9f/UP+oAcIA6wBEAZABLwKWAZkAywFY/ov/UP+HAAb+7v1k/sD//fxN/n79BQBH/un/RgAy/2cBh/58/nkBRP+ZAP3+SQGN/iYBpf5//2oA7P57ALwAbf+zAXkBXP/g/rr/Pv9z/2H/rv8n/67/7gGT/vv//QCkAJkA/f7p/7ECAALLAaj/GgGNAPX/RP91APX/vP46AA//UP9t/0AASv+f/sb/QACT/n4Bkf+F/2cBIAE7/mH/OP+l/nb+FwA7/kwA9/4DAav+Vv/y/lb/cP6kABcAy/9n/4f+LAEs/6j/Uv6u/+gBHQAsATIB7/8GAqgB3f+2AAAAJgE6AOgBlgGu/14AiAISAtkARP/L/28AOAEsAYv/eQH7/5P+nwCz/SkAEv70/YQBPv8M/jUAOAH3/uz+mQBqACz/qAEOAc4AZ/9w/hL+kwCkAA//bf/IAD7/mf5VAfv/igEjAN8A7/8P/2H/bwD7//X/wgB7ALYAMgH7/3UAov9eAJn+vAAaAS8AYQF8/pAB1P7IAGEBLP/G/wP/qP/O/lj+mQCr/uD+rgGQAU8BjQDR/w4BHf5S/rwAWACo/6oASQGR/3//EgKfAEQBrv+kAJz/dQCNAEH+KQDA/0AA3f2ZAPv/kwD6/Sz/Sv9e/oL+UgCkAIf+zv41ADUAogHu/UwA9f/A/8L+5v6T/hQB6f+iASYB5QA1AF4AqgBB/sv/Nf6HAPcAXv4V/0wAqgAD/8sBgQBkAGoCZwEXAPcA9/6/AUH+2QAXAAwCZAL1//cALP+QAeP/bwBPAQUAqP/6AcsBuv8h//EAsAAaAa7/ef9K/2QA1P7xACwBEQBJAYEAG/9e/jX+7P5zAZb/6f8vAF4AvACNAEH+Z/8J/+///QCH/nP/8QDd/eb+q/6kAML+JgE4/3MBDP7CAH4BGgHX/4cAwP/U/oL+gv60//3+L/4d/jIBi//d/8sB1/9zAQsACQFqALAAWwGo//cAjf6o/5MADgEvAML+Tf4y/2EBSv81AMgABQBE/5z/zv4GAgMBcwHR/98AnP+0/zoA6f9nAXkBD/9bATIBO/6r/jj/LP/j/x0AAwHa/tH9pf6HAIQBagB1AIcAFAE1/lb/If/9/kAA7v0AAP0AOAH3AGH/xv/L/0AAZwG2ACz/kwBS/k3+9wCx/g4ByP41AD7/dQBqAK4BFAHCABQBZAB8/oX/OgC5Aa7/FwAdArYAbwAh/7z+RgDC/r8BmQC8AK4BywFt/67/VQHlACYBagB2/nb+yP5H/iH/XgDFAWT+zv6NAAAA3f+NAHkBigGqAM7+fP51AGT+QADUAE8BhwAyAeb+n/4pAPL+9wBGAHUAQf5B/v0A5QCZAEr/IAFq/gn/MgFbAVgA2QCu/w//tgCWAeP/Tf4D/2cBLAFW/2f/h/5n/8b/Z/9e/vv/+gHdAcIAvwEmAU3+swEXAFj+NQBz/7r/uQHs/lb/TwFvAJP+lgFk/nn/WP63/m3/q/4v/uUAIwDp/7kBlv8+//L+zgB//9f/y/+HAMsBIf97AAAAlgGQAQkBRAE4AXz+qP+3/jL/Tf46AIEAMgFH/sgAWP5k/j4B8v66/2f/sf7p/yABEQDxAIf+ov+QAcv/rgFE/2cBCwCqAA//zv7C/nkBZwGf/ugBZwHuARX//f7ZAAn/Tf4J/7H+sf7X/+UACwDlAGf/Ff+3/oL+cP5t//X/7//X/1b/ewBPAZn+t/70/T4BYf/xAJb/Cf/I/mcB2v66/1sBBQDa/oQBEv4v/kf+rgHm/i/+Mv8gATL/Vv8XAMj+1AB7ANf/CQFE/58ARAFtASH/DAJEASYBcwEAApABRP+fANkAf//p/1b/uv9bAcgAYf8s/wwCJ/+l/rkB4P5//wkB7P7C/if/hwAyAVsBogGi/4f+av5K/939xv9k/m0B7P6C/rr/lv/xADgBBv7CAOUAdQD6/Vb/NQApAI3+nP8s/5wBXgDA/5n++/+QAaj/fP5eAI3+BQAs/1gA5v6i/5MAZACBAF4AD/+N/h0CywGEAcD/sf7O/lL+lv/1//f+dQCTAI3+sAAh/wn/k/5bAW0BkwCx/rf+Tf68AJb/mQA4AXn/Nf6ZAOn/Yf9kAPv/kf/UAB3+lv+fAFsBi/86AOD+RAEjABL+Cf/6/dQAfgFqAET/cwFGAJ/+t/5AAM7+OgC/AU8By/+wAIEAywHFAesAYQHLAZb/qP9SAMIAfgGu/z7/sADa/pb/4wEpAsL+Vv9k/uD+h/5YAHkBwgD7/xoBtP/j/xQBJ/+qAGoAXv5vAMgARgCHAHsAdv5N/m3/lv9Y/tT+PgFnAS/+9f9h/z7/If9qANQAZ//s/lj+f/8M/n4BO/4h/wAAf/8S/lgAL/52/rf+y/+ZAD7/Nf7XAbr/2QBY/iYBkf+TAGr+agALAFb/Cf+cAd0BAABAALz+Pv8LAG3/7gHR/zv+sADO/ssBcP5zARQBkwB5/8L+zgB5AYv/kf98/tEBZ/8D/zoA3f8RAHMBAwGoAbT/k/58/r8B0QERAMD/mQD9AKoAI/63/rMBRAERAIQBBv44//EAUgB2/kH+If9n/yMA8v4AALYACQFvAJ8AWP7L/4f+nAGzAez+UgBJAY0Agv6Z/uD+EQDIAAsAZwH3/pABhAEgATX+uQG0/9H/Kf5S/lb/8QBhAcv/WAB+AVD/yAAh/1IAUgBEAWEBsACi/xcA2QDL/6oAov+x/gMBOP+f/t3/UgBtAbwA1//3/rH+9wDp/8L+Sv9S/nkBpAAOARoBHQDg/ikAhf+W/3z+5QDCAOb+uv+u/84AUP8s/6v+rv9JAYf+ov+T/tQA3wCkAGQACwAAADoA5QBPAcD/ywHg/kr/Mv/C/mH/IAE+AfL+TACx/hEAqP9vAB0ANQCN/n//HQCiAaL/rgGc/3UAvP5VAbH+8v7FAZABOAHd/4X/RAEh/0wAk/5N/uD+kAGKAcsBtgCkAKX+uv+R/3UAFwBtAZYBAADXAYEAmf5k/pYB1AAsAVgAbQGL/7f+cP4yAYv/uv+C/jUAFAG6/3z+JgFw/of+fgE+/zX+kwBqAFL+yADXAcgAyABkAOD+3wCzAYcAPgE6AAUAVv9t/7YAG/+H/nb+WP4v/moA2QAXAN3/vP5n/wkBhf8AAGT+sAA6AA//ywHZAM4AA/8jACwBkAHU/lz/ogHm/sD/Tf6wAIQBigGWARL+OgBAAC/+fgHU/lIA1P7rACABrv8FAJABUv7d//v/4wEvAOUANQBN/if/gv5Q/zL/mf6HAEkB7/+8/pb/lgHfAM4ATABEAe//Tf6QAWf/1wFS/vEAogEjABoBuQGo/7f+jf7O/hv/gQCr/vL+IwBbAZz/hf/7/9H/gQDrAJz/Mv+o/8D/zv65AbwAIAHU/rr/CwAUAVz/sAAD/17+vwG8/lsBQAAV/yf/If8vALAA8QCx/pH//QA7/lj+FAE1/iP+Nf4OAc4AUgAjAFL+Qf7fAMv/LP8mAS8AQf6fAM4A4P6fAAMByAAh/+D+4P6l/jgBy/9VAUYAyAAXAEH+2QDj/+n/If+fAKv+3wCNAC/+kf+3/lD/HQBh/0H+RP86ABoBfgFkAMb/qP+3/tH/A/+ZADL/c/9+AX4Bt/5GAEkBKQAj/lD/LAFzAU3+kwBq/pkAeQG0/wMBJ/8y/9T+vABkADL/tgDIAKgBcP73AFL+XgBeAA4B2QBw/rr/5v7RAXP/tP8+/xcAbwBB/lz/GP4RAFUBCwBVAVIAUv6Z/rAAyACN/mQA0f+2AEwAjQAvABoBXP8pABv/OAGuAWf/n/4s/6IB7/8aAbAAuQFw/oX/CQHa/kQBzv41AD4BgQCR/23/cP4aAdT+uQG5ATIBAAC3/nP/XP9vAC8A6f/FASMAywH9/ssBdv5hAbYAhf9vAHMBxQGC/gP/rv8b/0QBKf5B/jL/TAC5AW8AOP+Z/t3/bf/1/yz/gv4yAYL+VQE+AVz/i/9PAUYABQBnAW0BHf7s/gn/c/9vANf/7P7G/17+bwCi//3+rv/FAT7/IwB5AQkBCwB+AV7+wv7dASH/ywFYACn+7gGEAfv/YQGu/1IA9wBN/lL+kAHdAfEASQGW/3D+nP84AQkBeQF//7f+L/6ZAKX+fP7LAc7+agDa/ub+sf6N/gP/Z//O/rYArgGR/8b/J/9S/nMBVv/O/qv+Ff9tAUkBlv9nARQBwgAh/5wBswFe/tT+Sv+L/ykA5v6T/vEA4P5Q/wMB6f92/vX/Nf4DAXMBWABQ/xQBuQHLAYf+BQCHACABR/4dAJ/+Mv8XAHP/hAEsAaQAtP+wAHsAqgB//8j+5QAjAOUACwBE/4L+mf7fAET/dv7UAAkBkwAOAXMBFf9bASH/FwC8/sIANQCo/yH/Uv6qACYBGP4s/3z+9/7X/2T+1ACzAXz+5QBY/o0AUgDm/rz+AAAdAKv+0f+N/hEAFf+H/vcAn/4h/1IAf//IAMb/q/4n/yYBAwEd/mEBbQGZADIB+//OAFz/gv4D/zj/2QBAAO//RP+C/qQAagDxAEwAmQBvAIoB8QDRAfL+sADxAE8Bef/R/8j+LP9Y/tkAFAFN/m3/lgGqABX/AADj/1IAi/9Y/nn/mQCf/sUB2QD3/joAL/6l/o3+vwHrAIcAG//fAAkBgQB5/7f+SQHxAEYAmf7RAaIBTADG/6IBnAGT/m0BwgAb/ywBpf7g/rAAhwD3/kwAPv8jAIcATAAMAo0A2QDC/gP/LAEJ/0YAzv6N/nP/c//3AMUBf/+ZALz+FAEJ//EAkwA7/of+6f9E/xj+bf+Z/jj/q/4JAW0BUv4JAWEB2v79/i8Af//IAGQAOP9qAMsBL/6cATUAkwAgAV4ARAGZAKj/tP8mAeb+tgDd/93/OP8p/tH/8v7XAUr/Z/+i/4EAywGF/yYB2v7I/gD+ef9EAXD+XgB//4cAkf/RAdr+AAJEARICagBh/14Aq/5MAEH+FAHUAKX+LP81APcAXP8v/gkBjQAP/1b/8QCrAu4BIAH3/tf/9P3R/Zn+zv63/mn8ov8FAAn/Mv/fAJAB9f84AwsAXgDFAYX/LAHIAGT+Bv7R/fH8pPx5/6v++/8n/0T/XgIbA2oCYQEaAeMBIwLL/8L+av4V/wUA2v4O/Y3+/QBh/6v+xv+2AH4BEgI4ARcArgFBAk3+CQGR/5z/Vf3x/Cf//f62AOD+EQAJAbAA/QDdAWf/8v5eAB0AQf5Y/i8AG/8n/5b9Bv44AbH+Xv44/wkB8v5kAAAA9AFSAAP/0f+TABL+Z/81AFL+c/+x/qIB1P5vAG3/3QEaAbr/kAE1ADgBDgHy/kwAUP9Y/pYBef+ZAFgASv/L/yAB9f/RAWoCCf/fACkC4P7xAIv/9wA7/u//6f8+Ae79TwEvAlMCqgBkAr8BA/9z/8IAGP4vACf/v/2TAPL+Bv4RAM7+JgGTAD7//f7RAW3/WwHCAMIA+gFqAAb+q/52/s7+BQC3/iP+PgGZ/rr/CQEdAkT/DALR/+gBagC5ASwBef8FAA4B7v0P/wAAGgFW/5kAkf/u/XsAQADg/k8B6f9c/20BNQJNAi8CVv8P/wkBgQD1/zL9L/5e/lgAT/2ZAKv+nAHdAW8AVQGWAcgAPv9MAO4BLP/CAJb9ov91AAsAlv28ACn+1/3g/rMB8v5W/20BBQBEAbcCkf/oAa7/CQFAAPL+HQA4/0wAgQA4/ywBxQFBAtEBCwARAFIAMv8J/4v/IAGNAJ/+tP86AAUAIAEyAV4A1wEUAbr/RgBh/5/+D/9GAKL/Uv7fAF7+1ABz/0AAsf5S/rf+GP63/pH/t/73/l4AbwDg/hj+hf81AF4AIf/v/+D+0f9n/+P/TAD7/17+J/+T/q7/Yf9H/kQBIAHX/7H+OP9EAbf+EQCNArT/4/8s/9H/8QBbAagBZ//3/p/+1//fACf/vwFE/+P/GALrANEBNQKu/xgCLP91AB0AbQEh/03+Xv6i/9f9AABvALwAh/7ZAOUA9wDG/7T/uQEXAPv/A//fAD4B5QBY/hcAWACF/3UA4P5P/Sf/JgEp/g4BA/9K/0T/y/9SAEQBR/77/8gAMgFvANf99wALAHMBVv8DAVz/Cf/UAJb/Pv9PAWQAVv8+AdH/IwIh/+D+LP+6/9EB3f/dAW0BhAFeAGEBtgCqAHAC3QEjAgMBWAKuAVD/FwBS/uz+av7G/4oBJ/9N/q7/D/+W/8b/1/+NAPcA0f2T/hcAsf7g/jUAO/7F/XUA9/6C/rr/Uv58/j7/zgAjAIf+wgC2AOUAxv+r/t8Aq/6HAHUAIf/v/9T+agAV/7kBFf9E/8gA0QF5AXMBTABqAKX+9f+fACkCVQEGAmf/qP/L/8v/A/9tATL/qAGkANkAJgFJAd3/NQJvACkCxQGkAJMAWACR/xoBZAAsAR3+MgHG/5ABwv63/ocAnwAFABX/PgEUAXMBQAAvACABk/41ALT/jQC3/qv+XP/m/nP/6wA+AR0AFf/3AJb/OP+r/gUAAwELAJn+Yf+F/wsA5QCW/9cBt/6o/6oAeQFzAY0AnAE4AfQBqgB+Af0AXgCr/vL+WwHy/uz+xQGF/w4BIAEUAbMBLwKH/gn/ZP6HALf+RAEOAWcBkf8j/gn/qP84ASMAfP6F//EACf+W/8gAWwEP/x0AFf+kAKX+hwALAHsAHf77/zgBTf4j/uUAbQH9ACwBMgHxAOP9Mv9B/tQAc/8J/1j+nwBAAJMAyABeAM4AAwEmAcj+ogFt/+b+1P46AFsBGgF1AEYARgDj/4EAWwG/AbT/swGo/8v/c//p/wwCD/9Q//f+HQBhAYoB3wD6ASMCrv8gAYX/XgC0/40AZAB//08BFwBQ/5/+pf76/R0A0f2i//cAwv4JAS/+eQGc/3UAZAAh/4L+pf6C/tr+PgEV/4v/h/62AGoA5QBAALYAdQB5/7H+WABbAYL+gv5tAe//yP5PAcUBWP4DAZMAwv6WAQ4BJgFK/6L/vABNArH+1ACR/yf/1/9HAgwCKQCF//v/6AHL/6QAigF8/g//lgFGALAA+gGTAMD/sf6KAREA1P71/87+qP8gAcv/4/+qAF4Abf8AALT/zv7U/l7+Pv8h/zUAEQAb/5P+RAEn/xv/uf3O/uz+O/5k/gP/Cf+T/nP/ZwFK/3//kwD6AYL+WP4y/34BRP/G/7H+xv8XALwAWwH3ANEBf/9PARX/IwILAGf/6f/A/+4B9f/UAOz+XP/LAWEBR/7xAH4BywEb/9T+BQB//7AAywEb/zUAKQCl/tkApf7lALH+9wAJASkAwv6EAWcBHf4UASABWADlADv+NQBB/gb+Kf4jAHP/XP8S/jj/lgHC/uUAav6r/vX/WwEn/0H+OgCwADoAxv9H/gn/7P5PAcsBav57AGoAfgGH/qQAnP+2AN3/DgGcAQn/ywFc/7YAJgH0AfoBswHC/pb/Z/9E/2r+CQEGAj4Bdv6ZAPoBYf+2AJwB1P4XAEwAsf7OAHz+agD3/pMAtgDfAHP/hf/A/zv+ov+QAVgAJ/+x/gMBbf+W/7YAwP9K/7wA7v0d/uUANQCL/6gBfgHI/hX/rgHfAA//nP/A/1D/R/4+AZkAAwFzAWT+y/9w/tH/1/91AAn/JgEsAe//Mv8RAHD+4P7y/gUAogGKAQn/hwCcAXD+FAH9ALwAwv6kAGT+RgDs/joALP+KAWT+IwBw/uD+UgCr/iMAf/8UAW3/8v6f/tr+bQGzAe//yAAY/m8AAABB/v3+ef8DAaX+Z/+F/wsAKf5Y/sL+JgFAAJwBUP+x/vX/nwAJAfv/7P6zAZABnP9JATUAcwEFAFUBsf6iAZn+uv9z//X/IwB5AToAbwDL/7MBYQGHAG0Bpf6cAXn/hAHI/k3+sf7fADv+8v58/lgAkwDy/jX+O/6L/9f/lgHCAHb+R/5vABQBq/4J/03+SQGWAdEBFAGuAcgARgD3AN3/k/4RALMBq/5K/5MAlv/G/1D/lv+i/+n/O/6WAT4BGgFkACz/pf4V/ywBRAGKATv+PgGuATv+If+5AYQBUgDU/vL+zv5N/tH/7gGoAcL+wP/p/zv+dv5k/kwAywHdAUH+CQE+AagBO/68/pkA4P5w/uP/FwARALYAkf+o/5P+hwBVAb8BzgAjAJz/vAAvALAAUgAy/2r+av6uAXsAXv44/0kBD/9Q/2QAG/8n/+UAwgDj/0kBjQA4/wkBdv4gAfv/vACqAJABdv7rADgBEQBq/mr+WwF7AD4BPv9kADv+MgHIAAP/tP/m/q4Bf//C/i8AzgC8AFL+J/84/5YBAwFN/g//LP+L/0r/qAFE/5YB0f8RAEkB9AGkAFj+Yf95/3D+QAD9/v0Akf+NAPcAO/6oAc4AWwFw/vv/Kf7s/rf+wP+uAQP/fP4aAVgAVv+u/7f+q/46AOn/TwHrAN8AkwBEAY3+NQBeAKj/mQD1/6QAWP7I/jIB3f8V/yMApf6fAOP/yP7U/gkBtgDRAfL+EQAjAKj/rgE6AEkB8v7v/20BAALR/67/UgBhASwBZAC3/p8AdQBt/4oBKQBn/yf/Xv4yAXn/7//rAN8Ak/5h/xEAQAAjAKv+mQCuAd3/VQGW/3MBt/65AXD+uQHCAHP/BQDd/1IAbwDI/vX/Pv9N/tQALAHUAAsAZwE7/qoAG/8FAMUBGgEmAZb/HQBGAP0AigE7/lD/5v4p/n//gQC3/hcAVQEXAKX+mf4+/zUA7//U/vcAjQCo/zoAhf+N/gMBBQBQ/3//eQGi/1L+Uv4gAX//1P7G/3z+YQGc/6QAFwA+ATX+bQE+AbwAgv4n/7z+bf+i/xv/kf9zAagBFwC2AGH/rgGW/xoBnP+KAdf/sf6l/u//0f9n/40AmQDG/7H+fgFhAeMBmf6uAWT+cwFQ/6L/ZABtAXP/ov/d/5kA1wFYAKIBNf5W//L+6f9AAHsACQHC/g4B2QBN/gAA1/9zAS/+gv4D/7YAogF//2T+qAHLAYcAuv8J/23/D/+H/jIB2QBe/iH/bwDlACz/qP/xAFD/VQH9/gkBLP+BAOsAgQBn/w//RAFMACAB9/7ZAFgAnAGuAQP/IAGR/xL+O/7d/zv+ywHU/iH/lgHrANr+ewAv/qj/t/7XAZ/+XP+l/un/2QDX/3b+qP+EAYQBOAF5/7r/J/92/sIArgFS/pz/XP9AAMUBmQDO/iYBf/9Q/0f+WADFAUT/mQCiAa7/7P7UAE3+JgG8/tcB0f81AMgA2v5k/l4A5v77/4QBCf8+AdcBc/8s/7YA8QARAG8Akf+F/5ABcwF5AY3+2QDg/rz+wgBJAd0Bwv6HAJwB+/8mAS8A8QDy/g//TADUADgBdQB8/nb+3wCC/p8ACf81/g//wgA+/yYBUgDd/7MB9f+QAaIBNQBkABv/Uv44AcUB/QDj/4EAzgD1/6j/AABvACwBQADL/03+2QBH/g//gv5+AbYAlv/ZAC8AAwEgAYEAgv5N/q7/eQHL/zL/sAAV/9f/AwHm/gMBnP+x/pYBQf68/j7/1ABAAEr/tP+cAZz/LwCNAGT+1AA4/3kBZwH1/0f+fgEvAMUB9wAOAYf+mQAv/mEBtP86AHz+cwGC/n4BcP4FAFD/TABvALwAqgDv/40ALwCHAGH/kAHfABEAy/84Acv/lgGBAHz+kf95ARcApADrAHn/bf9Y/p8AuQGBAP0Af//g/h3+XP/O/kH+ZwEOATX+zgD3/k8BnAELAH//n/7CALz+4/+i/3P/JgGH/n4Bn/57ABoBIf95/xQBZP6zATj/Sv9YAGr+KQBAAPL+TwFc/+D+i/8Y/k3+OP+qAOP/ogGWAUkBKQA4/7YALAGR/0T/I/68AIL+GgF1AKoAD/9VAZH/9wCo/0kBswGN/kkBbf9z/0f+PgGqAHMBJ/+cAd3/QACEAW3/RP9YAC/+R/73/p8ACf/1/5MAxQF//64B5QAY/k8BlgE1AIoBt/47/moAAwH3AJ/+cP4yAWoAqP9VAWH/+/8RAJ8AwP9H/q4BNQCl/gMBgQDG/4oBUgCuAf0AKQBhAXz+HQAb/8UBJgEV/2f/G/8D/4cARP97ALT/yAAs/2f/cwFQ/67/Pv9t/8v/5v7XAcb/zgDO/hX/bQFJAfL+XgBt/1j+3QEh/0kBdv4y/4EAWwGu/0H+OAEV/xoBJ/8UAeMBXP+fAOz+LAFhAWr+OAFH/uUANf5tAcL+sf5k/joAgv7fANEBhwDRAY0A/f6x/uz+CwBt/5/+VQFw/lj+av46AH//CwDy/in+LP+x/qj/t/44AW3/7/9VAYQBywGN/sgAUgBn/zgBMv+oAS/+rv/FAUQBgv58/nMBagCT/pP+mf6R/yH/3wA+AVUBPv8J/3kBXv4RABcAsAD7/6QAZ//d/zX+q/7v/90B8QCiARX/1P7m/gkBsADIAFIAigHIAAn/3wBh/8L+f/+i/40AZP5bARcATABB/p/+tP+HAFj+gQCWAbwAZ/86AK7/xv/xAOn/rv/R/+//rv95/x0AA/+R/7H+D/+C/uMBy/+wAD4BTf5N/mr+QACL/5z/Pv+/AdH/qP/3/qX+qgDFAfX/Sv8+AdcBqgDj//0Ay/9w/i/+0QEyAUYAnAGr/pwBsf4sASn+HQDa/qX+Mv/I/g4Bf/9S/pP+n/5eALH+WP4J/zoAzgDp/84AD//9/q7/ef9Y/t3/Ff/RAbz+KQCBANT+KQCZAF4AyAB//8b/5QCN/q7/RgAp/k8BCwB2/tcBLP+c/0f+Cf9z/5YBL/5w/nD+dv6N/q7/8v6W/8j+0QEP/+UAf/9nAXkBSv+f/tT+zv5e/mT+4/9zAXUAAwG2AMb/I/7m/lgAfgEj/r8BYf/ZANQAMv9SAGT+Xv6C/pwBk/4XACn+LAGNADoAXP/xAHUAxQFAAPf+WwHZAIEACQGKAQkBGP6wAFz/pACwAP3+kwD3/v3+7//X/wMBqgCZ/pAB9/5+ARoBxv/9/uUAAwGiAUYAXv7p/+P/hwBt/5H/9/7X/+UATACZ/gAA0f/FATv+2QCf/tr+Sv9Y/pb/WwFe/pH/CQFk/nn/1wHZAP0A3f+T/vv/CQHX/8L+PgHG//f+L/6Z/g//qP+fABv/WwFJATX+mf7s/t8AFwDdAWT+OP8mASwBJgFB/rkBnP+c/2f/KQDUAN0BmQDC/qv+tP9w/nsAkf8pAEkBFAEsAZH/hAHlAIv/1/8sAesAqP9c/9kAtgD9AEf+gQD9AB0Axv81AGQAUgAFAEH+HQBMANH/LP8+AZP+wv6wAHD+IwDU/mEBA/9+AaX+DgGL/zIBRAEmAZb/gQCfAMUBkwCqAFsBywEmAWEBL/4LAEf+ZABn/8gAi/+o/wkB3wDa/un/rgHa/rYA8QDRAYoB6AERAMb/9/4XAGr+QAC6/yf/4wHIAMj+wP9h/2oA5v6HAK4BHQAFADj/PgFbAaL/Z//j/3sA/f7FAWcBywE1ABX/Nf5vAGr+Nf52/sb/ogFEAX//wv6NAAsAsABVASf/4P7G/90Bmf5zAYX/SQG2AA//Nf79/l7+AwHU/lgAt/4+AaX+NQADAUf+h/5JAd0BcP7d/40AvABbAS8ALwB+AaoAD/8LAK7/vADv/y/+q/6T/m3/swHUABEATACTAAn/lv8sAdEBWP5Y/of+Pv/fACH/RgCNANf/Uv4pACn+qP+5AZMAtP8jAEAAXv5MAJAB1ABK/2r+ogHX/4oBnP+W/14At/5K/8sBCQHX/8j+GgGC/sIA/QBVAZz/8v6QAff+I/6Z/qQAlgE6APX/XgDUAGH/ZABk/jj/3f+QAdf/XP/y/h0AXgBtAZn+3QEgAfX/bQE1AP0ApAA1/oL+Yf8OARQBlv9zAZb/Uv4dAE3+SQHIAAAALwA+/3P/Z/8aAeUAigEdADUAEQB5/78BJ/9vAKj/WABvADUAAwFqAKoAgQBK/4X/f/9k/ocA7/8gAcL+wv5B/vf+9/5vAJYBSQH1/67/WwEFAMUBO/7O/rwAXgCzAX4BXP+WAVD/7P4mAXn/CwDU/iP+1/8b/17+UgCl/u//lgEp/s7++//3/mf/7/8pADUAy/86AFUB/QDFAZH/bf9z/6X+Kf4j/gn/vwHCAMb/jf5n/zL/Qf7A/1j+FAE1/nUAbQFS/in+eQEjANkAI/7UAJwB0QFnAaL/4wF7AKgBuv95/64BNf41/gMBwP98/sgANQCkAG3/zv7fAM4AUgAD/zX+ewDdAdf/igED/28AAwE4/zL/nP/O/sD/uv9GAIv/3f+HAFD/TwHy/pz/RgC2AO//WP6oAdH/Xv6l/l4AhwD3AAAA1wHL//X/2v6f/gn/lv9PASn+kwCzAQsAagC3/of+ZwFGAKIB1AAFAEkBuQFYABv/6wDlAG3/DgFPAUr/4/9N/mf/Mv9SADIBuv+oAf0APv8XADgBKf6x/ooBov81/tT+D//j/2T+DgFH/qQA4wFn/64BL/4UASP+CQEdAAMBOgCf/qL/vwGi/zL/PgFGALYAO/63/l7+LP+QAcb/k/7dAUwAXgDj/2H/A/+f/sb/5QBq/tkA4//lADL/Cf+W/3b+7P6l/uUASv9GAIf+vABz/4QBOgB//1z/+/9c/9f/KQApAJH/7/9n/zoAeQE4/8j+PgH3AK7/6f8aAXz+yP4LANr+OAHL/0H+sf6l/iMArgEDAa7/n/55/4L+JgG3/nMBfgFnAWr+0QFk/rYAdQAOASf/3f/d/xX/1P6u/5/+UgAFAM4AywFY/m0BIwD3/vX/KQAFAIv/swGqAHP/ewCQAav+R/5GAJMA1wH7/2T+nAFvAF4Ahf8sASP+Pv+0/0kBLP81/ocATf6wAHD+6f8n/23/k/6H/lD/jQBk/hv/c/+TAIQBGgHOAIX/hf+zAZH/6f/p/08BRP+r/t3/UP/OAOP/swGf/o0Ay/8DAc4A4wGNANEBq/4D/1L+hAHrAA4BqP8h/xQBjQDL/+sAD//a/lIA8QCi/1gAk/6R//L+Yf/IAF4ACwCBAHD+FAGEAVgAdv44/zL/ZP5Q/1D/yADv//3+Xv63/hj+ef+T/gUA8QB2/kwA3f8v/pwBA//ZADIBBQBk/j7/bQE6ADoAFAG0/8IAnwCN/sgA9f+NAJn+9wDxAGT+FAHL/3n/OP8d/iwBMv9AAJb/WABY/nMBLwDRATv+hf9W/zL/PgGwAFIAWP5qAKv+sf6qAGr+SQEd/lgAMv9H/tcBmQBYAML+WACi/xQBFAGo/08BRgBtAfX/IwBE/xcAYQFhAUQBxQE4/xEAhf9Q/1sBdv6Z/kAABQBJAagBqgD1/+n/Z/+zAQkBeQHd//EAXgB+Ad0BCwBYACn+WP7A/ykAwgBkALr/7/9e/t8Awv4FADoAwv7O/pAB7P51AJ8AZ//ZAD4BvwHUABj+1/+0/78By/+R/98AlgHxADIBEv6W/6gBcP4b/4X/Z/+2AIL+LP9h/zL/JgHlAAP/4wF7AEH+bf8+/zIBFf8UAc7+9/6o/xQBc/8n/ywBuQFVAWT+cwE4AXP/fgE+AUT/KQBq/lD/Mv9S/s7+BQDg/sD/fP7X/67/Xv79/usARgAs/zv+2QD9AJwB3f9vAF4A9/7R/wkBpACW/64Bhf/a/k8Blv81AAMBWAAsAcsBbf+8/pkAWwHXAaL/D/9t/2T+zgCr/joAOAEOAbT/qAFAAOsAfgFQ/2cBPv8V/6X+jQCi/08BVQHxAAAAZwE1/m8AZP7rAIQBIf9SAK4B1AA+/4cAi/8AAMUBHf6EAbr/7//RAXb+av5zAXb+SQGuAWoAXP/9AC/+IAGKASH/gQB+AaIBJgF7ABEA0QEaAQP/ewBeALMB0QEgAQn/3f+iAT4BG/+8AHD+Mv9tAZYBwv44/5AB9wCTAE3+6f9GAMUB/QDI/vL+6f9w/pYBXP+EAbAA9/4pAJH/7/+HAOz+rv/LAesAbf/CAMgA/QCcAYQBXP9EAVL+Sv/g/m3/jf5t/wkBWP5h/wP/Z//UAFD/f/8FAEwAMv9zAfEAWwF2/t0BO/4b/0YApAAsAT4BHQBnAXUAogEP/7r/IwDm/lsBzv79/moAtP/U/k8BJgEsAYoB0f+cASABnwDLAZ/+2QCiAd0B7/+iAeD+wP/s/iMAuv/R/23/ov9c/64BFf8XADv+Ff86AOsAfgGT/gsAogG6/43+6wBq/sgAO/6C/oX/WACfAA4BTwEgAYv/WP7dASMAZ//7/0f+7P5bAeD+EQBvADIB7//v/3P/SQEh/5n++/8vAGEBpACcAZz/Qf5w/ikAnwBz/xQBy/97ACMAsf5JAez+av7C/tT+OP8b/64BLAHZAJ8AGgG5Ac4A3f+/AWH/Qf5z/wAApf6r/oEAIwDL/93/pf6C/sb/5v4yAd3/ewBE/x3+sf4V/1sB2v5vAGQAXgDO/g4BAABSAEwAFf/3AOz+AADXASn+hAGl/pn+fP5z/0QBk/4XAML+ZP46AAkBwv4LAKgBPv/UAOz+Uv6H/nMBbQH7/5/+RP8p/t0BIf92/pYBxQGf/pABf/9N/gAA1/+EAav+MgHlAB0AYf9zAc4AQf44AXz+kwCT/tf/bwBtAXP/ywG6/2EBD/+i/9EBogHj/wkBvwGuASMATf7OAM4ATACW/zgBn/6W/zIBmf6Z/nP/QAAn/8UB8v4UAToAqgCuAZP+XP8y/wkBYQGZAJb/Ff+x/m0Bkf/p/7AA0QGEAWcBWP60/7wAhAEn/0r/swG6/+n/y/9qADL/dQDd//f+TwGiAc7+sABN/i/+zgC0/7YAZ/+T/sj+1/+3/rwAagApADL/lgE4AVD/wv65AWr+QADa/in+O/6NAFb/ZP5E/34B7P7CABv/dQCfAM7+LP+W/8UBPgFJAX//uv9z/yz/mf7C/ssBO/6EAc7+vP7OACz/eQFh/2H/q/6KAc7++/8gASYBTf5Q/yn+VQEUAY0AMv/m/kf+FwAFAIf+ewDC/pYB/QCkAE8BnAG8/qoAbf+R/6X+jQCr/of+jf4OAeb+vwHv/6oAzv7lAOsAGgGL/0AAUgCqAG0B6wAjAFD/f//FAU3+y/+5AdkA5v6KAWEBnAE1/kH+yAC0/4X/Kf7CAFgAywEjADL/i/9JAff+MgHCANr+OgDO/tH/8QBz/w4Bn/4v/s7+R/5AAEYAeQHX/yz/O/4pACYB3f84AYL+Xv6HALkBigGx/gAAyACNABcAkf/X/4X/J/8FAPX/OAG8/ssBIwBw/pYBLAHlAD7/bwAj/pP+R/44AZP+UP/v/9r+RAF2/un/ef+wAOb+Z//L/0wASv/fADoAZ//y/r8BZP5nAfv/JgHj/yABtP/v/9r+xQHIAHP/5QAsAaL/sAA+AbAAlgFE/0YAHQB//9T+LAE1AM7+h/5e/lUBWP6N/pABrgGwAGf/gQBtAen/bf9h/0T/kwCT/lj+3f9E/4v/EQC0/y/+eQE1AKoArv/OAPf+OAF5AXkBbf/v/3MBGgGQAXb+hAGZ/un/4//jASkAUgC0/zj/qAGiAR0AO/60/7YAgv5hAVL+h/7rAD4BfP5SALH+3wBc/zoAzv79/oEAn/65AU8BvwFq/ooBLP8n/9kAvwGL/yH/Qf6zAcL+3wAdAPX/kAFe/rf+kf/m/p/+pf5kAN3/agDd/7T/kf+6/9f/vwHU/kH+gQCBACwBy/+WAUkBn/7X/4cA8v6T/sv/dv6l/jUANQCTABv/qP8y/8v/0f8V/+sAZ//C/hX/dv5GAEr/OgCWAa7/Tf4+/0AAkwAn/wn/8QBYAD7/qAEaARX/i/+x/i8AkwBY/gUAjQCu/0r/JgG2AHD+rgEpAMIAUv6iAToAZAAaAY0AnwA+AfcA1ABEATj/bf/lAJz/1P7ZADj/L/7p/1z/+//rAK4BD//jAdT+LP+8/usAagDd/w//RgC2AMv/t/4sAcsB3QFW/34B+/9w/m0BCwCoAZP+Tf7fAJb/n/5bARX/TABMABcAbwDRAQP/kwCN/h0AyABt/7YA0f/U/jv+Xv5GACkAVQEJASH/Uv4UAdr+/QAs/ykAVv8AAOUALwBe/oEAFwB2/iMAyP6x/o3+av5e/qgBlv81ADL/4wHLAVsBogEjAI3+ewBvACn+/f4yAdQA3f/G/8D/AABbAQMBwgA+Ad3/zv6u/yH/KQAsAfL+wgAaAf3+vP5GAKL/pADZACYBzgAP/78BCwCZALMBuQGu/3sA2QDy/hcA+//FAYQB4P68AFD/n/68/iAB7/9kAGoAI/4jAFb/qgBW/0QBt/52/sD/wgBMAGf/NQAh/7wAh/5JAQ//UgBqAB3+kwDA/zX+mf6F/2cB9/7O/gAAJgGfAAsAMgFAAGcBcP4+/8gAfgHCABX/EQCuAeb+av6BABoBhf/UAAn/RAG8/tf/fP79AIX/HQBS/jj/hAEyAcUB9f9//6j/2v7G/6L/swGQAUwAwv7XAXb+hwDFAVsBcwGl/kAAWABkAKX+jf5B/sIAfP5vAEr/lv+HACP+nAHCAGH/6wDv/z7/QAB5//EAZ/+NAJ/+i/95AcL+fP6ZAGr+QACcAeb+cwHj/7T/zv5q/pYB3wBGAEQBI/7A/5wBk/7g/ssBQf7fAK7/y/8DAUYAOAELALH+AwHrAP0Amf5//7H+h/7ZAGr+vADdAbwAR/44/wP/7/9vADUAQf7v/4QBDgEjAG0Bdv52/joAjf7s/lj+bQGu/zIBQf7LAcb/rv+2AJwBq/6QAZ8AvP4RAN3/BQAJ/y8AG/+5AUAAWwHy/vX/Tf6ZAPcAkwCuASn+WwHv/8b/TADL/7H+tgCu/5z/sAAy/yH/fgHI/pkAgQDs/lL+IwBkAAUALP+HAGEB6wC0/wn/YQFJAZ/+Mv/ZAKX+rv9S/qj/J/+ZANQAnP/dAVz/J//ZAEr/vwFMAJ/+t/51ACkAJgF//2T+CQGWAbwAef9N/hQBPv/7/3sAdQDOALr/4P65AfL+TAD9AG3/uv8jAIL+3QHU/t8Arv+l/v3+h/5h/5MAt/5h/3//1wEJAUQB1/9GAA4BmQCo/7H+8v4P/y/+gQDX/5b/y/8UAbT/nAGT/ov/Z/+N/lj+hAFE/2QAZACuAbT/FwDUAJkA8v5Y/qoAyP7OAAsA3f84AWf/SQEs/8j+uv81/g//IAHy/iABPgHjAVz/1AAgAd8Ac/+o/7AAPgHoAR0AQf5B/gkBnAEp/pz/RP9hASn+A//9AGf/ov+BAE8BSQE1AGr+RgC8/m0BLAH7/5P+OP/jATj/R/5AACYBxQHIAIv/WwHCAF7+kAFEASMAFwCwAFj+zv6N/rr/qP+wALYAjQBnAfEA/QAp/lgAqAEmAWQAwv6H/s7+bQGTALwAfgHUALT/IAEgAdEBswGl/ub+3f9e/mH/yABS/tr+yP5bAaQANf4pAN0Bt/6uAR0AFf/I/hoBCQEJAXMB+/8aAVz/nAFqAGH/t/6/AS/+WABvAP0ATf6/AX4BewBS/iwBcP7OAKIBD//RAaj/XP+EAWcBWwHp/xv/igH1/yYBq/7lAPEATwGl/k8B2QCT/tT+i/9z/7MBJgGTAJP+c/+c/zUAvABkALwARgCQAeMBy/9B/nMBogFqAH4BA/9//4oBIf8sAcj+HQBE/zL/5v6zAYL+wP/xAHsAh/6l/hoBnAGcAd3/ZADs/iz/R/5H/lz/R/5bAZYBPgEh/0r/J/8RAFgAsADs/nP/nwAyAU3+pABc/ykAAAD3/qQArgGc/98APv/xAFj+kwBz/xX/nP/7/+b+OAFc/78B8QAvAOMBbwDlAOsAk/6zAQMBZADa/oQBOgCZAG3/i/9zAcb/CwBz/9T+q/7ZAIX/zgDa/hoBbwDfALf+Tf5k/hX/ov84/+z+G/9t/84AA/+r/nD+cP4d/hv/mf4pAKIBOgC8/lUBkwCfAOb+eQEb/yn+ZABEAcL+JgGfAIf+9/6WAegBIf/j/5/+pAAy/0AAR/5hAcsBTf5EAbYAbf+2AJMAOP+c/84Apf44/8b/zgBSAJH/igGR/ykAHQBYAAUAav5k/lb/bQEOATIBAwFEAZz/ewB5AXMBewDj/7f++/9t/4cAEQB+ASkAzgBEAYcA7/9SABX/A/9Y/lz/qgBB/hX/Qf4P/+D+h/4DAZkA9f9nASf/CQG3/sUB1wGu//f+Qf6fAE8BMgH3/o0AfP7X/9f/kf+uAfX/kf8d/lIAigHO/mcBcP7A/8v/rv9N/sb/IAEOAVb/D/+N/rH+mQDxAET/4/+o/6L/L/6x/lsBpf65AY3+VQGwABEAvwGqADL/RAFE/z7/ZwFkAAAATADI/hX/UP+T/lb/Sv8y/xcAywGzATIBFwAUAc7+5v5K/5P+pf79/tQAcP6i/5ABVv8+/1z/dQBMADX+IAHIAPX/dQDRAZ/+KQAy/7wATf6fABoBvwFe/kkBov/R/5kA8v6R/2cBZ/9q/vcAnAHjASP+k/4p/gMBKf7xAAkBNQBYACz/xv+2AAkBTwG0/zoAZwGZ/jUA/f5n/7MB4wEP/64Brv+8AM7+RP8dAL8B9wA4/5wBy/9t/90BcP6TAAsALP+x/iYBHQBzAdH/OgAh/90BnAGN/in+Yf+L/9f/bwCu//L+eQGZAGoA0QFK/3z+LAGWAYv/ZAAP/4X/WP5zAfv/6wCWAXn/3wBK/7H+R/6uAaX+D/+kANH/igGEASf/n/5W/8D/FAEp/tf/1ABc/yf/UP/3AJb/LAH9/kH+fgEgAXD+kf87/iP+ov+3/p/+1ADrAAMByP6kAEf+bQGTAM7+AwHLAd8Alv9w/oQBvP71/2f/9wD9/nb+IwCC/rAAZ//fANf/IwAP/wAAIwDm/rT/1ACwAIL+J/8FAIv/R/7s/nz+hAEaAa7/8QAvALYAPv8D/98ALP8OAa7//f7s/hoB3wCC/ugBGgGH/s7+If/O/l7+4P62AHkBc/9EAZMA+/+L/zj/wP9vAGr+Ff+L/6QAIf8b/1z/kAEP/0QBlv/G/58AL/62ADgB+/+oAQkBIf8sAfcAIAHp/0kBt/46ACwB4P6cAQP/Yf8LAF4Ah/6BAMIAdv44AVUB6wAgAd0Bpf51AFIAI/5z/9kAXgARAL8B0QG/AZYBOP8jALAA/QBYAKQAOP+iAdkA5v52/qX+If8+AeD+RAEs/ywBuv/CAFb/7P5nAQsA8v5kAIoB3wCwAHUAewDs/rMBD//s/nD+FAGW/zoAkf84AaX+D/+r/hQBywEaAXb+D/+kAB0AcP41/lIAwgCKAXz+1ABYANcBigEyASwB7/+R/2r+Nf5n/8sBBQCBAHsAwP/XAd3/pf7G/8v/5v6oAWr+/QBK/1IAOAFW/x0A1wHL/5z/LP8+/7H+dQDOAJP+YQFt/yABsf4s/5MAjf4OAez+Cf+l/kYAKQBSAFL+i//R/zgB3f81AHMBdQA6APcAagD9AGoAQf5k/qv+FAED/9EBqgDIAFL+kf/RASf/t/6NALH+ZAAn/yMA6wCC/k3+hf9bAZn+7P6/AaX+yABQ/+UAqgCl/rkBf//7/5MACwCNAK4Bhf/1/2oA2v6l/s7+Xv7UALH+xv+QASz/bf8D/9T+mf6EAc4Akf9e/i8AlgEyASYBhf8P/zIBIAG3/kr/gv5E/1UB9wAmAen/ov+6/0wAzgBH/rwAA/9kAL8BVQEjALH+LAFH/l7+dv60/7kBgQAXABoB0f8n/+b+bf91AKgBt/6kAHz+rv8dANf/dQDg/rAA0f9B/sj+fP6F//X/uv/lAIX/mf7d/9H/OP/LATgBNf4yAQAAyABbAdf/ZP5H/tr+JgFeAOn/WADA/14AsACKARcATwHL/8j+pf5E/6v+lgEdAP0AmQBhAYQBgQBVAQP/MgHfAIL+swGzAa4BmQBn/7AAFf86AJH/mf5//6oA+/+R/4QBTwE4/4f+yP6R/0f+tgCHADL/TACZAPcANf5bAaX+YQFGAI0A3f+l/mH/JgHO/rkBZwHI/lL+WP57ABX/av6F/yf/ZwEP/zoAZP62AMgAXP9AAHn/nwA+/7r/i/9S/jX+Pv/O/mcB9/6/AWT+ewDv/7z+8QDL/6gBOAEgAXUAOAG8AIX/DgFkACMA1AB5AUr/OP8AAPcAef81/in+JgHUABEAAwHy/pH//QBbAT4B6f/3AHn/5v7R/3//+/+5AeD+q/4+/3z+Uv6c/w//Hf6cAUQBAwHL/8j+WAADAUYAPgE6AHUA/QDX/yf/2v4d/gUATABJAcsBk/7g/uP/O/5JAesAmf4+AWH/bwCkABv/0f+3/gUAywGN/tkAqP8AAJkAWwEv/tEBkAGF/2H/VQE1/o3+AABw/qoAdv6BALYA7/+2AH//DgHp/+n/ewBh/y/+/QALAA//wgBbAeP/sABnAXMB5v4XAG0BCf8sAR0Aef/A/8L+NQCuAXsAhwD3AA//If81ANcBwv5SAE3+bf+TAA4Bn/6cAWQAD/8D/8L+FwDI/u//LP+H/sD/xv97AOUAsf7a/oL+hAED/5ABL/6TACwB8v6TAOsAigGN/nMBMv9+AQ//Vv9vANcBGgHLAYf+wP+x/lD/4wEOASf/zv4y/zoAxv/U/p8Awv6ZANr+UgAJAZYB7P68/rYAG/+5AdkAhf/s/vX/qgDRAa4BR/7R/2H/BQCEAUAA9f+NAOUAO/7A/1D/uQELAAUARAHLAXn/kwAP/0r/Uv4vAP3+Uv6qAE3+kAGx/lsBywFK/yf/FAG2AH4BFwAdAFL+sf7y/jIBk/6qAAP/OAGr/s7+vwGHAFL+9wDlAHsAi//LAY3+6wBt/wMBCQGi/y8A8v4pAPcAi/+ZAG0Bzv5c/58ATf7v/2QAuQFSALH+RAG8/hQBEQBvAGr+NQAsAeP//QAXAKL/If+wAAAAnwB2/jgBkwCL/3P/vP44Afv/4/9W/3b+tgDL/3b+/f7I/pn+Xv7LAcv/gv4yASP+jf6W/3D+n/41/ov/fP7C/qX+PgHdAYX/WP6TAAMB4/9H/tEB+/+kADX+3wAFALH+2QC0/4oBKf4y/1b/dQARAM4AR/7lAPL+cwFVAdEBbf/p/ywBlv/A/2QAkf95AY3+mf68AFUBLwCWAbf+t/7jAf0AnAHR/3n/Sv/s/pn+5QDA/6oA6wAdAJ/+ov/9ADL/1/+zAdH/+//m/usAnAH9/joA6wBW/7kB9wAp/i8Ak/6o/8gALP+c/5P+zgAj/h0AyABnAdf/OP9EAXn/1/+uASn+ogF5/9r+y//XATL/IwCEAXsAgv46AAkBmf6NAFIAWwFvAMIA4//rAHkBogGKAYEAAACW/5n+igFYACkAHf7g/j7/Tf6C/kr/7//A/5wBVv+r/ocA9f9q/pwBrgGx/i8Ahf8sAaIBhwBzAYEAyP6zASABxv/C/uD+RgBN/iYBCf/G/yH/CQG3/o0AOAH7/14A0f+ZAJH/9wDd/xEARP/LAfv/y/8d/kwAlgEaAesAO/5E/40AswGo/3P/BQDA/93/BQDR/4EAtgCoAXMBNQDI/sUBq/7O/o0AIf9EAdT+OAFz//f+eQEDARX/mf4y/1sBeQHG/wsAvP46ALMBmQBz/zoAfgHO/p/+Hf63/pMA2v5AAKL/4/9vABEA3QHOAIoBzv5YAEQBTwFc/9H/wgC8/jIB0f9Q/8UBrv+uAcUBTADR/4EARAE1/vX/n/7d/z7/J/9PAYL+Sv+/AToAxv+3/ooBWABEAbwA6f+c/8UBq/4pACMAFf/g/ocAKQD1/ywBFAFh/zIB2v58/lD/nAGKAVgAVv8AAET/eQFAAHsApADA/+D+R/4JAUT/TwG6/z4BKf6uAQkByP6fAJz/2v5w/uz+wgBGAHD+yAAy/9r+cP5//6gBTACf/ub+jQAs/98AIwAJ/2QAcwGu/wAAuv91ACz/Nf6qAF4C9f97AGQAXP95AWEB2v4n/43+7//j/zj/HQCEAXUAFf81AEf+dv7L//3+UgAS/qgBLwAAALH+D/+8/t3/y/1AAFj++//0/b8BqP+R/yz/HQI4/3n/n/7xAAsARAGi/4QBlgFW/wUAnwCR/zv+gQDZAGH/G/+EAQACD/9t/98AFf8h/8gAwP9eAkT/HQARANkAlv9n/Wf/DgF5/8gAQQIvAvcA9f8LAIQBKf7L/3P/n/6ZALAALAEdAMgAMgGZ/tQA6f+BAPX/h/4s/2cB4wG3/hEAy/8Y/lUB+v15/2r+RgBY/mr+ZwEj/v3+yABq/iMArv9MALH+SQE1/n//AwEDAUH+ZADxAFUBYf+N/kf+2QBnAcIATf52/kQB3f+oATIBpf6HAPL+TwFkAEH+ef8vALwAUv7OAEH+4P4aAW8AOAERAE3+t/7RAYQBhf+kAHz+qgCr/tQAzv4pAOn/6AH7/9T+5QDlAAUAOAHfAKgBCf/X/0QB7gGW/2f/mf4+/xEAwP8n/xEAXP+3/sD/3wAb/23/HQDfABQBG/9Q/yf/sf4j/u//A//I/q7/qAGNAOz+igFJAXMBlgFVAWQALAEn/08BcP7R/2T+i/9q/g//2QBh/xcAOAFB/tH/Mv+R/40Aef8UAe//Mv+kAKL/Tf5K/z7/Xv5qANf/pABVAUwAUP/g/kwAZP44/8v/nwAj/vf+WP6wADIBgQD3AMgAjf4V/43+pABSANr+gQCkAPEAFAGEAXn/bf8J/2cBkwAAAD4BmQAjADj/Vv/m/gAAxQGT/gP/GgG5ASP+Ff9t/6IBBQCZ/lL+yACfAG3/sf6R/5b/t/7ZAI0AG/+KAXb+rgHdATv+Vv8+AZ8A9/7A//0AfgHd/yMAZAAb/3//wv57AFgAIwCl/hcAqP86AIoBf/9q/sD/Tf6x/rH+agAvAPEA2QAXAHUAhAE+AZAB8v7U/moAIwCfAGH/dv4sAZz/0f+ZANr+wgDp/7T/rgFVAQ//kf9h/23/SQHO/pP+jQDI/oQBWP73ADoAXgB7AKL/rgGkACH/cwFVAQkBWAAvAPL+PgEvAGT+ewCHAEQBLwCc/5P+4/+HACABFf9hAQP/fgEP/2T+HQA1AFUBrv/s/ocAMgEvAKIBt/5t/43+lv+C/iP+OgBN/k8Bef9AANf/2v4dADoAkAFn/4QBjQAFAKX+wP9eAET/LP9eAPL+vACWAT7/uv+BAMD/i/9Y/qIBtgA7/jIB0QG2AHMB8v7CAK4B4P5h/87+3QFn/0YAWwHj/8UBA/9nAX4B6AEaAY0APv+BAJABzgDoAav+1/8LAKv+kwDp/98Af//OANkA9/6cAbz+nwARAPX/kf+N/iP+Kf4s/7z+ZADs/n//8QCHADj/GgGx/h3+3f8vAJ8ApADXAdH/8v6BABoBtP8sAdkAlv84AfX/ogHOAO//Hf5PARv/tgDC/ov/DgGN/tH/ywFh/5P+qP9K/3UAmf6F/wn/Cf/RAZb/ZACfAEkBav6kAPX/1wEyAR0ATwEJAX//nwAD/6L/UgBeAFUBVQHg/gkBYQF//5wB0f+c/zv+RgBn/3P/bwBbAS/+LP8mAYoBG/9//yYB3wCi/8j+I/5qAG0BXP8LAFb/pf55/yf/Nf5zAf3+nwCf/kT/L/6T/nUARP8D/40Adv4OAbYAlv86APv/gv5zAaL/jQAn/ykA+/8J/8v/0QFnAcv/rgEs/2EBogHrAAsA0f+2AFUBOAHs/iABLP8n/43+XP+NAP0AcP68/g4B4P58/pb/YQHA/43+GgGcAc4Ac//L/9cBRAGu/1D/mQBEAbr/BQAFACf/Pv/CABv/KQAvAG8AdQAh/5H/AwF5/17+fP7fAFsBXP9PARQBTADp/4v/WAALAIL+8v68/uD+igGNAIEA8QDO/vf+sf7j/67/TAB2/usAbf+8/lIA/QAV/z4BYQHX/0YA7/8UAYcAigHU/kQBPv+L/8gA0f9GAOn/VQEv/mQArgGNAGoAhwD9ANcBzgBtAXUAxQG8AK4BlgEJAaIBvwFw/kH+TAAUAUAAewDCABQBXv5N/iwBYQFSAP0ALwAJ/1gAIwDrAK4BXP+T/ugBagBEAdr+fgHZAEYA6f+T/qgB9f+iARX//f5+AUf+n/63/t8AOP/UALz+yAAP/7z+dv4JAez+EQDdAdQAhAGuAc7+SQE7/hQBhAGH/kYAdQCZ/ssBbQGx/h0A8v6o/7AAG/9w/lb/lv8LANkA/f5EAd8AGgE+/7f+hAH1/1UBXv5AANkAEQDUACH/cwEOAZ8AFwDv/7kBbQEDAf0AOP9z/6oA0QE4ATgBhAF5AdQAHQDXAV4ADgGl/s7+R/5H/q7/xv9vAAUAIAELAEYAhAHj/w//3f8RADj/y/+BADIB3wC2AKj/Sv/3ABv/TwEOAfL+YQEDAagBA/9EAbYAsf4XAML+MgG2AJABOP8h/w4BJ/+qAIf+J/8jAB0AMgGZAEQBJ//v/7f+yADv/28AQACcAUwALwCc/9f/RP9vAJz/9f9EARoBWADZAAP/xv+R/23/hf/m/hX/L/7L//L+h/4J/17+6f8dALMBqP+NAG3/mQA1ABQBgv5q/vX/igFeAFUB8v6Z/h0AhwC5AdcB6wC5AYL+wv5JAaL/Uv51AEH+ZP4AACABxv8pAFsB5QCu/9H/nP/jAWf/pADOADoA1P73ADIBLwDIAFUBkAHC/r8BqP9hAZP+zgB1AA==\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_wav(wav_paths[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
